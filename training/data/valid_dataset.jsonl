{"test_id": "quinn-rs-quinn/quinn-rs-quinn-83e4f46/quinn-proto/src/tests/mod.rs::finish_stream_simple", "code": "pub fn send_streams(&self) -> usize {\n        self.state.send_streams\n    }", "test": "fn finish_stream_simple() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    let (client_ch, server_ch) = pair.connect();\n\n    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();\n\n    const MSG: &[u8] = b\"hello\";\n    pair.client_send(client_ch, s).write(MSG).unwrap();\n    assert_eq!(pair.client_streams(client_ch).send_streams(), 1);\n    pair.client_send(client_ch, s).finish().unwrap();\n    pair.drive();\n\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Stream(StreamEvent::Finished { id })) if id == s\n    );\n    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);\n    assert_eq!(pair.client_streams(client_ch).send_streams(), 0);\n    assert_eq!(pair.server_conn_mut(client_ch).streams().send_streams(), 0);\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))\n    );\n    // Receive-only streams do not get `StreamFinished` events\n    assert_eq!(pair.server_conn_mut(client_ch).streams().send_streams(), 0);\n    assert_matches!(pair.server_streams(server_ch).accept(Dir::Uni), Some(stream) if stream == s);\n    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);\n\n    let mut recv = pair.server_recv(server_ch, s);\n    let mut chunks = recv.read(false).unwrap();\n    assert_matches!(\n        chunks.next(usize::MAX),\n        Ok(Some(chunk)) if chunk.offset == 0 && chunk.bytes == MSG\n    );\n    assert_matches!(chunks.next(usize::MAX), Ok(None));\n    let _ = chunks.finalize();\n}"}
{"test_id": "Alexhuszagh-minimal-lexical/Alexhuszagh-minimal-lexical-e997c46/tests/lemire_tests.rs::compute_error_scaled64_test", "code": "fn compute_error_scaled64(q: i32, w: u64, lz: i32) -> (i32, u64) {\n    let fp = lemire::compute_error_scaled::<f64>(q, w, lz);\n    (fp.exp, fp.mant)\n}", "test": "fn compute_error_scaled64_test() {\n    // These are the same examples above, just using pre-computed scaled values.\n\n    // These test near-halfway cases for double-precision floats.\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427387904, 10),\n        (1065 + f64::INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388416, 10),\n        (1065 + f64::INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388928, 10),\n        (1065 + f64::INVALID_FP, 9223372036854777856)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427389440, 10),\n        (1065 + f64::INVALID_FP, 9223372036854778880)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427389952, 10),\n        (1065 + f64::INVALID_FP, 9223372036854779904)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427387904, 9),\n        (1066 + f64::INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388416, 9),\n        (1066 + f64::INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388928, 9),\n        (1066 + f64::INVALID_FP, 9223372036854777856)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427389440, 9),\n        (1066 + f64::INVALID_FP, 9223372036854778880)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427389952, 9),\n        (1066 + f64::INVALID_FP, 9223372036854779904)\n    );\n\n    // Test a much closer set of examples.\n    assert_eq!(\n        compute_error_scaled64(0, 9223372036854774784, 11),\n        (1064 + f64::INVALID_FP, 18446744073709549568)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388415, 0),\n        (1075 + f64::INVALID_FP, 9223372036854776830)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388416, 0),\n        (1075 + f64::INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388416, 0),\n        (1075 + f64::INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error_scaled64(-42, 6510716281765748947, 10),\n        (925 + f64::INVALID_FP, 13021432563531497894)\n    );\n    assert_eq!(\n        compute_error_scaled64(-43, 6510716281765749303, 7),\n        (925 + f64::INVALID_FP, 13021432563531498606)\n    );\n    assert_eq!(\n        compute_error_scaled64(-42, 6510716281765749660, 10),\n        (925 + f64::INVALID_FP, 13021432563531499320)\n    );\n\n    // These are examples of the above tests, with\n    // digits from the exponent shifted to the mantissa.\n    assert_eq!(\n        compute_error_scaled64(-3, 9223372036854775808, 1),\n        (1065 + f64::INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error_scaled64(-3, 9223372036854776832, 1),\n        (1065 + f64::INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error_scaled64(-3, 9223372036854777856, 1),\n        (1065 + f64::INVALID_FP, 9223372036854777856)\n    );\n    assert_eq!(\n        compute_error_scaled64(-3, 9223372036854778880, 1),\n        (1065 + f64::INVALID_FP, 9223372036854778880)\n    );\n    assert_eq!(\n        compute_error_scaled64(-3, 9223372036854779904, 1),\n        (1065 + f64::INVALID_FP, 9223372036854779904)\n    );\n\n    // Test from errors in atof.\n    assert_eq!(\n        compute_error_scaled64(-18, 9223373686122217470, 4),\n        (1012 + f64::INVALID_FP, 9223373686122217470)\n    );\n\n    // Check edge-cases from previous errors.\n    assert_eq!(\n        compute_error_scaled64(-342, 9223372036854775804, 2),\n        (-64 + f64::INVALID_FP, 18446744073709551608)\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_runcon.rs::invalid", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn invalid() {\n    new_ucmd!().arg(\"invalid\").fails().code_is(1);\n\n    let args = &[\n        \"unconfined_u:unconfined_r:unconfined_t:s0\",\n        \"inexistent-file\",\n    ];\n    new_ucmd!().args(args).fails().code_is(127);\n\n    let args = &[\"invalid\", \"/bin/true\"];\n    new_ucmd!().args(args).fails().code_is(1);\n\n    let args = &[\"--compute\", \"inexistent-file\"];\n    new_ucmd!().args(args).fails().code_is(1);\n\n    let args = &[\"--compute\", \"--compute\"];\n    new_ucmd!().args(args).fails().code_is(1);\n\n    // clap has an issue that makes this test fail: https://github.com/clap-rs/clap/issues/1543\n    // TODO: Enable this code once the issue is fixed in the clap version we're using.\n    //new_ucmd!().arg(\"--compute=example\").fails().code_is(1);\n\n    for flag in [\n        \"-t\", \"--type\", \"-u\", \"--user\", \"-r\", \"--role\", \"-l\", \"--range\",\n    ] {\n        new_ucmd!().arg(flag).fails().code_is(1);\n\n        let args = &[flag, \"example\", flag, \"example\"];\n        new_ucmd!().args(args).fails().code_is(1);\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_split.rs::test_split_additional_suffix", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_additional_suffix() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"split_additional_suffix\";\n    RandomFile::new(&at, name).add_lines(2000);\n    ucmd.args(&[\"--additional-suffix\", \".txt\", name]).succeeds();\n\n    let glob = Glob::new(&at, \".\", r\"x[[:alpha:]][[:alpha:]].txt$\");\n    assert_eq!(glob.count(), 2);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_witness.rs::test_push_non_witness_availability", "code": "fn test_non_witness_availability(fp: &str) {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.pd_heartbeat_tick_interval = ReadableDuration::millis(100);\n    cluster.cfg.raft_store.check_peers_availability_interval = ReadableDuration::millis(20);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());\n\n    // non-witness -> witness\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![true],\n    );\n\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    std::thread::sleep(Duration::from_millis(100));\n    must_get_none(&cluster.get_engine(3), b\"k1\");\n\n    fail::cfg(fp, \"return\").unwrap();\n\n    // witness -> non-witness\n    cluster\n        .pd_client\n        .switch_witnesses(region.get_id(), vec![peer_on_store3.get_id()], vec![false]);\n    std::thread::sleep(Duration::from_millis(500));\n    // snapshot applied\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n    assert_eq!(cluster.pd_client.get_pending_peers().len(), 0);\n    fail::remove(fp);\n}", "test": "fn test_push_non_witness_availability() {\n    test_non_witness_availability(\"ignore schedule check non-witness availability tick\");\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/catalog_tests.rs::test_catalog_lookup_soa", "code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "async fn test_catalog_lookup_soa() {\n    let example = create_example();\n    let test = create_test();\n    let origin = example.origin().clone();\n    let test_origin = test.origin().clone();\n\n    let mut catalog: Catalog = Catalog::new();\n    catalog.upsert(origin.clone(), Box::new(Arc::new(example)));\n    catalog.upsert(test_origin, Box::new(Arc::new(test)));\n\n    let mut question: Message = Message::new();\n\n    let mut query: Query = Query::new();\n    query.set_name(origin.into());\n    query.set_query_type(RecordType::SOA);\n\n    question.add_query(query);\n\n    // temp request\n    let question_bytes = question.to_bytes().unwrap();\n    let question_req = MessageRequest::from_bytes(&question_bytes).unwrap();\n    let question_req = Request::new(question_req, ([127, 0, 0, 1], 5553).into(), Protocol::Udp);\n\n    let response_handler = TestResponseHandler::new();\n    catalog\n        .lookup(&question_req, None, response_handler.clone())\n        .await;\n    let result = response_handler.into_message().await;\n\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.message_type(), MessageType::Response);\n    assert!(result.header().authoritative());\n\n    let answers: &[Record] = result.answers();\n\n    assert!(!answers.is_empty());\n    assert_eq!(answers.first().unwrap().record_type(), RecordType::SOA);\n    assert_eq!(\n        answers.first().unwrap().data().unwrap(),\n        &RData::SOA(SOA::new(\n            Name::parse(\"sns.dns.icann.org.\", None).unwrap(),\n            Name::parse(\"noc.dns.icann.org.\", None).unwrap(),\n            2015082403,\n            7200,\n            3600,\n            1209600,\n            3600,\n        ))\n    );\n\n    // assert SOA requests get NS records\n    let mut ns: Vec<Record> = result.name_servers().to_vec();\n    ns.sort();\n\n    assert_eq!(ns.len(), 2);\n    assert_eq!(ns.first().unwrap().record_type(), RecordType::NS);\n    assert_eq!(\n        ns.first().unwrap().data().unwrap(),\n        &RData::NS(NS(Name::parse(\"a.iana-servers.net.\", None).unwrap()))\n    );\n    assert_eq!(ns.last().unwrap().record_type(), RecordType::NS);\n    assert_eq!(\n        ns.last().unwrap().data().unwrap(),\n        &RData::NS(NS(Name::parse(\"b.iana-servers.net.\", None).unwrap()))\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cat.rs::test_numbered_lines_no_trailing_newline", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_numbered_lines_no_trailing_newline() {\n    // spell-checker:disable\n    new_ucmd!()\n        .args(&[\"nonewline.txt\", \"alpha.txt\", \"-n\"])\n        .succeeds()\n        .stdout_only(\n            \"     1\\ttext without a trailing newlineabcde\\n     2\\tfghij\\n     \\\n             3\\tklmno\\n     4\\tpqrst\\n     5\\tuvwxyz\\n\",\n        );\n    // spell-checker:enable\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/import/test_sst_service.rs::test_duplicate_and_close", "code": "pub fn has_error(&self) -> bool {\n        self.error.is_some()\n    }", "test": "fn test_duplicate_and_close() {\n    let (_cluster, ctx, _, import) = new_cluster_and_tikv_import_client();\n    let mut req = SwitchModeRequest::default();\n    req.set_mode(SwitchMode::Import);\n    import.switch_mode(&req).unwrap();\n\n    let data_count: u64 = 4096;\n    for commit_ts in 0..4 {\n        let mut meta = new_sst_meta(0, 0);\n        meta.set_region_id(ctx.get_region_id());\n        meta.set_region_epoch(ctx.get_region_epoch().clone());\n\n        let mut keys = vec![];\n        let mut values = vec![];\n        for i in 1000..data_count {\n            let key = i.to_string();\n            keys.push(key.as_bytes().to_vec());\n            values.push(key.as_bytes().to_vec());\n        }\n        let resp = send_write_sst(&import, &meta, keys, values, commit_ts).unwrap();\n        for m in resp.metas.into_iter() {\n            let mut ingest = IngestRequest::default();\n            ingest.set_context(ctx.clone());\n            ingest.set_sst(m.clone());\n            let resp = import.ingest(&ingest).unwrap();\n            assert!(!resp.has_error());\n        }\n    }\n\n    let mut duplicate = DuplicateDetectRequest::default();\n    duplicate.set_context(ctx);\n    duplicate.set_start_key((0_u64).to_string().as_bytes().to_vec());\n    let mut stream = import.duplicate_detect(&duplicate).unwrap();\n    let ret = block_on(async move {\n        let mut ret: Vec<KvPair> = vec![];\n        while let Some(resp) = stream.next().await {\n            match resp {\n                Ok(mut resp) => {\n                    if resp.has_key_error() || resp.has_region_error() {\n                        break;\n                    }\n                    let pairs = resp.take_pairs();\n                    ret.append(&mut pairs.into());\n                }\n                Err(e) => {\n                    println!(\"receive error: {:?}\", e);\n                    break;\n                }\n            }\n        }\n        ret\n    });\n    assert_eq!(ret.len(), (data_count - 1000) as usize * 4);\n    req.set_mode(SwitchMode::Normal);\n    import.switch_mode(&req).unwrap();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_df.rs::ut_field_no_more_than_once() {\n    ", "code": "pub fn usage_error<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.stderr_only(format!(\n            \"{0}: {2}\\nTry '{1} {0} --help' for more information.\\n\",\n            self.util_name.as_ref().unwrap(), // This shouldn't be called using a normal command\n            self.bin_path.display(),\n            msg.as_ref()\n        ))\n    }", "test": "utput_field_no_more_than_once() {\n    new_ucmd!()\n        .arg(\"--output=target,source,target\")\n        .fails()\n        .usage_error(\"option --output: field 'target' used more than once\");\n}\n\n#[test]"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_sort.rs::test_ignore_case", "code": "fn test_helper(file_name: &str, term: &str) {\n    new_ucmd!()\n        .env(\"TERM\", term)\n        .arg(\"-c\")\n        .arg(format!(\"{file_name}.txt\"))\n        .run()\n        .stdout_is_fixture(format!(\"{file_name}.csh.expected\"));\n\n    new_ucmd!()\n        .env(\"TERM\", term)\n        .arg(\"-b\")\n        .arg(format!(\"{file_name}.txt\"))\n        .run()\n        .stdout_is_fixture(format!(\"{file_name}.sh.expected\"));\n}", "test": "fn test_ignore_case() {\n    test_helper(\"ignore_case\", &[\"-f\"]);\n}"}
{"test_id": "tafia-calamine/tafia-calamine-5a5804d/tests/test.rs::issue_6", "code": "fn worksheet_range(&mut self, name: &str) -> Option<Result<Range<DataType>, XlsError>> {\n        self.sheets.get(name).map(|r| Ok(r.0.clone()))\n    }", "test": "fn issue_6() {\n    setup();\n\n    // test if sheet is resolved with only one row\n    let path = format!(\"{}/tests/issues.xlsx\", env!(\"CARGO_MANIFEST_DIR\"));\n    let mut excel: Xlsx<_> = open_workbook(&path).unwrap();\n\n    let range = excel.worksheet_range(\"issue6\").unwrap().unwrap();\n    range_eq!(\n        range,\n        [\n            [Float(1.)],\n            [Float(2.)],\n            [String(\"ab\".to_string())],\n            [Bool(false)]\n        ]\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_split.rs::test_lines_kth", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_lines_kth() {\n    new_ucmd!()\n        .args(&[\"-n\", \"l/3/10\", \"onehundredlines.txt\"])\n        .succeeds()\n        .stdout_only(\"20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n\");\n}"}
{"test_id": "serde-rs-json/serde-rs-json-66f862f/tests/test.rs::test_integer128_key", "code": "pub fn to_string<T>(value: &T) -> Result<String>\nwhere\n    T: ?Sized + Serialize,\n{\n    let vec = tri!(to_vec(value));\n    let string = unsafe {\n        // We do not emit invalid UTF-8.\n        String::from_utf8_unchecked(vec)\n    };\n    Ok(string)\n}", "test": "fn test_integer128_key() {\n    let map = treemap! {\n        100000000000000000000000000000000000000u128 => (),\n    };\n    let j = r#\"{\"100000000000000000000000000000000000000\":null}\"#;\n    assert_eq!(to_string(&map).unwrap(), j);\n    assert_eq!(from_str::<BTreeMap<u128, ()>>(j).unwrap(), map);\n}"}
{"test_id": "dtolnay-serde-yaml/dtolnay-serde-yaml-f8adb28/tests/test_serde.rs::test_vec", "code": "fn test_serde<T>(thing: &T, yaml: &str)\nwhere\n    T: serde::Serialize + serde::de::DeserializeOwned + PartialEq + Debug,\n{\n    let serialized = serde_yaml::to_string(&thing).unwrap();\n    assert_eq!(yaml, serialized);\n\n    let value = serde_yaml::to_value(thing).unwrap();\n    let serialized = serde_yaml::to_string(&value).unwrap();\n    assert_eq!(yaml, serialized);\n\n    let deserialized: T = serde_yaml::from_str(yaml).unwrap();\n    assert_eq!(*thing, deserialized);\n\n    let value: Value = serde_yaml::from_str(yaml).unwrap();\n    let deserialized = T::deserialize(&value).unwrap();\n    assert_eq!(*thing, deserialized);\n\n    let deserialized: T = serde_yaml::from_value(value).unwrap();\n    assert_eq!(*thing, deserialized);\n\n    serde_yaml::from_str::<serde::de::IgnoredAny>(yaml).unwrap();\n}", "test": "fn test_vec() {\n    let thing = vec![1, 2, 3];\n    let yaml = indoc! {\"\n        - 1\n        - 2\n        - 3\n    \"};\n    test_serde(&thing, yaml);\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_bigquery.rs::parse_cast_type", "code": "pub fn verified_only_select(&self, query: &str) -> Select {\n        match *self.verified_query(query).body {\n            SetExpr::Select(s) => *s,\n            _ => panic!(\"Expected SetExpr::Select\"),\n        }\n    }", "test": "fn parse_cast_type() {\n    let sql = r\"SELECT SAFE_CAST(1 AS INT64)\";\n    bigquery_and_generic().verified_only_select(sql);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_echo.rs::test_escape_escape", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_escape_escape() {\n    new_ucmd!()\n        .args(&[\"-e\", \"\\\\e\"])\n        .succeeds()\n        .stdout_only(\"\\x1B\\n\");\n}"}
{"test_id": "ordinals-ord/ordinals-ord-8090538/tests/wallet/inscribe.rs::refuse_to_reinscribe_sats", "code": "pub(crate) fn run_and_extract_stdout(self) -> String {\n    self.run().1\n  }", "test": "fn refuse_to_reinscribe_sats() {\n  let rpc_server = test_bitcoincore_rpc::spawn();\n  create_wallet(&rpc_server);\n\n  rpc_server.mine_blocks(1);\n\n  let (_, reveal) = inscribe(&rpc_server);\n\n  rpc_server.mine_blocks_with_subsidy(1, 100);\n\n  CommandBuilder::new(format!(\n    \"wallet inscribe --satpoint {reveal}:0:0 --file hello.txt --fee-rate 1\"\n  ))\n  .write(\"hello.txt\", \"HELLOWORLD\")\n  .rpc_server(&rpc_server)\n  .expected_exit_code(1)\n  .expected_stderr(format!(\"error: sat at {reveal}:0:0 already inscribed\\n\"))\n  .run_and_extract_stdout();\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/raftstore-v2/tests/integrations/test_split.rs::test_split", "code": "pub fn get_tablet_index(&self) -> u64 {\n        self.tablet_index\n    }", "test": "fn test_split() {\n    let mut cluster = Cluster::default();\n    let store_id = cluster.node(0).id();\n    let raft_engine = cluster.node(0).running_state().unwrap().raft_engine.clone();\n    let router = &mut cluster.routers[0];\n\n    let region_2 = 2;\n    let region = router.region_detail(region_2);\n    let peer = region.get_peers()[0].clone();\n    router.wait_applied_to_current_term(region_2, Duration::from_secs(3));\n\n    // Region 2 [\"\", \"\"]\n    //   -> Region 2    [\"\", \"k22\"]\n    //      Region 1000 [\"k22\", \"\"] peer(1, 10)\n    let region_state = raft_engine\n        .get_region_state(region_2, u64::MAX)\n        .unwrap()\n        .unwrap();\n    assert_eq!(region_state.get_tablet_index(), RAFT_INIT_LOG_INDEX);\n    let (left, mut right) = split_region(\n        router,\n        region,\n        peer.clone(),\n        1000,\n        new_peer(store_id, 10),\n        Some(b\"k11\"),\n        Some(b\"k33\"),\n        b\"k22\",\n        b\"k22\",\n        false,\n    );\n    let region_state = raft_engine\n        .get_region_state(region_2, u64::MAX)\n        .unwrap()\n        .unwrap();\n    assert_ne!(region_state.get_tablet_index(), RAFT_INIT_LOG_INDEX);\n    assert_eq!(\n        region_state.get_region().get_region_epoch().get_version(),\n        INIT_EPOCH_VER + 1\n    );\n    let region_state0 = raft_engine\n        .get_region_state(region_2, region_state.get_tablet_index())\n        .unwrap()\n        .unwrap();\n    assert_eq!(region_state, region_state0);\n    let flushed_index = raft_engine\n        .get_flushed_index(region_2, CF_RAFT)\n        .unwrap()\n        .unwrap();\n    assert!(\n        flushed_index >= region_state.get_tablet_index(),\n        \"{flushed_index} >= {}\",\n        region_state.get_tablet_index()\n    );\n\n    // Region 2 [\"\", \"k22\"]\n    //   -> Region 2    [\"\", \"k11\"]\n    //      Region 1001 [\"k11\", \"k22\"] peer(1, 11)\n    let _ = split_region(\n        router,\n        left,\n        peer,\n        1001,\n        new_peer(store_id, 11),\n        Some(b\"k00\"),\n        Some(b\"k11\"),\n        b\"k11\",\n        b\"k11\",\n        false,\n    );\n    let region_state = raft_engine\n        .get_region_state(region_2, u64::MAX)\n        .unwrap()\n        .unwrap();\n    assert_ne!(\n        region_state.get_tablet_index(),\n        region_state0.get_tablet_index()\n    );\n    assert_eq!(\n        region_state.get_region().get_region_epoch().get_version(),\n        INIT_EPOCH_VER + 2\n    );\n    let region_state1 = raft_engine\n        .get_region_state(region_2, region_state.get_tablet_index())\n        .unwrap()\n        .unwrap();\n    assert_eq!(region_state, region_state1);\n    let flushed_index = raft_engine\n        .get_flushed_index(region_2, CF_RAFT)\n        .unwrap()\n        .unwrap();\n    assert!(\n        flushed_index >= region_state.get_tablet_index(),\n        \"{flushed_index} >= {}\",\n        region_state.get_tablet_index()\n    );\n\n    // Region 1000 [\"k22\", \"\"] peer(1, 10)\n    //   -> Region 1000 [\"k22\", \"k33\"] peer(1, 10)\n    //      Region 1002 [\"k33\", \"\"]    peer(1, 12)\n    let region_1000 = 1000;\n    let region_state = raft_engine\n        .get_region_state(region_1000, u64::MAX)\n        .unwrap()\n        .unwrap();\n    assert_eq!(region_state.get_tablet_index(), RAFT_INIT_LOG_INDEX);\n    right = split_region(\n        router,\n        right,\n        new_peer(store_id, 10),\n        1002,\n        new_peer(store_id, 12),\n        Some(b\"k22\"),\n        Some(b\"k33\"),\n        b\"k33\",\n        b\"k33\",\n        false,\n    )\n    .1;\n    let region_state = raft_engine\n        .get_region_state(region_1000, u64::MAX)\n        .unwrap()\n        .unwrap();\n    assert_ne!(region_state.get_tablet_index(), RAFT_INIT_LOG_INDEX);\n    assert_eq!(\n        region_state.get_region().get_region_epoch().get_version(),\n        INIT_EPOCH_VER + 2\n    );\n    let region_state2 = raft_engine\n        .get_region_state(region_1000, region_state.get_tablet_index())\n        .unwrap()\n        .unwrap();\n    assert_eq!(region_state, region_state2);\n    let flushed_index = raft_engine\n        .get_flushed_index(region_1000, CF_RAFT)\n        .unwrap()\n        .unwrap();\n    assert!(\n        flushed_index >= region_state.get_tablet_index(),\n        \"{flushed_index} >= {}\",\n        region_state.get_tablet_index()\n    );\n\n    // 1002 -> 1002, 1003\n    let split_key = Key::from_raw(b\"k44\").append_ts(TimeStamp::zero());\n    let actual_split_key = split_key.clone().truncate_ts().unwrap();\n    split_region(\n        router,\n        right,\n        new_peer(store_id, 12),\n        1003,\n        new_peer(store_id, 13),\n        Some(b\"k33\"),\n        Some(b\"k55\"),\n        split_key.as_encoded(),\n        actual_split_key.as_encoded(),\n        false,\n    );\n\n    // Split should survive restart.\n    drop(raft_engine);\n    cluster.restart(0);\n    let region_and_key = vec![\n        (2, b\"k00\"),\n        (1000, b\"k22\"),\n        (1001, b\"k11\"),\n        (1002, b\"k33\"),\n        (1003, b\"k55\"),\n    ];\n    for (region_id, key) in region_and_key {\n        let snapshot = cluster.routers[0].stale_snapshot(region_id);\n        assert!(\n            snapshot.get_value(key).unwrap().is_some(),\n            \"{} {:?}\",\n            region_id,\n            key\n        );\n    }\n}"}
{"test_id": "web-infra-dev-oxc/oxc-project-oxc-884a819/crates/oxc_minifier/tests/oxc/precedence.rs::r#yield", "code": "fn test(args: &[&str]) -> LintResult {\n        let mut new_args = vec![\"--quiet\"];\n        new_args.extend(args);\n        let options = lint_command().run_inner(new_args.as_slice()).unwrap().lint_options;\n        let CliRunResult::LintResult(lint_result) = LintRunner::new(options).run() else {\n            unreachable!()\n        };\n        lint_result\n    }", "test": "fn r#yield() {\n    test(\"function *foo() { yield }\", \"function*foo(){yield}\");\n\n    test(\"function *foo() { yield * a ? b : c }\", \"function*foo(){yield*a?b:c}\");\n    test(\"function *foo() { yield * yield * a }\", \"function*foo(){yield*yield*a}\");\n    test(\"function *foo() { yield * () => {} }\", \"function*foo(){yield*()=>{}}\");\n    test(\"function *foo() { yield * async () => {} }\", \"function*foo(){yield*async()=>{}}\");\n\n    test(\"function *foo() { yield a ? b : c }\", \"function*foo(){yield a?b:c}\");\n    test(\"function *foo() { yield yield a }\", \"function*foo(){yield yield a}\");\n    test(\"function *foo() { yield () => {} }\", \"function*foo(){yield ()=>{}}\");\n    test(\"function *foo() { yield async () => {} }\", \"function*foo(){yield async()=>{}}\");\n\n    test(\n        \"function *foo() { yield { a } = [ b ] = c ? b : d }\",\n        \"function*foo(){yield {a}=[b]=c?b:d}\",\n    );\n    // TODO: remove the extra space in `yield (a,b)`\n    test(\"function *foo() { yield (a, b) }\", \"function*foo(){yield (a,b)}\");\n    test(\"function *foo() { yield a, b }\", \"function*foo(){yield a,b}\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/engine_traits_tests/src/read_consistency.rs::snapshot_with_writes", "code": "fn get_value(\n        &mut self,\n        req: &Request,\n        region: &metapb::Region,\n        read_context: &Option<LocalReadContext<'_, Self::Tablet>>,\n    ) -> Result<Response> {\n        let key = req.get_get().get_key();\n        // region key range has no data prefix, so we must use origin key to check.\n        util::check_key_in_region(key, region)?;\n\n        let mut resp = Response::default();\n        let snapshot = self.get_snapshot(read_context);\n        let res = if !req.get_get().get_cf().is_empty() {\n            let cf = req.get_get().get_cf();\n            snapshot\n                .get_value_cf(cf, &keys::data_key(key))\n                .unwrap_or_else(|e| {\n                    panic!(\n                        \"[region {}] failed to get {} with cf {}: {:?}\",\n                        region.get_id(),\n                        log_wrappers::Value::key(key),\n                        cf,\n                        e\n                    )\n                })\n        } else {\n            snapshot\n                .get_value(&keys::data_key(key))\n                .unwrap_or_else(|e| {\n                    panic!(\n                        \"[region {}] failed to get {}: {:?}\",\n                        region.get_id(),\n                        log_wrappers::Value::key(key),\n                        e\n                    )\n                })\n        };\n        if let Some(res) = res {\n            resp.mut_get().set_value(res.to_vec());\n        }\n\n        Ok(resp)\n    }", "test": "fn snapshot_with_writes() {\n    let db = default_engine();\n\n    db.engine.put(b\"a\", b\"aa\").unwrap();\n\n    let snapshot = db.engine.snapshot();\n\n    assert_eq!(snapshot.get_value(b\"a\").unwrap().unwrap(), b\"aa\");\n\n    db.engine.put(b\"b\", b\"bb\").unwrap();\n\n    assert!(snapshot.get_value(b\"b\").unwrap().is_none());\n    assert_eq!(db.engine.get_value(b\"b\").unwrap().unwrap(), b\"bb\");\n\n    db.engine.delete(b\"a\").unwrap();\n\n    assert_eq!(snapshot.get_value(b\"a\").unwrap().unwrap(), b\"aa\");\n    assert!(db.engine.get_value(b\"a\").unwrap().is_none());\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_multi.rs::test_multi_node_random_restart", "code": "fn test_multi_random_restart<T: Simulator>(\n    cluster: &mut Cluster<T>,\n    node_count: usize,\n    restart_count: u32,\n) {\n    cluster.run();\n\n    let mut rng = rand::thread_rng();\n    let mut value = [0u8; 5];\n\n    for i in 1..restart_count {\n        let id = 1 + rng.gen_range(0..node_count as u64);\n        cluster.stop_node(id);\n\n        let key = i.to_string().into_bytes();\n\n        rng.fill_bytes(&mut value);\n        cluster.must_put(&key, &value);\n        assert_eq!(cluster.get(&key), Some(value.to_vec()));\n\n        cluster.run_node(id).unwrap();\n\n        // verify whether data is actually being replicated and waiting for node online.\n        must_get_equal(&cluster.get_engine(id), &key, &value);\n\n        cluster.must_delete(&key);\n        assert_eq!(cluster.get(&key), None);\n    }\n}", "test": "fn test_multi_node_random_restart() {\n    let count = 5;\n    let mut cluster = new_node_cluster(0, count);\n    test_multi_random_restart(&mut cluster, count, 10);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_with_dirs_t", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_with_dirs_t() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.arg(\"-t\")\n        .arg(TEST_COPY_TO_FOLDER)\n        .arg(TEST_HELLO_WORLD_SOURCE)\n        .succeeds();\n    assert_eq!(at.read(TEST_COPY_TO_FOLDER_FILE), \"Hello, World!\\n\");\n}"}
{"test_id": "cberner-redb/cberner-redb-267b473/tests/basic_tests.rs::abort", "code": "fn get<'a>(&self, key: impl Borrow<K::SelfType<'a>>) -> Result<MultimapValue<V>>\n    where\n        K: 'a,\n    {\n        let iter = if let Some(collection) = self.tree.get(key.borrow())? {\n            DynamicCollection::iter(collection, self.mem)?\n        } else {\n            MultimapValue::new_subtree(BtreeRangeIter::new::<RangeFull, &V::SelfType<'_>>(\n                &(..),\n                None,\n                self.mem,\n            )?)\n        };\n\n        Ok(iter)\n    }", "test": "fn abort() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(STR_TABLE).unwrap();\n        table.insert(\"hello\", \"aborted\").unwrap();\n        assert_eq!(\"aborted\", table.get(\"hello\").unwrap().unwrap().value());\n    }\n    write_txn.abort().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(STR_TABLE);\n    assert!(table.is_err());\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(STR_TABLE).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(STR_TABLE).unwrap();\n    assert_eq!(\"world\", table.get(\"hello\").unwrap().unwrap().value());\n    assert_eq!(table.len().unwrap(), 1);\n}"}
{"test_id": "mitsuhiko-minijinja/mitsuhiko-minijinja-5f2c1e8/minijinja/tests/test_loader.rs::test_source_replace_static", "code": "pub fn get_template(&self, name: &str) -> Result<Template<'_, '_>, Error> {\n        let compiled = ok!(self.templates.get(name));\n        Ok(Template::new(\n            self,\n            CompiledTemplateRef::Borrowed(compiled),\n            self.initial_auto_escape(name),\n        ))\n    }", "test": "fn test_source_replace_static() {\n    let mut env = Environment::new();\n    env.add_template_owned(\"a\", \"1\").unwrap();\n    env.add_template_owned(\"a\", \"2\").unwrap();\n    let rv = env.get_template(\"a\").unwrap().render(()).unwrap();\n    assert_eq!(rv, \"2\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_readlink.rs::test_canonicalize_trailing_slash_subdir_missing", "code": "pub fn no_stdout(&self) -> &Self {\n        assert!(\n            self.stdout.is_empty(),\n            \"Expected stdout to be empty, but it's:\\n{}\",\n            self.stdout_str()\n        );\n        self\n    }", "test": "fn test_canonicalize_trailing_slash_subdir_missing() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    at.mkdir(\"subdir\");\n    at.relative_symlink_file(\"subdir/missing\", \"link4\");\n    for query in [\"link4\", \"./link4/\"] {\n        scene\n            .ucmd()\n            .args(&[\"-f\", query])\n            .succeeds()\n            .stdout_contains(path_concat!(\"subdir\", \"missing\"));\n    }\n    for query in [\"link4/more\", \"./link4/more/\"] {\n        scene\n            .ucmd()\n            .args(&[\"-f\", query])\n            .fails()\n            .code_is(1)\n            .no_stdout();\n    }\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/client_future_tests.rs::test_timeout_query_udp", "code": "fn test_timeout_query(mut client: AsyncClient, io_loop: Runtime) {\n    let name = Name::from_str(\"www.example.com\").unwrap();\n\n    let err = io_loop\n        .block_on(client.query(name.clone(), DNSClass::IN, RecordType::A))\n        .unwrap_err();\n\n    println!(\"got error: {err:?}\");\n    if let ClientErrorKind::Timeout = err.kind() {\n    } else {\n        panic!(\"expected timeout error\");\n    }\n\n    io_loop\n        .block_on(client.query(name, DNSClass::IN, RecordType::AAAA))\n        .unwrap_err();\n\n    // test that we don't have any thing funky with registering new timeouts, etc...\n    //   it would be cool if we could maintain a different error here, but shutdown is probably ok.\n    //\n    // match err.kind() {\n    //     &ClientErrorKind::Timeout => (),\n    //     e @ _ => assert!(false, format!(\"something else: {}\", e)),\n    // }\n}", "test": "fn test_timeout_query_udp() {\n    //env_logger::try_init().ok();\n    let io_loop = Runtime::new().unwrap();\n\n    // this is a test network, it should NOT be in use\n    let addr: SocketAddr = (\"203.0.113.0\", 53)\n        .to_socket_addrs()\n        .unwrap()\n        .next()\n        .unwrap();\n\n    let stream =\n        UdpClientStream::<TokioUdpSocket>::with_timeout(addr, std::time::Duration::from_millis(1));\n    let client = AsyncClient::connect(stream);\n    let (client, bg) = io_loop.block_on(client).expect(\"client failed to connect\");\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    test_timeout_query(client, io_loop);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/engine_traits_tests/src/write_batch.rs::write_batch_clear", "code": "pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }", "test": "fn write_batch_clear() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch();\n\n    wb.put(b\"a\", b\"\").unwrap();\n    wb.put(b\"b\", b\"\").unwrap();\n    wb.clear();\n    assert!(wb.is_empty());\n    assert_eq!(wb.count(), 0);\n    wb.write().unwrap();\n    assert!(db.engine.get_value(b\"a\").unwrap().is_none());\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(1024);\n\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.clear();\n    assert!(wb.is_empty());\n    assert_eq!(wb.count(), 0);\n    wb.write().unwrap();\n    for i in 0..256_usize {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/control_flow/loops.rs::for_of_loop_declaration", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn for_of_loop_declaration() {\n    run_test_actions([\n        TestAction::run(indoc! {r#\"\n                var result = 0;\n                for (i of [1, 2, 3]) {\n                    result = i;\n                }\n            \"#}),\n        TestAction::assert_eq(\"result\", 3),\n        TestAction::assert_eq(\"i\", 3),\n    ]);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_pathchk.rs::test_posix_mode", "code": "pub fn no_stdout(&self) -> &Self {\n        assert!(\n            self.stdout.is_empty(),\n            \"Expected stdout to be empty, but it's:\\n{}\",\n            self.stdout_str()\n        );\n        self\n    }", "test": "fn test_posix_mode() {\n    // test the posix mode\n\n    // accept some reasonable default\n    new_ucmd!().args(&[\"-p\", \"dir/file\"]).succeeds().no_stdout();\n\n    // fail on long path\n    new_ucmd!()\n        .args(&[\"-p\", \"dir\".repeat(libc::PATH_MAX as usize + 1).as_str()])\n        .fails()\n        .no_stdout();\n\n    // fail on long filename\n    new_ucmd!()\n        .args(&[\n            \"-p\",\n            format!(\"dir/{}\", \"file\".repeat(libc::FILENAME_MAX as usize + 1)).as_str(),\n        ])\n        .fails()\n        .no_stdout();\n\n    // fail on non-portable chars\n    new_ucmd!().args(&[\"-p\", \"dir#/$file\"]).fails().no_stdout();\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_common.rs::parse_create_view_with_options", "code": "pub fn verified_stmt(&self, sql: &str) -> Statement {\n        self.one_statement_parses_to(sql, sql)\n    }", "test": "fn parse_create_view_with_options() {\n    let sql = \"CREATE VIEW v WITH (foo = 'bar', a = 123) AS SELECT 1\";\n    match verified_stmt(sql) {\n        Statement::CreateView { with_options, .. } => {\n            assert_eq!(\n                vec![\n                    SqlOption {\n                        name: \"foo\".into(),\n                        value: Value::SingleQuotedString(\"bar\".into()),\n                    },\n                    SqlOption {\n                        name: \"a\".into(),\n                        value: number(\"123\"),\n                    },\n                ],\n                with_options\n            );\n        }\n        _ => unreachable!(),\n    }\n}"}
{"test_id": "dtolnay-serde-yaml/dtolnay-serde-yaml-f8adb28/tests/test_serde.rs::test_float32", "code": "pub fn is_nan(&self) -> bool {\n        match self.n {\n            N::PosInt(_) | N::NegInt(_) => false,\n            N::Float(f) => f.is_nan(),\n        }\n    }", "test": "fn test_float32() {\n    let thing: f32 = 25.5;\n    let yaml = indoc! {\"\n        25.5\n    \"};\n    test_serde(&thing, yaml);\n\n    let thing = f32::INFINITY;\n    let yaml = indoc! {\"\n        .inf\n    \"};\n    test_serde(&thing, yaml);\n\n    let thing = f32::NEG_INFINITY;\n    let yaml = indoc! {\"\n        -.inf\n    \"};\n    test_serde(&thing, yaml);\n\n    let single_float: f32 = serde_yaml::from_str(indoc! {\"\n        .nan\n    \"})\n    .unwrap();\n    assert!(single_float.is_nan());\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_stale_read.rs::test_read_after_peer_destroyed", "code": "pub fn get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, false)\n    }", "test": "fn test_read_after_peer_destroyed() {\n    let mut cluster = new_node_cluster(0, 3);\n    let pd_client = cluster.pd_client.clone();\n    // Disable default max peer number check.\n    pd_client.disable_default_operator();\n    let r1 = cluster.run_conf_change();\n\n    // Add 2 peers.\n    for i in 2..4 {\n        pd_client.must_add_peer(r1, new_peer(i, i));\n    }\n\n    // Make sure peer 1 leads the region.\n    cluster.must_transfer_leader(r1, new_peer(1, 1));\n    let (key, value) = (b\"k1\", b\"v1\");\n    cluster.must_put(key, value);\n    assert_eq!(cluster.get(key), Some(value.to_vec()));\n\n    let destroy_peer_fp = \"destroy_peer\";\n    fail::cfg(destroy_peer_fp, \"pause\").unwrap();\n    pd_client.must_remove_peer(r1, new_peer(1, 1));\n    sleep_ms(300);\n\n    // Try writing k2 to peer3\n    let mut request = new_request(\n        r1,\n        cluster.pd_client.get_region_epoch(r1),\n        vec![new_get_cmd(b\"k1\")],\n        false,\n    );\n    request.mut_header().set_peer(new_peer(1, 1));\n    let (cb, mut rx) = make_cb(&request);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(1, request, cb)\n        .unwrap();\n    // Wait for raftstore receives the read request.\n    sleep_ms(200);\n    fail::remove(destroy_peer_fp);\n\n    let resp = rx.recv_timeout(Duration::from_millis(200)).unwrap();\n    assert!(\n        resp.get_header().get_error().has_region_not_found(),\n        \"{:?}\",\n        resp\n    );\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/client_tests.rs::test_delete_by_rdata", "code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "fn test_delete_by_rdata() {\n    let catalog = Catalog::new();\n    let (client, origin) = create_sig0_ready_client(catalog);\n\n    // append a record\n    let mut record = Record::with(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));\n\n    // first check the must_exist option\n    let result = client\n        .delete_by_rdata(record.clone(), origin.clone())\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // next create to a non-existent RRset\n    let result = client\n        .create(record.clone(), origin.clone())\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    record.set_data(Some(RData::A(A::new(101, 11, 101, 11))));\n    let result = client\n        .append(record.clone(), origin.clone(), true)\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // verify record contents\n    let result = client\n        .delete_by_rdata(record.clone(), origin)\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let result = client\n        .query(record.name(), record.dns_class(), record.record_type())\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.answers().len(), 1);\n    assert!(result\n        .answers()\n        .iter()\n        .any(|rr| if let RData::A(ip) = rr.data().unwrap() {\n            *ip == A::new(100, 10, 100, 10)\n        } else {\n            false\n        }));\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/resolved_ts/tests/failpoints/mod.rs::test_report_min_resolved_ts_disable", "code": "pub fn stop(&mut self) {\n        self.mut_store().cancel_applying_snap();\n        self.pending_reads.clear_all(None);\n    }", "test": "fn test_report_min_resolved_ts_disable() {\n    fail::cfg(\"mock_tick_interval\", \"return(0)\").unwrap();\n    fail::cfg(\"mock_collect_tick_interval\", \"return(0)\").unwrap();\n    fail::cfg(\"mock_min_resolved_ts_interval_disable\", \"return(0)\").unwrap();\n    let mut suite = TestSuite::new(1);\n    let region = suite.cluster.get_region(&[]);\n    let ts1 = suite.cluster.pd_client.get_min_resolved_ts();\n\n    // Prewrite\n    let (k, v) = (b\"k1\", b\"v\");\n    let start_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();\n    let mut mutation = Mutation::default();\n    mutation.set_op(Op::Put);\n    mutation.key = k.to_vec();\n    mutation.value = v.to_vec();\n    suite.must_kv_prewrite(region.id, vec![mutation], k.to_vec(), start_ts, false);\n\n    // Commit\n    let commit_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();\n    suite.must_kv_commit(region.id, vec![k.to_vec()], start_ts, commit_ts);\n\n    sleep_ms(100);\n\n    // no report\n    let ts3 = suite.cluster.pd_client.get_min_resolved_ts();\n    assert!(ts3 == ts1);\n    fail::remove(\"mock_tick_interval\");\n    fail::remove(\"mock_collect_tick_interval\");\n    fail::remove(\"mock_min_resolved_ts_interval_disable\");\n    suite.stop();\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_parser/src/parser/tests/mod.rs::deny_unicode_escape_in_null_expression", "code": "pub(super) fn check_invalid_script(js: &str) {\n    assert!(Parser::new(Source::from_bytes(js))\n        .parse_script(&mut Interner::default())\n        .is_err());\n}", "test": "fn deny_unicode_escape_in_null_expression() {\n    check_invalid_script(r\"let x = n\\u{75}ll;\");\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_hive.rs::test_drop_if_exists", "code": "pub fn verified_stmt(&self, sql: &str) -> Statement {\n        self.one_statement_parses_to(sql, sql)\n    }", "test": "fn test_drop_if_exists() {\n    let drop = \"ALTER TABLE db.table DROP IF EXISTS PARTITION (a = 'b', c = 'd')\";\n    hive().verified_stmt(drop);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/pd/test_rpc_client_legacy.rs::test_periodical_update", "code": "pub fn load(&self, ctx: TabletContext, create: bool) -> Result<CachedTablet<EK>>\n    where\n        EK: Clone,\n    {\n        assert!(ctx.suffix.is_some());\n        let id = ctx.id;\n        let path = self.tablet_path(id, ctx.suffix.unwrap());\n        if !create && !self.tablets.factory.exists(&path) {\n            return Err(Error::Other(box_err!(\n                \"tablet ({}, {:?}) doesn't exist\",\n                id,\n                ctx.suffix\n            )));\n        }\n        // TODO: use compaction filter to trim range.\n        let tablet = self.tablets.factory.open_tablet(ctx, &path)?;\n        let mut cached = self.get_or_default(id);\n        cached.set(tablet);\n        Ok(cached)\n    }", "test": "fn test_periodical_update() {\n    let eps_count = 3;\n    let server = MockServer::with_case(eps_count, Arc::new(LeaderChange::new()));\n    let eps = server.bind_addrs();\n\n    let counter = Arc::new(AtomicUsize::new(0));\n    let client = new_client_with_update_interval(eps, None, ReadableDuration::secs(3));\n    let counter1 = Arc::clone(&counter);\n    client.handle_reconnect(move || {\n        counter1.fetch_add(1, Ordering::SeqCst);\n    });\n    let leader = client.get_leader();\n\n    for _ in 0..5 {\n        let new = client.get_leader();\n        if new != leader {\n            assert!(counter.load(Ordering::SeqCst) >= 1);\n            return;\n        }\n        thread::sleep(LeaderChange::get_leader_interval());\n    }\n\n    panic!(\"failed, leader should changed\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_sparse_never_empty", "code": "pub fn read_bytes(&self, name: &str) -> Vec<u8> {\n        let mut f = self.open(name);\n        let mut contents = Vec::new();\n        f.read_to_end(&mut contents)\n            .unwrap_or_else(|e| panic!(\"Couldn't read {name}: {e}\"));\n        contents\n    }", "test": "fn test_cp_sparse_never_empty() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    const BUFFER_SIZE: usize = 4096 * 4;\n    let buf: [u8; BUFFER_SIZE] = [0; BUFFER_SIZE];\n\n    at.make_file(\"src_file1\");\n    at.write_bytes(\"src_file1\", &buf);\n\n    ucmd.args(&[\"--sparse=never\", \"src_file1\", \"dst_file_non_sparse\"])\n        .succeeds();\n    assert_eq!(at.read_bytes(\"dst_file_non_sparse\"), buf);\n    assert_eq!(\n        at.metadata(\"dst_file_non_sparse\").blocks() * 512,\n        buf.len() as u64\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_parents_with_permissions_copy_dir", "code": "pub fn metadata(&self, path: &str) -> fs::Metadata {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m,\n            Err(e) => panic!(\"{}\", e),\n        }\n    }", "test": "fn test_cp_parents_with_permissions_copy_dir() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let dir1 = \"dir\";\n    let dir2 = \"p1/p2\";\n    let file = \"p1/p2/file\";\n\n    at.mkdir(dir1);\n    at.mkdir_all(dir2);\n    at.touch(file);\n\n    #[cfg(unix)]\n    {\n        let p1_mode = 0o0777;\n        let p2_mode = 0o0711;\n        let file_mode = 0o0702;\n\n        at.set_mode(\"p1\", p1_mode);\n        at.set_mode(\"p1/p2\", p2_mode);\n        at.set_mode(file, file_mode);\n    }\n\n    ucmd.arg(\"-p\")\n        .arg(\"--parents\")\n        .arg(\"-r\")\n        .arg(dir2)\n        .arg(dir1)\n        .succeeds();\n\n    #[cfg(all(unix, not(target_os = \"freebsd\")))]\n    {\n        let p1_metadata = at.metadata(\"p1\");\n        let p2_metadata = at.metadata(\"p1/p2\");\n        let file_metadata = at.metadata(file);\n\n        assert_metadata_eq!(p1_metadata, at.metadata(\"dir/p1\"));\n        assert_metadata_eq!(p2_metadata, at.metadata(\"dir/p1/p2\"));\n        assert_metadata_eq!(file_metadata, at.metadata(\"dir/p1/p2/file\"));\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_rm.rs::test_rm_verbose", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_rm_verbose() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_rm_verbose_file_a\";\n    let file_b = \"test_rm_verbose_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n\n    ucmd.arg(\"-v\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .stdout_only(format!(\"removed '{file_a}'\\nremoved '{file_b}'\\n\"));\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/config/mod.rs::test_serde_custom_tikv_config", "code": "pub fn assert_eq_debug<C: PartialEq + Debug>(lhs: &C, rhs: &C) {\n    if lhs == rhs {\n        return;\n    }\n    let lhs_str = format!(\"{:?}\", lhs);\n    let rhs_str = format!(\"{:?}\", rhs);\n\n    fn find_index(l: impl Iterator<Item = (u8, u8)>) -> usize {\n        let it = l\n            .enumerate()\n            .take_while(|(_, (l, r))| l == r)\n            .filter(|(_, (l, _))| *l == b' ');\n        let mut last = None;\n        let mut second = None;\n        for a in it {\n            second = last;\n            last = Some(a);\n        }\n        second.map_or(0, |(i, _)| i)\n    }\n    let cpl = find_index(lhs_str.bytes().zip(rhs_str.bytes()));\n    let csl = find_index(lhs_str.bytes().rev().zip(rhs_str.bytes().rev()));\n    if cpl + csl > lhs_str.len() || cpl + csl > rhs_str.len() {\n        assert_eq!(lhs, rhs);\n    }\n    let lhs_diff = String::from_utf8_lossy(&lhs_str.as_bytes()[cpl..lhs_str.len() - csl]);\n    let rhs_diff = String::from_utf8_lossy(&rhs_str.as_bytes()[cpl..rhs_str.len() - csl]);\n    panic!(\n        \"config not matched:\\nlhs: ...{}...,\\nrhs: ...{}...\",\n        lhs_diff, rhs_diff\n    );\n}", "test": "fn test_serde_custom_tikv_config() {\n    let mut value = TikvConfig::default();\n    value.log_rotation_timespan = ReadableDuration::days(1);\n    value.log.level = Level::Critical.into();\n    value.log.file.filename = \"foo\".to_owned();\n    value.log.format = LogFormat::Json;\n    value.log.file.max_size = 1;\n    value.log.file.max_backups = 2;\n    value.log.file.max_days = 3;\n    value.slow_log_file = \"slow_foo\".to_owned();\n    value.slow_log_threshold = ReadableDuration::secs(1);\n    value.abort_on_panic = true;\n    value.memory_usage_limit = Some(ReadableSize::gb(10));\n    value.memory_usage_high_water = 0.65;\n    value.server = ServerConfig {\n        cluster_id: 0, // KEEP IT ZERO, it is skipped by serde.\n        addr: \"example.com:443\".to_owned(),\n        labels: HashMap::from_iter([(\"a\".to_owned(), \"b\".to_owned())]),\n        advertise_addr: \"example.com:443\".to_owned(),\n        status_addr: \"example.com:443\".to_owned(),\n        grpc_gzip_compression_level: 2,\n        grpc_min_message_size_to_compress: 4096,\n        advertise_status_addr: \"example.com:443\".to_owned(),\n        status_thread_pool_size: 1,\n        max_grpc_send_msg_len: 6 * (1 << 20),\n        raft_client_grpc_send_msg_buffer: 1234 * 1024,\n        raft_client_queue_size: 1234,\n        raft_client_max_backoff: ReadableDuration::secs(5),\n        raft_client_initial_reconnect_backoff: ReadableDuration::secs(1),\n        raft_msg_max_batch_size: 123,\n        concurrent_send_snap_limit: 4,\n        concurrent_recv_snap_limit: 4,\n        grpc_compression_type: GrpcCompressionType::Gzip,\n        grpc_concurrency: 123,\n        grpc_concurrent_stream: 1_234,\n        grpc_memory_pool_quota: ReadableSize(123_456),\n        grpc_raft_conn_num: 123,\n        grpc_stream_initial_window_size: ReadableSize(12_345),\n        grpc_keepalive_time: ReadableDuration::secs(3),\n        grpc_keepalive_timeout: ReadableDuration::secs(60),\n        end_point_concurrency: None,\n        end_point_max_tasks: None,\n        end_point_stack_size: None,\n        end_point_recursion_limit: 100,\n        end_point_stream_channel_size: 16,\n        end_point_batch_row_limit: 64,\n        end_point_stream_batch_row_limit: 4096,\n        end_point_enable_batch_if_possible: true,\n        end_point_request_max_handle_duration: ReadableDuration::secs(12),\n        end_point_max_concurrency: 10,\n        end_point_perf_level: PerfLevel::EnableTime,\n        snap_io_max_bytes_per_sec: ReadableSize::mb(10),\n        snap_max_total_size: ReadableSize::gb(10),\n        stats_concurrency: 10,\n        heavy_load_threshold: 25,\n        heavy_load_wait_duration: Some(ReadableDuration::millis(2)),\n        enable_request_batch: false,\n        background_thread_count: 999,\n        end_point_slow_log_threshold: ReadableDuration::secs(1),\n        forward_max_connections_per_address: 5,\n        reject_messages_on_memory_ratio: 0.8,\n        simplify_metrics: false,\n    };\n    value.readpool = ReadPoolConfig {\n        unified: UnifiedReadPoolConfig {\n            min_thread_count: 5,\n            max_thread_count: 10,\n            stack_size: ReadableSize::mb(20),\n            max_tasks_per_worker: 2200,\n            auto_adjust_pool_size: false,\n        },\n        storage: StorageReadPoolConfig {\n            use_unified_pool: Some(true),\n            high_concurrency: 1,\n            normal_concurrency: 3,\n            low_concurrency: 7,\n            max_tasks_per_worker_high: 1000,\n            max_tasks_per_worker_normal: 1500,\n            max_tasks_per_worker_low: 2500,\n            stack_size: ReadableSize::mb(20),\n        },\n        coprocessor: CoprReadPoolConfig {\n            use_unified_pool: Some(false),\n            high_concurrency: 2,\n            normal_concurrency: 4,\n            low_concurrency: 6,\n            max_tasks_per_worker_high: 2000,\n            max_tasks_per_worker_normal: 1000,\n            max_tasks_per_worker_low: 3000,\n            stack_size: ReadableSize::mb(12),\n        },\n    };\n    value.metric = MetricConfig {\n        interval: ReadableDuration::secs(15),\n        address: \"\".to_string(),\n        job: \"tikv_1\".to_owned(),\n    };\n    let mut apply_batch_system = BatchSystemConfig::default();\n    apply_batch_system.max_batch_size = Some(22);\n    apply_batch_system.pool_size = 4;\n    apply_batch_system.reschedule_duration = ReadableDuration::secs(3);\n    let mut store_batch_system = BatchSystemConfig::default();\n    store_batch_system.max_batch_size = Some(21);\n    store_batch_system.pool_size = 3;\n    store_batch_system.reschedule_duration = ReadableDuration::secs(2);\n    value.raft_store = RaftstoreConfig {\n        prevote: false,\n        raftdb_path: \"/var\".to_owned(),\n        capacity: ReadableSize(123),\n        raft_base_tick_interval: ReadableDuration::secs(12),\n        raft_heartbeat_ticks: 1,\n        raft_election_timeout_ticks: 12,\n        raft_min_election_timeout_ticks: 14,\n        raft_max_election_timeout_ticks: 20,\n        raft_max_size_per_msg: ReadableSize::mb(12),\n        raft_max_inflight_msgs: 123,\n        raft_entry_max_size: ReadableSize::mb(12),\n        raft_log_compact_sync_interval: ReadableDuration::secs(12),\n        raft_log_gc_tick_interval: ReadableDuration::secs(12),\n        request_voter_replicated_index_interval: ReadableDuration::minutes(5),\n        raft_log_gc_threshold: 12,\n        raft_log_gc_count_limit: Some(12),\n        raft_log_gc_size_limit: Some(ReadableSize::kb(1)),\n        raft_log_reserve_max_ticks: 100,\n        raft_engine_purge_interval: ReadableDuration::minutes(20),\n        raft_entry_cache_life_time: ReadableDuration::secs(12),\n        raft_reject_transfer_leader_duration: ReadableDuration::secs(3),\n        split_region_check_tick_interval: ReadableDuration::secs(12),\n        region_split_check_diff: Some(ReadableSize::mb(20)),\n        region_compact_check_interval: ReadableDuration::secs(12),\n        clean_stale_peer_delay: ReadableDuration::secs(0),\n        region_compact_check_step: Some(1_234),\n        region_compact_min_tombstones: 999,\n        region_compact_tombstones_percent: 33,\n        region_compact_min_redundant_rows: 999,\n        region_compact_redundant_rows_percent: 33,\n        pd_heartbeat_tick_interval: ReadableDuration::minutes(12),\n        pd_store_heartbeat_tick_interval: ReadableDuration::secs(12),\n        notify_capacity: 12_345,\n        snap_mgr_gc_tick_interval: ReadableDuration::minutes(12),\n        snap_gc_timeout: ReadableDuration::hours(12),\n        messages_per_tick: 12_345,\n        max_peer_down_duration: ReadableDuration::minutes(12),\n        max_leader_missing_duration: ReadableDuration::hours(12),\n        abnormal_leader_missing_duration: ReadableDuration::hours(6),\n        peer_stale_state_check_interval: ReadableDuration::hours(2),\n        leader_transfer_max_log_lag: 123,\n        snap_apply_batch_size: ReadableSize::mb(12),\n        region_worker_tick_interval: ReadableDuration::millis(1000),\n        clean_stale_ranges_tick: 10,\n        lock_cf_compact_interval: ReadableDuration::minutes(12),\n        lock_cf_compact_bytes_threshold: ReadableSize::mb(123),\n        consistency_check_interval: ReadableDuration::secs(12),\n        report_region_flow_interval: ReadableDuration::minutes(12),\n        raft_store_max_leader_lease: ReadableDuration::secs(12),\n        allow_unsafe_vote_after_start: false,\n        right_derive_when_split: false,\n        allow_remove_leader: true,\n        merge_max_log_gap: 3,\n        merge_check_tick_interval: ReadableDuration::secs(11),\n        use_delete_range: true,\n        snap_generator_pool_size: 2,\n        cleanup_import_sst_interval: ReadableDuration::minutes(12),\n        region_max_size: ReadableSize(0),\n        region_split_size: ReadableSize(0),\n        local_read_batch_size: 33,\n        apply_batch_system,\n        store_batch_system,\n        store_io_pool_size: 5,\n        store_io_notify_capacity: 123456,\n        future_poll_size: 2,\n        hibernate_regions: false,\n        dev_assert: true,\n        apply_yield_duration: ReadableDuration::millis(333),\n        apply_yield_write_size: ReadableSize(12345),\n        perf_level: PerfLevel::Disable,\n        evict_cache_on_memory_ratio: 0.8,\n        cmd_batch: false,\n        cmd_batch_concurrent_ready_max_count: 123,\n        raft_write_size_limit: ReadableSize::mb(34),\n        waterfall_metrics: true,\n        io_reschedule_concurrent_max_count: 1234,\n        io_reschedule_hotpot_duration: ReadableDuration::secs(4321),\n        inspect_interval: ReadableDuration::millis(444),\n        report_min_resolved_ts_interval: ReadableDuration::millis(233),\n        raft_msg_flush_interval: ReadableDuration::micros(250),\n        check_leader_lease_interval: ReadableDuration::millis(123),\n        renew_leader_lease_advance_duration: ReadableDuration::millis(456),\n        reactive_memory_lock_tick_interval: ReadableDuration::millis(566),\n        reactive_memory_lock_timeout_tick: 8,\n        report_region_buckets_tick_interval: ReadableDuration::secs(1234),\n        check_long_uncommitted_interval: ReadableDuration::secs(1),\n        long_uncommitted_base_threshold: ReadableDuration::secs(1),\n        max_entry_cache_warmup_duration: ReadableDuration::secs(2),\n        max_snapshot_file_raw_size: ReadableSize::gb(10),\n        unreachable_backoff: ReadableDuration::secs(111),\n        check_peers_availability_interval: ReadableDuration::secs(30),\n        check_request_snapshot_interval: ReadableDuration::minutes(1),\n        slow_trend_unsensitive_cause: 10.0,\n        slow_trend_unsensitive_result: 0.5,\n        enable_v2_compatible_learner: false,\n        unsafe_disable_check_quorum: false,\n    };\n    value.pd = PdConfig::new(vec![\"example.com:443\".to_owned()]);\n    let titan_cf_config = TitanCfConfig {\n        min_blob_size: ReadableSize(2018),\n        blob_file_compression: CompressionType::Zstd,\n        blob_cache_size: ReadableSize::gb(12),\n        min_gc_batch_size: ReadableSize::kb(12),\n        max_gc_batch_size: ReadableSize::mb(12),\n        discardable_ratio: 0.00156,\n        sample_ratio: None,\n        merge_small_file_threshold: ReadableSize::kb(21),\n        blob_run_mode: BlobRunMode::Fallback,\n        level_merge: true,\n        range_merge: true,\n        max_sorted_runs: 100,\n        gc_merge_rewrite: false,\n    };\n    let titan_db_config = TitanDbConfig {\n        enabled: true,\n        dirname: \"bar\".to_owned(),\n        disable_gc: false,\n        max_background_gc: 9,\n        purge_obsolete_files_period: ReadableDuration::secs(1),\n    };\n    value.rocksdb = DbConfig {\n        wal_recovery_mode: DBRecoveryMode::AbsoluteConsistency,\n        wal_dir: \"/var\".to_owned(),\n        wal_ttl_seconds: 1,\n        wal_size_limit: ReadableSize::kb(1),\n        max_total_wal_size: ReadableSize::gb(1),\n        max_background_jobs: 12,\n        max_background_flushes: 4,\n        max_manifest_file_size: ReadableSize::mb(12),\n        create_if_missing: false,\n        max_open_files: 12_345,\n        enable_statistics: true,\n        stats_dump_period: ReadableDuration::minutes(12),\n        compaction_readahead_size: ReadableSize::kb(1),\n        info_log_max_size: ReadableSize::kb(1),\n        info_log_roll_time: ReadableDuration::secs(12),\n        info_log_keep_log_file_num: 1000,\n        info_log_dir: \"/var\".to_owned(),\n        info_log_level: LogLevel::Info,\n        rate_bytes_per_sec: ReadableSize::kb(1),\n        rate_limiter_refill_period: ReadableDuration::millis(10),\n        rate_limiter_mode: DBRateLimiterMode::AllIo,\n        auto_tuned: None,\n        rate_limiter_auto_tuned: false,\n        bytes_per_sync: ReadableSize::mb(1),\n        wal_bytes_per_sync: ReadableSize::kb(32),\n        max_sub_compactions: 12,\n        writable_file_max_buffer_size: ReadableSize::mb(12),\n        use_direct_io_for_flush_and_compaction: true,\n        enable_pipelined_write: false,\n        enable_multi_batch_write: Some(true),\n        paranoid_checks: None,\n        allow_concurrent_memtable_write: Some(false),\n        enable_unordered_write: true,\n        write_buffer_limit: Some(ReadableSize::gb(1)),\n        write_buffer_stall_ratio: 0.0,\n        write_buffer_flush_oldest_first: false,\n        defaultcf: DefaultCfConfig {\n            block_size: ReadableSize::kb(12),\n            block_cache_size: ReadableSize::gb(12),\n            disable_block_cache: false,\n            cache_index_and_filter_blocks: false,\n            pin_l0_filter_and_index_blocks: false,\n            use_bloom_filter: false,\n            optimize_filters_for_hits: false,\n            whole_key_filtering: true,\n            bloom_filter_bits_per_key: 123,\n            block_based_bloom_filter: true,\n            read_amp_bytes_per_bit: 0,\n            compression_per_level: [\n                DBCompressionType::No,\n                DBCompressionType::No,\n                DBCompressionType::Zstd,\n                DBCompressionType::Zstd,\n                DBCompressionType::No,\n                DBCompressionType::Zstd,\n                DBCompressionType::Lz4,\n            ],\n            write_buffer_size: ReadableSize::mb(1),\n            max_write_buffer_number: 12,\n            min_write_buffer_number_to_merge: 12,\n            max_bytes_for_level_base: ReadableSize::kb(12),\n            target_file_size_base: Some(ReadableSize::kb(123)),\n            level0_file_num_compaction_trigger: 123,\n            level0_slowdown_writes_trigger: Some(123),\n            level0_stop_writes_trigger: Some(123),\n            max_compaction_bytes: ReadableSize::gb(1),\n            compaction_pri: CompactionPriority::MinOverlappingRatio,\n            dynamic_level_bytes: true,\n            num_levels: 4,\n            max_bytes_for_level_multiplier: 8,\n            compaction_style: DBCompactionStyle::Universal,\n            disable_auto_compactions: true,\n            disable_write_stall: true,\n            soft_pending_compaction_bytes_limit: Some(ReadableSize::gb(12)),\n            hard_pending_compaction_bytes_limit: Some(ReadableSize::gb(12)),\n            force_consistency_checks: true,\n            titan: titan_cf_config.clone(),\n            prop_size_index_distance: 4000000,\n            prop_keys_index_distance: 40000,\n            enable_doubly_skiplist: false,\n            enable_compaction_guard: Some(false),\n            compaction_guard_min_output_file_size: ReadableSize::mb(12),\n            compaction_guard_max_output_file_size: ReadableSize::mb(34),\n            bottommost_level_compression: DBCompressionType::Disable,\n            bottommost_zstd_compression_dict_size: 1024,\n            bottommost_zstd_compression_sample_size: 1024,\n            prepopulate_block_cache: PrepopulateBlockCache::FlushOnly,\n            format_version: 5,\n            checksum: ChecksumType::XXH3,\n            max_compactions: 3,\n            ttl: Some(ReadableDuration::days(10)),\n            periodic_compaction_seconds: Some(ReadableDuration::days(10)),\n        },\n        writecf: WriteCfConfig {\n            block_size: ReadableSize::kb(12),\n            block_cache_size: ReadableSize::gb(12),\n            disable_block_cache: false,\n            cache_index_and_filter_blocks: false,\n            pin_l0_filter_and_index_blocks: false,\n            use_bloom_filter: false,\n            optimize_filters_for_hits: true,\n            whole_key_filtering: true,\n            bloom_filter_bits_per_key: 123,\n            block_based_bloom_filter: true,\n            read_amp_bytes_per_bit: 0,\n            compression_per_level: [\n                DBCompressionType::No,\n                DBCompressionType::No,\n                DBCompressionType::Zstd,\n                DBCompressionType::Zstd,\n                DBCompressionType::No,\n                DBCompressionType::Zstd,\n                DBCompressionType::Lz4,\n            ],\n            write_buffer_size: ReadableSize::mb(1),\n            max_write_buffer_number: 12,\n            min_write_buffer_number_to_merge: 12,\n            max_bytes_for_level_base: ReadableSize::kb(12),\n            target_file_size_base: Some(ReadableSize::kb(123)),\n            level0_file_num_compaction_trigger: 123,\n            level0_slowdown_writes_trigger: Some(123),\n            level0_stop_writes_trigger: Some(123),\n            max_compaction_bytes: ReadableSize::gb(1),\n            compaction_pri: CompactionPriority::MinOverlappingRatio,\n            dynamic_level_bytes: true,\n            num_levels: 4,\n            max_bytes_for_level_multiplier: 8,\n            compaction_style: DBCompactionStyle::Universal,\n            disable_auto_compactions: true,\n            disable_write_stall: true,\n            soft_pending_compaction_bytes_limit: Some(ReadableSize::gb(12)),\n            hard_pending_compaction_bytes_limit: Some(ReadableSize::gb(12)),\n            force_consistency_checks: true,\n            titan: TitanCfConfig {\n                min_blob_size: ReadableSize(1024), // default value\n                blob_file_compression: CompressionType::Lz4,\n                blob_cache_size: ReadableSize::mb(0),\n                min_gc_batch_size: ReadableSize::mb(16),\n                max_gc_batch_size: ReadableSize::mb(64),\n                discardable_ratio: 0.5,\n                sample_ratio: None,\n                merge_small_file_threshold: ReadableSize::mb(8),\n                blob_run_mode: BlobRunMode::ReadOnly,\n                level_merge: false,\n                range_merge: true,\n                max_sorted_runs: 20,\n                gc_merge_rewrite: false,\n            },\n            prop_size_index_distance: 4000000,\n            prop_keys_index_distance: 40000,\n            enable_doubly_skiplist: true,\n            enable_compaction_guard: Some(false),\n            compaction_guard_min_output_file_size: ReadableSize::mb(12),\n            compaction_guard_max_output_file_size: ReadableSize::mb(34),\n            bottommost_level_compression: DBCompressionType::Zstd,\n            bottommost_zstd_compression_dict_size: 0,\n            bottommost_zstd_compression_sample_size: 0,\n            prepopulate_block_cache: PrepopulateBlockCache::FlushOnly,\n            format_version: 5,\n            checksum: ChecksumType::XXH3,\n            max_compactions: 3,\n            ttl: Some(ReadableDuration::days(10)),\n            periodic_compaction_seconds: Some(ReadableDuration::days(10)),\n        },\n        lockcf: LockCfConfig {\n            block_size: ReadableSize::kb(12),\n            block_cache_size: ReadableSize::gb(12),\n            disable_block_cache: false,\n            cache_index_and_filter_blocks: false,\n            pin_l0_filter_and_index_blocks: false,\n            use_bloom_filter: false,\n            optimize_filters_for_hits: true,\n            whole_key_filtering: true,\n            bloom_filter_bits_per_key: 123,\n            block_based_bloom_filter: true,\n            read_amp_bytes_per_bit: 0,\n            compression_per_level: [\n                DBCompressionType::No,\n                DBCompressionType::No,\n                DBCompressionType::Zstd,\n                DBCompressionType::Zstd,\n                DBCompressionType::No,\n                DBCompressionType::Zstd,\n                DBCompressionType::Lz4,\n            ],\n            write_buffer_size: ReadableSize::mb(1),\n            max_write_buffer_number: 12,\n            min_write_buffer_number_to_merge: 12,\n            max_bytes_for_level_base: ReadableSize::kb(12),\n            target_file_size_base: Some(ReadableSize::kb(123)),\n            level0_file_num_compaction_trigger: 123,\n            level0_slowdown_writes_trigger: Some(123),\n            level0_stop_writes_trigger: Some(123),\n            max_compaction_bytes: ReadableSize::gb(1),\n            compaction_pri: CompactionPriority::MinOverlappingRatio,\n            dynamic_level_bytes: true,\n            num_levels: 4,\n            max_bytes_for_level_multiplier: 8,\n            compaction_style: DBCompactionStyle::Universal,\n            disable_auto_compactions: true,\n            disable_write_stall: true,\n            soft_pending_compaction_bytes_limit: Some(ReadableSize::gb(12)),\n            hard_pending_compaction_bytes_limit: Some(ReadableSize::gb(12)),\n            force_consistency_checks: true,\n            titan: TitanCfConfig {\n                min_blob_size: ReadableSize(1024), // default value\n                blob_file_compression: CompressionType::Lz4,\n                blob_cache_size: ReadableSize::mb(0),\n                min_gc_batch_size: ReadableSize::mb(16),\n                max_gc_batch_size: ReadableSize::mb(64),\n                discardable_ratio: 0.5,\n                sample_ratio: None,\n                merge_small_file_threshold: ReadableSize::mb(8),\n                blob_run_mode: BlobRunMode::ReadOnly, // default value\n                level_merge: false,\n                range_merge: true,\n                max_sorted_runs: 20,\n                gc_merge_rewrite: false,\n            },\n            prop_size_index_distance: 4000000,\n            prop_keys_index_distance: 40000,\n            enable_doubly_skiplist: true,\n            enable_compaction_guard: Some(true),\n            compaction_guard_min_output_file_size: ReadableSize::mb(12),\n            compaction_guard_max_output_file_size: ReadableSize::mb(34),\n            bottommost_level_compression: DBCompressionType::Disable,\n            bottommost_zstd_compression_dict_size: 0,\n            bottommost_zstd_compression_sample_size: 0,\n            prepopulate_block_cache: PrepopulateBlockCache::FlushOnly,\n            format_version: 5,\n            checksum: ChecksumType::XXH3,\n            max_compactions: 3,\n            ttl: Some(ReadableDuration::days(10)),\n            periodic_compaction_seconds: Some(ReadableDuration::days(10)),\n        },\n        raftcf: RaftCfConfig {\n            block_size: ReadableSize::kb(12),\n            block_cache_size: ReadableSize::gb(12),\n            disable_block_cache: false,\n            cache_index_and_filter_blocks: false,\n            pin_l0_filter_and_index_blocks: false,\n            use_bloom_filter: false,\n            optimize_filters_for_hits: false,\n            whole_key_filtering: true,\n            bloom_filter_bits_per_key: 123,\n            block_based_bloom_filter: true,\n            read_amp_bytes_per_bit: 0,\n            compression_per_level: [\n                DBCompressionType::No,\n                DBCompressionType::No,\n                DBCompressionType::Zstd,\n                DBCompressionType::Zstd,\n                DBCompressionType::No,\n                DBCompressionType::Zstd,\n                DBCompressionType::Lz4,\n            ],\n            write_buffer_size: ReadableSize::mb(1),\n            max_write_buffer_number: 12,\n            min_write_buffer_number_to_merge: 12,\n            max_bytes_for_level_base: ReadableSize::kb(12),\n            target_file_size_base: Some(ReadableSize::kb(123)),\n            level0_file_num_compaction_trigger: 123,\n            level0_slowdown_writes_trigger: Some(123),\n            level0_stop_writes_trigger: Some(123),\n            max_compaction_bytes: ReadableSize::gb(1),\n            compaction_pri: CompactionPriority::MinOverlappingRatio,\n            dynamic_level_bytes: true,\n            num_levels: 4,\n            max_bytes_for_level_multiplier: 8,\n            compaction_style: DBCompactionStyle::Universal,\n            disable_auto_compactions: true,\n            disable_write_stall: true,\n            soft_pending_compaction_bytes_limit: Some(ReadableSize::gb(12)),\n            hard_pending_compaction_bytes_limit: Some(ReadableSize::gb(12)),\n            force_consistency_checks: true,\n            titan: TitanCfConfig {\n                min_blob_size: ReadableSize(1024), // default value\n                blob_file_compression: CompressionType::Lz4,\n                blob_cache_size: ReadableSize::mb(0),\n                min_gc_batch_size: ReadableSize::mb(16),\n                max_gc_batch_size: ReadableSize::mb(64),\n                discardable_ratio: 0.5,\n                sample_ratio: None,\n                merge_small_file_threshold: ReadableSize::mb(8),\n                blob_run_mode: BlobRunMode::ReadOnly, // default value\n                level_merge: false,\n                range_merge: true,\n                max_sorted_runs: 20,\n                gc_merge_rewrite: false,\n            },\n            prop_size_index_distance: 4000000,\n            prop_keys_index_distance: 40000,\n            enable_doubly_skiplist: true,\n            enable_compaction_guard: Some(true),\n            compaction_guard_min_output_file_size: ReadableSize::mb(12),\n            compaction_guard_max_output_file_size: ReadableSize::mb(34),\n            bottommost_level_compression: DBCompressionType::Disable,\n            bottommost_zstd_compression_dict_size: 0,\n            bottommost_zstd_compression_sample_size: 0,\n            prepopulate_block_cache: PrepopulateBlockCache::FlushOnly,\n            format_version: 5,\n            checksum: ChecksumType::XXH3,\n            max_compactions: 3,\n            ttl: Some(ReadableDuration::days(10)),\n            periodic_compaction_seconds: Some(ReadableDuration::days(10)),\n        },\n        titan: titan_db_config.clone(),\n    };\n    value.raftdb = RaftDbConfig {\n        info_log_level: LogLevel::Info,\n        wal_recovery_mode: DBRecoveryMode::SkipAnyCorruptedRecords,\n        wal_dir: \"/var\".to_owned(),\n        wal_ttl_seconds: 1,\n        wal_size_limit: ReadableSize::kb(12),\n        max_total_wal_size: ReadableSize::gb(1),\n        max_background_jobs: 12,\n        max_background_flushes: 4,\n        max_manifest_file_size: ReadableSize::mb(12),\n        create_if_missing: false,\n        max_open_files: 12_345,\n        enable_statistics: true,\n        stats_dump_period: ReadableDuration::minutes(12),\n        compaction_readahead_size: ReadableSize::kb(1),\n        info_log_max_size: ReadableSize::kb(1),\n        info_log_roll_time: ReadableDuration::secs(1),\n        info_log_keep_log_file_num: 1000,\n        info_log_dir: \"/var\".to_owned(),\n        max_sub_compactions: 12,\n        writable_file_max_buffer_size: ReadableSize::mb(12),\n        use_direct_io_for_flush_and_compaction: true,\n        enable_pipelined_write: false,\n        enable_unordered_write: false,\n        allow_concurrent_memtable_write: false,\n        bytes_per_sync: ReadableSize::mb(1),\n        wal_bytes_per_sync: ReadableSize::kb(32),\n        defaultcf: RaftDefaultCfConfig {\n            block_size: ReadableSize::kb(12),\n            block_cache_size: ReadableSize::gb(12),\n            disable_block_cache: false,\n            cache_index_and_filter_blocks: false,\n            pin_l0_filter_and_index_blocks: false,\n            use_bloom_filter: false,\n            optimize_filters_for_hits: false,\n            whole_key_filtering: true,\n            bloom_filter_bits_per_key: 123,\n            block_based_bloom_filter: true,\n            read_amp_bytes_per_bit: 0,\n            compression_per_level: [\n                DBCompressionType::No,\n                DBCompressionType::No,\n                DBCompressionType::Zstd,\n                DBCompressionType::Zstd,\n                DBCompressionType::No,\n                DBCompressionType::Zstd,\n                DBCompressionType::Lz4,\n            ],\n            write_buffer_size: ReadableSize::mb(1),\n            max_write_buffer_number: 12,\n            min_write_buffer_number_to_merge: 12,\n            max_bytes_for_level_base: ReadableSize::kb(12),\n            target_file_size_base: Some(ReadableSize::kb(123)),\n            level0_file_num_compaction_trigger: 123,\n            level0_slowdown_writes_trigger: Some(123),\n            level0_stop_writes_trigger: Some(123),\n            max_compaction_bytes: ReadableSize::gb(1),\n            compaction_pri: CompactionPriority::MinOverlappingRatio,\n            dynamic_level_bytes: true,\n            num_levels: 4,\n            max_bytes_for_level_multiplier: 8,\n            compaction_style: DBCompactionStyle::Universal,\n            disable_auto_compactions: true,\n            disable_write_stall: true,\n            soft_pending_compaction_bytes_limit: Some(ReadableSize::gb(12)),\n            hard_pending_compaction_bytes_limit: Some(ReadableSize::gb(12)),\n            force_consistency_checks: true,\n            titan: titan_cf_config,\n            prop_size_index_distance: 4000000,\n            prop_keys_index_distance: 40000,\n            enable_doubly_skiplist: true,\n            enable_compaction_guard: Some(true),\n            compaction_guard_min_output_file_size: ReadableSize::mb(12),\n            compaction_guard_max_output_file_size: ReadableSize::mb(34),\n            bottommost_level_compression: DBCompressionType::Disable,\n            bottommost_zstd_compression_dict_size: 0,\n            bottommost_zstd_compression_sample_size: 0,\n            prepopulate_block_cache: PrepopulateBlockCache::FlushOnly,\n            format_version: 5,\n            checksum: ChecksumType::XXH3,\n            max_compactions: 3,\n            ttl: None,\n            periodic_compaction_seconds: None,\n        },\n        titan: titan_db_config,\n    };\n    value.raft_engine.enable = false;\n    let raft_engine_config = value.raft_engine.mut_config();\n    raft_engine_config.dir = \"test-dir\".to_owned();\n    raft_engine_config.batch_compression_threshold.0 = ReadableSize::kb(1).0;\n    raft_engine_config.target_file_size.0 = ReadableSize::mb(1).0;\n    raft_engine_config.purge_threshold.0 = ReadableSize::gb(1).0;\n    raft_engine_config.recovery_mode = RecoveryMode::TolerateTailCorruption;\n    raft_engine_config.recovery_read_block_size.0 = ReadableSize::kb(1).0;\n    raft_engine_config.recovery_threads = 2;\n    raft_engine_config.memory_limit = Some(RaftEngineReadableSize::gb(1));\n    value.storage = StorageConfig {\n        data_dir: \"/var\".to_owned(),\n        engine: EngineType::RaftKv2,\n        gc_ratio_threshold: 1.2,\n        max_key_size: 4096,\n        scheduler_concurrency: 123,\n        scheduler_worker_pool_size: 1,\n        scheduler_pending_write_threshold: ReadableSize::kb(123),\n        reserve_space: ReadableSize::gb(10),\n        reserve_raft_space: ReadableSize::gb(2),\n        enable_async_apply_prewrite: true,\n        api_version: 1,\n        enable_ttl: true,\n        ttl_check_poll_interval: ReadableDuration::hours(0),\n        flow_control: FlowControlConfig {\n            enable: false,\n            l0_files_threshold: 10,\n            memtables_threshold: 10,\n            soft_pending_compaction_bytes_limit: ReadableSize(1),\n            hard_pending_compaction_bytes_limit: ReadableSize(1),\n        },\n        block_cache: BlockCacheConfig {\n            shared: None,\n            capacity: Some(ReadableSize::gb(40)),\n            num_shard_bits: 10,\n            strict_capacity_limit: true,\n            high_pri_pool_ratio: 0.8,\n            memory_allocator: Some(String::from(\"nodump\")),\n        },\n        io_rate_limit: IoRateLimitConfig {\n            max_bytes_per_sec: ReadableSize::mb(1000),\n            mode: IoRateLimitMode::AllIo,\n            strict: true,\n            foreground_read_priority: IoPriority::Low,\n            foreground_write_priority: IoPriority::Low,\n            flush_priority: IoPriority::Low,\n            level_zero_compaction_priority: IoPriority::Low,\n            compaction_priority: IoPriority::High,\n            replication_priority: IoPriority::Low,\n            load_balance_priority: IoPriority::Low,\n            gc_priority: IoPriority::High,\n            import_priority: IoPriority::High,\n            export_priority: IoPriority::High,\n            other_priority: IoPriority::Low,\n        },\n        background_error_recovery_window: ReadableDuration::hours(1),\n    };\n    value.coprocessor = CopConfig {\n        split_region_on_table: false,\n        batch_split_limit: 1,\n        region_max_size: Some(ReadableSize::mb(12)),\n        region_split_size: Some(ReadableSize::mb(12)),\n        region_max_keys: Some(100000),\n        region_split_keys: Some(100000),\n        consistency_check_method: ConsistencyCheckMethod::Raw,\n        perf_level: PerfLevel::Uninitialized,\n        enable_region_bucket: Some(true),\n        region_bucket_size: ReadableSize::mb(1),\n        region_size_threshold_for_approximate: ReadableSize::mb(3),\n        prefer_approximate_bucket: false,\n        region_bucket_merge_size_ratio: 0.4,\n    };\n    let mut cert_allowed_cn = HashSet::default();\n    cert_allowed_cn.insert(\"example.tikv.com\".to_owned());\n    value.security = SecurityConfig {\n        ca_path: \"invalid path\".to_owned(),\n        cert_path: \"invalid path\".to_owned(),\n        key_path: \"invalid path\".to_owned(),\n        override_ssl_target: \"\".to_owned(),\n        cert_allowed_cn,\n        redact_info_log: Some(true),\n        encryption: EncryptionConfig {\n            data_encryption_method: EncryptionMethod::Aes128Ctr,\n            data_key_rotation_period: ReadableDuration::days(14),\n            enable_file_dictionary_log: false,\n            file_dictionary_rewrite_threshold: 123456,\n            master_key: MasterKeyConfig::File {\n                config: FileConfig {\n                    path: \"/master/key/path\".to_owned(),\n                },\n            },\n            previous_master_key: MasterKeyConfig::Plaintext,\n        },\n    };\n    value.backup = BackupConfig {\n        num_threads: 456,\n        batch_size: 7,\n        sst_max_size: ReadableSize::mb(789),\n        s3_multi_part_size: ReadableSize::mb(15),\n        hadoop: HadoopConfig {\n            home: \"/root/hadoop\".to_string(),\n            linux_user: \"hadoop\".to_string(),\n        },\n        ..Default::default()\n    };\n    value.log_backup = BackupStreamConfig {\n        max_flush_interval: ReadableDuration::secs(11),\n        num_threads: 7,\n        enable: true,\n        temp_path: \"./stream\".to_string(),\n        file_size_limit: ReadableSize::gb(5),\n        initial_scan_pending_memory_quota: ReadableSize::kb(2),\n        initial_scan_rate_limit: ReadableSize::mb(3),\n        min_ts_interval: ReadableDuration::secs(2),\n        ..Default::default()\n    };\n    value.import = ImportConfig {\n        num_threads: 123,\n        stream_channel_window: 123,\n        import_mode_timeout: ReadableDuration::secs(1453),\n        memory_use_ratio: 0.3,\n    };\n    value.panic_when_unexpected_key_or_data = true;\n    value.gc = GcConfig {\n        ratio_threshold: 1.2,\n        batch_keys: 256,\n        max_write_bytes_per_sec: ReadableSize::mb(10),\n        enable_compaction_filter: false,\n        compaction_filter_skip_version_check: true,\n    };\n    value.pessimistic_txn = PessimisticTxnConfig {\n        wait_for_lock_timeout: ReadableDuration::millis(10),\n        wake_up_delay_duration: ReadableDuration::millis(100),\n        pipelined: false,\n        in_memory: false,\n    };\n    value.cdc = CdcConfig {\n        min_ts_interval: ReadableDuration::secs(4),\n        old_value_cache_size: 0,\n        hibernate_regions_compatible: false,\n        incremental_scan_threads: 3,\n        incremental_scan_concurrency: 4,\n        incremental_scan_speed_limit: ReadableSize(7),\n        incremental_scan_ts_filter_ratio: 0.7,\n        tso_worker_threads: 2,\n        old_value_cache_memory_quota: ReadableSize::mb(14),\n        sink_memory_quota: ReadableSize::mb(7),\n    };\n    value.resolved_ts = ResolvedTsConfig {\n        enable: true,\n        advance_ts_interval: ReadableDuration::secs(5),\n        scan_lock_pool_size: 1,\n    };\n    value.causal_ts = CausalTsConfig {\n        renew_interval: ReadableDuration::millis(100),\n        renew_batch_min_size: 100,\n        renew_batch_max_size: 8192,\n        alloc_ahead_buffer: ReadableDuration::millis(3000),\n    };\n    value.resource_control = ResourceControlConfig { enabled: false };\n\n    let custom = read_file_in_project_dir(\"integrations/config/test-custom.toml\");\n    let load = toml::from_str(&custom).unwrap();\n    assert_eq_debug(&value, &load);\n\n    let dump = toml::to_string_pretty(&load).unwrap();\n    let load_from_dump = toml::from_str(&dump).unwrap();\n    assert_eq_debug(&load, &load_from_dump);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_users.rs::test_users_no_arg", "code": "pub fn succeeds(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.success();\n        cmd_result\n    }", "test": "fn test_users_no_arg() {\n    new_ucmd!().succeeds();\n}"}
{"test_id": "web-infra-dev-oxc/oxc-project-oxc-884a819/crates/oxc_minifier/tests/closure/fold_conditions.rs::test_fold_not", "code": "fn test(args: &[&str]) -> LintResult {\n        let mut new_args = vec![\"--quiet\"];\n        new_args.extend(args);\n        let options = lint_command().run_inner(new_args.as_slice()).unwrap().lint_options;\n        let CliRunResult::LintResult(lint_result) = LintRunner::new(options).run() else {\n            unreachable!()\n        };\n        lint_result\n    }", "test": "fn test_fold_not() {\n    test(\"while(!(x==y)){a=b;}\", \"for(;x!=y;)a=b;\");\n    test(\"while(!(x!=y)){a=b;}\", \"for(;x==y;)a=b;\");\n    test(\"while(!(x===y)){a=b;}\", \"for(;x!==y;)a=b;\");\n    test(\"while(!(x!==y)){a=b;}\", \"for(;x===y;)a=b;\");\n\n    // Because !(x<NaN) != x>=NaN don't fold < and > cases.\n    test(\"while(!(x>y)){a=b;}\", \"for(;!(x>y);)a=b;\");\n    test(\"while(!(x>=y)){a=b;}\", \"for(;!(x>=y);)a=b;\");\n    test(\"while(!(x<y)){a=b;}\", \"for(;!(x<y);)a=b;\");\n    test(\"while(!(x<=y)){a=b;}\", \"for(;!(x<=y);)a=b;\");\n    test(\"while(!(x<=NaN)){a=b;}\", \"for(;!(x<=NaN);)a=b;\");\n\n    // NOT forces a boolean context\n    // test(\"x = !(y() && true)\", \"x=!y()\");\n    // This will be further optimized by PeepholeFoldConstants.\n    // test(\"x = !true\", \"x=!1\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_realpath.rs::test_realpath_file_and_links_strip", "code": "pub fn stdout_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stdout_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stdout_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_realpath_file_and_links_strip() {\n    let strip_args = [\"-s\", \"--strip\", \"--no-symlinks\"];\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    at.touch(\"foo\");\n    at.symlink_file(\"foo\", \"bar\");\n\n    for strip_arg in strip_args {\n        scene\n            .ucmd()\n            .arg(\"foo\")\n            .arg(strip_arg)\n            .succeeds()\n            .stdout_contains(\"foo\\n\");\n\n        scene\n            .ucmd()\n            .arg(\"bar\")\n            .arg(strip_arg)\n            .succeeds()\n            .stdout_contains(\"bar\\n\");\n    }\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_mssql.rs::parse_mssql_create_role", "code": "pub fn assert_eq_vec<T: ToString>(expected: &[&str], actual: &[T]) {\n    assert_eq!(\n        expected,\n        actual.iter().map(ToString::to_string).collect::<Vec<_>>()\n    );\n}", "test": "fn parse_mssql_create_role() {\n    let sql = \"CREATE ROLE mssql AUTHORIZATION helena\";\n    match ms().verified_stmt(sql) {\n        Statement::CreateRole {\n            names,\n            authorization_owner,\n            ..\n        } => {\n            assert_eq_vec(&[\"mssql\"], &names);\n            assert_eq!(\n                authorization_owner,\n                Some(ObjectName(vec![Ident {\n                    value: \"helena\".into(),\n                    quote_style: None\n                }]))\n            );\n        }\n        _ => unreachable!(),\n    }\n}"}
{"test_id": "Keats-tera/Keats-tera-1f95878/src/renderer/tests/errors.rs::error_location_basic", "code": "pub fn render(&self, template_name: &str, context: &Context) -> Result<String> {\n        let template = self.get_template(template_name)?;\n        let renderer = Renderer::new(template, self, context);\n        renderer.render()\n    }", "test": "fn error_location_basic() {\n    let mut tera = Tera::default();\n    tera.add_raw_templates(vec![(\"tpl\", \"{{ 1 + true }}\")]).unwrap();\n\n    let result = tera.render(\"tpl\", &Context::new());\n\n    assert_eq!(result.unwrap_err().to_string(), \"Failed to render \\'tpl\\'\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_unsafe_recovery.rs::test_unsafe_recovery_create_region", "code": "pub fn sleep_ms(ms: u64) {\n    std::thread::sleep(Duration::from_millis(ms));\n}", "test": "fn test_unsafe_recovery_create_region() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    // Disable default max peer number check.\n    pd_client.disable_default_operator();\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let store0_peer = find_peer(&region, nodes[0]).unwrap().to_owned();\n\n    // Removes the boostrap region, since it overlaps with any regions we create.\n    pd_client.must_remove_peer(region.get_id(), store0_peer);\n    cluster.must_remove_region(nodes[0], region.get_id());\n\n    cluster.stop_node(nodes[1]);\n    cluster.stop_node(nodes[2]);\n    cluster.must_wait_for_leader_expire(nodes[0], region.get_id());\n\n    let mut create = metapb::Region::default();\n    create.set_id(101);\n    create.set_start_key(b\"anykey\".to_vec());\n    let mut peer = metapb::Peer::default();\n    peer.set_id(102);\n    peer.set_store_id(nodes[0]);\n    create.mut_peers().push(peer);\n    let mut plan = pdpb::RecoveryPlan::default();\n    plan.mut_creates().push(create);\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);\n    cluster.must_send_store_heartbeat(nodes[0]);\n    let mut created = false;\n    for _ in 1..11 {\n        let region = pd_client.get_region(b\"anykey1\").unwrap();\n        if region.get_id() == 101 {\n            created = true;\n        }\n        sleep_ms(200);\n    }\n    assert_eq!(created, true);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_timeout.rs::test_preserve_status", "code": "pub fn no_stdout(&self) -> &Self {\n        assert!(\n            self.stdout.is_empty(),\n            \"Expected stdout to be empty, but it's:\\n{}\",\n            self.stdout_str()\n        );\n        self\n    }", "test": "fn test_preserve_status() {\n    new_ucmd!()\n        .args(&[\"--preserve-status\", \".1\", \"sleep\", \"10\"])\n        .fails()\n        // 128 + SIGTERM = 128 + 15\n        .code_is(128 + 15)\n        .no_stderr()\n        .no_stdout();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_split.rs::test_numeric_suffix", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_numeric_suffix() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-n\", \"4\", \"--numeric-suffixes=9\", \"threebytes.txt\"])\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"x09\"), \"a\");\n    assert_eq!(at.read(\"x10\"), \"b\");\n    assert_eq!(at.read(\"x11\"), \"c\");\n    assert_eq!(at.read(\"x12\"), \"\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_csplit.rs::test_up_to_no_match2", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_up_to_no_match2() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"/4/\", \"/nope/\", \"{50}\"])\n        .fails()\n        .stdout_is(\"6\\n135\\n\")\n        .stderr_is(\"csplit: '/nope/': match not found\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"counting splits\")\n        .count();\n    assert_eq!(count, 0);\n\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"/4/\", \"/nope/\", \"{50}\", \"-k\"])\n        .fails()\n        .stdout_is(\"6\\n135\\n\")\n        .stderr_is(\"csplit: '/nope/': match not found\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"counting splits\")\n        .count();\n    assert_eq!(count, 2);\n    assert_eq!(at.read(\"xx00\"), generate(1, 4));\n    assert_eq!(at.read(\"xx01\"), generate(4, 51));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_du.rs::test_du_symlink_multiple_fail", "code": "fn code(&self) -> i32 {\n        match self {\n            Self::BackupImpossible() => 2,\n            _ => 1,\n        }\n    }", "test": "fn test_du_symlink_multiple_fail() {\n    let ts = TestScenario::new(util_name!());\n    let at = &ts.fixtures;\n\n    at.symlink_file(\"non-existing.txt\", \"target.txt\");\n    let mut file1 = at.make_file(\"file1\");\n    file1.write_all(b\"azeaze\").unwrap();\n\n    let result = ts.ucmd().arg(\"-L\").arg(\"target.txt\").arg(\"file1\").fails();\n    assert_eq!(result.code(), 1);\n    result.stdout_contains(\"4\\tfile1\\n\");\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/line_prefixes.rs::infallible_after_quiet", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn infallible_after_quiet() {\n  Test::new()\n    .justfile(\n      \"\n        foo:\n          @-exit 1\n      \",\n    )\n    .run();\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/lint.rs::fs_error_dereferenced_symlink", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn fs_error_dereferenced_symlink() {\n    let fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let root_path = temp_dir().join(\"lint_rome_test_broken_symlink\");\n    let subdir_path = root_path.join(\"prefix\");\n\n    let _ = remove_dir_all(&root_path);\n    create_dir(&root_path).unwrap();\n    create_dir(subdir_path).unwrap();\n\n    #[cfg(target_family = \"unix\")]\n    {\n        symlink(root_path.join(\"null\"), root_path.join(\"broken_symlink\")).unwrap();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        check_windows_symlink!(symlink_file(\n            root_path.join(\"null\"),\n            root_path.join(\"broken_symlink\")\n        ));\n    }\n\n    let result = run_cli(\n        DynRef::Owned(Box::new(OsFileSystem)),\n        &mut console,\n        Args::from([(\"lint\"), root_path.display().to_string().as_str()].as_slice()),\n    );\n\n    remove_dir_all(root_path).unwrap();\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"fs_error_dereferenced_symlink\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/slash_operator.rs::no_lhs_parenthesized", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn no_lhs_parenthesized() {\n  Test::new()\n    .justfile(\n      \"\n      foo x=(/ 'a' / 'b'):\n        echo {{x}}\n    \",\n    )\n    .stderr(\"echo /a/b\\n\")\n    .stdout(\"/a/b\\n\")\n    .run();\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/dnssec_client_handle_tests.rs::test_secure_query_example_tcp", "code": "fn with_tcp<F>(test: F)\nwhere\n    F: Fn(DnssecDnsHandle<MemoizeClientHandle<AsyncClient>>, Runtime),\n{\n    let succeeded = std::sync::Arc::new(std::sync::atomic::AtomicBool::new(false));\n    let succeeded_clone = succeeded.clone();\n    let join = std::thread::Builder::new()\n        .name(\"thread_killer\".to_string())\n        .spawn(move || {\n            let succeeded = succeeded_clone;\n            for _ in 0..15 {\n                std::thread::sleep(std::time::Duration::from_secs(1));\n                if succeeded.load(std::sync::atomic::Ordering::Relaxed) {\n                    return;\n                }\n            }\n\n            println!(\"Thread Killer has been awoken, killing process\");\n            std::process::exit(-1);\n        })\n        .unwrap();\n\n    let io_loop = Runtime::new().unwrap();\n    let addr: SocketAddr = (\"8.8.8.8\", 53).to_socket_addrs().unwrap().next().unwrap();\n    let (stream, sender) = TcpClientStream::<AsyncIoTokioAsStd<TokioTcpStream>>::new(addr);\n    let client = AsyncClient::new(Box::new(stream), sender, None);\n    let (client, bg) = io_loop.block_on(client).expect(\"client failed to connect\");\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    let client = MemoizeClientHandle::new(client);\n    let secure_client = DnssecDnsHandle::new(client);\n\n    test(secure_client, io_loop);\n    succeeded.store(true, std::sync::atomic::Ordering::Relaxed);\n    join.join().unwrap();\n}", "test": "fn test_secure_query_example_tcp() {\n    with_tcp(test_secure_query_example);\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/slash_operator.rs::default_un_parenthesized", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn default_un_parenthesized() {\n  Test::new()\n    .justfile(\n      \"\n      foo x='a' / 'b':\n        echo {{x}}\n    \",\n    )\n    .stderr(\n      \"\n      error: Expected '*', ':', '$', identifier, or '+', but found '/'\n        |\n      1 | foo x='a' / 'b':\n        |           ^\n    \",\n    )\n    .status(EXIT_FAILURE)\n    .run();\n}"}
{"test_id": "Keats-tera/Keats-tera-1f95878/src/parser/tests/errors.rs::invalid_macro_call", "code": "fn assert_err_msg(input: &str, needles: &[&str]) {\n    let res = parse(input);\n    assert!(res.is_err());\n    let err = res.unwrap_err();\n    let err_msg = err.to_string();\n    println!(\"{}\", err_msg);\n    println!(\"Looking for:\");\n    for needle in needles {\n        println!(\"{}\", needle);\n        assert!(err_msg.contains(needle));\n    }\n}", "test": "fn invalid_macro_call() {\n    assert_err_msg(\n        \"{{ my:macro() }}\",\n        &[\n            \"1:6\",\n            \"expected `or`, `and`, `not`, `<=`, `>=`, `<`, `>`, `==`, `!=`, `+`, `-`, `*`, `/`, `%`, a filter, or a variable end (`}}`)\"\n        ],\n    );\n}"}
{"test_id": "mitsuhiko-minijinja/mitsuhiko-minijinja-5f2c1e8/minijinja/tests/test_environment.rs::test_expression", "code": "pub fn eval<S: Serialize>(&self, ctx: S) -> Result<Value, Error> {\n        // reduce total amount of code faling under mono morphization into\n        // this function, and share the rest in _eval.\n        self._eval(Value::from_serializable(&ctx))\n    }", "test": "fn test_expression() {\n    let env = Environment::new();\n    let expr = env.compile_expression(\"foo + bar\").unwrap();\n    let mut ctx = BTreeMap::new();\n    ctx.insert(\"foo\", 42);\n    ctx.insert(\"bar\", 23);\n    assert_eq!(expr.eval(&ctx).unwrap(), Value::from(65));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_wc.rs::test_utf8_line_length_lines_words", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_utf8_line_length_lines_words() {\n    new_ucmd!()\n        .arg(\"-Llw\")\n        .pipe_in_fixture(\"UTF_8_weirdchars.txt\")\n        .run()\n        .stdout_is(\"     25      87      48\\n\");\n}"}
{"test_id": "astral-sh-ruff/astral-sh-ruff-1a6898a/crates/ruff_python_ast/tests/preorder.rs::list_comprehension", "code": "fn trace_preorder_visitation(source: &str) -> String {\n    let tokens = lex(source, Mode::Module);\n    let parsed = parse_tokens(tokens, source, Mode::Module, \"test.py\").unwrap();\n\n    let mut visitor = RecordVisitor::default();\n    visitor.visit_mod(&parsed);\n\n    visitor.output\n}", "test": "fn list_comprehension() {\n    let source = \"[x for x in numbers]\";\n\n    let trace = trace_preorder_visitation(source);\n\n    assert_snapshot!(trace);\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/control_flow/loops.rs::do_while_in_block", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn do_while_in_block() {\n    run_test_actions([TestAction::assert_eq(\n        indoc! {r#\"\n            {\n                var i = 0;\n                do {\n                    i += 1;\n                }\n                while(false);\n                i;\n            }\n        \"#},\n        1,\n    )]);\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-parse-float/tests/bellerophon_tests.rs::compute_float_f32_test", "code": "pub fn compute_float32(q: i64, w: u64) -> (i32, u64) {\n    let num = Number {\n        exponent: q,\n        mantissa: w,\n        is_negative: false,\n        many_digits: false,\n        integer: &[],\n        fraction: None,\n    };\n    let fp = bellerophon::<f32, { STANDARD }>(&num, false);\n    (fp.exp, fp.mant)\n}", "test": "fn compute_float_f32_test() {\n    // These test near-halfway cases for single-precision floats.\n    assert_eq!(compute_float32(0, 16777216), (151, 0));\n    assert_eq!(compute_float32(0, 16777217), (111 + INVALID_FP, 9223372586610589696));\n    assert_eq!(compute_float32(0, 16777218), (151, 1));\n    assert_eq!(compute_float32(0, 16777219), (111 + INVALID_FP, 9223373686122217472));\n    assert_eq!(compute_float32(0, 16777220), (151, 2));\n\n    // These are examples of the above tests, with\n    // digits from the exponent shifted to the mantissa.\n    assert_eq!(compute_float32(-10, 167772160000000000), (151, 0));\n    assert_eq!(compute_float32(-10, 167772170000000000), (111 + INVALID_FP, 9223372586610589696));\n    assert_eq!(compute_float32(-10, 167772180000000000), (151, 1));\n    // Let's check the lines to see if anything is different in table...\n    assert_eq!(compute_float32(-10, 167772190000000000), (111 + INVALID_FP, 9223373686122217472));\n    assert_eq!(compute_float32(-10, 167772200000000000), (151, 2));\n}"}
{"test_id": "mitsuhiko-minijinja/mitsuhiko-minijinja-5f2c1e8/minijinja/tests/test_value.rs::test_return_none", "code": "pub fn is_none(v: Value) -> bool {\n    v.is_none()\n}", "test": "fn test_return_none() {\n    let env = Environment::empty();\n    let val = Value::from_function(|| -> Result<(), Error> { Ok(()) });\n    let rv = val.call(&env.empty_state(), &[][..]).unwrap();\n    assert!(rv.is_none());\n    let val = Value::from_function(|| ());\n    let rv = val.call(&env.empty_state(), &[][..]).unwrap();\n    assert!(rv.is_none());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_nl.rs::test_stdin_no_newline", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_stdin_no_newline() {\n    new_ucmd!()\n        .pipe_in(\"No Newline\")\n        .run()\n        .stdout_is(\"     1\\tNo Newline\\n\");\n}"}
{"test_id": "raphlinus-pulldown-cmark/raphlinus-pulldown-cmark-3da63d5/tests/suite/heading_attrs.rs::heading_attrs_test_39", "code": "pub fn test_markdown_html(input: &str, output: &str, smart_punct: bool) {\n    let mut s = String::new();\n\n    let mut opts = Options::empty();\n    opts.insert(Options::ENABLE_TABLES);\n    opts.insert(Options::ENABLE_FOOTNOTES);\n    opts.insert(Options::ENABLE_STRIKETHROUGH);\n    opts.insert(Options::ENABLE_TASKLISTS);\n    if smart_punct {\n        opts.insert(Options::ENABLE_SMART_PUNCTUATION);\n    }\n    opts.insert(Options::ENABLE_HEADING_ATTRIBUTES);\n\n    let p = Parser::new_ext(input, opts);\n    pulldown_cmark::html::push_html(&mut s, p);\n\n    assert_eq!(normalize_html(output), normalize_html(&s));\n}", "test": "fn heading_attrs_test_39() {\n    let original = r##\"# horizontal tab (U+000A) {#ht    .myclass}\n## form feed (U+000C) {#ff\f.myclass}\n\n# vertical tab (U+000B) {#vt\u000b.myclass}\n\"##;\n    let expected = r##\"<h1 id=\"ht\" class=\"myclass\">horizontal tab (U+000A)</h1>\n<h2 id=\"ff\" class=\"myclass\">form feed (U+000C)</h2>\n<h1 id=\"vt\u000b.myclass\">vertical tab (U+000B)</h1>\n\"##;\n\n    test_markdown_html(original, expected, false);\n}"}
{"test_id": "ordinals-ord/ordinals-ord-8090538/tests/wallet/send.rs::do_not_send_within_dust_limit_of_an_inscription", "code": "pub(crate) fn run_and_extract_stdout(self) -> String {\n    self.run().1\n  }", "test": "fn do_not_send_within_dust_limit_of_an_inscription() {\n  let rpc_server = test_bitcoincore_rpc::spawn();\n  create_wallet(&rpc_server);\n\n  let (inscription, reveal) = inscribe(&rpc_server);\n\n  rpc_server.mine_blocks(1);\n\n  let output = OutPoint {\n    txid: reveal,\n    vout: 0,\n  };\n\n  CommandBuilder::new(format!(\n    \"wallet send --fee-rate 1 bc1qw508d6qejxtdg4y5r3zarvary0c5xw7kv8f3t4 {output}:329\"\n  ))\n  .rpc_server(&rpc_server)\n  .expected_exit_code(1)\n  .expected_stderr(format!(\n    \"error: cannot send {output}:329 without also sending inscription {inscription} at {output}:0\\n\"\n  ))\n  .run_and_extract_stdout();\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_multi.rs::test_multi_node_lost_majority", "code": "fn test_multi_lost_majority<T: Simulator>(cluster: &mut Cluster<T>, count: usize) {\n    cluster.run();\n    let leader = cluster.leader_of_region(1);\n\n    let half = (count as u64 + 1) / 2;\n    for i in 1..=half {\n        cluster.stop_node(i);\n    }\n    if let Some(leader) = leader {\n        if leader.get_store_id() > half {\n            cluster.stop_node(leader.get_store_id());\n        }\n    }\n    cluster.reset_leader_of_region(1);\n    sleep_ms(600);\n\n    assert!(cluster.leader_of_region(1).is_none());\n}", "test": "fn test_multi_node_lost_majority() {\n    let mut tests = vec![4, 5];\n    for count in tests.drain(..) {\n        let mut cluster = new_node_cluster(0, count);\n        test_multi_lost_majority(&mut cluster, count)\n    }\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/raftstore-v2/tests/integrations/test_conf_change.rs::test_simple_change", "code": "pub fn latest(&mut self) -> Option<&EK> {\n        if self.latest.version.load(Ordering::Relaxed) > self.version {\n            let latest_data = self.latest.data.lock().unwrap();\n            self.version = self.latest.version.load(Ordering::Relaxed);\n            self.cache = latest_data.clone();\n        }\n        self.cache()\n    }", "test": "fn test_simple_change() {\n    let mut cluster = Cluster::with_node_count(2, None);\n    let (region_id, peer_id, offset_id) = (2, 10, 1);\n\n    // 1. add learner on store-2\n    add_learner(&cluster, offset_id, region_id, peer_id);\n    let meta = cluster.routers[0]\n        .must_query_debug_info(region_id, Duration::from_secs(3))\n        .unwrap();\n    let match_index = meta.raft_apply.applied_index;\n\n    // 2. write one kv after snapshot\n    let (key, val) = (b\"key\", b\"value\");\n    write_kv(&cluster, region_id, key, val);\n    let meta = cluster.routers[1]\n        .must_query_debug_info(region_id, Duration::from_secs(3))\n        .unwrap();\n    // the learner truncated index muse be equal the leader applied index and can\n    // read the new written kv.\n    assert_eq!(match_index, meta.raft_apply.truncated_state.index);\n    assert!(meta.raft_apply.applied_index >= match_index);\n    let snap = cluster.routers[offset_id].stale_snapshot(region_id);\n    assert_eq!(snap.get_value(key).unwrap().unwrap(), val);\n    // 3. remove peer from store-2\n    remove_peer(&cluster, offset_id, region_id, peer_id);\n\n    // To avaid that some status doesn't clear after destroying, it can support to\n    // create peer by many times.\n    let repeat = 3;\n    for i in 1..repeat {\n        add_learner(&cluster, offset_id, region_id, peer_id + i);\n        write_kv(&cluster, region_id, key, val);\n        remove_peer(&cluster, offset_id, region_id, peer_id + i);\n    }\n\n    add_learner(&cluster, offset_id, region_id, peer_id + repeat);\n    write_kv(&cluster, region_id, key, val);\n    let snap = cluster.routers[offset_id].stale_snapshot(region_id);\n    assert_eq!(snap.get_value(key).unwrap().unwrap(), val);\n\n    // TODO: check if the peer is removed once life trace is implemented or\n    // snapshot is implemented.\n    // Check if WAL is skipped for admin command.\n    let mut cached = cluster.node(0).tablet_registry().get(region_id).unwrap();\n    check_skip_wal(cached.latest().unwrap().as_inner().path());\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/lint.rs::no_lint_when_file_is_ignored", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn no_lint_when_file_is_ignored() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"biome.json\");\n    fs.insert(file_path.into(), CONFIG_LINTER_IGNORED_FILES.as_bytes());\n\n    let file_path = Path::new(\"test.js\");\n    fs.insert(file_path.into(), FIX_BEFORE.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"lint\"),\n                (\"--apply\"),\n                file_path.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut buffer = String::new();\n    fs.open(file_path)\n        .unwrap()\n        .read_to_string(&mut buffer)\n        .unwrap();\n\n    assert_eq!(buffer, FIX_BEFORE);\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"no_lint_when_file_is_ignored\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_touch.rs::test_touch_reference", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_reference() {\n    let scenario = TestScenario::new(\"touch\");\n    let (at, mut _ucmd) = (scenario.fixtures.clone(), scenario.ucmd());\n    let file_a = \"test_touch_reference_a\";\n    let file_b = \"test_touch_reference_b\";\n    let start_of_year = str_to_filetime(\"%Y%m%d%H%M\", \"201501010000\");\n\n    at.touch(file_a);\n    set_file_times(&at, file_a, start_of_year, start_of_year);\n    assert!(at.file_exists(file_a));\n    for opt in [\"-r\", \"--ref\", \"--reference\"] {\n        scenario\n            .ccmd(\"touch\")\n            .args(&[opt, file_a, file_b])\n            .succeeds()\n            .no_stderr();\n\n        assert!(at.file_exists(file_b));\n\n        let (atime, mtime) = get_file_times(&at, file_b);\n        assert_eq!(atime, mtime);\n        assert_eq!(atime, start_of_year);\n        assert_eq!(mtime, start_of_year);\n        let _ = remove_file(file_b);\n    }\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_common.rs::parse_from_advanced", "code": "pub fn verified_only_select(&self, query: &str) -> Select {\n        match *self.verified_query(query).body {\n            SetExpr::Select(s) => *s,\n            _ => panic!(\"Expected SetExpr::Select\"),\n        }\n    }", "test": "fn parse_from_advanced() {\n    let sql = \"SELECT * FROM fn(1, 2) AS foo, schema.bar AS bar WITH (NOLOCK)\";\n    let _select = verified_only_select(sql);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_hostid.rs::test_normal", "code": "pub fn stdout_matches(&self, regex: &regex::Regex) -> &Self {\n        assert!(\n            regex.is_match(self.stdout_str()),\n            \"Stdout does not match regex:\\n{}\",\n            self.stdout_str()\n        );\n        self\n    }", "test": "fn test_normal() {\n    let re = Regex::new(r\"^[0-9a-f]{8}\").unwrap();\n    new_ucmd!().succeeds().stdout_matches(&re);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_arg_update_all", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_arg_update_all() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .arg(\"--update=all\")\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    assert_eq!(\n        at.read(TEST_HOW_ARE_YOU_SOURCE),\n        at.read(TEST_HELLO_WORLD_SOURCE)\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_mkdir.rs::test_mkdir_dup_dir_parent", "code": "pub fn succeeds(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.success();\n        cmd_result\n    }", "test": "fn test_mkdir_dup_dir_parent() {\n    let _guard = TEST_MUTEX.lock();\n\n    let scene = TestScenario::new(util_name!());\n    let test_dir = \"test_dir\";\n\n    scene.ucmd().arg(test_dir).succeeds();\n    scene.ucmd().arg(\"-p\").arg(test_dir).succeeds();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_mv.rs::test_mv_fail", "code": "pub fn fails(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.failure();\n        cmd_result\n    }", "test": "fn test_mv_fail() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir1 = \"test_mv_rename_dir\";\n\n    at.mkdir(dir1);\n\n    ucmd.arg(dir1).fails();\n}"}
{"test_id": "astral-sh-ruff/astral-sh-ruff-1a6898a/crates/ruff_python_ast/tests/visitor.rs::compare", "code": "fn trace_visitation(source: &str) -> String {\n    let tokens = lex(source, Mode::Module);\n    let parsed = parse_tokens(tokens, source, Mode::Module, \"test.py\").unwrap();\n\n    let mut visitor = RecordVisitor::default();\n    walk_module(&mut visitor, &parsed);\n\n    visitor.output\n}", "test": "fn compare() {\n    let source = r#\"4 < x < 5\"#;\n\n    let trace = trace_visitation(source);\n\n    assert_snapshot!(trace);\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-write-float/tests/algorithm_tests.rs::floor_log10_pow2_minus_log10_4_over_3_test", "code": "fn dragonbox_log10_2_sub_log10_4_div3(q: i32) -> i32 {\n    let c = floor_shift(0, 0x4d104d427de7fbcc, 22);\n    let s = floor_shift(0, 0x1ffbfc2bbc780375, 22);\n    (q * c - s) >> 22\n}", "test": "fn floor_log10_pow2_minus_log10_4_over_3_test() {\n    for q in -1700i32..=1700 {\n        let actual = algorithm::floor_log10_pow2_minus_log10_4_over_3(q);\n        let expected = dragonbox_log10_2_sub_log10_4_div3(q);\n        assert_eq!(actual, expected);\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_parents_dest_not_directory", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_cp_parents_dest_not_directory() {\n    new_ucmd!()\n        .arg(\"--parents\")\n        .arg(TEST_COPY_FROM_FOLDER_FILE)\n        .arg(TEST_HELLO_WORLD_DEST)\n        .fails()\n        .stderr_contains(\"with --parents, the destination must be a directory\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_no_deref_link_onto_link", "code": "pub fn is_symlink(&self, path: &str) -> bool {\n        log_info(\"is_symlink\", self.plus_as_string(path));\n        match fs::symlink_metadata(self.plus(path)) {\n            Ok(m) => m.file_type().is_symlink(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_cp_no_deref_link_onto_link() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    at.copy(TEST_HELLO_WORLD_SOURCE, TEST_HELLO_WORLD_DEST);\n\n    #[cfg(not(windows))]\n    let _r = fs::symlink(\n        TEST_HELLO_WORLD_SOURCE,\n        at.subdir.join(TEST_HELLO_WORLD_SOURCE_SYMLINK),\n    );\n    #[cfg(windows)]\n    let _r = symlink_file(\n        TEST_HELLO_WORLD_SOURCE,\n        at.subdir.join(TEST_HELLO_WORLD_SOURCE_SYMLINK),\n    );\n\n    #[cfg(not(windows))]\n    let _r = fs::symlink(\n        TEST_HELLO_WORLD_DEST,\n        at.subdir.join(TEST_HELLO_WORLD_DEST_SYMLINK),\n    );\n    #[cfg(windows)]\n    let _r = symlink_file(\n        TEST_HELLO_WORLD_DEST,\n        at.subdir.join(TEST_HELLO_WORLD_DEST_SYMLINK),\n    );\n\n    ucmd.arg(\"-P\")\n        .arg(TEST_HELLO_WORLD_SOURCE_SYMLINK)\n        .arg(TEST_HELLO_WORLD_DEST_SYMLINK)\n        .succeeds();\n\n    // Ensure that the target of the destination was not modified.\n    assert!(!at\n        .symlink_metadata(TEST_HELLO_WORLD_DEST)\n        .file_type()\n        .is_symlink());\n    assert!(at\n        .symlink_metadata(TEST_HELLO_WORLD_DEST_SYMLINK)\n        .file_type()\n        .is_symlink());\n    assert_eq!(at.read(TEST_HELLO_WORLD_DEST_SYMLINK), \"Hello, World!\\n\");\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/cli_tests.rs::preview2_stdin", "code": "fn success() -> Self {\n        Self::Success\n    }", "test": "fn preview2_stdin() -> Result<()> {\n    let test = \"tests/all/cli_tests/count-stdin.wat\";\n    let cmd = || -> Result<_> {\n        let mut cmd = get_wasmtime_command()?;\n        cmd.arg(\"--invoke=count\").arg(\"-Spreview2\").arg(test);\n        Ok(cmd)\n    };\n\n    // read empty pipe is ok\n    let output = cmd()?.output()?;\n    assert!(output.status.success());\n    assert_eq!(String::from_utf8_lossy(&output.stdout), \"0\\n\");\n\n    // read itself is ok\n    let file = File::open(test)?;\n    let size = file.metadata()?.len();\n    let output = cmd()?.stdin(File::open(test)?).output()?;\n    assert!(output.status.success());\n    assert_eq!(String::from_utf8_lossy(&output.stdout), format!(\"{size}\\n\"));\n\n    // read piped input ok is ok\n    let mut child = cmd()?\n        .stdin(Stdio::piped())\n        .stdout(Stdio::piped())\n        .stderr(Stdio::piped())\n        .spawn()?;\n    let mut stdin = child.stdin.take().unwrap();\n    std::thread::spawn(move || {\n        stdin.write_all(b\"hello\").unwrap();\n    });\n    let output = child.wait_with_output()?;\n    assert!(output.status.success());\n    assert_eq!(String::from_utf8_lossy(&output.stdout), \"5\\n\");\n\n    let count_up_to = |n: usize| -> Result<_> {\n        let mut child = get_wasmtime_command()?\n            .arg(\"--invoke=count-up-to\")\n            .arg(\"-Spreview2\")\n            .arg(test)\n            .arg(n.to_string())\n            .stdin(Stdio::piped())\n            .stdout(Stdio::piped())\n            .stderr(Stdio::piped())\n            .spawn()?;\n        let mut stdin = child.stdin.take().unwrap();\n        let t = std::thread::spawn(move || {\n            let mut written = 0;\n            let bytes = [0; 64 * 1024];\n            loop {\n                written += match stdin.write(&bytes) {\n                    Ok(n) => n,\n                    Err(_) => break written,\n                };\n            }\n        });\n        let output = child.wait_with_output()?;\n        assert!(output.status.success());\n        let written = t.join().unwrap();\n        let read = String::from_utf8_lossy(&output.stdout)\n            .trim()\n            .parse::<usize>()\n            .unwrap();\n        // The test reads in 1000 byte chunks so make sure that it doesn't read\n        // more than 1000 bytes than requested.\n        assert!(read < n + 1000, \"test read too much {read}\");\n        Ok(written)\n    };\n\n    // wasmtime shouldn't eat information that the guest never actually tried to\n    // read.\n    //\n    // NB: this may be a bit flaky. Exactly how much we wrote in the above\n    // helper thread depends on how much the OS buffers for us. For now give\n    // some some slop and assume that OSes are unlikely to buffer more than\n    // that.\n    let slop = 256 * 1024;\n    for amt in [0, 100, 100_000] {\n        let written = count_up_to(amt)?;\n        assert!(written < slop + amt, \"wrote too much {written}\");\n    }\n    Ok(())\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_pr.rs::test_value_for_number_lines", "code": "pub fn fails(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.failure();\n        cmd_result\n    }", "test": "fn test_value_for_number_lines() {\n    // *5 is of the form [SEP[NUMBER]] so is accepted and succeeds\n    new_ucmd!().args(&[\"-n\", \"*5\", \"test.log\"]).succeeds();\n\n    // a is of the form [SEP[NUMBER]] so is accepted and succeeds\n    new_ucmd!().args(&[\"-n\", \"a\", \"test.log\"]).succeeds();\n\n    // foo5.txt is of not the form [SEP[NUMBER]] so is not used as value.\n    // Therefore, pr tries to access the file, which does not exist.\n    new_ucmd!().args(&[\"-n\", \"foo5.txt\", \"test.log\"]).fails();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_readlink.rs::test_canonicalize", "code": "pub fn root_dir_resolved(&self) -> String {\n        log_info(\"current_directory_resolved\", \"\");\n        let s = self\n            .subdir\n            .canonicalize()\n            .unwrap()\n            .to_str()\n            .unwrap()\n            .to_owned();\n\n        // Due to canonicalize()'s use of GetFinalPathNameByHandleW() on Windows, the resolved path\n        // starts with '\\\\?\\' to extend the limit of a given path to 32,767 wide characters.\n        //\n        // To address this issue, we remove this prepended string if available.\n        //\n        // Source:\n        // http://stackoverflow.com/questions/31439011/getfinalpathnamebyhandle-without-prepended\n        let prefix = \"\\\\\\\\?\\\\\";\n\n        if let Some(stripped) = s.strip_prefix(prefix) {\n            String::from(stripped)\n        } else {\n            s\n        }\n    }", "test": "fn test_canonicalize() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let actual = ucmd.arg(\"-f\").arg(\".\").run().stdout_move_str();\n    let expect = at.root_dir_resolved() + \"\\n\";\n    println!(\"actual: {actual:?}\");\n    println!(\"expect: {expect:?}\");\n    assert_eq!(actual, expect);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/storage/test_storage.rs::test_txn_store_resolve_lock_in_a_batch", "code": "pub fn scan_locks_ok(\n        &self,\n        max_ts: impl Into<TimeStamp>,\n        start_key: &[u8],\n        end_key: &[u8],\n        limit: usize,\n        expect: Vec<LockInfo>,\n    ) {\n        let start_key = if start_key.is_empty() {\n            None\n        } else {\n            Some(Key::from_raw(start_key))\n        };\n        let end_key = if end_key.is_empty() {\n            None\n        } else {\n            Some(Key::from_raw(end_key))\n        };\n\n        assert_eq!(\n            self.store\n                .scan_locks(self.ctx.clone(), max_ts.into(), start_key, end_key, limit)\n                .unwrap(),\n            expect\n        );\n    }", "test": "fn test_txn_store_resolve_lock_in_a_batch() {\n    let store = AssertionStorage::default();\n\n    store.prewrite_ok(\n        vec![\n            Mutation::make_put(Key::from_raw(b\"p1\"), b\"v5\".to_vec()),\n            Mutation::make_put(Key::from_raw(b\"s1\"), b\"v5\".to_vec()),\n        ],\n        b\"p1\",\n        5,\n    );\n    store.prewrite_ok(\n        vec![\n            Mutation::make_put(Key::from_raw(b\"p2\"), b\"v10\".to_vec()),\n            Mutation::make_put(Key::from_raw(b\"s2\"), b\"v10\".to_vec()),\n        ],\n        b\"p2\",\n        10,\n    );\n    store.resolve_lock_batch_ok(5, 0, 10, 20);\n    store.get_none(b\"p1\", 30);\n    store.get_none(b\"s1\", 30);\n    store.get_ok(b\"p2\", 30, b\"v10\");\n    store.get_ok(b\"s2\", 30, b\"v10\");\n    store.scan_locks_ok(30, b\"\", b\"\", 100, vec![]);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_unexpand.rs::test_tabs_must_be_ascending", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_tabs_must_be_ascending() {\n    new_ucmd!()\n        .arg(\"--tabs=1,1\")\n        .fails()\n        .stderr_contains(\"tab sizes must be ascending\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/cdc/tests/failpoints/test_resolve.rs::test_region_error", "code": "pub fn stop(&mut self) {\n        self.mut_store().cancel_applying_snap();\n        self.pending_reads.clear_all(None);\n    }", "test": "fn test_region_error() {\n    let mut cluster = new_server_cluster(1, 1);\n    cluster.cfg.cdc.min_ts_interval = ReadableDuration::millis(100);\n    let mut suite = TestSuiteBuilder::new().cluster(cluster).build();\n\n    let multi_batch_fp = \"cdc_before_handle_multi_batch\";\n    fail::cfg(multi_batch_fp, \"return\").unwrap();\n    let deregister_fp = \"cdc_before_handle_deregister\";\n    fail::cfg(deregister_fp, \"return\").unwrap();\n\n    // Split region\n    let region = suite.cluster.get_region(&[]);\n    suite.cluster.must_split(&region, b\"k1\");\n    // Subscribe source region\n    let source = suite.cluster.get_region(b\"k0\");\n    let mut req = suite.new_changedata_request(region.get_id());\n    req.region_id = source.get_id();\n    req.set_region_epoch(source.get_region_epoch().clone());\n    let (mut source_tx, source_wrap, _source_event) =\n        new_event_feed(suite.get_region_cdc_client(source.get_id()));\n    block_on(source_tx.send((req.clone(), WriteFlags::default()))).unwrap();\n    // Subscribe target region\n    let target = suite.cluster.get_region(b\"k2\");\n    req.region_id = target.get_id();\n    req.set_region_epoch(target.get_region_epoch().clone());\n    let (mut target_tx, target_wrap, target_event) =\n        new_event_feed(suite.get_region_cdc_client(target.get_id()));\n    block_on(target_tx.send((req, WriteFlags::default()))).unwrap();\n    sleep_ms(200);\n\n    suite\n        .cluster\n        .must_try_merge(source.get_id(), target.get_id());\n    sleep_ms(200);\n\n    let mut last_resolved_ts = 0;\n    for _ in 0..5 {\n        let event = target_event(true);\n        if let Some(resolved_ts) = event.resolved_ts.as_ref() {\n            let ts = resolved_ts.ts;\n            assert!(ts > last_resolved_ts);\n            last_resolved_ts = ts;\n        }\n    }\n    fail::remove(multi_batch_fp);\n    fail::remove(deregister_fp);\n\n    source_wrap.replace(None);\n    target_wrap.replace(None);\n    suite.stop();\n}"}
{"test_id": "web-infra-dev-oxc/oxc-project-oxc-884a819/crates/oxc_minifier/tests/esbuild/mod.rs::function", "code": "fn test(args: &[&str]) -> LintResult {\n        let mut new_args = vec![\"--quiet\"];\n        new_args.extend(args);\n        let options = lint_command().run_inner(new_args.as_slice()).unwrap().lint_options;\n        let CliRunResult::LintResult(lint_result) = LintRunner::new(options).run() else {\n            unreachable!()\n        };\n        lint_result\n    }", "test": "fn function() {\n    test(\"function foo(a = (b, c), ...d) {}\", \"function foo(a=(b,c),...d){}\");\n    test(\"function foo({[1 + 2]: a = 3} = {[1 + 2]: 3}) {}\", \"function foo({[3]:a=3}={[3]:3}){}\");\n    test(\n        \"function foo([a = (1, 2), ...[b, ...c]] = [1, [2, 3]]) {}\",\n        \"function foo([a=(1,2),...[b,...c]]=[1,[2,3]]){}\",\n    );\n    test(\"function foo([] = []) {}\", \"function foo([]=[]){}\");\n    test(\"function foo([,] = [,]) {}\", \"function foo([,]=[,]){}\");\n    test(\"function foo([,,] = [,,]) {}\", \"function foo([,,]=[,,]){}\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_chown.rs::test_chown_recursive", "code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_chown_recursive() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let result = scene.cmd(\"whoami\").run();\n    if skipping_test_is_okay(&result, \"whoami: cannot find name for user ID\") {\n        return;\n    }\n    let user_name = String::from(result.stdout_str().trim());\n    assert!(!user_name.is_empty());\n\n    at.mkdir_all(\"a/b/c\");\n    at.mkdir(\"z\");\n    at.touch(at.plus_as_string(\"a/a\"));\n    at.touch(at.plus_as_string(\"a/b/b\"));\n    at.touch(at.plus_as_string(\"a/b/c/c\"));\n    at.touch(at.plus_as_string(\"z/y\"));\n\n    let result = scene\n        .ucmd()\n        .arg(\"-R\")\n        .arg(\"--verbose\")\n        .arg(user_name)\n        .arg(\"a\")\n        .arg(\"z\")\n        .run();\n    result.stderr_contains(\"ownership of 'a/a' retained as\");\n    result.stderr_contains(\"ownership of 'z/y' retained as\");\n}"}
{"test_id": "astral-sh-ruff/astral-sh-ruff-1a6898a/crates/ruff_python_ast/tests/preorder.rs::match_class_pattern", "code": "fn trace_preorder_visitation(source: &str) -> String {\n    let tokens = lex(source, Mode::Module);\n    let parsed = parse_tokens(tokens, source, Mode::Module, \"test.py\").unwrap();\n\n    let mut visitor = RecordVisitor::default();\n    visitor.visit_mod(&parsed);\n\n    visitor.output\n}", "test": "fn match_class_pattern() {\n    let source = r#\"\nmatch x:\n    case Point2D(0, 0):\n        ...\n    case Point3D(x=0, y=0, z=0):\n        ...\n\"#;\n\n    let trace = trace_preorder_visitation(source);\n\n    assert_snapshot!(trace);\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/cli_tests.rs::exit_with_saved_fprs", "code": "fn code(&self, pc: usize) -> Option<(&LoadedCode, usize)> {\n        let (end, (start, code)) = self.loaded_code.range(pc..).next()?;\n        if pc < *start || *end < pc {\n            return None;\n        }\n        Some((code, pc - *start))\n    }", "test": "fn exit_with_saved_fprs() -> Result<()> {\n    let wasm = build_wasm(\"tests/all/cli_tests/exit_with_saved_fprs.wat\")?;\n    let output = run_wasmtime_for_output(&[\"-Ccache=n\", wasm.path().to_str().unwrap()], None)?;\n    assert_eq!(output.status.code().unwrap(), 0);\n    assert!(output.stdout.is_empty());\n    Ok(())\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_fold.rs::test_bytewise_backspace_should_not_decrease_column_count", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_bytewise_backspace_should_not_decrease_column_count() {\n    new_ucmd!()\n        .args(&[\"-w2\", \"-b\"])\n        .pipe_in(\"1\\x08345\")\n        .succeeds()\n        .stdout_is(\"1\\x08\\n34\\n5\");\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/cranelift/object/tests/basic.rs::libcall_function", "code": "pub fn finish(self) -> ModuleTypes {\n        self.types\n    }", "test": "fn libcall_function() {\n    let flag_builder = settings::builder();\n    let isa_builder = cranelift_codegen::isa::lookup_by_name(\"x86_64-unknown-linux-gnu\").unwrap();\n    let isa = isa_builder\n        .finish(settings::Flags::new(flag_builder))\n        .unwrap();\n    let mut module =\n        ObjectModule::new(ObjectBuilder::new(isa, \"foo\", default_libcall_names()).unwrap());\n\n    let sig = Signature {\n        params: vec![],\n        returns: vec![],\n        call_conv: CallConv::SystemV,\n    };\n\n    let func_id = module\n        .declare_function(\"function\", Linkage::Local, &sig)\n        .unwrap();\n\n    let mut ctx = Context::new();\n    ctx.func = Function::with_name_signature(UserFuncName::user(0, func_id.as_u32()), sig);\n    let mut func_ctx = FunctionBuilderContext::new();\n    {\n        let mut bcx: FunctionBuilder = FunctionBuilder::new(&mut ctx.func, &mut func_ctx);\n        let block = bcx.create_block();\n        bcx.switch_to_block(block);\n\n        let int = module.target_config().pointer_type();\n        let zero = bcx.ins().iconst(I16, 0);\n        let size = bcx.ins().iconst(int, 10);\n\n        let mut signature = module.make_signature();\n        signature.params.push(AbiParam::new(int));\n        signature.returns.push(AbiParam::new(int));\n        let callee = module\n            .declare_function(\"malloc\", Linkage::Import, &signature)\n            .expect(\"declare malloc function\");\n        let local_callee = module.declare_func_in_func(callee, &mut bcx.func);\n        let argument_exprs = vec![size];\n        let call = bcx.ins().call(local_callee, &argument_exprs);\n        let buffer = bcx.inst_results(call)[0];\n\n        bcx.call_memset(module.target_config(), buffer, zero, size);\n\n        bcx.ins().return_(&[]);\n    }\n\n    module.define_function(func_id, &mut ctx).unwrap();\n\n    module.finish();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_du.rs::test_du_inodes", "code": "pub fn stdout_str(&self) -> &str {\n        std::str::from_utf8(&self.stdout).unwrap()\n    }", "test": "fn test_du_inodes() {\n    let ts = TestScenario::new(util_name!());\n\n    ts.ucmd()\n        .arg(\"--summarize\")\n        .arg(\"--inodes\")\n        .succeeds()\n        .stdout_only(\"11\\t.\\n\");\n\n    let result = ts.ucmd().arg(\"--separate-dirs\").arg(\"--inodes\").succeeds();\n\n    #[cfg(target_os = \"windows\")]\n    result.stdout_contains(\"3\\t.\\\\subdir\\\\links\\n\");\n    #[cfg(not(target_os = \"windows\"))]\n    result.stdout_contains(\"3\\t./subdir/links\\n\");\n    result.stdout_contains(\"3\\t.\\n\");\n\n    #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n    {\n        let result_reference =\n            unwrap_or_return!(expected_result(&ts, &[\"--separate-dirs\", \"--inodes\"]));\n        assert_eq!(result.stdout_str(), result_reference.stdout_str());\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_ln.rs::test_symlink_target_only", "code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_symlink_target_only() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_symlink_target_only\";\n\n    at.mkdir(dir);\n\n    assert!(!ucmd\n        .args(&[\"-s\", \"-t\", dir])\n        .fails()\n        .stderr_str()\n        .is_empty());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_rm.rs::test_rm_no_operand", "code": "pub fn usage_error<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.stderr_only(format!(\n            \"{0}: {2}\\nTry '{1} {0} --help' for more information.\\n\",\n            self.util_name.as_ref().unwrap(), // This shouldn't be called using a normal command\n            self.bin_path.display(),\n            msg.as_ref()\n        ))\n    }", "test": "fn test_rm_no_operand() {\n    let ts = TestScenario::new(util_name!());\n    ts.ucmd().fails().usage_error(\"missing operand\");\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-write-integer/tests/decimal_tests.rs::u128toa_test", "code": "pub const fn decimal() -> u128 {\n        let mut builder = Self::new();\n        builder.mantissa_radix = 10;\n        builder.exponent_base = num::NonZeroU8::new(10);\n        builder.exponent_radix = num::NonZeroU8::new(10);\n        builder.build()\n    }", "test": "fn u128toa_test() {\n    let mut buffer = [b'\\x00'; 48];\n    unsafe {\n        assert_eq!(5u128.decimal(&mut buffer), 1);\n        assert_eq!(&buffer[..1], b\"5\");\n\n        assert_eq!(11u128.decimal(&mut buffer), 2);\n        assert_eq!(&buffer[..2], b\"11\");\n\n        assert_eq!(99u128.decimal(&mut buffer), 2);\n        assert_eq!(&buffer[..2], b\"99\");\n\n        assert_eq!(101u128.decimal(&mut buffer), 3);\n        assert_eq!(&buffer[..3], b\"101\");\n\n        assert_eq!(999u128.decimal(&mut buffer), 3);\n        assert_eq!(&buffer[..3], b\"999\");\n\n        assert_eq!(1001u128.decimal(&mut buffer), 4);\n        assert_eq!(&buffer[..4], b\"1001\");\n\n        assert_eq!(9999u128.decimal(&mut buffer), 4);\n        assert_eq!(&buffer[..4], b\"9999\");\n\n        assert_eq!(10001u128.decimal(&mut buffer), 5);\n        assert_eq!(&buffer[..5], b\"10001\");\n\n        assert_eq!(65535u128.decimal(&mut buffer), 5);\n        assert_eq!(&buffer[..5], b\"65535\");\n\n        assert_eq!(99999u128.decimal(&mut buffer), 5);\n        assert_eq!(&buffer[..5], b\"99999\");\n\n        assert_eq!(100001u128.decimal(&mut buffer), 6);\n        assert_eq!(&buffer[..6], b\"100001\");\n\n        assert_eq!(999999u128.decimal(&mut buffer), 6);\n        assert_eq!(&buffer[..6], b\"999999\");\n\n        assert_eq!(1000001u128.decimal(&mut buffer), 7);\n        assert_eq!(&buffer[..7], b\"1000001\");\n\n        assert_eq!(9999999u128.decimal(&mut buffer), 7);\n        assert_eq!(&buffer[..7], b\"9999999\");\n\n        assert_eq!(10000001u128.decimal(&mut buffer), 8);\n        assert_eq!(&buffer[..8], b\"10000001\");\n\n        assert_eq!(99999999u128.decimal(&mut buffer), 8);\n        assert_eq!(&buffer[..8], b\"99999999\");\n\n        assert_eq!(100000001u128.decimal(&mut buffer), 9);\n        assert_eq!(&buffer[..9], b\"100000001\");\n\n        assert_eq!(999999999u128.decimal(&mut buffer), 9);\n        assert_eq!(&buffer[..9], b\"999999999\");\n\n        assert_eq!(1000000001u128.decimal(&mut buffer), 10);\n        assert_eq!(&buffer[..10], b\"1000000001\");\n\n        assert_eq!(9999999999u128.decimal(&mut buffer), 10);\n        assert_eq!(&buffer[..10], b\"9999999999\");\n\n        assert_eq!(10000000001u128.decimal(&mut buffer), 11);\n        assert_eq!(&buffer[..11], b\"10000000001\");\n\n        assert_eq!(99999999999u128.decimal(&mut buffer), 11);\n        assert_eq!(&buffer[..11], b\"99999999999\");\n\n        assert_eq!(100000000001u128.decimal(&mut buffer), 12);\n        assert_eq!(&buffer[..12], b\"100000000001\");\n\n        assert_eq!(999999999999u128.decimal(&mut buffer), 12);\n        assert_eq!(&buffer[..12], b\"999999999999\");\n\n        assert_eq!(1000000000001u128.decimal(&mut buffer), 13);\n        assert_eq!(&buffer[..13], b\"1000000000001\");\n\n        assert_eq!(9999999999999u128.decimal(&mut buffer), 13);\n        assert_eq!(&buffer[..13], b\"9999999999999\");\n\n        assert_eq!(10000000000001u128.decimal(&mut buffer), 14);\n        assert_eq!(&buffer[..14], b\"10000000000001\");\n\n        assert_eq!(99999999999999u128.decimal(&mut buffer), 14);\n        assert_eq!(&buffer[..14], b\"99999999999999\");\n\n        assert_eq!(100000000000001u128.decimal(&mut buffer), 15);\n        assert_eq!(&buffer[..15], b\"100000000000001\");\n\n        assert_eq!(999999999999999u128.decimal(&mut buffer), 15);\n        assert_eq!(&buffer[..15], b\"999999999999999\");\n\n        assert_eq!(1000000000000001u128.decimal(&mut buffer), 16);\n        assert_eq!(&buffer[..16], b\"1000000000000001\");\n\n        assert_eq!(9999999999999999u128.decimal(&mut buffer), 16);\n        assert_eq!(&buffer[..16], b\"9999999999999999\");\n\n        assert_eq!(10000000000000001u128.decimal(&mut buffer), 17);\n        assert_eq!(&buffer[..17], b\"10000000000000001\");\n\n        assert_eq!(99999999999999999u128.decimal(&mut buffer), 17);\n        assert_eq!(&buffer[..17], b\"99999999999999999\");\n\n        assert_eq!(100000000000000001u128.decimal(&mut buffer), 18);\n        assert_eq!(&buffer[..18], b\"100000000000000001\");\n\n        assert_eq!(999999999999999999u128.decimal(&mut buffer), 18);\n        assert_eq!(&buffer[..18], b\"999999999999999999\");\n\n        assert_eq!(1000000000000000001u128.decimal(&mut buffer), 19);\n        assert_eq!(&buffer[..19], b\"1000000000000000001\");\n\n        assert_eq!(9999999999999999999u128.decimal(&mut buffer), 19);\n        assert_eq!(&buffer[..19], b\"9999999999999999999\");\n\n        assert_eq!(10000000000000000001u128.decimal(&mut buffer), 20);\n        assert_eq!(&buffer[..20], b\"10000000000000000001\");\n\n        assert_eq!(999999999999999999999999u128.decimal(&mut buffer), 24);\n        assert_eq!(&buffer[..24], b\"999999999999999999999999\");\n\n        assert_eq!(1000000000000000000000001u128.decimal(&mut buffer), 25);\n        assert_eq!(&buffer[..25], b\"1000000000000000000000001\");\n\n        assert_eq!(66620387370000000000000000000u128.decimal(&mut buffer), 29);\n        assert_eq!(&buffer[..29], b\"66620387370000000000000000000\");\n\n        assert_eq!(99999999999999999999999999999u128.decimal(&mut buffer), 29);\n        assert_eq!(&buffer[..29], b\"99999999999999999999999999999\");\n\n        assert_eq!(100000000000000000000000000001u128.decimal(&mut buffer), 30);\n        assert_eq!(&buffer[..30], b\"100000000000000000000000000001\");\n\n        assert_eq!(9999999999999999999999999999999999u128.decimal(&mut buffer), 34);\n        assert_eq!(&buffer[..34], b\"9999999999999999999999999999999999\");\n\n        assert_eq!(10000000000000000000000000000000001u128.decimal(&mut buffer), 35);\n        assert_eq!(&buffer[..35], b\"10000000000000000000000000000000001\");\n\n        assert_eq!(340282366920938463463374607431768211455u128.decimal(&mut buffer), 39);\n        assert_eq!(&buffer[..39], b\"340282366920938463463374607431768211455\");\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_join.rs::empty_files", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn empty_files() {\n    new_ucmd!()\n        .arg(\"empty.txt\")\n        .arg(\"empty.txt\")\n        .succeeds()\n        .stdout_only(\"\");\n\n    new_ucmd!()\n        .arg(\"empty.txt\")\n        .arg(\"fields_1.txt\")\n        .succeeds()\n        .stdout_only(\"\");\n\n    new_ucmd!()\n        .arg(\"fields_1.txt\")\n        .arg(\"empty.txt\")\n        .succeeds()\n        .stdout_only(\"\");\n}"}
{"test_id": "zip-rs-zip/zip-rs-zip-ed187d6/tests/zip_comment_garbage.rs::correctly_handle_zip_with_garbage_after_comment", "code": "pub fn comment(&self) -> &[u8] {\n        &self.shared.comment\n    }", "test": "fn correctly_handle_zip_with_garbage_after_comment() {\n    let mut v = Vec::new();\n    v.extend_from_slice(include_bytes!(\"../tests/data/comment_garbage.zip\"));\n    let archive = ZipArchive::new(io::Cursor::new(v)).expect(\"couldn't open test zip file\");\n\n    assert_eq!(archive.comment(), \"short.\".as_bytes());\n}"}
{"test_id": "image-rs-jpeg-decoder/image-rs-jpeg-decoder-cacc433/tests/lib.rs::read_info", "code": "pub fn info(&self) -> Option<ImageInfo> {\n        match self.frame {\n            Some(ref frame) => {\n                let pixel_format = match frame.components.len() {\n                    1 => match frame.precision {\n                        8 => PixelFormat::L8,\n                        16 => PixelFormat::L16,\n                        _ => panic!(),\n                    },\n                    3 => PixelFormat::RGB24,\n                    4 => PixelFormat::CMYK32,\n                    _ => panic!(),\n                };\n\n                Some(ImageInfo {\n                    width: frame.output_size.width,\n                    height: frame.output_size.height,\n                    pixel_format,\n                    coding_process: frame.coding_process,\n                })\n            }\n            None => None,\n        }\n    }", "test": "fn read_info() {\n    let path = Path::new(\"tests\").join(\"reftest\").join(\"images\").join(\"mozilla\").join(\"jpg-progressive.jpg\");\n\n    let mut decoder = jpeg::Decoder::new(File::open(&path).unwrap());\n    let ref_data = decoder.decode().unwrap();\n    let ref_info = decoder.info().unwrap();\n\n    decoder = jpeg::Decoder::new(File::open(&path).unwrap());\n    decoder.read_info().unwrap();\n    let info = decoder.info().unwrap();\n    let data = decoder.decode().unwrap();\n\n    assert_eq!(info, decoder.info().unwrap());\n    assert_eq!(info, ref_info);\n    assert_eq!(data, ref_data);\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/fallback.rs::fallback_from_subdir_bugfix", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn fallback_from_subdir_bugfix() {\n  Test::new()\n    .write(\n      \"sub/justfile\",\n      unindent(\n        \"\n        set fallback\n\n        @default:\n          echo foo\n      \",\n      ),\n    )\n    .args([\"sub/default\"])\n    .stdout(\"foo\\n\")\n    .run();\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_hibernate.rs::test_store_disconnect_with_hibernate", "code": "pub fn get_engine(&self, node_id: u64) -> WrapFactory<EK> {\n        WrapFactory::new(\n            self.pd_client.clone(),\n            self.raft_engines[&node_id].clone(),\n            self.tablet_registries[&node_id].clone(),\n        )\n    }", "test": "fn test_store_disconnect_with_hibernate() {\n    let mut cluster = new_server_cluster(0, 3);\n    let base_tick_ms = 50;\n    cluster.cfg.raft_store.raft_base_tick_interval = ReadableDuration::millis(base_tick_ms);\n    cluster.cfg.raft_store.raft_heartbeat_ticks = 2;\n    cluster.cfg.raft_store.raft_election_timeout_ticks = 10;\n    cluster.cfg.raft_store.unreachable_backoff = ReadableDuration::millis(500);\n    cluster.cfg.server.raft_client_max_backoff = ReadableDuration::millis(200);\n    // So the random election timeout will always be 10, which makes the case more\n    // stable.\n    cluster.cfg.raft_store.raft_min_election_timeout_ticks = 10;\n    cluster.cfg.raft_store.raft_max_election_timeout_ticks = 11;\n    configure_for_hibernate(&mut cluster.cfg);\n    cluster.pd_client.disable_default_operator();\n    let r = cluster.run_conf_change();\n    cluster.pd_client.must_add_peer(r, new_peer(2, 2));\n    cluster.pd_client.must_add_peer(r, new_peer(3, 3));\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(2), b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n\n    // Wait until all peers of region 1 hibernate.\n    thread::sleep(Duration::from_millis(base_tick_ms * 30));\n\n    // Stop the region leader.\n    fail::cfg(\"receive_raft_message_from_outside\", \"pause\").unwrap();\n    let _ = cluster.async_put(b\"k2\", b\"v2\").unwrap();\n    cluster.stop_node(1);\n\n    // Wait for a while so that the failpoint can be triggered on followers.\n    thread::sleep(Duration::from_millis(100));\n    fail::remove(\"receive_raft_message_from_outside\");\n\n    // Wait for a while. Peers of region 1 shouldn't hibernate.\n    thread::sleep(Duration::from_millis(base_tick_ms * 30));\n    must_get_equal(&cluster.get_engine(2), b\"k2\", b\"v2\");\n    must_get_equal(&cluster.get_engine(3), b\"k2\", b\"v2\");\n}"}
{"test_id": "serde-rs-json/serde-rs-json-66f862f/tests/test.rs::test_write_option", "code": "fn test_pretty_encode_ok<T>(errors: &[(T, &str)])\nwhere\n    T: PartialEq + Debug + ser::Serialize,\n{\n    for &(ref value, out) in errors {\n        let out = out.to_string();\n\n        let s = to_string_pretty(value).unwrap();\n        assert_eq!(s, out);\n\n        let v = to_value(value).unwrap();\n        let s = to_string_pretty(&v).unwrap();\n        assert_eq!(s, out);\n    }\n}", "test": "fn test_write_option() {\n    test_encode_ok(&[(None, \"null\"), (Some(\"jodhpurs\"), \"\\\"jodhpurs\\\"\")]);\n\n    test_encode_ok(&[\n        (None, \"null\"),\n        (Some(vec![\"foo\", \"bar\"]), \"[\\\"foo\\\",\\\"bar\\\"]\"),\n    ]);\n\n    test_pretty_encode_ok(&[(None, \"null\"), (Some(\"jodhpurs\"), \"\\\"jodhpurs\\\"\")]);\n\n    test_pretty_encode_ok(&[\n        (None, \"null\"),\n        (Some(vec![\"foo\", \"bar\"]), pretty_str!([\"foo\", \"bar\"])),\n    ]);\n}"}
{"test_id": "serde-rs-json/serde-rs-json-66f862f/tests/test.rs::test_borrowed_raw_value", "code": "pub fn get<Q>(&self, key: &Q) -> Option<&Value>\n    where\n        String: Borrow<Q>,\n        Q: ?Sized + Ord + Eq + Hash,\n    {\n        self.map.get(key)\n    }", "test": "fn test_borrowed_raw_value() {\n    #[derive(Serialize, Deserialize)]\n    struct Wrapper<'a> {\n        a: i8,\n        #[serde(borrow)]\n        b: &'a RawValue,\n        c: i8,\n    }\n\n    let wrapper_from_str: Wrapper =\n        serde_json::from_str(r#\"{\"a\": 1, \"b\": {\"foo\": 2}, \"c\": 3}\"#).unwrap();\n    assert_eq!(r#\"{\"foo\": 2}\"#, wrapper_from_str.b.get());\n\n    let wrapper_to_string = serde_json::to_string(&wrapper_from_str).unwrap();\n    assert_eq!(r#\"{\"a\":1,\"b\":{\"foo\": 2},\"c\":3}\"#, wrapper_to_string);\n\n    let wrapper_to_value = serde_json::to_value(&wrapper_from_str).unwrap();\n    assert_eq!(json!({\"a\": 1, \"b\": {\"foo\": 2}, \"c\": 3}), wrapper_to_value);\n\n    let array_from_str: Vec<&RawValue> =\n        serde_json::from_str(r#\"[\"a\", 42, {\"foo\": \"bar\"}, null]\"#).unwrap();\n    assert_eq!(r#\"\"a\"\"#, array_from_str[0].get());\n    assert_eq!(r#\"42\"#, array_from_str[1].get());\n    assert_eq!(r#\"{\"foo\": \"bar\"}\"#, array_from_str[2].get());\n    assert_eq!(r#\"null\"#, array_from_str[3].get());\n\n    let array_to_string = serde_json::to_string(&array_from_str).unwrap();\n    assert_eq!(r#\"[\"a\",42,{\"foo\": \"bar\"},null]\"#, array_to_string);\n}"}
{"test_id": "cberner-redb/cberner-redb-267b473/tests/integration_tests.rs::regression14", "code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn regression14() {\n    let tmpfile = create_tempfile();\n\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let table_def: MultimapTableDefinition<u64, &[u8]> = MultimapTableDefinition::new(\"x\");\n\n    let mut tx = db.begin_write().unwrap();\n    tx.set_durability(Durability::None);\n    {\n        let mut t = tx.open_multimap_table(table_def).unwrap();\n        let value = vec![0; 1424];\n        t.insert(&539749, value.as_slice()).unwrap();\n    }\n    tx.commit().unwrap();\n\n    let mut tx = db.begin_write().unwrap();\n    tx.set_durability(Durability::None);\n    {\n        let mut t = tx.open_multimap_table(table_def).unwrap();\n        let value = vec![0; 2230];\n        t.insert(&776971, value.as_slice()).unwrap();\n\n        let mut iter = t.range(514043..(514043 + 514043)).unwrap().rev();\n        {\n            let (key, mut value_iter) = iter.next().unwrap().unwrap();\n            assert_eq!(key.value(), 776971);\n            assert_eq!(value_iter.next().unwrap().unwrap().value(), &[0; 2230]);\n        }\n        {\n            let (key, mut value_iter) = iter.next().unwrap().unwrap();\n            assert_eq!(key.value(), 539749);\n            assert_eq!(value_iter.next().unwrap().unwrap().value(), &[0; 1424]);\n        }\n    }\n    tx.abort().unwrap();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cat.rs::test_stdin_show_all", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_stdin_show_all() {\n    for same_param in [\"-A\", \"--show-all\", \"--show-a\"] {\n        new_ucmd!()\n            .args(&[same_param])\n            .pipe_in(\"\\t\\0\\n\")\n            .succeeds()\n            .stdout_only(\"^I^@$\\n\");\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_seq.rs::test_ignore_leading_whitespace", "code": "pub fn no_stderr(&self) -> &Self {\n        assert!(\n            self.stderr.is_empty(),\n            \"Expected stderr to be empty, but it's:\\n{}\",\n            self.stderr_str()\n        );\n        self\n    }", "test": "fn test_ignore_leading_whitespace() {\n    new_ucmd!()\n        .arg(\"   1\")\n        .succeeds()\n        .stdout_is(\"1\\n\")\n        .no_stderr();\n}"}
{"test_id": "rust-bitcoin-rust-bitcoin/rust-bitcoin-rust-bitcoin-5ee33ea/bitcoin/tests/serde.rs::serde_regression_proprietary_key", "code": "pub fn serialize(&self) -> Vec<u8> {\n        let mut buf: Vec<u8> = Vec::new();\n\n        //  <magic>\n        buf.extend_from_slice(b\"psbt\");\n\n        buf.push(0xff_u8);\n\n        buf.extend(self.serialize_map());\n\n        for i in &self.inputs {\n            buf.extend(i.serialize_map());\n        }\n\n        for i in &self.outputs {\n            buf.extend(i.serialize_map());\n        }\n\n        buf\n    }", "test": "fn serde_regression_proprietary_key() {\n    let key = ProprietaryKey {\n        prefix: vec![0u8, 1u8, 2u8, 3u8],\n        subtype: 1u8,\n        key: vec![0u8, 1u8, 2u8, 3u8],\n    };\n    let got = serialize(&key).unwrap();\n    let want = include_bytes!(\"data/serde/proprietary_key_bincode\") as &[_];\n    assert_eq!(got, want)\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_install.rs::test_install_compare_option", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_install_compare_option() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let first = \"a\";\n    let second = \"b\";\n    at.touch(first);\n    scene\n        .ucmd()\n        .args(&[\"-Cv\", first, second])\n        .succeeds()\n        .stdout_contains(format!(\"'{first}' -> '{second}'\"));\n    scene\n        .ucmd()\n        .args(&[\"-Cv\", first, second])\n        .succeeds()\n        .no_stdout();\n    scene\n        .ucmd()\n        .args(&[\"-Cv\", \"-m0644\", first, second])\n        .succeeds()\n        .stdout_contains(format!(\"removed '{second}'\\n'{first}' -> '{second}'\"));\n    scene\n        .ucmd()\n        .args(&[\"-Cv\", first, second])\n        .succeeds()\n        .stdout_contains(format!(\"removed '{second}'\\n'{first}' -> '{second}'\"));\n    scene\n        .ucmd()\n        .args(&[\"-C\", \"--preserve-timestamps\", first, second])\n        .fails()\n        .code_is(1)\n        .stderr_contains(\"Options --compare and --preserve-timestamps are mutually exclusive\");\n    scene\n        .ucmd()\n        .args(&[\"-C\", \"--strip\", \"--strip-program=echo\", first, second])\n        .fails()\n        .code_is(1)\n        .stderr_contains(\"Options --compare and --strip are mutually exclusive\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_storage.rs::test_raw_put_deadline", "code": "pub fn has_region_error(&self) -> bool {\n        matches!(\n            self,\n            Error::Kv(KvError(box EngineErrorInner::Request(_)))\n                | Error::Txn(TxnError(box TxnErrorInner::Engine(KvError(\n                    box EngineErrorInner::Request(_),\n                ))))\n                | Error::Txn(TxnError(box TxnErrorInner::Mvcc(MvccError(\n                    box MvccErrorInner::Kv(KvError(box EngineErrorInner::Request(_))),\n                ))))\n                | Error::Request(_)\n        )\n    }", "test": "fn test_raw_put_deadline() {\n    let deadline_fp = \"deadline_check_fail\";\n    let mut cluster = new_server_cluster(0, 1);\n    cluster.run();\n    let region = cluster.get_region(b\"\");\n    let leader = region.get_peers()[0].clone();\n\n    let env = Arc::new(Environment::new(1));\n    let channel =\n        ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(leader.get_store_id()));\n    let client = TikvClient::new(channel);\n\n    let mut ctx = Context::default();\n    ctx.set_region_id(region.get_id());\n    ctx.set_region_epoch(region.get_region_epoch().clone());\n    ctx.set_peer(leader);\n\n    let mut put_req = RawPutRequest::default();\n    put_req.set_context(ctx);\n    put_req.key = b\"k3\".to_vec();\n    put_req.value = b\"v3\".to_vec();\n    fail::cfg(deadline_fp, \"return()\").unwrap();\n    let put_resp = client.raw_put(&put_req).unwrap();\n    assert!(put_resp.has_region_error(), \"{:?}\", put_resp);\n    must_get_none(&cluster.get_engine(1), b\"k3\");\n\n    fail::remove(deadline_fp);\n    let put_resp = client.raw_put(&put_req).unwrap();\n    assert!(!put_resp.has_region_error(), \"{:?}\", put_resp);\n    must_get_equal(&cluster.get_engine(1), b\"k3\", b\"v3\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_csplit.rs::test_up_to_no_match1", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_up_to_no_match1() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"/4/\", \"/nope/\"])\n        .fails()\n        .stdout_is(\"6\\n135\\n\")\n        .stderr_is(\"csplit: '/nope/': match not found\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"counting splits\")\n        .count();\n    assert_eq!(count, 0);\n\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"/4/\", \"/nope/\", \"-k\"])\n        .fails()\n        .stdout_is(\"6\\n135\\n\")\n        .stderr_is(\"csplit: '/nope/': match not found\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"counting splits\")\n        .count();\n    assert_eq!(count, 2);\n    assert_eq!(at.read(\"xx00\"), generate(1, 4));\n    assert_eq!(at.read(\"xx01\"), generate(4, 51));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cut.rs::test_whitespace_with_explicit_delimiter", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_whitespace_with_explicit_delimiter() {\n    new_ucmd!()\n        .args(&[\"-w\", \"-f\", COMPLEX_SEQUENCE.sequence, \"-d:\"])\n        .fails()\n        .code_is(1);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/config/test_config_client.rs::test_write_update_to_file", "code": "pub fn as_bytes(&self) -> Option<BytesRef<'_>> {\n        EvaluableRef::borrow_scalar_value(self)\n    }", "test": "fn test_write_update_to_file() {\n    let (mut cfg, tmp_dir) = TikvConfig::with_tmp().unwrap();\n    cfg.cfg_path = tmp_dir.path().join(\"cfg_file\").to_str().unwrap().to_owned();\n    {\n        let c = r#\"\n## comment should be reserve\n[raftstore]\n\n# config that comment out by one `#` should be update in place\n## pd-heartbeat-tick-interval = \"30s\"\n# pd-heartbeat-tick-interval = \"30s\"\n\n[rocksdb.defaultcf]\n## config should be update in place\nblock-cache-size = \"10GB\"\n\n[rocksdb.lockcf]\n## this config will not update even it has the same last \n## name as `rocksdb.defaultcf.block-cache-size`\nblock-cache-size = \"512MB\"\n\n[coprocessor]\n## the update to `coprocessor.region-split-keys`, which do not show up \n## as key-value pair after [coprocessor], will be written at the end of [coprocessor]\n\n[gc]\n## config should be update in place\nmax-write-bytes-per-sec = \"1KB\"\n\n[rocksdb.defaultcf.titan]\nblob-run-mode = \"normal\"\n\"#;\n        let mut f = File::create(&cfg.cfg_path).unwrap();\n        f.write_all(c.as_bytes()).unwrap();\n        f.sync_all().unwrap();\n    }\n    let cfg_controller = ConfigController::new(cfg);\n    let change = {\n        let mut change = HashMap::new();\n        change.insert(\n            \"raftstore.pd-heartbeat-tick-interval\".to_owned(),\n            \"1h\".to_owned(),\n        );\n        change.insert(\n            \"coprocessor.region-split-keys\".to_owned(),\n            \"10000\".to_owned(),\n        );\n        change.insert(\"gc.max-write-bytes-per-sec\".to_owned(), \"100MB\".to_owned());\n        change.insert(\n            \"rocksdb.defaultcf.block-cache-size\".to_owned(),\n            \"1GB\".to_owned(),\n        );\n        change.insert(\n            \"rocksdb.defaultcf.titan.blob-run-mode\".to_owned(),\n            \"read-only\".to_owned(),\n        );\n        change\n    };\n    cfg_controller.update(change).unwrap();\n    let res = {\n        let mut buf = Vec::new();\n        let mut f = File::open(cfg_controller.get_current().cfg_path).unwrap();\n        f.read_to_end(&mut buf).unwrap();\n        buf\n    };\n\n    let expect = r#\"\n## comment should be reserve\n[raftstore]\n\n# config that comment out by one `#` should be update in place\n## pd-heartbeat-tick-interval = \"30s\"\npd-heartbeat-tick-interval = \"1h\"\n\n[rocksdb.defaultcf]\n## config should be update in place\nblock-cache-size = \"1GB\"\n\n[rocksdb.lockcf]\n## this config will not update even it has the same last \n## name as `rocksdb.defaultcf.block-cache-size`\nblock-cache-size = \"512MB\"\n\n[coprocessor]\n## the update to `coprocessor.region-split-keys`, which do not show up \n## as key-value pair after [coprocessor], will be written at the end of [coprocessor]\n\nregion-split-keys = 10000\n[gc]\n## config should be update in place\nmax-write-bytes-per-sec = \"100MB\"\n\n[rocksdb.defaultcf.titan]\nblob-run-mode = \"read-only\"\n\"#;\n    assert_eq!(expect.as_bytes(), res.as_slice());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_ln.rs::test_symlink_overwrite_force", "code": "pub fn is_symlink(&self, path: &str) -> bool {\n        log_info(\"is_symlink\", self.plus_as_string(path));\n        match fs::symlink_metadata(self.plus(path)) {\n            Ok(m) => m.file_type().is_symlink(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_overwrite_force() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_symlink_overwrite_force_a\";\n    let file_b = \"test_symlink_overwrite_force_b\";\n    let link = \"test_symlink_overwrite_force_link\";\n\n    // Create symlink\n    at.symlink_file(file_a, link);\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file_a);\n\n    // Force overwrite of existing symlink\n    ucmd.args(&[\"--force\", \"-s\", file_b, link]).succeeds();\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file_b);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_env.rs::test_env_version", "code": "pub fn stdout_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stdout_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stdout_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_env_version() {\n    new_ucmd!()\n        .arg(\"--version\")\n        .succeeds()\n        .no_stderr()\n        .stdout_contains(util_name!());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_parents_multiple_files", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_parents_multiple_files() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(\"--parents\")\n        .arg(TEST_COPY_FROM_FOLDER_FILE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .arg(TEST_COPY_TO_FOLDER)\n        .succeeds();\n\n    assert_eq!(\n        at.read(&format!(\n            \"{TEST_COPY_TO_FOLDER}/{TEST_COPY_FROM_FOLDER_FILE}\"\n        )),\n        \"Hello, World!\\n\"\n    );\n    assert_eq!(\n        at.read(&format!(\"{TEST_COPY_TO_FOLDER}/{TEST_HOW_ARE_YOU_SOURCE}\")),\n        \"How are you?\\n\"\n    );\n}"}
{"test_id": "rust-lang-flate2-rs/rust-lang-flate2-rs-649aaae/tests/empty-read.rs::gzip_encoder_empty_read", "code": "fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        // If we don't have any buffered data and we're doing a massive read\n        // (larger than our internal buffer), bypass our internal buffer\n        // entirely.\n        if self.pos == self.cap && buf.len() >= self.buf.len() {\n            return self.inner.read(buf);\n        }\n        let nread = {\n            let mut rem = self.fill_buf()?;\n            rem.read(buf)?\n        };\n        self.consume(nread);\n        Ok(nread)\n    }", "test": "fn gzip_encoder_empty_read() {\n    let original: &[u8] = b\"Lorem ipsum dolor sit amet.\";\n    let mut encoder = flate2::read::GzEncoder::new(original, flate2::Compression::default());\n    assert_eq!(encoder.read(&mut []).unwrap(), 0);\n    let mut encoded = Vec::new();\n    encoder.read_to_end(&mut encoded).unwrap();\n    let mut decoder = flate2::read::GzDecoder::new(encoded.as_slice());\n    let mut decoded = Vec::new();\n    decoder.read_to_end(&mut decoded).unwrap();\n    assert_eq!(decoded.as_slice(), original);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_kill.rs::test_kill_list_final_new_line", "code": "pub fn stdout_str(&self) -> &str {\n        std::str::from_utf8(&self.stdout).unwrap()\n    }", "test": "fn test_kill_list_final_new_line() {\n    let re = Regex::new(\"\\\\n$\").unwrap();\n    assert!(re.is_match(new_ucmd!().arg(\"-l\").succeeds().stdout_str()));\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/engine_traits_tests/src/iterator.rs::iter_forward_snapshot", "code": "fn iterator(&self, cf: &str) -> Result<Self::Iterator> {\n        self.iterator_opt(cf, IterOptions::default())\n    }", "test": "fn iter_forward_snapshot() {\n    let db = default_engine();\n    iter_forward(&db.engine, |e| e.snapshot().iterator(CF_DEFAULT).unwrap());\n}"}
{"test_id": "wasmerio-wasmer/wasmerio-wasmer-7cb550d/tests/compilers/deterministic.rs::deterministic_empty", "code": "fn compile_and_compare(wasm: &[u8]) -> Result<()> {\n    let store = Store::default();\n\n    // compile for first time\n    let module = Module::new(&store, wasm)?;\n    let first = module.serialize()?;\n\n    // compile for second time\n    let module = Module::new(&store, wasm)?;\n    let second = module.serialize()?;\n\n    assert!(first == second);\n\n    Ok(())\n}", "test": "fn deterministic_empty() -> Result<()> {\n    let wasm_bytes = wat2wasm(\n        br#\"\n    (module)\n    \"#,\n    )?;\n\n    compile_and_compare(&wasm_bytes)\n}"}
{"test_id": "serde-rs-json/serde-rs-json-66f862f/tests/test.rs::test_write_f64", "code": "fn test_pretty_encode_ok<T>(errors: &[(T, &str)])\nwhere\n    T: PartialEq + Debug + ser::Serialize,\n{\n    for &(ref value, out) in errors {\n        let out = out.to_string();\n\n        let s = to_string_pretty(value).unwrap();\n        assert_eq!(s, out);\n\n        let v = to_value(value).unwrap();\n        let s = to_string_pretty(&v).unwrap();\n        assert_eq!(s, out);\n    }\n}", "test": "fn test_write_f64() {\n    let tests = &[\n        (3.0, \"3.0\"),\n        (3.1, \"3.1\"),\n        (-1.5, \"-1.5\"),\n        (0.5, \"0.5\"),\n        (f64::MIN, \"-1.7976931348623157e308\"),\n        (f64::MAX, \"1.7976931348623157e308\"),\n        (f64::EPSILON, \"2.220446049250313e-16\"),\n    ];\n    test_encode_ok(tests);\n    test_pretty_encode_ok(tests);\n}"}
{"test_id": "ordinals-ord/ordinals-ord-8090538/tests/wallet/inscribe.rs::batch_in_separate_outputs_with_parent_and_non_default_postage", "code": "pub fn descriptors(&self) -> Vec<String> {\n    self.state().descriptors.clone()\n  }", "test": "fn batch_in_separate_outputs_with_parent_and_non_default_postage() {\n  let rpc_server = test_bitcoincore_rpc::spawn();\n  rpc_server.mine_blocks(1);\n\n  assert_eq!(rpc_server.descriptors().len(), 0);\n\n  create_wallet(&rpc_server);\n\n  let parent_output = CommandBuilder::new(\"wallet inscribe --fee-rate 5.0 --file parent.png\")\n    .write(\"parent.png\", [1; 520])\n    .rpc_server(&rpc_server)\n    .run_and_deserialize_output::<Inscribe>();\n\n  rpc_server.mine_blocks(1);\n\n  assert_eq!(rpc_server.descriptors().len(), 3);\n\n  let parent_id = parent_output.inscriptions[0].id;\n\n  let output = CommandBuilder::new(\"wallet inscribe --fee-rate 1 --batch batch.yaml --postage 777sat\")\n    .write(\"inscription.txt\", \"Hello World\")\n    .write(\"tulip.png\", [0; 555])\n    .write(\"meow.wav\", [0; 2048])\n    .write(\n      \"batch.yaml\",\n      format!(\"parent: {parent_id}\\nmode: separate-outputs\\ninscriptions:\\n- file: inscription.txt\\n- file: tulip.png\\n- file: meow.wav\\n\")\n    )\n    .rpc_server(&rpc_server)\n    .run_and_deserialize_output::<Inscribe>();\n\n  for inscription in &output.inscriptions {\n    assert_eq!(inscription.location.offset, 0);\n  }\n\n  let mut outpoints = output\n    .inscriptions\n    .iter()\n    .map(|inscription| inscription.location.outpoint)\n    .collect::<Vec<OutPoint>>();\n  outpoints.sort();\n  outpoints.dedup();\n  assert_eq!(outpoints.len(), output.inscriptions.len());\n\n  rpc_server.mine_blocks(1);\n\n  let ord_server = TestServer::spawn_with_args(&rpc_server, &[]);\n\n  let output_1 = output.inscriptions[0].location.outpoint;\n  let output_2 = output.inscriptions[1].location.outpoint;\n  let output_3 = output.inscriptions[2].location.outpoint;\n\n  ord_server.assert_response_regex(\n    format!(\"/inscription/{}\", output.inscriptions[0].id),\n    format!(\n      r\".*<dt>parent</dt>\\s*<dd>.*{parent_id}.*</dd>.*<dt>output value</dt>.*<dd>777</dd>.*.*<dt>location</dt>.*<dd class=monospace>{}:0</dd>.*\",\n      output_1\n    ),\n  );\n\n  ord_server.assert_response_regex(\n    format!(\"/inscription/{}\", output.inscriptions[1].id),\n    format!(\n      r\".*<dt>parent</dt>\\s*<dd>.*{parent_id}.*</dd>.*<dt>output value</dt>.*<dd>777</dd>.*.*<dt>location</dt>.*<dd class=monospace>{}:0</dd>.*\",\n      output_2\n    ),\n  );\n\n  ord_server.assert_response_regex(\n    format!(\"/inscription/{}\", output.inscriptions[2].id),\n    format!(\n      r\".*<dt>parent</dt>\\s*<dd>.*{parent_id}.*</dd>.*<dt>output value</dt>.*<dd>777</dd>.*.*<dt>location</dt>.*<dd class=monospace>{}:0</dd>.*\",\n      output_3\n    ),\n  );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_dd.rs::test_ascii_521k_to_file", "code": "pub fn metadata(&self, path: &str) -> fs::Metadata {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m,\n            Err(e) => panic!(\"{}\", e),\n        }\n    }", "test": "fn test_ascii_521k_to_file() {\n    let tname = \"ascii-521k\";\n    let input = build_ascii_block(512 * 1024);\n    let tmp_fn = format!(\"TESTFILE-{}.tmp\", &tname);\n\n    let (fix, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"status=none\", of!(tmp_fn)])\n        .pipe_in(input.clone())\n        .run()\n        .no_stderr()\n        .no_stdout()\n        .success();\n\n    assert_eq!(512 * 1024, fix.metadata(&tmp_fn).len());\n\n    cmp_file!(\n        {\n            let mut input_f = tempfile().unwrap();\n            input_f.write_all(&input).unwrap();\n            input_f\n        },\n        fix.open(&tmp_fn)\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_basename.rs::test_no_args_output", "code": "pub fn usage_error<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.stderr_only(format!(\n            \"{0}: {2}\\nTry '{1} {0} --help' for more information.\\n\",\n            self.util_name.as_ref().unwrap(), // This shouldn't be called using a normal command\n            self.bin_path.display(),\n            msg.as_ref()\n        ))\n    }", "test": "fn test_no_args_output() {\n    new_ucmd!().fails().usage_error(\"missing operand\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_expand.rs::test_tabs_with_specifier_only_allowed_with_last_value", "code": "pub fn succeeds(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.success();\n        cmd_result\n    }", "test": "fn test_tabs_with_specifier_only_allowed_with_last_value() {\n    fn run_cmd(arg: &str, specifier: &str) {\n        let expected_msg = format!(\n            \"{} specifier only allowed with the last value\",\n            specifier.quote()\n        );\n        new_ucmd!().arg(arg).fails().stderr_contains(expected_msg);\n    }\n    run_cmd(\"--tabs=/1,2,3\", \"/\");\n    run_cmd(\"--tabs=1,/2,3\", \"/\");\n    new_ucmd!().arg(\"--tabs=1,2,/3\").succeeds();\n\n    run_cmd(\"--tabs=+1,2,3\", \"+\");\n    run_cmd(\"--tabs=1,+2,3\", \"+\");\n    new_ucmd!().arg(\"--tabs=1,2,+3\").succeeds();\n}"}
{"test_id": "tafia-quick-xml/tafia-quick-xml-120e074/tests/unit_tests.rs::test_empty_can_be_expanded", "code": "pub fn expand_empty_elements(&mut self, expand: bool) -> &mut Self {\n        self.ser.expand_empty_elements = expand;\n        self\n    }", "test": "fn test_empty_can_be_expanded() {\n    let mut r = Reader::from_str(\"<a />\");\n    r.trim_text(true).expand_empty_elements(true);\n    next_eq!(r, Start, b\"a\", End, b\"a\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_pending_peers.rs::test_pending_snapshot", "code": "fn get_term(&self) -> Option<NonZeroU64> {\n        self.snapshot.term\n    }", "test": "fn test_pending_snapshot() {\n    let mut cluster = new_node_cluster(0, 3);\n    configure_for_snapshot(&mut cluster.cfg);\n    let election_timeout = configure_for_lease_read(&mut cluster.cfg, None, Some(15));\n    let gc_limit = cluster.cfg.raft_store.raft_log_gc_count_limit();\n    cluster.cfg.raft_store.pd_heartbeat_tick_interval = ReadableDuration::millis(100);\n\n    let handle_snapshot_fp = \"apply_on_handle_snapshot_1_1\";\n    let handle_snapshot_finish_fp = \"apply_on_handle_snapshot_finish_1_1\";\n    fail::cfg(\"apply_on_handle_snapshot_sync\", \"return\").unwrap();\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    // Disable default max peer count check.\n    pd_client.disable_default_operator();\n\n    let region_id = cluster.run_conf_change();\n    pd_client.must_add_peer(region_id, new_peer(2, 2));\n    cluster.must_transfer_leader(region_id, new_peer(1, 1));\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    fail::cfg(handle_snapshot_fp, \"pause\").unwrap();\n    pd_client.must_add_peer(region_id, new_peer(3, 3));\n    // Give some time for peer 3 to request snapshot.\n    sleep_ms(100);\n\n    // Isolate peer 1 from rest of the cluster.\n    cluster.add_send_filter(IsolationFilterFactory::new(1));\n\n    sleep_ms((election_timeout.as_millis() * 2) as _);\n    cluster.reset_leader_of_region(region_id);\n    // Compact logs to force requesting snapshot after clearing send filters.\n    let state2 = cluster.truncated_state(1, 2);\n    for i in 1..gc_limit * 10 {\n        let k = i.to_string().into_bytes();\n        cluster.must_put(&k, &k.clone());\n    }\n    cluster.wait_log_truncated(1, 2, state2.get_index() + 5 * gc_limit);\n\n    // Make sure peer 1 has applied snapshot.\n    cluster.clear_send_filters();\n    let start = Instant::now();\n    loop {\n        if cluster.pd_client.get_pending_peers().get(&1).is_none()\n            || start.saturating_elapsed() > election_timeout * 10\n        {\n            break;\n        }\n        sleep_ms(50);\n    }\n    let state1 = cluster.truncated_state(1, 1);\n\n    // Peer 2 continues to handle snapshot.\n    fail::cfg(handle_snapshot_finish_fp, \"pause\").unwrap();\n    fail::remove(handle_snapshot_fp);\n    sleep_ms(200);\n    let state2 = cluster.truncated_state(1, 1);\n    fail::remove(handle_snapshot_finish_fp);\n    assert!(\n        state1.get_term() <= state2.get_term(),\n        \"{:?} {:?}\",\n        state1,\n        state2\n    );\n    assert!(\n        state1.get_index() <= state2.get_index(),\n        \"{:?} {:?}\",\n        state1,\n        state2\n    );\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/gc.rs::global_init_no_leak", "code": "pub fn strong_count(&self) -> usize {\n        self.extern_data().ref_count.load(Ordering::SeqCst)\n    }", "test": "fn global_init_no_leak() -> anyhow::Result<()> {\n    let (mut store, module) = ref_types_module(\n        false,\n        r#\"\n            (module\n                (import \"\" \"\" (global externref))\n                (global externref (global.get 0))\n            )\n        \"#,\n    )?;\n\n    let externref = ExternRef::new(());\n    let global = Global::new(\n        &mut store,\n        GlobalType::new(ValType::ExternRef, Mutability::Const),\n        externref.clone().into(),\n    )?;\n    Instance::new(&mut store, &module, &[global.into()])?;\n    drop(store);\n    assert_eq!(externref.strong_count(), 1);\n\n    Ok(())\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_replica_stale_read.rs::test_stale_read_basic_flow_replicate", "code": "pub fn has_data_is_not_ready(&self) -> bool {\n        self.data_is_not_ready.is_some()\n    }", "test": "fn test_stale_read_basic_flow_replicate() {\n    let (mut cluster, pd_client, mut leader_client) = prepare_for_stale_read(new_peer(1, 1));\n    let mut follower_client2 = PeerClient::new(&cluster, 1, new_peer(2, 2));\n    // Set the `stale_read` flag\n    leader_client.ctx.set_stale_read(true);\n    follower_client2.ctx.set_stale_read(true);\n\n    let commit_ts1 = leader_client.must_kv_write(\n        &pd_client,\n        vec![new_mutation(Op::Put, &b\"key1\"[..], &b\"value1\"[..])],\n        b\"key1\".to_vec(),\n    );\n\n    // Can read `value1` with the newest ts\n    follower_client2.must_kv_read_equal(b\"key1\".to_vec(), b\"value1\".to_vec(), get_tso(&pd_client));\n\n    // Stop replicate data to follower 2\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(1, 2)\n            .direction(Direction::Recv)\n            .msg_type(MessageType::MsgAppend),\n    ));\n\n    // Update `key1`\n    let commit_ts2 = leader_client.must_kv_write(\n        &pd_client,\n        vec![new_mutation(Op::Put, &b\"key1\"[..], &b\"value2\"[..])],\n        b\"key1\".to_vec(),\n    );\n\n    // Follower 2 can still read `value1`, but can not read `value2` due\n    // to it don't have enough data\n    follower_client2.must_kv_read_equal(b\"key1\".to_vec(), b\"value1\".to_vec(), commit_ts1);\n    let resp1 = follower_client2.kv_read(b\"key1\".to_vec(), commit_ts2);\n    assert!(resp1.get_region_error().has_data_is_not_ready());\n\n    // Leader have up to date data so it can read `value2`\n    leader_client.must_kv_read_equal(b\"key1\".to_vec(), b\"value2\".to_vec(), get_tso(&pd_client));\n\n    // clear the `MsgAppend` filter\n    cluster.clear_send_filters();\n\n    // Now we can read `value2` with the newest ts\n    follower_client2.must_kv_read_equal(b\"key1\".to_vec(), b\"value2\".to_vec(), get_tso(&pd_client));\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/slash_operator.rs::twice", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn twice() {\n  Test::new()\n    .justfile(\"x := 'a' / 'b' / 'c'\")\n    .args([\"--evaluate\", \"x\"])\n    .stdout(\"a/b/c\")\n    .run();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_uname.rs::test_uname_kernel_version", "code": "pub fn succeeds(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.success();\n        cmd_result\n    }", "test": "fn test_uname_kernel_version() {\n    new_ucmd!().arg(\"-v\").succeeds();\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_bigquery.rs::parse_literal_string", "code": "pub fn verified_only_select(&self, query: &str) -> Select {\n        match *self.verified_query(query).body {\n            SetExpr::Select(s) => *s,\n            _ => panic!(\"Expected SetExpr::Select\"),\n        }\n    }", "test": "fn parse_literal_string() {\n    let sql = r#\"SELECT 'single', \"double\"\"#;\n    let select = bigquery().verified_only_select(sql);\n    assert_eq!(2, select.projection.len());\n    assert_eq!(\n        &Expr::Value(Value::SingleQuotedString(\"single\".to_string())),\n        expr_from_projection(&select.projection[0])\n    );\n    assert_eq!(\n        &Expr::Value(Value::DoubleQuotedString(\"double\".to_string())),\n        expr_from_projection(&select.projection[1])\n    );\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_common.rs::parse_not_precedence", "code": "pub fn verified_expr(&self, sql: &str) -> Expr {\n        self.expr_parses_to(sql, sql)\n    }", "test": "fn parse_not_precedence() {\n    // NOT has higher precedence than OR/AND, so the following must parse as (NOT true) OR true\n    let sql = \"NOT true OR true\";\n    assert_matches!(\n        verified_expr(sql),\n        Expr::BinaryOp {\n            op: BinaryOperator::Or,\n            ..\n        }\n    );\n\n    // But NOT has lower precedence than comparison operators, so the following parses as NOT (a IS NULL)\n    let sql = \"NOT a IS NULL\";\n    assert_matches!(\n        verified_expr(sql),\n        Expr::UnaryOp {\n            op: UnaryOperator::Not,\n            ..\n        }\n    );\n\n    // NOT has lower precedence than BETWEEN, so the following parses as NOT (1 NOT BETWEEN 1 AND 2)\n    let sql = \"NOT 1 NOT BETWEEN 1 AND 2\";\n    assert_eq!(\n        verified_expr(sql),\n        Expr::UnaryOp {\n            op: UnaryOperator::Not,\n            expr: Box::new(Expr::Between {\n                expr: Box::new(Expr::Value(number(\"1\"))),\n                low: Box::new(Expr::Value(number(\"1\"))),\n                high: Box::new(Expr::Value(number(\"2\"))),\n                negated: true,\n            }),\n        },\n    );\n\n    // NOT has lower precedence than LIKE, so the following parses as NOT ('a' NOT LIKE 'b')\n    let sql = \"NOT 'a' NOT LIKE 'b'\";\n    assert_eq!(\n        verified_expr(sql),\n        Expr::UnaryOp {\n            op: UnaryOperator::Not,\n            expr: Box::new(Expr::Like {\n                expr: Box::new(Expr::Value(Value::SingleQuotedString(\"a\".into()))),\n                negated: true,\n                pattern: Box::new(Expr::Value(Value::SingleQuotedString(\"b\".into()))),\n                escape_char: None,\n            }),\n        },\n    );\n\n    // NOT has lower precedence than IN, so the following parses as NOT (a NOT IN 'a')\n    let sql = \"NOT a NOT IN ('a')\";\n    assert_eq!(\n        verified_expr(sql),\n        Expr::UnaryOp {\n            op: UnaryOperator::Not,\n            expr: Box::new(Expr::InList {\n                expr: Box::new(Expr::Identifier(\"a\".into())),\n                list: vec![Expr::Value(Value::SingleQuotedString(\"a\".into()))],\n                negated: true,\n            }),\n        },\n    );\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_hibernate.rs::test_inconsistent_configuration", "code": "pub fn load(&self, ctx: TabletContext, create: bool) -> Result<CachedTablet<EK>>\n    where\n        EK: Clone,\n    {\n        assert!(ctx.suffix.is_some());\n        let id = ctx.id;\n        let path = self.tablet_path(id, ctx.suffix.unwrap());\n        if !create && !self.tablets.factory.exists(&path) {\n            return Err(Error::Other(box_err!(\n                \"tablet ({}, {:?}) doesn't exist\",\n                id,\n                ctx.suffix\n            )));\n        }\n        // TODO: use compaction filter to trim range.\n        let tablet = self.tablets.factory.open_tablet(ctx, &path)?;\n        let mut cached = self.get_or_default(id);\n        cached.set(tablet);\n        Ok(cached)\n    }", "test": "fn test_inconsistent_configuration() {\n    let mut cluster = new_node_cluster(0, 3);\n    configure_for_hibernate(&mut cluster.cfg);\n    cluster.run();\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n\n    // Wait till leader peer goes to sleep.\n    thread::sleep(\n        cluster.cfg.raft_store.raft_base_tick_interval.0\n            * 3\n            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,\n    );\n\n    // Ensure leader can sleep if all nodes enable hibernate region.\n    let awakened = Arc::new(AtomicBool::new(false));\n    let filter = Arc::new(AtomicBool::new(true));\n    let a = awakened.clone();\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(1, 1)\n            .direction(Direction::Send)\n            .set_msg_callback(Arc::new(move |_| {\n                a.store(true, Ordering::SeqCst);\n            }))\n            .when(filter.clone()),\n    ));\n    thread::sleep(cluster.cfg.raft_store.raft_heartbeat_interval() * 2);\n    assert!(!awakened.load(Ordering::SeqCst));\n\n    // Simulate rolling disable hibernate region in followers\n    filter.store(false, Ordering::SeqCst);\n    cluster.cfg.raft_store.hibernate_regions = false;\n    cluster.stop_node(3);\n    cluster.run_node(3).unwrap();\n    cluster.must_put(b\"k2\", b\"v2\");\n    // In case leader changes.\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    must_get_equal(&cluster.get_engine(3), b\"k2\", b\"v2\");\n    // Wait till leader peer goes to sleep.\n    thread::sleep(\n        cluster.cfg.raft_store.raft_base_tick_interval.0\n            * 3\n            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,\n    );\n    awakened.store(false, Ordering::SeqCst);\n    filter.store(true, Ordering::SeqCst);\n    thread::sleep(cluster.cfg.raft_store.raft_heartbeat_interval() * 2);\n    // Leader should keep awake as peer 3 won't agree to sleep.\n    assert!(awakened.load(Ordering::SeqCst));\n    cluster.reset_leader_of_region(1);\n    assert_eq!(cluster.leader_of_region(1), Some(new_peer(1, 1)));\n\n    // Simulate rolling disable hibernate region in leader\n    cluster.clear_send_filters();\n    cluster.must_transfer_leader(1, new_peer(3, 3));\n    cluster.must_put(b\"k3\", b\"v3\");\n    must_get_equal(&cluster.get_engine(1), b\"k3\", b\"v3\");\n    // Wait till leader peer goes to sleep.\n    thread::sleep(\n        cluster.cfg.raft_store.raft_base_tick_interval.0\n            * 3\n            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,\n    );\n    awakened.store(false, Ordering::SeqCst);\n    let a = awakened.clone();\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(1, 3)\n            .direction(Direction::Send)\n            .set_msg_callback(Arc::new(move |_| {\n                a.store(true, Ordering::SeqCst);\n            })),\n    ));\n    thread::sleep(cluster.cfg.raft_store.raft_heartbeat_interval() * 2);\n    // Leader should keep awake as hibernate region is disabled.\n    assert!(awakened.load(Ordering::SeqCst));\n    cluster.reset_leader_of_region(1);\n    assert_eq!(cluster.leader_of_region(1), Some(new_peer(3, 3)));\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/control_flow/loops.rs::for_loop_continue_label", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn for_loop_continue_label() {\n    run_test_actions([TestAction::assert_eq(\n        indoc! {r#\"\n            var count = 0;\n            label: for (let x = 0; x < 10;) {\n                while (true) {\n                    x++;\n                    count++;\n                    continue label;\n                }\n            }\n            count\n        \"#},\n        10,\n    )]);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_compact_log.rs::test_node_compact_count_limit", "code": "fn test_compact_count_limit<T: Simulator>(cluster: &mut Cluster<T>) {\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(100);\n    cluster.cfg.raft_store.raft_log_gc_threshold = 500;\n    cluster.cfg.raft_store.raft_log_gc_size_limit = Some(ReadableSize::mb(20));\n    cluster.run();\n\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    let mut before_states = HashMap::default();\n\n    for (&id, engines) in &cluster.engines {\n        must_get_equal(&engines.kv, b\"k1\", b\"v1\");\n        let mut state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        let state = state.take_truncated_state();\n        // compact should not start\n        assert_eq!(RAFT_INIT_LOG_INDEX, state.get_index());\n        assert_eq!(RAFT_INIT_LOG_TERM, state.get_term());\n        before_states.insert(id, state);\n    }\n\n    for i in 1..60 {\n        let k = i.to_string().into_bytes();\n        let v = k.clone();\n        cluster.must_put(&k, &v);\n    }\n\n    // wait log gc.\n    sleep_ms(500);\n\n    // limit has not reached, should not gc.\n    for (&id, engines) in &cluster.engines {\n        let mut state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        let after_state = state.take_truncated_state();\n\n        let before_state = &before_states[&id];\n        let idx = after_state.get_index();\n        assert_eq!(idx, before_state.get_index());\n    }\n\n    for i in 60..200 {\n        let k = i.to_string().into_bytes();\n        let v = k.clone();\n        cluster.must_put(&k, &v);\n        let v2 = cluster.get(&k);\n        assert_eq!(v2, Some(v));\n\n        if i > 100\n            && check_compacted(\n                &cluster.engines,\n                &before_states,\n                1,\n                false, // must_compacted\n            )\n        {\n            return;\n        }\n    }\n    check_compacted(\n        &cluster.engines,\n        &before_states,\n        1,\n        true, // must_compacted\n    );\n}", "test": "fn test_node_compact_count_limit() {\n    let count = 5;\n    let mut cluster = new_node_cluster(0, count);\n    test_compact_count_limit(&mut cluster);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_nproc.rs::test_nproc_all_omp", "code": "fn parse(s: &str) -> Result<usize, &'static str> {\n            match s.parse::<usize>() {\n                Ok(0) => Err(\"fields and positions are numbered from 1\"),\n                // GNU fails when we are at the limit. Match their behavior\n                Ok(n) if n == usize::MAX => Err(\"byte/character offset is too large\"),\n                Ok(n) => Ok(n),\n                Err(_) => Err(\"failed to parse range\"),\n            }\n        }", "test": "fn test_nproc_all_omp() {\n    let result = new_ucmd!().arg(\"--all\").succeeds();\n\n    let nproc: u8 = result.stdout_str().trim().parse().unwrap();\n    assert!(nproc > 0);\n\n    let result = TestScenario::new(util_name!())\n        .ucmd()\n        .env(\"OMP_NUM_THREADS\", \"60\")\n        .succeeds();\n\n    let nproc_omp: u8 = result.stdout_str().trim().parse().unwrap();\n    assert_eq!(nproc_omp, 60);\n\n    let result = TestScenario::new(util_name!())\n        .ucmd()\n        .env(\"OMP_NUM_THREADS\", \"1\") // Has no effect\n        .arg(\"--all\")\n        .succeeds();\n    let nproc_omp: u8 = result.stdout_str().trim().parse().unwrap();\n    assert_eq!(nproc, nproc_omp);\n\n    // If the parsing fails, returns the number of CPU\n    let result = TestScenario::new(util_name!())\n        .ucmd()\n        .env(\"OMP_NUM_THREADS\", \"incorrectnumber\") // returns the number CPU\n        .succeeds();\n    let nproc_omp: u8 = result.stdout_str().trim().parse().unwrap();\n    assert_eq!(nproc, nproc_omp);\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-parse-float/tests/options_tests.rs::invalid_inf_test", "code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn invalid_inf_test() {\n    let mut builder = OptionsBuilder::default();\n    builder = builder.inf_string(Some(b\"innnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnf\"));\n    assert!(!builder.is_valid());\n    builder = builder.inf_string(Some(b\"nan\"));\n    assert!(!builder.is_valid());\n    builder = builder.inf_string(Some(b\"in00f\"));\n    assert!(!builder.is_valid());\n    assert!(builder.build().is_err());\n    builder = builder.inf_string(Some(b\"i\"));\n    assert!(builder.is_valid());\n    builder = builder.inf_string(Some(b\"inf\"));\n    assert!(builder.is_valid());\n    assert!(builder.build().is_ok());\n    builder = builder.inf_string(None);\n    assert!(builder.is_valid());\n    builder = builder.infinity_string(None);\n    assert!(builder.is_valid());\n}"}
{"test_id": "paritytech-wasmi/paritytech-wasmi-d66f271/crates/wasi/tests/wasi_wat.rs::test_hello_world", "code": "pub fn call(\n        &self,\n        mut ctx: impl AsContextMut<UserState = T>,\n        instance: Option<&Instance>,\n        params: FuncParams,\n    ) -> Result<FuncFinished, Trap> {\n        let caller = <Caller<T>>::new(&mut ctx, instance);\n        (self.closure)(caller, params)\n    }", "test": "fn test_hello_world() {\n    let (mut store, instance) = load();\n    let f = instance\n        .get_export(&store, \"_start\")\n        .and_then(Extern::into_func)\n        .unwrap();\n    let mut result = [];\n    f.call(&mut store, &[], &mut result).unwrap();\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-write-integer/tests/api_tests.rs::u128_pow10_test", "code": "pub fn roundtrip<F>(float: F, buffer: &mut [u8]) -> Result<(), String>\nwhere\n    F: RawFloat + ToLexical + std::str::FromStr + std::string::ToString,\n{\n    let bytes = float.to_lexical(buffer);\n    let string = unsafe { std::str::from_utf8_unchecked(bytes) };\n    let roundtrip = string.parse::<F>().map_err(|_| float.to_string())?;\n    let is_equal = if float.is_nan() {\n        roundtrip.is_nan()\n    } else {\n        float == roundtrip\n    };\n    if !is_equal {\n        return Err(float.to_string());\n    }\n    Ok(())\n}", "test": "fn u128_pow10_test() {\n    let values: &[u128] = &[\n        0,\n        1,\n        5,\n        9,\n        10,\n        11,\n        15,\n        99,\n        100,\n        101,\n        105,\n        999,\n        1000,\n        1001,\n        1005,\n        9999,\n        10000,\n        10001,\n        10005,\n        99999,\n        100000,\n        100001,\n        100005,\n        999999,\n        1000000,\n        1000001,\n        1000005,\n        9999999,\n        10000000,\n        10000001,\n        10000005,\n        99999999,\n        100000000,\n        100000001,\n        100000005,\n        999999999,\n        1000000000,\n        1000000001,\n        1000000005,\n        9999999999,\n        10000000000,\n        10000000001,\n        10000000005,\n        99999999999,\n        100000000000,\n        100000000001,\n        100000000005,\n        999999999999,\n        1000000000000,\n        1000000000001,\n        1000000000005,\n        9999999999999,\n        10000000000000,\n        10000000000001,\n        10000000000005,\n        99999999999999,\n        100000000000000,\n        100000000000001,\n        100000000000005,\n        999999999999999,\n        1000000000000000,\n        1000000000000001,\n        1000000000000005,\n        9999999999999999,\n        10000000000000000,\n        10000000000000001,\n        10000000000000005,\n        99999999999999999,\n        100000000000000000,\n        100000000000000001,\n        100000000000000005,\n        999999999999999999,\n        1000000000000000000,\n        1000000000000000001,\n        1000000000000000005,\n        9999999999999999999,\n        10000000000000000000,\n        10000000000000000001,\n        10000000000000000005,\n        99999999999999999999,\n        100000000000000000000,\n        100000000000000000001,\n        100000000000000000005,\n        999999999999999999999,\n        1000000000000000000000,\n        1000000000000000000001,\n        1000000000000000000005,\n        9999999999999999999999,\n        10000000000000000000000,\n        10000000000000000000001,\n        10000000000000000000005,\n        99999999999999999999999,\n        100000000000000000000000,\n        100000000000000000000001,\n        100000000000000000000005,\n        999999999999999999999999,\n        1000000000000000000000000,\n        1000000000000000000000001,\n        1000000000000000000000005,\n        9999999999999999999999999,\n        10000000000000000000000000,\n        10000000000000000000000001,\n        10000000000000000000000005,\n        99999999999999999999999999,\n        100000000000000000000000000,\n        100000000000000000000000001,\n        100000000000000000000000005,\n        999999999999999999999999999,\n        1000000000000000000000000000,\n        1000000000000000000000000001,\n        1000000000000000000000000005,\n        9999999999999999999999999999,\n        10000000000000000000000000000,\n        10000000000000000000000000001,\n        10000000000000000000000000005,\n        99999999999999999999999999999,\n        100000000000000000000000000000,\n        100000000000000000000000000001,\n        100000000000000000000000000005,\n        999999999999999999999999999999,\n        1000000000000000000000000000000,\n        1000000000000000000000000000001,\n        1000000000000000000000000000005,\n        9999999999999999999999999999999,\n        10000000000000000000000000000000,\n        10000000000000000000000000000001,\n        10000000000000000000000000000005,\n        99999999999999999999999999999999,\n        100000000000000000000000000000000,\n        100000000000000000000000000000001,\n        100000000000000000000000000000005,\n        999999999999999999999999999999999,\n        1000000000000000000000000000000000,\n        1000000000000000000000000000000001,\n        1000000000000000000000000000000005,\n        9999999999999999999999999999999999,\n        10000000000000000000000000000000000,\n        10000000000000000000000000000000001,\n        10000000000000000000000000000000005,\n        99999999999999999999999999999999999,\n        100000000000000000000000000000000000,\n        100000000000000000000000000000000001,\n        100000000000000000000000000000000005,\n        999999999999999999999999999999999999,\n        1000000000000000000000000000000000000,\n        1000000000000000000000000000000000001,\n        1000000000000000000000000000000000005,\n        9999999999999999999999999999999999999,\n        10000000000000000000000000000000000000,\n        10000000000000000000000000000000000001,\n        10000000000000000000000000000000000005,\n        99999999999999999999999999999999999999,\n        100000000000000000000000000000000000000,\n        100000000000000000000000000000000000001,\n        100000000000000000000000000000000000005,\n    ];\n    for &i in values.iter() {\n        assert_eq!(i, roundtrip(i));\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_truncate.rs::test_fifo_error_reference_and_size", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_fifo_error_reference_and_size() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    at.mkfifo(\"fifo\");\n    at.make_file(\"reference_file\");\n    ucmd.args(&[\"-r\", \"reference_file\", \"-s\", \"+0\", \"fifo\"])\n        .fails()\n        .no_stdout()\n        .stderr_contains(\"cannot open 'fifo' for writing: No such device or address\");\n}"}
{"test_id": "ron-rs-ron/ron-rs-ron-eafa2b6/tests/123_enum_representation.rs::test_externally_b_ser", "code": "fn test_ser<T: Serialize>(value: &T, expected: &str) {\n    let actual = to_string(value).expect(\"Failed to serialize\");\n    assert_eq!(actual, expected);\n}", "test": "fn test_externally_b_ser() {\n    let v = EnumStructExternally::VariantB { foo: 1, bar: 2 };\n    let e = \"VariantB(foo:1,bar:2)\";\n    test_ser(&v, e);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_more.rs::test_more_no_arg", "code": "pub fn succeeds(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.success();\n        cmd_result\n    }", "test": "fn test_more_no_arg() {\n    // Reading from stdin is now supported, so this must succeed\n    if std::io::stdout().is_terminal() {\n        new_ucmd!().succeeds();\n    }\n}"}
{"test_id": "Lokathor-tinyvec/Lokathor-tinyvec-6e1bbaf/tests/arrayvec.rs::iter_last_nth", "code": "pub fn push(&mut self, val: A::Item) {\n    let x = self.try_push(val);\n    assert!(x.is_none(), \"ArrayVec::push> capacity overflow!\");\n  }", "test": "fn iter_last_nth() {\n  let mut av: ArrayVec<[i32; 10]> = Default::default();\n  av.push(1);\n  av.push(2);\n  av.push(3);\n  av.push(4);\n  assert_eq!(av.len(), 4);\n  let mut iter = av.into_iter();\n  assert_eq!(iter.next(), Some(1));\n  assert_eq!(iter.next(), Some(2));\n  assert_eq!(iter.next(), Some(3));\n  assert_eq!(iter.next(), Some(4));\n  assert_eq!(iter.next(), None);\n  assert_eq!(iter.last(), None);\n\n  let mut av: ArrayVec<[i32; 10]> = Default::default();\n  av.push(1);\n  av.push(2);\n  av.push(3);\n\n  assert_eq!(av.into_iter().nth(0), Some(1));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_csplit.rs::test_up_to_line_sequence", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_up_to_line_sequence() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"10\", \"25\"])\n        .succeeds()\n        .stdout_only(\"18\\n45\\n78\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"there should be splits created\")\n        .count();\n    assert_eq!(count, 3);\n    assert_eq!(at.read(\"xx00\"), generate(1, 10));\n    assert_eq!(at.read(\"xx01\"), generate(10, 25));\n    assert_eq!(at.read(\"xx02\"), generate(25, 51));\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/lint.rs::fs_error_infinite_symlink_expansion_to_files", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn fs_error_infinite_symlink_expansion_to_files() {\n    let mut console = BufferConsole::default();\n\n    let root_path = temp_dir().join(\"lint_rome_test_infinite_symlink_expansion_to_files\");\n    let subdir1_path = root_path.join(\"prefix\");\n    let subdir2_path = root_path.join(\"foo\").join(\"bar\");\n\n    let _ = remove_dir_all(&root_path);\n    create_dir_all(&subdir1_path).unwrap();\n    create_dir_all(&subdir2_path).unwrap();\n\n    let symlink1_path = subdir1_path.join(\"symlink1\");\n    let symlink2_path = subdir2_path.join(\"symlink2\");\n\n    #[cfg(target_family = \"unix\")]\n    {\n        symlink(&symlink2_path, &symlink1_path).unwrap();\n        symlink(&symlink1_path, &symlink2_path).unwrap();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        check_windows_symlink!(symlink_dir(&symlink2_path, &symlink1_path));\n        check_windows_symlink!(symlink_dir(&symlink1_path, &symlink2_path));\n    }\n\n    let result = run_cli(\n        DynRef::Owned(Box::new(OsFileSystem)),\n        &mut console,\n        Args::from([(\"lint\"), (root_path.display().to_string().as_str())].as_slice()),\n    );\n\n    remove_dir_all(root_path).unwrap();\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    // Don't use a snapshot here, since the diagnostics can be reported in\n    // arbitrary order:\n    assert!(console\n        .out_buffer\n        .iter()\n        .flat_map(|msg| msg.content.0.iter())\n        .any(|node| node.content.contains(\"Deeply nested symlink expansion\")));\n    assert!(console\n        .out_buffer\n        .iter()\n        .flat_map(|msg| msg.content.0.iter())\n        .any(|node| node.content.contains(&symlink1_path.display().to_string())));\n    assert!(console\n        .out_buffer\n        .iter()\n        .flat_map(|msg| msg.content.0.iter())\n        .any(|node| node.content.contains(&symlink2_path.display().to_string())));\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/engine_traits_tests/src/ctor.rs::new_engine_opt_missing_dir", "code": "pub fn sync(&mut self) -> Result<()> {\n        if self.enable_log {\n            self.append_file.as_mut().unwrap().sync_all()?;\n        }\n        Ok(())\n    }", "test": "fn new_engine_opt_missing_dir() {\n    let dir = tempdir();\n    let path = dir.path();\n    let path = path.join(\"missing\").to_str().unwrap().to_owned();\n    let db_opts = DbOptions::default();\n    let cf_opts = ALL_CFS.iter().map(|cf| (*cf, CfOptions::new())).collect();\n    let db = KvTestEngine::new_kv_engine_opt(&path, db_opts, cf_opts).unwrap();\n    db.put(b\"foo\", b\"bar\").unwrap();\n    db.sync().unwrap();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_stat.rs::test_char", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_char() {\n    // TODO: \"(%t) (%x) (%w)\" deviate from GNU stat for `character special file` on macOS\n    // Diff < left / right > :\n    // <\"(f0000) (2021-05-20 23:08:03.442555000 +0200) (1970-01-01 01:00:00.000000000 +0100)\\n\"\n    // >\"(f) (2021-05-20 23:08:03.455598000 +0200) (-)\\n\"\n    let args = [\n        \"-c\",\n        #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n        DEV_FORMAT_STR,\n        #[cfg(target_os = \"linux\")]\n        \"/dev/pts/ptmx\",\n        #[cfg(target_vendor = \"apple\")]\n        \"%a %A %b %B %d %D %f %F %g %G %h %i %m %n %o %s (/%T) %u %U %W %X %y %Y %z %Z\",\n        #[cfg(any(target_os = \"android\", target_vendor = \"apple\"))]\n        \"/dev/ptmx\",\n    ];\n    let ts = TestScenario::new(util_name!());\n    let expected_stdout = unwrap_or_return!(expected_result(&ts, &args)).stdout_move_str();\n    ts.ucmd().args(&args).succeeds().stdout_is(expected_stdout);\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/fallback.rs::works_with_provided_search_directory", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn works_with_provided_search_directory() {\n  Test::new()\n    .tree(tree! {\n      bar: {\n        justfile: \"\n          set fallback := true\n\n          baz:\n            echo subdir\n        \"\n      }\n    })\n    .justfile(\n      \"\n      foo:\n        echo root\n    \",\n    )\n    .args([\"./foo\"])\n    .stdout(\"root\\n\")\n    .stderr(\n      \"\n      echo root\n    \",\n    )\n    .current_dir(\"bar\")\n    .run();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_date.rs::test_date_format_m", "code": "pub fn stdout_matches(&self, regex: &regex::Regex) -> &Self {\n        assert!(\n            regex.is_match(self.stdout_str()),\n            \"Stdout does not match regex:\\n{}\",\n            self.stdout_str()\n        );\n        self\n    }", "test": "fn test_date_format_m() {\n    let scene = TestScenario::new(util_name!());\n\n    let mut re = Regex::new(r\"\\S+\").unwrap();\n    scene.ucmd().arg(\"+%b\").succeeds().stdout_matches(&re);\n\n    re = Regex::new(r\"^\\d{2}\\n$\").unwrap();\n    scene.ucmd().arg(\"+%m\").succeeds().stdout_matches(&re);\n}"}
{"test_id": "astral-sh-ruff/astral-sh-ruff-1a6898a/crates/ruff_cache/tests/cache_key.rs::named_field_struct", "code": "fn finish(&self) -> u64 {\n        self.inner.finish()\n    }", "test": "fn named_field_struct() {\n    #[derive(CacheKey, Hash)]\n    struct NamedFieldsStruct {\n        a: String,\n        b: String,\n    }\n\n    let mut key = CacheKeyHasher::new();\n\n    let named_fields = NamedFieldsStruct {\n        a: \"Hello\".into(),\n        b: \"World\".into(),\n    };\n\n    named_fields.cache_key(&mut key);\n\n    let mut hash = CacheKeyHasher::new();\n    named_fields.hash(&mut hash);\n\n    assert_eq!(hash.finish(), key.finish());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_arg_update_none_then_all", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_arg_update_none_then_all() {\n    // take last if multiple update args are supplied,\n    // update=all wins in this case\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let old = \"test_cp_arg_update_none_then_all_file1\";\n    let new = \"test_cp_arg_update_none_then_all_file2\";\n    let old_content = \"old content\\n\";\n    let new_content = \"new content\\n\";\n\n    at.write(old, old_content);\n\n    sleep(Duration::from_secs(1));\n\n    at.write(new, new_content);\n\n    ucmd.arg(old)\n        .arg(new)\n        .arg(\"--update=none\")\n        .arg(\"--update=all\")\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    assert_eq!(at.read(new), \"old content\\n\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_seq.rs::test_width_decimal_scientific_notation_trailing_zeros_start", "code": "pub fn no_stderr(&self) -> &Self {\n        assert!(\n            self.stderr.is_empty(),\n            \"Expected stderr to be empty, but it's:\\n{}\",\n            self.stderr_str()\n        );\n        self\n    }", "test": "fn test_width_decimal_scientific_notation_trailing_zeros_start() {\n    new_ucmd!()\n        .args(&[\"-w\", \".1000\", \"1e-2\", \".11\"])\n        .succeeds()\n        .stdout_is(\"0.1000\\n0.1100\\n\")\n        .no_stderr();\n}"}
{"test_id": "rustls-rustls/rustls-rustls-ae583bd/rustls/tests/api.rs::stream_write_swallows_underlying_io_error_after_plaintext_processed", "code": "fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        self.sess.write_early_data(buf)\n    }", "test": "fn stream_write_swallows_underlying_io_error_after_plaintext_processed() {\n    let (mut client, mut server) = make_pair(KeyType::Rsa);\n    do_handshake(&mut client, &mut server);\n\n    let mut pipe = FailsWrites {\n        errkind: io::ErrorKind::ConnectionAborted,\n        after: 1,\n    };\n    client\n        .writer()\n        .write_all(b\"hello\")\n        .unwrap();\n    let mut client_stream = Stream::new(&mut client, &mut pipe);\n    let rc = client_stream.write(b\"world\");\n    assert_eq!(format!(\"{:?}\", rc), \"Ok(5)\");\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/choose.rs::skip_recipes_that_require_arguments", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn skip_recipes_that_require_arguments() {\n  Test::new()\n    .arg(\"--choose\")\n    .env(\"JUST_CHOOSER\", \"head -n1\")\n    .justfile(\n      \"\n        foo:\n          echo foo\n\n        bar BAR:\n          echo {{BAR}}\n      \",\n    )\n    .stderr(\"echo foo\\n\")\n    .stdout(\"foo\\n\")\n    .run();\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/resolved_ts/tests/integrations/mod.rs::test_resolved_ts_basic", "code": "pub fn stop(&mut self) {\n        self.mut_store().cancel_applying_snap();\n        self.pending_reads.clear_all(None);\n    }", "test": "fn test_resolved_ts_basic() {\n    let mut suite = TestSuite::new(1);\n    let region = suite.cluster.get_region(&[]);\n\n    // Prewrite\n    let (k, v) = (b\"k1\", b\"v\");\n    let mut start_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();\n    let mut mutation = Mutation::default();\n    mutation.set_op(Op::Put);\n    mutation.key = k.to_vec();\n    mutation.value = v.to_vec();\n    suite.must_kv_prewrite(region.id, vec![mutation], k.to_vec(), start_ts, false);\n\n    // The `resolved-ts` won't be updated due to there is lock on the region,\n    // the `resolved-ts` may not be the `start_ts` of the lock if the `resolved-ts`\n    // is updated with a newer ts before the prewrite request come, but still the\n    // `resolved-ts` won't be updated\n    let rts = suite.region_resolved_ts(region.id).unwrap();\n\n    // Split region\n    suite.cluster.must_split(&region, k);\n    let r1 = suite.cluster.get_region(&[]);\n    let r2 = suite.cluster.get_region(k);\n    let current_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();\n    // Resolved ts of region1 should be advanced\n    suite.must_get_rts_ge(r1.id, current_ts);\n    // Resolved ts of region2 should be equal to rts\n    suite.must_get_rts(r2.id, rts);\n\n    // Merge region2 to region1\n    suite.cluster.must_try_merge(r2.id, r1.id);\n    // Resolved ts of region1 should be equal to rts\n    suite.must_get_rts(r1.id, rts);\n\n    // Commit\n    let commit_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();\n    suite.must_kv_commit(r1.id, vec![k.to_vec()], start_ts, commit_ts);\n    // Resolved ts of region1 should be advanced\n    let current_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();\n    suite.must_get_rts_ge(r1.id, current_ts);\n\n    // ingest sst\n    let temp_dir = Builder::new().prefix(\"test_resolved_ts\").tempdir().unwrap();\n    let sst_path = temp_dir.path().join(\"test.sst\");\n    let sst_range = (0, 100);\n\n    let mut sst_epoch = RegionEpoch::default();\n    sst_epoch.set_conf_ver(1);\n    sst_epoch.set_version(4);\n\n    let (mut meta, data) = gen_sst_file(sst_path, sst_range);\n    meta.set_region_id(r1.id);\n    meta.set_region_epoch(sst_epoch);\n\n    suite.upload_sst(r1.id, &meta, &data).unwrap();\n\n    let tracked_index_before = suite.region_tracked_index(r1.id);\n    suite.must_ingest_sst(r1.id, meta);\n    let mut tracked_index_after = suite.region_tracked_index(r1.id);\n    for _ in 0..10 {\n        if tracked_index_after > tracked_index_before {\n            break;\n        }\n        tracked_index_after = suite.region_tracked_index(r1.id);\n        sleep_ms(200)\n    }\n    assert!(tracked_index_after > tracked_index_before);\n\n    // 1PC\n    let tracked_index_before = suite.region_tracked_index(r1.id);\n\n    start_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();\n    let (k, v) = (b\"k2\", b\"v\");\n    let mut mutation_1pc = Mutation::default();\n    mutation_1pc.set_op(Op::Put);\n    mutation_1pc.key = k.to_vec();\n    mutation_1pc.value = v.to_vec();\n    suite.must_kv_prewrite(r1.id, vec![mutation_1pc], k.to_vec(), start_ts, true);\n\n    tracked_index_after = suite.region_tracked_index(r1.id);\n    for _ in 0..10 {\n        if tracked_index_after > tracked_index_before {\n            break;\n        }\n        tracked_index_after = suite.region_tracked_index(r1.id);\n        sleep_ms(200)\n    }\n    assert!(tracked_index_after > tracked_index_before);\n\n    suite.stop();\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_early_apply.rs::test_all_node_crash", "code": "fn test_early_apply(mode: DataLost) {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.pd_client.disable_default_operator();\n    // So compact log will not be triggered automatically.\n    configure_for_request_snapshot(&mut cluster);\n    cluster.run();\n    if mode == DataLost::LeaderCommit || mode == DataLost::AllLost {\n        cluster.must_transfer_leader(1, new_peer(1, 1));\n    } else {\n        cluster.must_transfer_leader(1, new_peer(3, 3));\n    }\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(1), b\"k1\", b\"v1\");\n\n    test(\n        &mut cluster,\n        |c| {\n            c.async_put(b\"k2\", b\"v2\").unwrap();\n        },\n        |c| must_get_equal(&c.get_engine(1), b\"k2\", b\"v2\"),\n        mode,\n    );\n    let region = cluster.get_region(b\"\");\n    test(\n        &mut cluster,\n        |c| {\n            c.split_region(&region, b\"k2\", Callback::None);\n        },\n        |c| c.wait_region_split(&region),\n        mode,\n    );\n    if mode != DataLost::LeaderCommit && mode != DataLost::AllLost {\n        test(\n            &mut cluster,\n            |c| {\n                c.async_remove_peer(1, new_peer(1, 1)).unwrap();\n            },\n            |c| must_get_none(&c.get_engine(1), b\"k2\"),\n            mode,\n        );\n    }\n}", "test": "fn test_all_node_crash() {\n    test_early_apply(DataLost::AllLost)\n}"}
{"test_id": "web-infra-dev-oxc/oxc-project-oxc-884a819/crates/oxc_minifier/tests/oxc/precedence.rs::logical_and", "code": "fn test(args: &[&str]) -> LintResult {\n        let mut new_args = vec![\"--quiet\"];\n        new_args.extend(args);\n        let options = lint_command().run_inner(new_args.as_slice()).unwrap().lint_options;\n        let CliRunResult::LintResult(lint_result) = LintRunner::new(options).run() else {\n            unreachable!()\n        };\n        lint_result\n    }", "test": "fn logical_and() {\n    test(\"a && b && c\", \"a&&b&&c;\");\n    test(\"a && ((b && c) && d)\", \"a&&b&&c&&d;\");\n    test(\"((a && b) && c) && d\", \"a&&b&&c&&d;\");\n    test(\"(a || b) && (c || d)\", \"(a||b)&&(c||d);\");\n    test(\"a, b && c, d\", \"a,b&&c,d;\");\n    test(\"(a, b) && (c, d)\", \"(a,b)&&(c,d);\");\n    test(\"a || b && c || d\", \"a||b&&c||d;\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_wc.rs::test_stdin_default", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_stdin_default() {\n    new_ucmd!()\n        .pipe_in_fixture(\"lorem_ipsum.txt\")\n        .run()\n        .stdout_is(\"     13     109     772\\n\");\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/crates/server/tests/sqlite_tests.rs::test_new_journal", "code": "pub fn schema_version(&self) -> i64 {\n        self.version\n    }", "test": "fn test_new_journal() {\n    let conn = Connection::open_in_memory().expect(\"could not create in memory DB\");\n    assert_eq!(\n        Journal::new(conn).expect(\"new Journal\").schema_version(),\n        -1\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_dd.rs::test_null_fullblock", "code": "pub fn success(&self) -> &Self {\n        assert!(\n            self.succeeded(),\n            \"Command was expected to succeed.\\nstdout = {}\\n stderr = {}\",\n            self.stdout_str(),\n            self.stderr_str()\n        );\n        self\n    }", "test": "fn test_null_fullblock() {\n    new_ucmd!()\n        .args(&[\"if=null.txt\", \"status=none\", \"iflag=fullblock\"])\n        .run()\n        .no_stdout()\n        .no_stderr()\n        .success();\n}"}
{"test_id": "dtolnay-syn/dtolnay-syn-b1a038c/tests/test_attribute.rs::test_meta_item_multiple", "code": "fn test(input: &str) -> Meta {\n    let attrs = Attribute::parse_outer.parse_str(input).unwrap();\n\n    assert_eq!(attrs.len(), 1);\n    let attr = attrs.into_iter().next().unwrap();\n\n    attr.meta\n}", "test": "fn test_meta_item_multiple() {\n    let meta = test(\"#[foo(word, name = 5, list(name2 = 6), word2)]\");\n\n    snapshot!(meta, @r###\"\n    Meta::List {\n        path: Path {\n            segments: [\n                PathSegment {\n                    ident: \"foo\",\n                },\n            ],\n        },\n        delimiter: MacroDelimiter::Paren,\n        tokens: TokenStream(`word , name = 5 , list (name2 = 6) , word2`),\n    }\n    \"###);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_stale_peer.rs::test_destroy_clean_up_logs_with_unfinished_log_gc", "code": "pub fn is_empty(&self) -> bool {\n        self.entries.len() == 0\n    }", "test": "fn test_destroy_clean_up_logs_with_unfinished_log_gc() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(15);\n    cluster.cfg.raft_store.raft_log_gc_threshold = 15;\n    let pd_client = cluster.pd_client.clone();\n\n    // Disable default max peer number check.\n    pd_client.disable_default_operator();\n    cluster.run();\n    // Simulate raft log gc tasks are lost during shutdown.\n    let fp = \"worker_gc_raft_log\";\n    fail::cfg(fp, \"return\").unwrap();\n\n    let state = cluster.truncated_state(1, 3);\n    for i in 0..30 {\n        let b = format!(\"k{}\", i).into_bytes();\n        cluster.must_put(&b, &b);\n    }\n    must_get_equal(&cluster.get_engine(3), b\"k29\", b\"k29\");\n    cluster.wait_log_truncated(1, 3, state.get_index() + 1);\n    cluster.stop_node(3);\n    let truncated_index = cluster.truncated_state(1, 3).get_index();\n    let raft_engine = cluster.engines[&3].raft.clone();\n    // Make sure there are stale logs.\n    raft_engine.get_entry(1, truncated_index).unwrap().unwrap();\n\n    pd_client.must_remove_peer(1, new_peer(3, 3));\n    cluster.must_put(b\"k30\", b\"v30\");\n    must_get_equal(&cluster.get_engine(1), b\"k30\", b\"v30\");\n\n    fail::remove(fp);\n    // So peer (3, 3) will be destroyed by gc message. And all stale logs before\n    // first index should be cleaned up.\n    cluster.run_node(3).unwrap();\n    must_get_none(&cluster.get_engine(3), b\"k29\");\n\n    let mut dest = vec![];\n    raft_engine.get_all_entries_to(1, &mut dest).unwrap();\n    // All logs should be deleted.\n    assert!(dest.is_empty(), \"{:?}\", dest);\n}"}
{"test_id": "hyperium-http/hyperium-http-818269d/tests/header_map.rs::remove_entry_multi_2", "code": "fn remove_all_values<K>(headers: &mut HeaderMap, key: K) -> Vec<HeaderValue>\n    where K: IntoHeaderName\n{\n    match headers.entry(key) {\n        Entry::Occupied(e) => e.remove_entry_mult().1.collect(),\n        Entry::Vacant(_) => vec![],\n    }\n}", "test": "fn remove_entry_multi_2() {\n    let mut headers = HeaderMap::new();\n    headers.insert(SET_COOKIE, \"cookie_1=value 1\".parse().unwrap());\n    headers.append(SET_COOKIE, \"cookie_2=value 2\".parse().unwrap());\n\n    let cookies = remove_all_values(&mut headers, SET_COOKIE);\n    assert_eq!(cookies.len(), 2);\n    assert_eq!(headers.len(), 0);\n}"}
{"test_id": "serde-rs-json/serde-rs-json-66f862f/tests/test.rs::test_serialize_map_with_no_len", "code": "pub fn to_string_pretty<T>(value: &T) -> Result<String>\nwhere\n    T: ?Sized + Serialize,\n{\n    let vec = tri!(to_vec_pretty(value));\n    let string = unsafe {\n        // We do not emit invalid UTF-8.\n        String::from_utf8_unchecked(vec)\n    };\n    Ok(string)\n}", "test": "fn test_serialize_map_with_no_len() {\n    #[derive(Clone, Debug, PartialEq)]\n    struct MyMap<K, V>(BTreeMap<K, V>);\n\n    impl<K, V> ser::Serialize for MyMap<K, V>\n    where\n        K: ser::Serialize + Ord,\n        V: ser::Serialize,\n    {\n        fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n        where\n            S: ser::Serializer,\n        {\n            let mut map = serializer.serialize_map(None)?;\n            for (k, v) in &self.0 {\n                map.serialize_entry(k, v)?;\n            }\n            map.end()\n        }\n    }\n\n    struct Visitor<K, V> {\n        marker: PhantomData<MyMap<K, V>>,\n    }\n\n    impl<'de, K, V> de::Visitor<'de> for Visitor<K, V>\n    where\n        K: de::Deserialize<'de> + Eq + Ord,\n        V: de::Deserialize<'de>,\n    {\n        type Value = MyMap<K, V>;\n\n        fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {\n            formatter.write_str(\"map\")\n        }\n\n        fn visit_unit<E>(self) -> Result<MyMap<K, V>, E>\n        where\n            E: de::Error,\n        {\n            Ok(MyMap(BTreeMap::new()))\n        }\n\n        fn visit_map<Visitor>(self, mut visitor: Visitor) -> Result<MyMap<K, V>, Visitor::Error>\n        where\n            Visitor: de::MapAccess<'de>,\n        {\n            let mut values = BTreeMap::new();\n\n            while let Some((key, value)) = visitor.next_entry()? {\n                values.insert(key, value);\n            }\n\n            Ok(MyMap(values))\n        }\n    }\n\n    impl<'de, K, V> de::Deserialize<'de> for MyMap<K, V>\n    where\n        K: de::Deserialize<'de> + Eq + Ord,\n        V: de::Deserialize<'de>,\n    {\n        fn deserialize<D>(deserializer: D) -> Result<MyMap<K, V>, D::Error>\n        where\n            D: de::Deserializer<'de>,\n        {\n            deserializer.deserialize_map(Visitor {\n                marker: PhantomData,\n            })\n        }\n    }\n\n    let mut map = BTreeMap::new();\n    map.insert(\"a\", MyMap(BTreeMap::new()));\n    map.insert(\"b\", MyMap(BTreeMap::new()));\n    let map: MyMap<_, MyMap<u32, u32>> = MyMap(map);\n\n    test_encode_ok(&[(map.clone(), \"{\\\"a\\\":{},\\\"b\\\":{}}\")]);\n\n    let s = to_string_pretty(&map).unwrap();\n    let expected = pretty_str!({\n        \"a\": {},\n        \"b\": {}\n    });\n    assert_eq!(s, expected);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_install.rs::test_install_copy_file", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_copy_file() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file1 = \"source_file\";\n    let file2 = \"target_file\";\n\n    at.touch(file1);\n    ucmd.arg(file1).arg(file2).succeeds().no_stderr();\n\n    assert!(at.file_exists(file1));\n    assert!(at.file_exists(file2));\n}"}
{"test_id": "serde-rs-json/serde-rs-json-66f862f/tests/test.rs::test_byte_buf_ser", "code": "pub fn to_string<T>(value: &T) -> Result<String>\nwhere\n    T: ?Sized + Serialize,\n{\n    let vec = tri!(to_vec(value));\n    let string = unsafe {\n        // We do not emit invalid UTF-8.\n        String::from_utf8_unchecked(vec)\n    };\n    Ok(string)\n}", "test": "fn test_byte_buf_ser() {\n    let bytes = ByteBuf::new();\n    assert_eq!(to_string(&bytes).unwrap(), \"[]\".to_string());\n\n    let bytes = ByteBuf::from(vec![1, 2, 3]);\n    assert_eq!(to_string(&bytes).unwrap(), \"[1,2,3]\".to_string());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_dircolors.rs::test_stdin", "code": "pub fn no_stderr(&self) -> &Self {\n        assert!(\n            self.stderr.is_empty(),\n            \"Expected stderr to be empty, but it's:\\n{}\",\n            self.stderr_str()\n        );\n        self\n    }", "test": "fn test_stdin() {\n    new_ucmd!()\n        .pipe_in(\"owt 40;33\\n\")\n        .args(&[\"-b\", \"-\"])\n        .succeeds()\n        .stdout_is(\"LS_COLORS='tw=40;33:';\\nexport LS_COLORS\\n\")\n        .no_stderr();\n}"}
{"test_id": "rustls-rustls/rustls-rustls-ae583bd/rustls/tests/api.rs::server_closes_uncleanly", "code": "fn write(&mut self, buf: &[u8]) -> Result<usize> {\n        self.complete_prior_io()?;\n\n        let len = self.conn.writer().write(buf)?;\n\n        // Try to write the underlying transport here, but don't let\n        // any errors mask the fact we've consumed `len` bytes.\n        // Callers will learn of permanent errors on the next call.\n        let _ = self.conn.complete_io(self.sock);\n\n        Ok(len)\n    }", "test": "fn server_closes_uncleanly() {\n    let kt = KeyType::Rsa;\n    let server_config = Arc::new(make_server_config(kt));\n\n    for version in rustls::ALL_VERSIONS {\n        let client_config = make_client_config_with_versions(kt, &[version]);\n        let (mut client, mut server) =\n            make_pair_for_arc_configs(&Arc::new(client_config), &server_config);\n        do_handshake(&mut client, &mut server);\n\n        // check that unclean EOF reporting does not overtake appdata\n        assert_eq!(\n            12,\n            server\n                .writer()\n                .write(b\"from-server!\")\n                .unwrap()\n        );\n        assert_eq!(\n            12,\n            client\n                .writer()\n                .write(b\"from-client!\")\n                .unwrap()\n        );\n\n        transfer(&mut server, &mut client);\n        transfer_eof(&mut client);\n        let io_state = client.process_new_packets().unwrap();\n        assert!(!io_state.peer_has_closed());\n        check_read(&mut client.reader(), b\"from-server!\");\n\n        check_read_err(\n            &mut client.reader() as &mut dyn io::Read,\n            io::ErrorKind::UnexpectedEof,\n        );\n\n        // may still transmit pending frames\n        transfer(&mut client, &mut server);\n        server.process_new_packets().unwrap();\n        check_read(&mut server.reader(), b\"from-client!\");\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_join.rs::tab_multi_character", "code": "pub fn stderr_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stderr_str(), msg.as_ref());\n        self\n    }", "test": "fn tab_multi_character() {\n    new_ucmd!()\n        .arg(\"semicolon_fields_1.txt\")\n        .arg(\"semicolon_fields_2.txt\")\n        .arg(\"-t\")\n        .arg(\"\u044d\")\n        .fails()\n        .stderr_is(\"join: multi-character tab \u044d\\n\");\n}\n\n"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_numfmt.rs::test_from_iec_i", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_from_iec_i() {\n    new_ucmd!()\n        .args(&[\"--from=iec-i\"])\n        .pipe_in(\"1.1Mi\\n0.1Gi\")\n        .run()\n        .stdout_is(\"1153434\\n107374183\\n\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_transfer_leader.rs::test_prewrite_before_max_ts_is_synced", "code": "pub fn has_max_timestamp_not_synced(&self) -> bool {\n        self.max_timestamp_not_synced.is_some()\n    }", "test": "fn test_prewrite_before_max_ts_is_synced() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.raft_heartbeat_ticks = 20;\n    cluster.run();\n\n    let addr = cluster.sim.rl().get_addr(1);\n    let env = Arc::new(Environment::new(1));\n    let channel = ChannelBuilder::new(env).connect(&addr);\n    let client = TikvClient::new(channel);\n\n    let do_prewrite = |cluster: &mut Cluster<ServerCluster>| {\n        let region_id = 1;\n        let leader = cluster.leader_of_region(region_id).unwrap();\n        let epoch = cluster.get_region_epoch(region_id);\n        let mut ctx = Context::default();\n        ctx.set_region_id(region_id);\n        ctx.set_peer(leader);\n        ctx.set_region_epoch(epoch);\n\n        let mut req = PrewriteRequest::default();\n        req.set_context(ctx);\n        req.set_primary_lock(b\"key\".to_vec());\n        let mut mutation = Mutation::default();\n        mutation.set_op(Op::Put);\n        mutation.set_key(b\"key\".to_vec());\n        mutation.set_value(b\"value\".to_vec());\n        req.mut_mutations().push(mutation);\n        req.set_start_version(100);\n        req.set_lock_ttl(20000);\n        req.set_use_async_commit(true);\n        client.kv_prewrite(&req).unwrap()\n    };\n\n    cluster.must_transfer_leader(1, new_peer(2, 2));\n    fail::cfg(\"test_raftstore_get_tso\", \"return(50)\").unwrap();\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    let resp = do_prewrite(&mut cluster);\n    assert!(resp.get_region_error().has_max_timestamp_not_synced());\n    fail::remove(\"test_raftstore_get_tso\");\n    thread::sleep(Duration::from_millis(200));\n    let resp = do_prewrite(&mut cluster);\n    assert!(!resp.get_region_error().has_max_timestamp_not_synced());\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/lint.rs::lint_error", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn lint_error() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"check.js\");\n    fs.insert(file_path.into(), LINT_ERROR.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"lint\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"lint_error\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "yamafaktory-jql/yamafaktory-jql-d2dde2f/crates/jql-runner/tests/integration.rs::check_raw_integration", "code": "pub fn raw(input: &str, json: &Value) -> Result<Value, JqlRunnerError> {\n    if input.is_empty() {\n        return Err(JqlRunnerError::EmptyQueryError);\n    }\n\n    let tokens = parse(input)?;\n\n    token(&tokens, json)\n}", "test": "fn check_raw_integration() {\n    assert_eq!(\n        raw(r#\"\"a\",\"b\"\"#, &json!({ \"a\": 1, \"b\": 2 })),\n        Ok(json!([1, 2]))\n    );\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/control_flow/mod.rs::test_invalid_continue_target", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn test_invalid_continue_target() {\n    run_test_actions([TestAction::assert_native_error(\n        indoc! {r#\"\n            while (false) {\n                continue nonexistent;\n            }\n        \"#},\n        JsNativeErrorKind::Syntax,\n        \"undefined continue target: nonexistent at line 1, col 1\",\n    )]);\n}"}
{"test_id": "ron-rs-ron/ron-rs-ron-eafa2b6/tests/250_variant_newtypes.rs::test_serialise_non_newtypes", "code": "fn assert_eq_serialize_roundtrip<\n    S: Serialize + serde::de::DeserializeOwned + PartialEq + std::fmt::Debug,\n>(\n    value: S,\n    extensions: Extensions,\n) {\n    assert_eq!(\n        from_str::<S>(\n            &to_string_pretty(&value, PrettyConfig::default().extensions(extensions)).unwrap()\n        )\n        .unwrap(),\n        value,\n    );\n}", "test": "fn test_serialise_non_newtypes() {\n    assert_eq_serialize_roundtrip(TestEnum::Unit, Extensions::UNWRAP_VARIANT_NEWTYPES);\n\n    assert_eq_serialize_roundtrip(\n        TestEnum::PrimitiveNewtype(String::from(\"hi\")),\n        Extensions::UNWRAP_VARIANT_NEWTYPES,\n    );\n\n    assert_eq_serialize_roundtrip(\n        TestEnum::Tuple(4, false),\n        Extensions::UNWRAP_VARIANT_NEWTYPES,\n    );\n\n    assert_eq_serialize_roundtrip(\n        TestEnum::Struct { a: 4, b: false },\n        Extensions::UNWRAP_VARIANT_NEWTYPES,\n    );\n}"}
{"test_id": "astral-sh-ruff/astral-sh-ruff-1a6898a/crates/ruff_python_ast/tests/stmt_if.rs::extract_elif_else_range", "code": "pub const fn start(self) -> TextSize {\n        self.start\n    }", "test": "fn extract_elif_else_range() -> Result<(), ParseError> {\n    let contents = \"if a:\n    ...\nelif b:\n    ...\n\";\n    let mut stmts = parse_suite(contents, \"<filename>\")?;\n    let stmt = stmts\n        .pop()\n        .and_then(ruff_python_ast::Stmt::if_stmt)\n        .unwrap();\n    let range = elif_else_range(&stmt.elif_else_clauses[0], contents).unwrap();\n    assert_eq!(range.start(), TextSize::from(14));\n    assert_eq!(range.end(), TextSize::from(18));\n\n    let contents = \"if a:\n    ...\nelse:\n    ...\n\";\n    let mut stmts = parse_suite(contents, \"<filename>\")?;\n    let stmt = stmts\n        .pop()\n        .and_then(ruff_python_ast::Stmt::if_stmt)\n        .unwrap();\n    let range = elif_else_range(&stmt.elif_else_clauses[0], contents).unwrap();\n    assert_eq!(range.start(), TextSize::from(14));\n    assert_eq!(range.end(), TextSize::from(18));\n\n    Ok(())\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/externals.rs::fill_funcref_tables_via_api", "code": "pub fn get(&self, index: u32) -> Option<TableElement> {\n        self.elements()\n            .get(index as usize)\n            .map(|p| unsafe { TableElement::clone_from_table_value(self.element_type(), *p) })\n    }", "test": "fn fill_funcref_tables_via_api() -> anyhow::Result<()> {\n    let mut cfg = Config::new();\n    cfg.wasm_reference_types(true);\n    let engine = Engine::new(&cfg)?;\n    let mut store = Store::new(&engine, ());\n\n    let table_ty = TableType::new(ValType::FuncRef, 10, None);\n    let table = Table::new(&mut store, table_ty, Val::FuncRef(None))?;\n\n    for i in 0..10 {\n        assert!(table.get(&mut store, i).unwrap().unwrap_funcref().is_none());\n    }\n\n    let fill = Val::FuncRef(Some(Func::wrap(&mut store, || {})));\n    table.fill(&mut store, 2, fill, 4)?;\n\n    for i in (0..2).chain(7..10) {\n        assert!(table.get(&mut store, i).unwrap().unwrap_funcref().is_none());\n    }\n    for i in 2..6 {\n        assert!(table.get(&mut store, i).unwrap().unwrap_funcref().is_some());\n    }\n\n    Ok(())\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_hashsum.rs::test_check_sha1", "code": "pub fn stderr_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stderr_str(), msg.as_ref());\n        self\n    }", "test": "fn test_check_sha1() {\n    // To make sure that #3815 doesn't happen again\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    at.write(\"testf\", \"foobar\\n\");\n    at.write(\n        \"testf.sha1\",\n        \"988881adc9fc3655077dc2d4d757d480b5ea0e11  testf\\n\",\n    );\n    scene\n        .ccmd(\"sha1sum\")\n        .arg(\"-c\")\n        .arg(at.subdir.join(\"testf.sha1\"))\n        .succeeds()\n        .stdout_is(\"testf: OK\\n\")\n        .stderr_is(\"\");\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/newline_escape.rs::newline_escape_deps_invalid_esc", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn newline_escape_deps_invalid_esc() {\n  Test::new()\n    .justfile(\n      \"\n      default: a\\\\ b\n    \",\n    )\n    .stdout(\"\")\n    .stderr(\n      \"\n        error: `\\\\ ` is not a valid escape sequence\n          |\n        1 | default: a\\\\ b\n          |           ^\n      \",\n    )\n    .status(EXIT_FAILURE)\n    .run();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_split.rs::test_alphabetic_dynamic_suffix_length", "code": "pub fn succeeds(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.success();\n        cmd_result\n    }", "test": "fn test_alphabetic_dynamic_suffix_length() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    // Split into chunks of one byte each.\n    //\n    // The input file has (26^2) - 26 + 1 = 651 bytes. This is just\n    // enough to force `split` to dynamically increase the length of\n    // the filename for the very last chunk.\n    //\n    // We expect the output files to be named\n    //\n    //     xaa, xab, xac, ..., xyx, xyy, xyz, xzaaa\n    //\n    ucmd.args(&[\"-b\", \"1\", \"sixhundredfiftyonebytes.txt\"])\n        .succeeds();\n    for i in b'a'..=b'y' {\n        for j in b'a'..=b'z' {\n            let filename = format!(\"x{}{}\", i as char, j as char);\n            let contents = file_read(&at, &filename);\n            assert_eq!(contents, \"a\");\n        }\n    }\n    assert_eq!(file_read(&at, \"xzaaa\"), \"a\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_arg_suffix_hyphen_value", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_arg_suffix_hyphen_value() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(\"-b\")\n        .arg(\"--suffix\")\n        .arg(\"-v\")\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .succeeds();\n\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), \"Hello, World!\\n\");\n    assert_eq!(\n        at.read(&format!(\"{TEST_HOW_ARE_YOU_SOURCE}-v\")),\n        \"How are you?\\n\"\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_touch.rs::test_touch_set_mdhms_time", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_mdhms_time() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_mdhms_time\";\n\n    ucmd.args(&[\"-t\", \"01011234.56\", file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n\n    let start_of_year = str_to_filetime(\n        \"%Y%m%d%H%M.%S\",\n        &format!(\"{}01010000.00\", time::OffsetDateTime::now_utc().year()),\n    );\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, mtime);\n    assert_eq!(atime.unix_seconds() - start_of_year.unix_seconds(), 45296);\n    assert_eq!(mtime.unix_seconds() - start_of_year.unix_seconds(), 45296);\n}"}
{"test_id": "rust-bitcoin-rust-bitcoin/rust-bitcoin-rust-bitcoin-5ee33ea/bitcoin/tests/serde.rs::serde_regression_witness", "code": "pub fn serialize(&self) -> Vec<u8> {\n        let mut buf: Vec<u8> = Vec::new();\n\n        //  <magic>\n        buf.extend_from_slice(b\"psbt\");\n\n        buf.push(0xff_u8);\n\n        buf.extend(self.serialize_map());\n\n        for i in &self.inputs {\n            buf.extend(i.serialize_map());\n        }\n\n        for i in &self.outputs {\n            buf.extend(i.serialize_map());\n        }\n\n        buf\n    }", "test": "fn serde_regression_witness() {\n    let w0 = Vec::from_hex(\"03d2e15674941bad4a996372cb87e1856d3652606d98562fe39c5e9e7e413f2105\")\n        .unwrap();\n    let w1 = Vec::from_hex(\"000000\").unwrap();\n    let vec = vec![w0, w1];\n    let witness = Witness::from_slice(&vec);\n\n    let got = serialize(&witness).unwrap();\n    let want = include_bytes!(\"data/serde/witness_bincode\") as &[_];\n    assert_eq!(got, want)\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_printf.rs::escaped_hex", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn escaped_hex() {\n    new_ucmd!().args(&[\"\\\\x41\"]).succeeds().stdout_only(\"A\");\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/component_model/func.rs::chars", "code": "pub fn call(&self, arguments: &[DataValue]) -> Vec<DataValue> {\n        let mut values = UnboxedValues::make_arguments(arguments, &self.func_signature);\n        let arguments_address = values.as_mut_ptr();\n\n        let function_ptr = self.module.get_finalized_function(self.func_id);\n        let trampoline_ptr = self.module.get_finalized_function(self.trampoline_id);\n\n        let callable_trampoline: fn(*const u8, *mut u128) -> () =\n            unsafe { mem::transmute(trampoline_ptr) };\n        callable_trampoline(function_ptr, arguments_address);\n\n        values.collect_returns(&self.func_signature)\n    }", "test": "fn chars() -> Result<()> {\n    let component = r#\"\n        (component\n            (core module $m\n                (func (export \"pass\") (param i32) (result i32) local.get 0)\n            )\n            (core instance $i (instantiate $m))\n\n            (func (export \"u32-to-char\") (param \"a\" u32) (result char)\n                (canon lift (core func $i \"pass\"))\n            )\n            (func (export \"char-to-u32\") (param \"a\" char) (result u32)\n                (canon lift (core func $i \"pass\"))\n            )\n        )\n    \"#;\n\n    let engine = super::engine();\n    let component = Component::new(&engine, component)?;\n    let mut store = Store::new(&engine, ());\n    let instance = Linker::new(&engine).instantiate(&mut store, &component)?;\n    let u32_to_char = instance.get_typed_func::<(u32,), (char,)>(&mut store, \"u32-to-char\")?;\n    let char_to_u32 = instance.get_typed_func::<(char,), (u32,)>(&mut store, \"char-to-u32\")?;\n\n    let mut roundtrip = |x: char| -> Result<()> {\n        assert_eq!(char_to_u32.call(&mut store, (x,))?, (x as u32,));\n        char_to_u32.post_return(&mut store)?;\n        assert_eq!(u32_to_char.call(&mut store, (x as u32,))?, (x,));\n        u32_to_char.post_return(&mut store)?;\n        Ok(())\n    };\n\n    roundtrip('x')?;\n    roundtrip('a')?;\n    roundtrip('\\0')?;\n    roundtrip('\\n')?;\n    roundtrip('\ud83d\udc9d')?;\n\n    let u32_to_char = |store: &mut Store<()>| {\n        Linker::new(&engine)\n            .instantiate(&mut *store, &component)?\n            .get_typed_func::<(u32,), (char,)>(&mut *store, \"u32-to-char\")\n    };\n    let err = u32_to_char(&mut store)?\n        .call(&mut store, (0xd800,))\n        .unwrap_err();\n    assert!(err.to_string().contains(\"integer out of range\"), \"{}\", err);\n    let err = u32_to_char(&mut store)?\n        .call(&mut store, (0xdfff,))\n        .unwrap_err();\n    assert!(err.to_string().contains(\"integer out of range\"), \"{}\", err);\n    let err = u32_to_char(&mut store)?\n        .call(&mut store, (0x110000,))\n        .unwrap_err();\n    assert!(err.to_string().contains(\"integer out of range\"), \"{}\", err);\n    let err = u32_to_char(&mut store)?\n        .call(&mut store, (u32::MAX,))\n        .unwrap_err();\n    assert!(err.to_string().contains(\"integer out of range\"), \"{}\", err);\n\n    Ok(())\n}\n\n#"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/control_flow/loops.rs::do_loop_late_break", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn do_loop_late_break() {\n    // Ordering with statement before the break.\n    run_test_actions([TestAction::assert_eq(\n        indoc! {r#\"\n            let a = 1;\n            do {\n                a++;\n                if (a == 3) {\n                    break;\n                }\n            } while (a < 5);\n            a;\n        \"#},\n        3,\n    )]);\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_bigquery.rs::parse_typeless_struct_syntax", "code": "pub fn verified_only_select(&self, query: &str) -> Select {\n        match *self.verified_query(query).body {\n            SetExpr::Select(s) => *s,\n            _ => panic!(\"Expected SetExpr::Select\"),\n        }\n    }", "test": "fn parse_typeless_struct_syntax() {\n    // typeless struct syntax https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#typeless_struct_syntax\n    // syntax: STRUCT( expr1 [AS field_name] [, ... ])\n    let sql = \"SELECT STRUCT(1, 2, 3), STRUCT('abc'), STRUCT(1, t.str_col), STRUCT(1 AS a, 'abc' AS b), STRUCT(str_col AS abc)\";\n    let select = bigquery().verified_only_select(sql);\n    assert_eq!(5, select.projection.len());\n    assert_eq!(\n        &Expr::Struct {\n            values: vec![\n                Expr::Value(number(\"1\")),\n                Expr::Value(number(\"2\")),\n                Expr::Value(number(\"3\")),\n            ],\n            fields: Default::default()\n        },\n        expr_from_projection(&select.projection[0])\n    );\n\n    assert_eq!(\n        &Expr::Struct {\n            values: vec![Expr::Value(Value::SingleQuotedString(\"abc\".to_string())),],\n            fields: Default::default()\n        },\n        expr_from_projection(&select.projection[1])\n    );\n    assert_eq!(\n        &Expr::Struct {\n            values: vec![\n                Expr::Value(number(\"1\")),\n                Expr::CompoundIdentifier(vec![Ident::from(\"t\"), Ident::from(\"str_col\")]),\n            ],\n            fields: Default::default()\n        },\n        expr_from_projection(&select.projection[2])\n    );\n    assert_eq!(\n        &Expr::Struct {\n            values: vec![\n                Expr::Named {\n                    expr: Expr::Value(number(\"1\")).into(),\n                    name: Ident::from(\"a\")\n                },\n                Expr::Named {\n                    expr: Expr::Value(Value::SingleQuotedString(\"abc\".to_string())).into(),\n                    name: Ident::from(\"b\")\n                },\n            ],\n            fields: Default::default()\n        },\n        expr_from_projection(&select.projection[3])\n    );\n    assert_eq!(\n        &Expr::Struct {\n            values: vec![Expr::Named {\n                expr: Expr::Identifier(Ident::from(\"str_col\")).into(),\n                name: Ident::from(\"abc\")\n            }],\n            fields: Default::default()\n        },\n        expr_from_projection(&select.projection[4])\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_stty.rs::test_invalid_arg", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_invalid_arg() {\n    new_ucmd!().arg(\"--definitely-invalid\").fails().code_is(1);\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_bigquery.rs::parse_invalid_brackets", "code": "pub fn parse_sql_statements(&self, sql: &str) -> Result<Vec<Statement>, ParserError> {\n        self.one_of_identical_results(|dialect| {\n            let mut tokenizer = Tokenizer::new(dialect, sql);\n            if let Some(options) = &self.options {\n                tokenizer = tokenizer.with_unescape(options.unescape);\n            }\n            let tokens = tokenizer.tokenize()?;\n            self.new_parser(dialect)\n                .with_tokens(tokens)\n                .parse_statements()\n        })\n        // To fail the `ensure_multiple_dialects_are_tested` test:\n        // Parser::parse_sql(&**self.dialects.first().unwrap(), sql)\n    }", "test": "fn parse_invalid_brackets() {\n    let sql = \"SELECT STRUCT<INT64>>(NULL)\";\n    assert_eq!(\n        bigquery().parse_sql_statements(sql).unwrap_err(),\n        ParserError::ParserError(\"unmatched > in STRUCT literal\".to_string())\n    );\n\n    let sql = \"SELECT STRUCT<STRUCT<INT64>>>(NULL)\";\n    assert_eq!(\n        bigquery().parse_sql_statements(sql).unwrap_err(),\n        ParserError::ParserError(\"Expected (, found: >\".to_string())\n    );\n\n    let sql = \"CREATE TABLE table (x STRUCT<STRUCT<INT64>>>)\";\n    assert_eq!(\n        bigquery().parse_sql_statements(sql).unwrap_err(),\n        ParserError::ParserError(\n            \"Expected ',' or ')' after column definition, found: >\".to_string()\n        )\n    );\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/component_model/instance.rs::instance_exports", "code": "pub fn is_none(&self) -> bool {\n        self.0.is_reserved_value()\n    }", "test": "fn instance_exports() -> Result<()> {\n    let engine = super::engine();\n    let component = r#\"\n        (component\n            (import \"a\" (instance $i))\n            (import \"b\" (instance $i2 (export \"m\" (core module))))\n\n            (alias export $i2 \"m\" (core module $m))\n\n            (component $c\n                (component $c\n                    (export \"m\" (core module $m))\n                )\n                (instance $c (instantiate $c))\n                (export \"i\" (instance $c))\n            )\n            (instance $c (instantiate $c))\n            (export \"i\" (instance $c))\n            (export \"r\" (instance $i))\n            (export \"r2\" (instance $i2))\n        )\n    \"#;\n    let component = Component::new(&engine, component)?;\n    let mut store = Store::new(&engine, ());\n    let mut linker = Linker::new(&engine);\n    linker.instance(\"a\")?;\n    linker\n        .instance(\"b\")?\n        .module(\"m\", &Module::new(&engine, \"(module)\")?)?;\n    let instance = linker.instantiate(&mut store, &component)?;\n\n    let mut exports = instance.exports(&mut store);\n    assert!(exports.instance(\"not an instance\").is_none());\n    let mut i = exports.instance(\"r\").unwrap();\n    assert!(i.func(\"x\").is_none());\n    drop(i);\n    exports.root().instance(\"i\").unwrap();\n    let mut i2 = exports.instance(\"r2\").unwrap();\n    assert!(i2.func(\"m\").is_none());\n    assert!(i2.module(\"m\").is_some());\n    drop(i2);\n\n    exports\n        .instance(\"i\")\n        .unwrap()\n        .instance(\"i\")\n        .unwrap()\n        .module(\"m\")\n        .unwrap();\n\n    Ok(())\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_witness.rs::test_witness_raftlog_gc_lagged_witness", "code": "pub fn get_raft_msg_or_default<M: protobuf::Message + Default>(\n    engines: &Engines<RocksEngine, RaftTestEngine>,\n    key: &[u8],\n) -> M {\n    engines\n        .kv\n        .get_msg_cf(CF_RAFT, key)\n        .unwrap()\n        .unwrap_or_default()\n}", "test": "fn test_witness_raftlog_gc_lagged_witness() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(100);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1);\n    // nonwitness -> witness\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![true],\n    );\n    cluster.must_put(b\"k0\", b\"v0\");\n\n    // make sure raft log gc is triggered\n    std::thread::sleep(Duration::from_millis(200));\n    let mut before_states = HashMap::default();\n    for (&id, engines) in &cluster.engines {\n        let mut state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        before_states.insert(id, state.take_truncated_state());\n    }\n\n    // the witness is down\n    cluster.stop_node(nodes[2]);\n\n    // write some data to make log gap exceeds the gc limit\n    for i in 1..1000 {\n        let (k, v) = (format!(\"k{}\", i), format!(\"v{}\", i));\n        let key = k.as_bytes();\n        let value = v.as_bytes();\n        cluster.must_put(key, value);\n    }\n\n    // the witness is back online\n    cluster.run_node(nodes[2]).unwrap();\n\n    cluster.must_put(b\"k00\", b\"v00\");\n    std::thread::sleep(Duration::from_millis(200));\n\n    // the truncated index is advanced\n    for (&id, engines) in &cluster.engines {\n        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        assert_ne!(\n            900,\n            state.get_truncated_state().get_index() - before_states[&id].get_index()\n        );\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_csplit.rs::test_skip_to_no_match3", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_skip_to_no_match3() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"%0$%\", \"{50}\"])\n        .fails()\n        .stderr_only(\"csplit: '%0$%': match not found on repetition 5\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"counting splits\")\n        .count();\n    assert_eq!(count, 0);\n}"}
{"test_id": "weggli-rs-weggli/weggli-rs-weggli-ad8d424/tests/query.rs::type_simple", "code": "fn parse_and_match(needle: &str, source: &str) -> usize {\n    parse_and_match_helper(needle, source, false).len()\n}", "test": "fn type_simple() {\n    let needle = \"{$t $a = 3;}\";\n    let source = \"void foo() {int foo = 3; uint16_t foo = 3; unsigned long foo = 3;}\";\n\n    let matches = parse_and_match(needle, source);\n\n    assert_eq!(matches, 3);\n}"}
{"test_id": "hyperium-h2/hyperium-h2-da38b1c/tests/h2-tests/tests/flow_control.rs::stream_close_by_data_frame_releases_capacity", "code": "pub fn capacity(&self) -> usize {\n        self.inner.capacity() as usize\n    }", "test": "async fn stream_close_by_data_frame_releases_capacity() {\n    h2_support::trace_init!();\n    let (io, mut srv) = mock::new();\n\n    let window_size = frame::DEFAULT_INITIAL_WINDOW_SIZE as usize;\n\n    let h2 = async move {\n        let (mut client, mut h2) = client::handshake(io).await.unwrap();\n        let request = Request::builder()\n            .method(Method::POST)\n            .uri(\"https://http2.akamai.com/\")\n            .body(())\n            .unwrap();\n\n        // Send request\n        let (resp1, mut s1) = client.send_request(request, false).unwrap();\n\n        // This effectively reserves the entire connection window\n        s1.reserve_capacity(window_size);\n\n        // The capacity should be immediately available as nothing else is\n        // happening on the stream.\n        assert_eq!(s1.capacity(), window_size);\n\n        let request = Request::builder()\n            .method(Method::POST)\n            .uri(\"https://http2.akamai.com/\")\n            .body(())\n            .unwrap();\n\n        // Create a second stream\n        let (resp2, mut s2) = client.send_request(request, false).unwrap();\n\n        // Request capacity\n        s2.reserve_capacity(5);\n\n        // There should be no available capacity (as it is being held up by\n        // the previous stream\n        assert_eq!(s2.capacity(), 0);\n\n        // Closing the previous stream by sending an empty data frame will\n        // release the capacity to s2\n        s1.send_data(\"\".into(), true).unwrap();\n\n        // The capacity should be available\n        assert_eq!(s2.capacity(), 5);\n\n        // Send the frame\n        s2.send_data(\"hello\".into(), true).unwrap();\n\n        // Drive both streams to prevent the handles from being dropped\n        // (which will send a RST_STREAM) before the connection is closed.\n        h2.drive(resp1).await.unwrap();\n        h2.drive(resp2).await.unwrap();\n    };\n\n    let srv = async move {\n        let settings = srv.assert_client_handshake().await;\n        assert_default_settings!(settings);\n        srv.recv_frame(frames::headers(1).request(\"POST\", \"https://http2.akamai.com/\"))\n            .await;\n        srv.send_frame(frames::headers(1).response(200)).await;\n        srv.recv_frame(frames::headers(3).request(\"POST\", \"https://http2.akamai.com/\"))\n            .await;\n        srv.send_frame(frames::headers(3).response(200)).await;\n        srv.recv_frame(frames::data(1, &b\"\"[..]).eos()).await;\n        srv.recv_frame(frames::data(3, &b\"hello\"[..]).eos()).await;\n    };\n    join(srv, h2).await;\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_false.rs::test_version", "code": "pub fn stdout_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stdout_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stdout_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_version() {\n    new_ucmd!()\n        .args(&[\"--version\"])\n        .fails()\n        .stdout_contains(\"false\");\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/func.rs::call_array_to_native", "code": "pub fn i32(i: i32) -> ValRaw {\n        // Note that this is intentionally not setting the `i32` field, instead\n        // setting the `i64` field with a zero-extended version of `i`. For more\n        // information on this see the comments on `Lower for Result` in the\n        // `wasmtime` crate. Otherwise though all `ValRaw` constructors are\n        // otherwise constrained to guarantee that the initial 64-bits are\n        // always initialized.\n        ValRaw::u64((i as u32).into())\n    }", "test": "fn call_array_to_native() -> Result<()> {\n    let mut store = Store::<()>::default();\n    let func = Func::wrap(&mut store, |a: i32, b: i32, c: i32| -> (i32, i32, i32) {\n        (a * 10, b * 10, c * 10)\n    });\n    let mut results = [Val::I32(0), Val::I32(0), Val::I32(0)];\n    func.call(\n        &mut store,\n        &[Val::I32(10), Val::I32(20), Val::I32(30)],\n        &mut results,\n    )?;\n    assert_eq!(results[0].i32(), Some(100));\n    assert_eq!(results[1].i32(), Some(200));\n    assert_eq!(results[2].i32(), Some(300));\n    Ok(())\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/raftstore-v2/tests/failpoints/test_bucket.rs::test_refresh_bucket", "code": "pub fn get_tablet_index(&self) -> u64 {\n        self.tablet_index\n    }", "test": "fn test_refresh_bucket() {\n    let mut cluster = Cluster::default();\n    let store_id = cluster.node(0).id();\n    let raft_engine = cluster.node(0).running_state().unwrap().raft_engine.clone();\n    let router = &mut cluster.routers[0];\n\n    let region_2 = 2;\n    let region = router.region_detail(region_2);\n    let peer = region.get_peers()[0].clone();\n    router.wait_applied_to_current_term(region_2, Duration::from_secs(3));\n\n    // Region 2 [\"\", \"\"]\n    //   -> Region 2    [\"\", \"k22\"]\n    //      Region 1000 [\"k22\", \"\"] peer(1, 10)\n    let region_state = raft_engine\n        .get_region_state(region_2, u64::MAX)\n        .unwrap()\n        .unwrap();\n    assert_eq!(region_state.get_tablet_index(), RAFT_INIT_LOG_INDEX);\n\n    // to simulate the delay of set_apply_scheduler\n    fail::cfg(\"delay_set_apply_scheduler\", \"sleep(1000)\").unwrap();\n    split_region_and_refresh_bucket(\n        router,\n        region,\n        peer,\n        1000,\n        new_peer(store_id, 10),\n        b\"k22\",\n        false,\n    );\n\n    for _i in 1..100 {\n        std::thread::sleep(Duration::from_millis(50));\n        let meta = router\n            .must_query_debug_info(1000, Duration::from_secs(1))\n            .unwrap();\n        if !meta.bucket_keys.is_empty() {\n            assert_eq!(meta.bucket_keys.len(), 4); // include region start/end keys\n            assert_eq!(meta.bucket_keys[1], b\"1\".to_vec());\n            assert_eq!(meta.bucket_keys[2], b\"2\".to_vec());\n            return;\n        }\n    }\n    panic!(\"timeout for updating buckets\"); // timeout\n}"}
{"test_id": "mitsuhiko-minijinja/mitsuhiko-minijinja-5f2c1e8/minijinja/tests/test_value.rs::test_value_object_interface", "code": "fn item_count(&self) -> usize {\n        4\n    }", "test": "fn test_value_object_interface() {\n    let val = Value::from_seq_object(vec![1u32, 2, 3, 4]);\n    let seq = val.as_seq().unwrap();\n    assert_eq!(seq.item_count(), 4);\n\n    let obj = val.as_object().unwrap();\n    let seq2 = match obj.kind() {\n        ObjectKind::Seq(s) => s,\n        _ => panic!(\"did not expect this\"),\n    };\n    assert_eq!(seq2.item_count(), 4);\n    assert_eq!(obj.to_string(), \"[1, 2, 3, 4]\");\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/format.rs::line_width_parse_errors_negative", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn line_width_parse_errors_negative() {\n    let mut console = BufferConsole::default();\n    let mut fs = MemoryFileSystem::default();\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([\"format\", \"--line-width=-1\", \"file.js\"].as_slice()),\n    );\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"line_width_parse_errors_negative\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/function.rs::duplicate_function_name", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn duplicate_function_name() {\n    run_test_actions([TestAction::assert_eq(\n        indoc! {r#\"\n            function f () {}\n            function f () {return 12;}\n            f()\n        \"#},\n        12,\n    )]);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_comm.rs::test_invalid_arg", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_invalid_arg() {\n    new_ucmd!().arg(\"--definitely-invalid\").fails().code_is(1);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/engine_traits_tests/src/iterator.rs::seek_for_prev_engine", "code": "fn iterator(&self, cf: &str) -> Result<Self::Iterator> {\n        self.iterator_opt(cf, IterOptions::default())\n    }", "test": "fn seek_for_prev_engine() {\n    let db = default_engine();\n    seek_for_prev(&db.engine, |e| e.iterator(CF_DEFAULT).unwrap());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_tail.rs::test_positive_zero_lines", "code": "pub fn no_stdout(&self) -> &Self {\n        assert!(\n            self.stdout.is_empty(),\n            \"Expected stdout to be empty, but it's:\\n{}\",\n            self.stdout_str()\n        );\n        self\n    }", "test": "fn test_positive_zero_lines() {\n    let ts = TestScenario::new(util_name!());\n    ts.ucmd()\n        .args(&[\"-n\", \"+0\"])\n        .pipe_in(\"a\\nb\\nc\\nd\\ne\\n\")\n        .succeeds()\n        .stdout_is(\"a\\nb\\nc\\nd\\ne\\n\");\n    ts.ucmd()\n        .args(&[\"-n\", \"0\"])\n        .pipe_in(\"a\\nb\\nc\\nd\\ne\\n\")\n        .ignore_stdin_write_error()\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_tail.rs::test_n_greater_than_number_of_lines", "code": "pub fn stdout_is_fixture<T: AsRef<OsStr>>(&self, file_rel_path: T) -> &Self {\n        let contents = read_scenario_fixture(&self.tmpd, file_rel_path);\n        self.stdout_is(String::from_utf8(contents).unwrap())\n    }", "test": "fn test_n_greater_than_number_of_lines() {\n    new_ucmd!()\n        .arg(\"-n\")\n        .arg(\"99999999\")\n        .arg(FOOBAR_TXT)\n        .run()\n        .stdout_is_fixture(FOOBAR_TXT);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_dd.rs::test_self_transfer", "code": "pub fn success(&self) -> &Self {\n        assert!(\n            self.succeeded(),\n            \"Command was expected to succeed.\\nstdout = {}\\n stderr = {}\",\n            self.stdout_str(),\n            self.stderr_str()\n        );\n        self\n    }", "test": "fn test_self_transfer() {\n    let fname = \"self-transfer-256k.txt\";\n    assert_fixture_exists!(fname);\n\n    let (fix, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"status=none\", \"conv=notrunc\", inf!(fname), of!(fname)]);\n\n    assert!(fix.file_exists(fname));\n    assert_eq!(256 * 1024, fix.metadata(fname).len());\n\n    ucmd.run().no_stdout().no_stderr().success();\n\n    assert!(fix.file_exists(fname));\n    assert_eq!(256 * 1024, fix.metadata(fname).len());\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-parse-float/tests/stackvec_tests.rs::large_mul_test", "code": "pub fn vec_from_u32<const SIZE: usize>(x: &[u32]) -> StackVec<SIZE> {\n    let mut vec = StackVec::<SIZE>::new();\n    #[cfg(not(all(target_pointer_width = \"64\", not(target_arch = \"sparc\"))))]\n    {\n        for &xi in x {\n            vec.try_push(xi as Limb).unwrap();\n        }\n    }\n\n    #[cfg(all(target_pointer_width = \"64\", not(target_arch = \"sparc\")))]\n    {\n        for xi in x.chunks(2) {\n            match xi.len() {\n                1 => vec.try_push(xi[0] as Limb).unwrap(),\n                2 => {\n                    let xi0 = xi[0] as Limb;\n                    let xi1 = xi[1] as Limb;\n                    vec.try_push((xi1 << 32) | xi0).unwrap()\n                },\n                _ => unreachable!(),\n            }\n        }\n    }\n\n    vec\n}", "test": "fn large_mul_test() {\n    // Test by empty\n    let mut x = VecType::from_u32(0xFFFFFFFF);\n    let y = VecType::new();\n    bigint::large_mul(&mut x, &y);\n    let expected = VecType::new();\n    assert_eq!(&*x, &*expected);\n\n    // Simple case\n    let mut x = VecType::from_u32(0xFFFFFFFF);\n    let y = VecType::from_u32(5);\n    bigint::large_mul(&mut x, &y);\n    let expected: VecType = vec_from_u32(&[0xFFFFFFFB, 0x4]);\n    assert_eq!(&*x, &*expected);\n\n    // Large u32, but still just as easy.\n    let mut x = VecType::from_u32(0xFFFFFFFF);\n    let y = VecType::from_u32(0xFFFFFFFE);\n    bigint::large_mul(&mut x, &y);\n    let expected: VecType = vec_from_u32(&[0x2, 0xFFFFFFFD]);\n    assert_eq!(&*x, &*expected);\n\n    // Let's multiply two large values together.\n    let mut x: VecType = vec_from_u32(&[0xFFFFFFFE, 0x0FFFFFFF, 1]);\n    let y: VecType = vec_from_u32(&[0x99999999, 0x99999999, 0xCCCD9999, 0xCCCC]);\n    bigint::large_mul(&mut x, &y);\n    let expected: VecType =\n        vec_from_u32(&[0xCCCCCCCE, 0x5CCCCCCC, 0x9997FFFF, 0x33319999, 0x999A7333, 0xD999]);\n    assert_eq!(&*x, &*expected);\n}"}
{"test_id": "bincode-org-bincode/bincode-org-bincode-aada4bb/tests/derive.rs::test_c_style_enum", "code": "fn assert_de_fails(num: u8) {\n        match bincode::decode_from_slice::<CStyleEnum, _>(&[num], bincode::config::standard()) {\n            Ok(_) => {\n                panic!(\"Expected to not be able to decode CStyleEnum index {num}, but it succeeded\")\n            }\n            Err(DecodeError::UnexpectedVariant {\n                type_name: \"CStyleEnum\",\n                allowed: &bincode::error::AllowedEnumVariants::Allowed(&[0, 1, 2, 3, 4]),\n                found,\n            }) if found == num as u32 => {}\n            Err(e) => panic!(\"Expected DecodeError::UnexpectedVariant, got {e:?}\"),\n        }\n    }", "test": "fn test_c_style_enum() {\n    fn ser(e: CStyleEnum) -> u8 {\n        let mut slice = [0u8; 10];\n        let bytes_written =\n            bincode::encode_into_slice(e, &mut slice, bincode::config::standard()).unwrap();\n        assert_eq!(bytes_written, 1);\n        slice[0]\n    }\n\n    assert_eq!(ser(CStyleEnum::A), 0);\n    assert_eq!(ser(CStyleEnum::B), 1);\n    assert_eq!(ser(CStyleEnum::C), 2);\n    assert_eq!(ser(CStyleEnum::D), 3);\n    assert_eq!(ser(CStyleEnum::E), 4);\n\n    fn assert_de_successfully(num: u8, expected: CStyleEnum) {\n        match bincode::decode_from_slice::<CStyleEnum, _>(&[num], bincode::config::standard()) {\n            Ok((result, len)) => {\n                assert_eq!(len, 1);\n                assert_eq!(result, expected)\n            }\n            Err(e) => panic!(\"Could not deserialize CStyleEnum idx {num}: {e:?}\"),\n        }\n    }\n\n    fn assert_de_fails(num: u8) {\n        match bincode::decode_from_slice::<CStyleEnum, _>(&[num], bincode::config::standard()) {\n            Ok(_) => {\n                panic!(\"Expected to not be able to decode CStyleEnum index {num}, but it succeeded\")\n            }\n            Err(DecodeError::UnexpectedVariant {\n                type_name: \"CStyleEnum\",\n                allowed: &bincode::error::AllowedEnumVariants::Allowed(&[0, 1, 2, 3, 4]),\n                found,\n            }) if found == num as u32 => {}\n            Err(e) => panic!(\"Expected DecodeError::UnexpectedVariant, got {e:?}\"),\n        }\n    }\n\n    assert_de_successfully(0, CStyleEnum::A);\n    assert_de_successfully(1, CStyleEnum::B);\n    assert_de_successfully(2, CStyleEnum::C);\n    assert_de_successfully(3, CStyleEnum::D);\n    assert_de_successfully(4, CStyleEnum::E);\n    assert_de_fails(5);\n}"}
{"test_id": "image-rs-jpeg-decoder/image-rs-jpeg-decoder-cacc433/tests/lib.rs::read_icc_profile", "code": "pub fn icc_profile(&self) -> Option<Vec<u8>> {\n        let mut marker_present: [Option<&IccChunk>; 256] = [None; 256];\n        let num_markers = self.icc_markers.len();\n        if num_markers == 0 || num_markers >= 255 {\n            return None;\n        }\n        // check the validity of the markers\n        for chunk in &self.icc_markers {\n            if usize::from(chunk.num_markers) != num_markers {\n                // all the lengths must match\n                return None;\n            }\n            if chunk.seq_no == 0 {\n                return None;\n            }\n            if marker_present[usize::from(chunk.seq_no)].is_some() {\n                // duplicate seq_no\n                return None;\n            } else {\n                marker_present[usize::from(chunk.seq_no)] = Some(chunk);\n            }\n        }\n\n        // assemble them together by seq_no failing if any are missing\n        let mut data = Vec::new();\n        // seq_no's start at 1\n        for &chunk in marker_present.get(1..=num_markers)? {\n            data.extend_from_slice(&chunk?.data);\n        }\n        Some(data)\n    }", "test": "fn read_icc_profile() {\n    let path = Path::new(\"tests\")\n        .join(\"reftest\")\n        .join(\"images\")\n        .join(\"mozilla\")\n        .join(\"jpg-srgb-icc.jpg\");\n\n    let mut decoder = jpeg::Decoder::new(File::open(&path).unwrap());\n    decoder.decode().unwrap();\n\n    let profile = decoder.icc_profile().unwrap();\n    // \"acsp\" is a mandatory string in ICC profile headers.\n    assert_eq!(&profile[36..40], b\"acsp\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_stats.rs::test_node_simple_store_stats", "code": "fn test_simple_store_stats<T: Simulator>(cluster: &mut Cluster<T>) {\n    let pd_client = Arc::clone(&cluster.pd_client);\n\n    cluster.cfg.raft_store.pd_store_heartbeat_tick_interval = ReadableDuration::millis(20);\n    cluster.run();\n\n    // wait store reports stats.\n    for _ in 0..100 {\n        sleep_ms(20);\n\n        if pd_client.get_store_stats(1).is_some() {\n            break;\n        }\n    }\n\n    let engine = cluster.get_engine(1);\n    engine.flush_cfs(&[], true).unwrap();\n    let last_stats = pd_client.get_store_stats(1).unwrap();\n    assert_eq!(last_stats.get_region_count(), 1);\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k3\", b\"v3\");\n\n    let region = pd_client.get_region(b\"\").unwrap();\n    cluster.must_split(&region, b\"k2\");\n    engine.flush_cfs(&[], true).unwrap();\n\n    // wait report region count after split\n    for _ in 0..100 {\n        sleep_ms(20);\n\n        let stats = pd_client.get_store_stats(1).unwrap();\n        if stats.get_region_count() == 2 {\n            break;\n        }\n    }\n\n    let stats = pd_client.get_store_stats(1).unwrap();\n    assert_eq!(stats.get_region_count(), 2);\n\n    check_available(cluster);\n}", "test": "fn test_node_simple_store_stats() {\n    let mut cluster = new_node_cluster(0, 1);\n    test_simple_store_stats(&mut cluster);\n}"}
{"test_id": "raphlinus-pulldown-cmark/raphlinus-pulldown-cmark-3da63d5/tests/suite/heading_attrs.rs::heading_attrs_test_30", "code": "pub fn test_markdown_html(input: &str, output: &str, smart_punct: bool) {\n    let mut s = String::new();\n\n    let mut opts = Options::empty();\n    opts.insert(Options::ENABLE_TABLES);\n    opts.insert(Options::ENABLE_FOOTNOTES);\n    opts.insert(Options::ENABLE_STRIKETHROUGH);\n    opts.insert(Options::ENABLE_TASKLISTS);\n    if smart_punct {\n        opts.insert(Options::ENABLE_SMART_PUNCTUATION);\n    }\n    opts.insert(Options::ENABLE_HEADING_ATTRIBUTES);\n\n    let p = Parser::new_ext(input, opts);\n    pulldown_cmark::html::push_html(&mut s, p);\n\n    assert_eq!(normalize_html(output), normalize_html(&s));\n}", "test": "fn heading_attrs_test_30() {\n    let original = r##\"H1 \\{.foo}\n==\nH2 \\\\{.bar}\n--\n\nstray backslash at the end is preserved \\\n--\n\"##;\n    let expected = r##\"<h1 class=\"foo\">H1 \\</h1>\n<h2 class=\"bar\">H2 \\</h2>\n<h2>stray backslash at the end is preserved \\</h2>\n\"##;\n\n    test_markdown_html(original, expected, false);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_stat.rs::test_printf", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_printf() {\n    let args = [\n        \"--printf=123%-# 15q\\\\r\\\\\\\"\\\\\\\\\\\\a\\\\b\\\\e\\\\f\\\\v%+020.23m\\\\x12\\\\167\\\\132\\\\112\\\\n\",\n        \"/\",\n    ];\n    let ts = TestScenario::new(util_name!());\n    let expected_stdout = unwrap_or_return!(expected_result(&ts, &args)).stdout_move_str();\n    ts.ucmd().args(&args).succeeds().stdout_is(expected_stdout);\n}"}
{"test_id": "mitsuhiko-minijinja/mitsuhiko-minijinja-5f2c1e8/minijinja-contrib/tests/datetime.rs::test_datetimeformat_time_rs", "code": "pub fn eval<S: Serialize>(&self, ctx: S) -> Result<Value, Error> {\n        // reduce total amount of code faling under mono morphization into\n        // this function, and share the rest in _eval.\n        self._eval(Value::from_serializable(&ctx))\n    }", "test": "fn test_datetimeformat_time_rs() {\n    let mut env = minijinja::Environment::new();\n    env.add_global(\"TIMEZONE\", \"Europe/Vienna\");\n    env.add_global(\"DATETIME_FORMAT\", \"[hour]:[minute]\");\n    minijinja_contrib::add_to_environment(&mut env);\n\n    let expr = env\n        .compile_expression(\"d|datetimeformat(format=format)\")\n        .unwrap();\n\n    let d = time::OffsetDateTime::from_unix_timestamp(1687624642).unwrap();\n    assert_eq!(\n        expr.eval(context!(d, format => \"short\"))\n            .unwrap()\n            .to_string(),\n        \"2023-06-24 18:37\"\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_fold.rs::test_carriage_return_should_reset_column_count", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_carriage_return_should_reset_column_count() {\n    new_ucmd!()\n        .arg(\"-w6\")\n        .pipe_in(\"12345\\r123456789abcdef\")\n        .succeeds()\n        .stdout_is(\"12345\\r123456\\n789abc\\ndef\");\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/unstable.rs::set_unstable_true_with_env_var", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn set_unstable_true_with_env_var() {\n  let justfile = r#\"\ndefault:\n    echo 'foo'\n  \"#;\n\n  for val in [\"true\", \"some-arbitrary-string\"] {\n    Test::new()\n      .justfile(justfile)\n      .args([\"--fmt\"])\n      .env(\"JUST_UNSTABLE\", val)\n      .status(EXIT_SUCCESS)\n      .stderr_regex(\"Wrote justfile to `.*`\\n\")\n      .run();\n  }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_hashsum.rs::test_invalid_b2sum_length_option_too_large", "code": "pub fn join(&mut self) -> &mut Self {\n        if let Some(join_handle) = self.join_handle.take() {\n            join_handle\n                .join()\n                .expect(\"Error joining with the piping stdin thread\")\n                .unwrap();\n        }\n        self\n    }", "test": "fn test_invalid_b2sum_length_option_too_large() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    at.write(\"testf\", \"foobar\\n\");\n\n    scene\n        .ccmd(\"b2sum\")\n        .arg(\"--length=513\")\n        .arg(at.subdir.join(\"testf\"))\n        .fails()\n        .code_is(1);\n}"}
{"test_id": "hyperium-http/hyperium-http-818269d/tests/status_code.rs::is_success", "code": "fn is_success() {\n    assert!(status_code(200).is_success());\n    assert!(status_code(299).is_success());\n\n    assert!(!status_code(199).is_success());\n    assert!(!status_code(300).is_success());\n}", "test": "fn is_success() {\n    assert!(status_code(200).is_success());\n    assert!(status_code(299).is_success());\n\n    assert!(!status_code(199).is_success());\n    assert!(!status_code(300).is_success());\n}"}
{"test_id": "astral-sh-ruff/astral-sh-ruff-1a6898a/crates/ruff_cache/tests/cache_key.rs::enum_unit_variant", "code": "fn finish(&self) -> u64 {\n        self.inner.finish()\n    }", "test": "fn enum_unit_variant() {\n    let mut key = CacheKeyHasher::new();\n\n    let variant = Enum::Unit;\n    variant.cache_key(&mut key);\n\n    let mut hash = CacheKeyHasher::new();\n    variant.hash(&mut hash);\n\n    assert_eq!(hash.finish(), key.finish());\n}"}
{"test_id": "raphlinus-pulldown-cmark/raphlinus-pulldown-cmark-3da63d5/tests/suite/heading_attrs.rs::heading_attrs_test_5", "code": "pub fn test_markdown_html(input: &str, output: &str, smart_punct: bool) {\n    let mut s = String::new();\n\n    let mut opts = Options::empty();\n    opts.insert(Options::ENABLE_TABLES);\n    opts.insert(Options::ENABLE_FOOTNOTES);\n    opts.insert(Options::ENABLE_STRIKETHROUGH);\n    opts.insert(Options::ENABLE_TASKLISTS);\n    if smart_punct {\n        opts.insert(Options::ENABLE_SMART_PUNCTUATION);\n    }\n    opts.insert(Options::ENABLE_HEADING_ATTRIBUTES);\n\n    let p = Parser::new_ext(input, opts);\n    pulldown_cmark::html::push_html(&mut s, p);\n\n    assert_eq!(normalize_html(output), normalize_html(&s));\n}", "test": "fn heading_attrs_test_5() {\n    let original = r##\"# H1 \\\nnextline\n\"##;\n    let expected = r##\"<h1>H1 \\</h1>\n<p>nextline</p>\n\"##;\n\n    test_markdown_html(original, expected, false);\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/control_flow/loops.rs::for_loop_continue_out_of_switch", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn for_loop_continue_out_of_switch() {\n    run_test_actions([\n        TestAction::run(indoc! {r#\"\n                var a = 0, b = 0, c = 0;\n                for (let i = 0; i < 3; i++) {\n                    a++;\n                    switch (i) {\n                        case 0:\n                            continue;\n                            c++;\n                        case 1:\n                            continue;\n                        case 5:\n                            c++;\n                    }\n                    b++;\n                }\n            \"#}),\n        TestAction::assert_eq(\"a\", 3),\n        TestAction::assert_eq(\"b\", 1),\n        TestAction::assert_eq(\"c\", 0),\n    ]);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_rm.rs::test_rm_recursive", "code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_recursive() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_rm_recursive_directory\";\n    let file_a = \"test_rm_recursive_directory/test_rm_recursive_file_a\";\n    let file_b = \"test_rm_recursive_directory/test_rm_recursive_file_b\";\n\n    at.mkdir(dir);\n    at.touch(file_a);\n    at.touch(file_b);\n\n    ucmd.arg(\"-r\").arg(dir).succeeds().no_stderr();\n\n    assert!(!at.dir_exists(dir));\n    assert!(!at.file_exists(file_a));\n    assert!(!at.file_exists(file_b));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_split.rs::test_split_separator_same_multiple", "code": "pub fn fails(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.failure();\n        cmd_result\n    }", "test": "fn test_split_separator_same_multiple() {\n    let scene = TestScenario::new(util_name!());\n    scene\n        .ucmd()\n        .args(&[\"--separator=:\", \"--separator=:\", \"fivelines.txt\"])\n        .succeeds();\n    scene\n        .ucmd()\n        .args(&[\"-t:\", \"--separator=:\", \"fivelines.txt\"])\n        .succeeds();\n    scene\n        .ucmd()\n        .args(&[\"-t\", \":\", \"-t\", \":\", \"fivelines.txt\"])\n        .succeeds();\n    scene\n        .ucmd()\n        .args(&[\"-t:\", \"-t:\", \"-t,\", \"fivelines.txt\"])\n        .fails();\n}"}
{"test_id": "cberner-redb/cberner-redb-267b473/tests/basic_tests.rs::drain_lifetime", "code": "fn next(\n        self,\n        reverse: bool,\n        manager: &'a TransactionalMemory,\n    ) -> Result<Option<RangeIterState>> {\n        match self {\n            Leaf {\n                page,\n                fixed_key_size,\n                fixed_value_size,\n                entry,\n                parent,\n            } => {\n                let accessor = LeafAccessor::new(page.memory(), fixed_key_size, fixed_value_size);\n                let direction = if reverse { -1 } else { 1 };\n                let next_entry = isize::try_from(entry).unwrap() + direction;\n                if 0 <= next_entry && next_entry < accessor.num_pairs().try_into().unwrap() {\n                    Ok(Some(Leaf {\n                        page,\n                        fixed_key_size,\n                        fixed_value_size,\n                        entry: next_entry.try_into().unwrap(),\n                        parent,\n                    }))\n                } else {\n                    Ok(parent.map(|x| *x))\n                }\n            }\n            Internal {\n                page,\n                fixed_key_size,\n                fixed_value_size,\n                child,\n                mut parent,\n            } => {\n                let accessor = BranchAccessor::new(&page, fixed_key_size);\n                let child_page = accessor.child_page(child).unwrap();\n                let child_page = manager.get_page(child_page)?;\n                let direction = if reverse { -1 } else { 1 };\n                let next_child = isize::try_from(child).unwrap() + direction;\n                if 0 <= next_child && next_child < accessor.count_children().try_into().unwrap() {\n                    parent = Some(Box::new(Internal {\n                        page,\n                        fixed_key_size,\n                        fixed_value_size,\n                        child: next_child.try_into().unwrap(),\n                        parent,\n                    }));\n                }\n                match child_page.memory()[0] {\n                    LEAF => {\n                        let child_accessor = LeafAccessor::new(\n                            child_page.memory(),\n                            fixed_key_size,\n                            fixed_value_size,\n                        );\n                        let entry = if reverse {\n                            child_accessor.num_pairs() - 1\n                        } else {\n                            0\n                        };\n                        Ok(Some(Leaf {\n                            page: child_page,\n                            fixed_key_size,\n                            fixed_value_size,\n                            entry,\n                            parent,\n                        }))\n                    }\n                    BRANCH => {\n                        let child_accessor = BranchAccessor::new(&child_page, fixed_key_size);\n                        let child = if reverse {\n                            child_accessor.count_children() - 1\n                        } else {\n                            0\n                        };\n                        Ok(Some(Internal {\n                            page: child_page,\n                            fixed_key_size,\n                            fixed_value_size,\n                            child,\n                            parent,\n                        }))\n                    }\n                    _ => unreachable!(),\n                }\n            }\n        }\n    }", "test": "fn drain_lifetime() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let definition: TableDefinition<&str, &str> = TableDefinition::new(\"x\");\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(definition).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let txn = db.begin_write().unwrap();\n    let mut table = txn.open_table(definition).unwrap();\n\n    let mut iter = {\n        let start = \"hello\".to_string();\n        table.drain::<&str>(start.as_str()..).unwrap()\n    };\n    assert_eq!(iter.next().unwrap().unwrap().1.value(), \"world\");\n    assert!(iter.next().is_none());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_pwd.rs::test_default", "code": "pub fn root_dir_resolved(&self) -> String {\n        log_info(\"current_directory_resolved\", \"\");\n        let s = self\n            .subdir\n            .canonicalize()\n            .unwrap()\n            .to_str()\n            .unwrap()\n            .to_owned();\n\n        // Due to canonicalize()'s use of GetFinalPathNameByHandleW() on Windows, the resolved path\n        // starts with '\\\\?\\' to extend the limit of a given path to 32,767 wide characters.\n        //\n        // To address this issue, we remove this prepended string if available.\n        //\n        // Source:\n        // http://stackoverflow.com/questions/31439011/getfinalpathnamebyhandle-without-prepended\n        let prefix = \"\\\\\\\\?\\\\\";\n\n        if let Some(stripped) = s.strip_prefix(prefix) {\n            String::from(stripped)\n        } else {\n            s\n        }\n    }", "test": "fn test_default() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.succeeds().stdout_is(at.root_dir_resolved() + \"\\n\");\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/check.rs::fs_error_infinite_symlink_expansion_to_dirs", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn fs_error_infinite_symlink_expansion_to_dirs() {\n    let fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let root_path = temp_dir().join(\"check_rome_test_infinite_symlink_expansion_to_dirs\");\n    let subdir1_path = root_path.join(\"prefix\");\n    let subdir2_path = root_path.join(\"foo\").join(\"bar\");\n\n    let _ = remove_dir_all(&root_path);\n    create_dir_all(&subdir1_path).unwrap();\n    create_dir_all(&subdir2_path).unwrap();\n\n    #[cfg(target_family = \"unix\")]\n    {\n        symlink(&subdir2_path, subdir1_path.join(\"symlink1\")).unwrap();\n        symlink(subdir1_path, subdir2_path.join(\"symlink2\")).unwrap();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        check_windows_symlink!(symlink_dir(&subdir2_path, &subdir1_path.join(\"symlink1\")));\n        check_windows_symlink!(symlink_dir(subdir1_path, subdir2_path.join(\"symlink2\")));\n    }\n\n    let result = run_cli(\n        DynRef::Owned(Box::new(OsFileSystem)),\n        &mut console,\n        Args::from([(\"check\"), (root_path.display().to_string().as_str())].as_slice()),\n    );\n\n    remove_dir_all(root_path).unwrap();\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"fs_error_infinite_symlink_expansion_to_dirs\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "mitsuhiko-minijinja/mitsuhiko-minijinja-5f2c1e8/minijinja/tests/test_value.rs::test_values_in_vec", "code": "pub fn apply_filter(&self, filter: &str, args: &[Value]) -> Result<Value, Error> {\n        match self.env.get_filter(filter) {\n            Some(filter) => filter.apply_to(self, args),\n            None => Err(Error::from(ErrorKind::UnknownFilter)),\n        }\n    }", "test": "fn test_values_in_vec() {\n    fn upper(value: &str) -> String {\n        value.to_uppercase()\n    }\n\n    fn sum(value: Vec<i64>) -> i64 {\n        value.into_iter().sum::<i64>()\n    }\n\n    let mut env = Environment::new();\n    env.add_filter(\"upper\", upper);\n    env.add_filter(\"sum\", sum);\n    let state = env.empty_state();\n\n    assert_eq!(\n        state.apply_filter(\"upper\", args!(\"Hello World!\")).unwrap(),\n        Value::from(\"HELLO WORLD!\")\n    );\n\n    assert_eq!(\n        state.apply_filter(\"sum\", args!(vec![1, 2])).unwrap(),\n        Value::from(3)\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_csplit.rs::test_skip_to_match_negative_offset_before_a_match", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_skip_to_match_negative_offset_before_a_match() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"/20/-10\", \"/15/\"])\n        .fails()\n        .stdout_is(\"18\\n123\\n\")\n        .stderr_is(\"csplit: '/15/': match not found\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"there should be splits created\")\n        .count();\n    assert_eq!(count, 0);\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/control_flow/mod.rs::test_invalid_continue", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn test_invalid_continue() {\n    run_test_actions([TestAction::assert_native_error(\n        \"continue;\",\n        JsNativeErrorKind::Syntax,\n        \"illegal continue statement at line 1, col 1\",\n    )]);\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/ci.rs::ci_does_not_run_linter", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn ci_does_not_run_linter() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    fs.insert(\n        PathBuf::from(\"biome.json\"),\n        CONFIG_LINTER_DISABLED.as_bytes(),\n    );\n\n    let file_path = Path::new(\"file.js\");\n    fs.insert(file_path.into(), CUSTOM_FORMAT_BEFORE.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"ci\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut file = fs\n        .open(file_path)\n        .expect(\"formatting target file was removed by the CLI\");\n\n    let mut content = String::new();\n    file.read_to_string(&mut content)\n        .expect(\"failed to read file from memory FS\");\n\n    assert_eq!(content, CUSTOM_FORMAT_BEFORE);\n\n    drop(file);\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"ci_does_not_run_linter\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_backup_off", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_backup_off() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(\"--backup=off\")\n        .arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .succeeds()\n        .no_stderr();\n\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), \"Hello, World!\\n\");\n    assert!(!at.file_exists(format!(\"{TEST_HOW_ARE_YOU_SOURCE}~\")));\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/engine_traits_tests/src/iterator.rs::iter_forward_then_reverse_engine", "code": "fn iterator(&self, cf: &str) -> Result<Self::Iterator> {\n        self.iterator_opt(cf, IterOptions::default())\n    }", "test": "fn iter_forward_then_reverse_engine() {\n    let db = default_engine();\n    iter_forward_then_reverse(&db.engine, |e| e.iterator(CF_DEFAULT).unwrap());\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/func.rs::dtor_delayed", "code": "pub unsafe fn load(ptr: *mut Self) -> Self {\n        let other = &*ptr;\n        VMMemoryDefinition {\n            base: other.base,\n            current_length: other.current_length().into(),\n        }\n    }", "test": "fn dtor_delayed() -> Result<()> {\n    static HITS: AtomicUsize = AtomicUsize::new(0);\n\n    struct A;\n\n    impl Drop for A {\n        fn drop(&mut self) {\n            HITS.fetch_add(1, SeqCst);\n        }\n    }\n\n    let mut store = Store::<()>::default();\n    let a = A;\n    let func = Func::wrap(&mut store, move || {\n        let _ = &a;\n    });\n\n    assert_eq!(HITS.load(SeqCst), 0);\n    let wasm = wat::parse_str(r#\"(import \"\" \"\" (func))\"#)?;\n    let module = Module::new(store.engine(), &wasm)?;\n    let _instance = Instance::new(&mut store, &module, &[func.into()])?;\n    assert_eq!(HITS.load(SeqCst), 0);\n    drop(store);\n    assert_eq!(HITS.load(SeqCst), 1);\n    Ok(())\n}"}
{"test_id": "rust-lang-regex/rust-lang-regex-cf1a26a/tests/crazy.rs::nest_limit_makes_it_parse", "code": "pub fn build(self) -> Result<Exec, Error> {\n        // Special case when we have no patterns to compile.\n        // This can happen when compiling a regex set.\n        if self.options.pats.is_empty() {\n            let ro = Arc::new(ExecReadOnly {\n                res: vec![],\n                nfa: Program::new(),\n                dfa: Program::new(),\n                dfa_reverse: Program::new(),\n                suffixes: LiteralSearcher::empty(),\n                match_type: MatchType::Nothing,\n            });\n            return Ok(Exec { ro: ro, cache: CachedThreadLocal::new() });\n        }\n        let parsed = self.parse()?;\n        let mut nfa =\n            Compiler::new()\n                     .size_limit(self.options.size_limit)\n                     .bytes(self.bytes || parsed.bytes)\n                     .only_utf8(self.only_utf8)\n                     .compile(&parsed.exprs)?;\n        let mut dfa =\n            Compiler::new()\n                     .size_limit(self.options.size_limit)\n                     .dfa(true)\n                     .only_utf8(self.only_utf8)\n                     .compile(&parsed.exprs)?;\n        let mut dfa_reverse =\n            Compiler::new()\n                     .size_limit(self.options.size_limit)\n                     .dfa(true)\n                     .only_utf8(self.only_utf8)\n                     .reverse(true)\n                     .compile(&parsed.exprs)?;\n\n        let prefixes = parsed.prefixes.unambiguous_prefixes();\n        let suffixes = parsed.suffixes.unambiguous_suffixes();\n        nfa.prefixes = LiteralSearcher::prefixes(prefixes);\n        dfa.prefixes = nfa.prefixes.clone();\n        dfa.dfa_size_limit = self.options.dfa_size_limit;\n        dfa_reverse.dfa_size_limit = self.options.dfa_size_limit;\n\n        let mut ro = ExecReadOnly {\n            res: self.options.pats,\n            nfa: nfa,\n            dfa: dfa,\n            dfa_reverse: dfa_reverse,\n            suffixes: LiteralSearcher::suffixes(suffixes),\n            match_type: MatchType::Nothing,\n        };\n        ro.match_type = ro.choose_match_type(self.match_type);\n\n        let ro = Arc::new(ro);\n        Ok(Exec { ro: ro, cache: CachedThreadLocal::new() })\n    }", "test": "fn nest_limit_makes_it_parse() {\n    use regex::RegexBuilder;\n\n    RegexBuilder::new(\n        r#\"\n        2(?:\n          [45]\\d{3}|\n          7(?:\n            1[0-267]|\n            2[0-289]|\n            3[0-29]|\n            4[01]|\n            5[1-3]|\n            6[013]|\n            7[0178]|\n            91\n          )|\n          8(?:\n            0[125]|\n            [139][1-6]|\n            2[0157-9]|\n            41|\n            6[1-35]|\n            7[1-5]|\n            8[1-8]|\n            90\n          )|\n          9(?:\n            0[0-2]|\n            1[0-4]|\n            2[568]|\n            3[3-6]|\n            5[5-7]|\n            6[0167]|\n            7[15]|\n            8[0146-9]\n          )\n        )\\d{4}|\n        3(?:\n          12?[5-7]\\d{2}|\n          0(?:\n            2(?:\n              [025-79]\\d|\n              [348]\\d{1,2}\n            )|\n            3(?:\n              [2-4]\\d|\n              [56]\\d?\n            )\n          )|\n          2(?:\n            1\\d{2}|\n            2(?:\n              [12]\\d|\n              [35]\\d{1,2}|\n              4\\d?\n            )\n          )|\n          3(?:\n            1\\d{2}|\n            2(?:\n              [2356]\\d|\n              4\\d{1,2}\n            )\n          )|\n          4(?:\n            1\\d{2}|\n            2(?:\n              2\\d{1,2}|\n              [47]|\n              5\\d{2}\n            )\n          )|\n          5(?:\n            1\\d{2}|\n            29\n          )|\n          [67]1\\d{2}|\n          8(?:\n            1\\d{2}|\n            2(?:\n              2\\d{2}|\n              3|\n              4\\d\n            )\n          )\n        )\\d{3}|\n        4(?:\n          0(?:\n            2(?:\n              [09]\\d|\n              7\n            )|\n            33\\d{2}\n          )|\n          1\\d{3}|\n          2(?:\n            1\\d{2}|\n            2(?:\n              [25]\\d?|\n              [348]\\d|\n              [67]\\d{1,2}\n            )\n          )|\n          3(?:\n            1\\d{2}(?:\n              \\d{2}\n            )?|\n            2(?:\n              [045]\\d|\n              [236-9]\\d{1,2}\n            )|\n            32\\d{2}\n          )|\n          4(?:\n            [18]\\d{2}|\n            2(?:\n              [2-46]\\d{2}|\n              3\n            )|\n            5[25]\\d{2}\n          )|\n          5(?:\n            1\\d{2}|\n            2(?:\n              3\\d|\n              5\n            )\n          )|\n          6(?:\n            [18]\\d{2}|\n            2(?:\n              3(?:\n                \\d{2}\n              )?|\n              [46]\\d{1,2}|\n              5\\d{2}|\n              7\\d\n            )|\n            5(?:\n              3\\d?|\n              4\\d|\n              [57]\\d{1,2}|\n              6\\d{2}|\n              8\n            )\n          )|\n          71\\d{2}|\n          8(?:\n            [18]\\d{2}|\n            23\\d{2}|\n            54\\d{2}\n          )|\n          9(?:\n            [18]\\d{2}|\n            2[2-5]\\d{2}|\n            53\\d{1,2}\n          )\n        )\\d{3}|\n        5(?:\n          02[03489]\\d{2}|\n          1\\d{2}|\n          2(?:\n            1\\d{2}|\n            2(?:\n              2(?:\n                \\d{2}\n              )?|\n              [457]\\d{2}\n            )\n          )|\n          3(?:\n            1\\d{2}|\n            2(?:\n              [37](?:\n                \\d{2}\n              )?|\n              [569]\\d{2}\n            )\n          )|\n          4(?:\n            1\\d{2}|\n            2[46]\\d{2}\n          )|\n          5(?:\n            1\\d{2}|\n            26\\d{1,2}\n          )|\n          6(?:\n            [18]\\d{2}|\n            2|\n            53\\d{2}\n          )|\n          7(?:\n            1|\n            24\n          )\\d{2}|\n          8(?:\n            1|\n            26\n          )\\d{2}|\n          91\\d{2}\n        )\\d{3}|\n        6(?:\n          0(?:\n            1\\d{2}|\n            2(?:\n              3\\d{2}|\n              4\\d{1,2}\n            )\n          )|\n          2(?:\n            2[2-5]\\d{2}|\n            5(?:\n              [3-5]\\d{2}|\n              7\n            )|\n            8\\d{2}\n          )|\n          3(?:\n            1|\n            2[3478]\n          )\\d{2}|\n          4(?:\n            1|\n            2[34]\n          )\\d{2}|\n          5(?:\n            1|\n            2[47]\n          )\\d{2}|\n          6(?:\n            [18]\\d{2}|\n            6(?:\n              2(?:\n                2\\d|\n                [34]\\d{2}\n              )|\n              5(?:\n                [24]\\d{2}|\n                3\\d|\n                5\\d{1,2}\n              )\n            )\n          )|\n          72[2-5]\\d{2}|\n          8(?:\n            1\\d{2}|\n            2[2-5]\\d{2}\n          )|\n          9(?:\n            1\\d{2}|\n            2[2-6]\\d{2}\n          )\n        )\\d{3}|\n        7(?:\n          (?:\n            02|\n            [3-589]1|\n            6[12]|\n            72[24]\n          )\\d{2}|\n          21\\d{3}|\n          32\n        )\\d{3}|\n        8(?:\n          (?:\n            4[12]|\n            [5-7]2|\n            1\\d?\n          )|\n          (?:\n            0|\n            3[12]|\n            [5-7]1|\n            217\n          )\\d\n        )\\d{4}|\n        9(?:\n          [35]1|\n          (?:\n            [024]2|\n            81\n          )\\d|\n          (?:\n            1|\n            [24]1\n          )\\d{2}\n        )\\d{3}\n        \"#\n    )\n    .build()\n    .unwrap();\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_bigquery.rs::parse_cast_timestamp_format_tz", "code": "pub fn verified_only_select(&self, query: &str) -> Select {\n        match *self.verified_query(query).body {\n            SetExpr::Select(s) => *s,\n            _ => panic!(\"Expected SetExpr::Select\"),\n        }\n    }", "test": "fn parse_cast_timestamp_format_tz() {\n    let sql = r\"SELECT CAST(TIMESTAMP '2008-12-25 00:00:00+00:00' AS STRING FORMAT 'TZH' AT TIME ZONE 'Asia/Kolkata') AS date_time_to_string\";\n    bigquery_and_generic().verified_only_select(sql);\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-util/tests/skip_tests.rs::test_skip_iter_ilt", "code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn test_skip_iter_ilt() {\n    // Test iterators that skip single digit separators.\n    pub const FORMAT: u128 = NumberFormatBuilder::new()\n        .digit_separator(num::NonZeroU8::new(b'_'))\n        .integer_internal_digit_separator(true)\n        .integer_leading_digit_separator(true)\n        .integer_trailing_digit_separator(true)\n        .build();\n    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());\n\n    skip_iter_eq::<{ FORMAT }>(b\"123.45\", b\"123.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e45\", b\"1e45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e\", b\"1e\");\n    skip_iter_eq::<{ FORMAT }>(b\"1\", b\"1\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45\", b\"_45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45\", b\"_.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5\", b\"4_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_\", b\"4\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__\", b\"4_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_.\", b\"4.\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__.\", b\"4_.\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_5\", b\"455\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__5\", b\"_45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45_5\", b\".455\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45__5\", b\"_.45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__\", b\"4_5_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_.5\", b\"45.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__.5\", b\"4_5_.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__\", b\"_45_\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_.56\", b\"45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__.56\", b\"_45_.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__\", b\"_4_5_\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_.56\", b\"45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__.56\", b\"_4_5_.56\");\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_hive.rs::parse_insert_overwrite", "code": "pub fn verified_stmt(&self, sql: &str) -> Statement {\n        self.one_statement_parses_to(sql, sql)\n    }", "test": "fn parse_insert_overwrite() {\n    let insert_partitions = r#\"INSERT OVERWRITE TABLE db.new_table PARTITION (a = '1', b) SELECT a, b, c FROM db.table\"#;\n    hive().verified_stmt(insert_partitions);\n}"}
{"test_id": "snapview-tungstenite-rs/snapview-tungstenite-rs-219075e/tests/connection_reset.rs::test_evil_server_close", "code": "pub fn is_close(&self) -> bool {\n        matches!(*self, Message::Close(_))\n    }", "test": "fn test_evil_server_close() {\n    do_test(\n        3013,\n        |mut cli_sock| {\n            cli_sock.send(Message::Text(\"Hello WebSocket\".into())).unwrap();\n\n            sleep(Duration::from_secs(1));\n\n            let message = cli_sock.read().unwrap(); // receive close from server\n            assert!(message.is_close());\n\n            let err = cli_sock.read().unwrap_err(); // now we should get ConnectionClosed\n            match err {\n                Error::ConnectionClosed => {}\n                _ => panic!(\"unexpected error: {:?}\", err),\n            }\n        },\n        |mut srv_sock| {\n            let message = srv_sock.read().unwrap();\n            assert_eq!(message.into_data(), b\"Hello WebSocket\");\n\n            srv_sock.close(None).unwrap(); // send close to client\n\n            let message = srv_sock.read().unwrap(); // receive acknowledgement\n            assert!(message.is_close());\n            // and now just drop the connection without waiting for `ConnectionClosed`\n            srv_sock.get_mut().set_linger(Some(Duration::from_secs(0))).unwrap();\n            drop(srv_sock);\n        },\n    );\n}"}
{"test_id": "cberner-redb/cberner-redb-267b473/tests/basic_tests.rs::insert_overwrite", "code": "pub fn insert<'k, 'v>(\n        &mut self,\n        key: impl Borrow<K::SelfType<'k>>,\n        value: impl Borrow<V::SelfType<'v>>,\n    ) -> Result<bool> {\n        let value_bytes = V::as_bytes(value.borrow());\n        let value_bytes_ref = value_bytes.as_ref();\n        if value_bytes_ref.len() > MAX_VALUE_LENGTH {\n            return Err(StorageError::ValueTooLarge(value_bytes_ref.len()));\n        }\n        let key_bytes = K::as_bytes(key.borrow());\n        if key_bytes.as_ref().len() > MAX_VALUE_LENGTH {\n            return Err(StorageError::ValueTooLarge(key_bytes.as_ref().len()));\n        }\n        let get_result = self.tree.get(key.borrow())?;\n        let existed = if get_result.is_some() {\n            #[allow(clippy::unnecessary_unwrap)]\n            let guard = get_result.unwrap();\n            let collection_type = guard.value().collection_type();\n            match collection_type {\n                Inline => {\n                    let leaf_data = guard.value().as_inline();\n                    let accessor = LeafAccessor::new(\n                        leaf_data,\n                        V::fixed_width(),\n                        <() as RedbValue>::fixed_width(),\n                    );\n                    let (position, found) = accessor.position::<V>(value_bytes_ref);\n                    if found {\n                        return Ok(true);\n                    }\n\n                    let new_pairs = accessor.num_pairs() + 1;\n                    let new_pair_bytes =\n                        accessor.length_of_pairs(0, accessor.num_pairs()) + value_bytes_ref.len();\n                    let new_key_bytes =\n                        accessor.length_of_keys(0, accessor.num_pairs()) + value_bytes_ref.len();\n                    let required_inline_bytes =\n                        RawLeafBuilder::required_bytes(new_pairs, new_pair_bytes);\n\n                    if required_inline_bytes < self.mem.get_page_size() / 2 {\n                        let mut data = vec![0; required_inline_bytes];\n                        let mut builder = RawLeafBuilder::new(\n                            &mut data,\n                            new_pairs,\n                            V::fixed_width(),\n                            <() as RedbValue>::fixed_width(),\n                            new_key_bytes,\n                        );\n                        for i in 0..accessor.num_pairs() {\n                            if i == position {\n                                builder.append(\n                                    value_bytes_ref,\n                                    <() as RedbValue>::as_bytes(&()).as_ref(),\n                                );\n                            }\n                            let entry = accessor.entry(i).unwrap();\n                            builder.append(entry.key(), entry.value());\n                        }\n                        if position == accessor.num_pairs() {\n                            builder\n                                .append(value_bytes_ref, <() as RedbValue>::as_bytes(&()).as_ref());\n                        }\n                        drop(builder);\n                        drop(guard);\n                        let inline_data = DynamicCollection::<V>::make_inline_data(&data);\n                        self.tree\n                            .insert(key.borrow(), &DynamicCollection::new(&inline_data))?;\n                    } else {\n                        // convert into a subtree\n                        let mut page = self.mem.allocate(leaf_data.len(), CachePriority::Low)?;\n                        page.memory_mut()[..leaf_data.len()].copy_from_slice(leaf_data);\n                        let page_number = page.get_page_number();\n                        drop(page);\n                        drop(guard);\n\n                        // Don't bother computing the checksum, since we're about to modify the tree\n                        let mut subtree: BtreeMut<'_, V, ()> = BtreeMut::new(\n                            Some((page_number, 0)),\n                            self.mem,\n                            self.freed_pages.clone(),\n                        );\n                        let existed = subtree.insert(value.borrow(), &())?.is_some();\n                        assert_eq!(existed, found);\n                        let (new_root, new_checksum) = subtree.get_root().unwrap();\n                        let subtree_data =\n                            DynamicCollection::<V>::make_subtree_data(new_root, new_checksum);\n                        self.tree\n                            .insert(key.borrow(), &DynamicCollection::new(&subtree_data))?;\n                    }\n\n                    found\n                }\n                Subtree => {\n                    let mut subtree: BtreeMut<'_, V, ()> = BtreeMut::new(\n                        Some(guard.value().as_subtree()),\n                        self.mem,\n                        self.freed_pages.clone(),\n                    );\n                    drop(guard);\n                    let existed = subtree.insert(value.borrow(), &())?.is_some();\n                    let (new_root, new_checksum) = subtree.get_root().unwrap();\n                    let subtree_data =\n                        DynamicCollection::<V>::make_subtree_data(new_root, new_checksum);\n                    self.tree\n                        .insert(key.borrow(), &DynamicCollection::new(&subtree_data))?;\n\n                    existed\n                }\n            }\n        } else {\n            drop(get_result);\n            let required_inline_bytes = RawLeafBuilder::required_bytes(1, value_bytes_ref.len());\n            if required_inline_bytes < self.mem.get_page_size() / 2 {\n                let mut data = vec![0; required_inline_bytes];\n                let mut builder = RawLeafBuilder::new(\n                    &mut data,\n                    1,\n                    V::fixed_width(),\n                    <() as RedbValue>::fixed_width(),\n                    value_bytes_ref.len(),\n                );\n                builder.append(value_bytes_ref, <() as RedbValue>::as_bytes(&()).as_ref());\n                drop(builder);\n                let inline_data = DynamicCollection::<V>::make_inline_data(&data);\n                self.tree\n                    .insert(key.borrow(), &DynamicCollection::new(&inline_data))?;\n            } else {\n                let mut subtree: BtreeMut<'_, V, ()> =\n                    BtreeMut::new(None, self.mem, self.freed_pages.clone());\n                subtree.insert(value.borrow(), &())?;\n                let (new_root, new_checksum) = subtree.get_root().unwrap();\n                let subtree_data =\n                    DynamicCollection::<V>::make_subtree_data(new_root, new_checksum);\n                self.tree\n                    .insert(key.borrow(), &DynamicCollection::new(&subtree_data))?;\n            }\n            false\n        };\n\n        Ok(existed)\n    }", "test": "fn insert_overwrite() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(STR_TABLE).unwrap();\n        assert!(table.insert(\"hello\", \"world\").unwrap().is_none());\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(STR_TABLE).unwrap();\n    assert_eq!(\"world\", table.get(\"hello\").unwrap().unwrap().value());\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(STR_TABLE).unwrap();\n        let old_value = table.insert(\"hello\", \"replaced\").unwrap();\n        assert_eq!(old_value.unwrap().value(), \"world\");\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(STR_TABLE).unwrap();\n    assert_eq!(\"replaced\", table.get(\"hello\").unwrap().unwrap().value());\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/quote.rs::single_quotes_are_prepended_and_appended", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn single_quotes_are_prepended_and_appended() {\n  Test::new()\n    .justfile(\n      \"\n      x := quote('abc')\n    \",\n    )\n    .args([\"--evaluate\", \"x\"])\n    .stdout(\"'abc'\")\n    .run();\n}"}
{"test_id": "weggli-rs-weggli/weggli-rs-weggli-ad8d424/tests/query.rs::test_comparisons", "code": "fn parse_and_match_cpp(needle: &str, source: &str) -> usize {\n    parse_and_match_helper(needle, source, true).len()\n}", "test": "fn test_comparisons() {\n    let needle = \"{if ($x + size > dst_size){}}\";\n    let source = r\"\n    void func(){\n    if (dst_size < size + $x) {\n        func2();\n    }}\";\n\n    let matches = parse_and_match_cpp(needle, source);\n\n    assert_eq!(matches, 1);\n\n    let needle = \"{while ($x <= max) {$x++;}}\";\n    let source = r\"\n    void func(){\n        while (max >= count) {count++;}\n    }\";\n\n    let matches = parse_and_match_cpp(needle, source);\n\n    assert_eq!(matches, 1);\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_common.rs::parse_nullary_table_valued_function", "code": "pub fn verified_only_select(&self, query: &str) -> Select {\n        match *self.verified_query(query).body {\n            SetExpr::Select(s) => *s,\n            _ => panic!(\"Expected SetExpr::Select\"),\n        }\n    }", "test": "fn parse_nullary_table_valued_function() {\n    let sql = \"SELECT * FROM fn()\";\n    let _select = verified_only_select(sql);\n}"}
{"test_id": "dtolnay-serde-yaml/dtolnay-serde-yaml-f8adb28/tests/test_serde.rs::test_float", "code": "pub fn is_nan(&self) -> bool {\n        match self.n {\n            N::PosInt(_) | N::NegInt(_) => false,\n            N::Float(f) => f.is_nan(),\n        }\n    }", "test": "fn test_float() {\n    let thing = 25.6;\n    let yaml = indoc! {\"\n        25.6\n    \"};\n    test_serde(&thing, yaml);\n\n    let thing = 25.;\n    let yaml = indoc! {\"\n        25.0\n    \"};\n    test_serde(&thing, yaml);\n\n    let thing = f64::INFINITY;\n    let yaml = indoc! {\"\n        .inf\n    \"};\n    test_serde(&thing, yaml);\n\n    let thing = f64::NEG_INFINITY;\n    let yaml = indoc! {\"\n        -.inf\n    \"};\n    test_serde(&thing, yaml);\n\n    let float: f64 = serde_yaml::from_str(indoc! {\"\n        .nan\n    \"})\n    .unwrap();\n    assert!(float.is_nan());\n}"}
{"test_id": "dtolnay-syn/dtolnay-syn-b1a038c/tests/test_token_trees.rs::test_literal_mangling", "code": "pub(crate) fn to_string(&self) -> String {\n        let mut repr = String::with_capacity(self.digits.len());\n\n        let mut has_nonzero = false;\n        for digit in self.digits.iter().rev() {\n            has_nonzero |= *digit != 0;\n            if has_nonzero {\n                repr.push((*digit + b'0') as char);\n            }\n        }\n\n        if repr.is_empty() {\n            repr.push('0');\n        }\n\n        repr\n    }", "test": "fn test_literal_mangling() {\n    let code = \"0_4\";\n    let parsed: Lit = syn::parse_str(code).unwrap();\n    assert_eq!(code, quote!(#parsed).to_string());\n}"}
{"test_id": "weggli-rs-weggli/weggli-rs-weggli-ad8d424/tests/query.rs::casts", "code": "fn parse_and_match(needle: &str, source: &str) -> usize {\n    parse_and_match_helper(needle, source, false).len()\n}", "test": "fn casts() {\n    let source = r#\"\n        int* foo() {\n           bla *x = (bla *) malloc(10); \n        }\"#;\n\n    let needle = \"{$x = malloc(_);}\";\n    let matches = parse_and_match(needle, source);\n    assert_eq!(matches, 1);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/config/dynamic/pessimistic_txn.rs::test_config_validate", "code": "pub fn validate(&self) -> std::result::Result<(), Box<dyn std::error::Error>> {\n        if self.split_balance_score > 1.0\n            || self.split_balance_score < 0.0\n            || self.split_contained_score > 1.0\n            || self.split_contained_score < 0.0\n        {\n            return Err(\n                (\"split_balance_score or split_contained_score should be between 0 and 1.\").into(),\n            );\n        }\n        if self.sample_num >= self.qps_threshold {\n            return Err(\n                (\"sample_num should be less than qps_threshold for load-base-split.\").into(),\n            );\n        }\n        if self.grpc_thread_cpu_overload_threshold_ratio > 1.0\n            || self.grpc_thread_cpu_overload_threshold_ratio < 0.0\n            || self.unified_read_pool_thread_cpu_overload_threshold_ratio > 1.0\n            || self.unified_read_pool_thread_cpu_overload_threshold_ratio < 0.0\n            || self.region_cpu_overload_threshold_ratio > 1.0\n            || self.region_cpu_overload_threshold_ratio < 0.0\n        {\n            return Err((\"threshold ratio should be between 0 and 1.\").into());\n        }\n        Ok(())\n    }", "test": "fn test_config_validate() {\n    let cfg = Config::default();\n    cfg.validate().unwrap();\n\n    let mut invalid_cfg = Config::default();\n    invalid_cfg.wait_for_lock_timeout = ReadableDuration::millis(0);\n    invalid_cfg.validate().unwrap_err();\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_merge.rs::test_node_merge_rollback", "code": "pub fn get_version(&self) -> u64 {\n        self.memtable_version\n    }", "test": "fn test_node_merge_rollback() {\n    let mut cluster = new_node_cluster(0, 3);\n    configure_for_merge(&mut cluster.cfg);\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.run_conf_change();\n\n    let region = pd_client.get_region(b\"k1\").unwrap();\n    cluster.must_split(&region, b\"k2\");\n    let left = pd_client.get_region(b\"k1\").unwrap();\n    let right = pd_client.get_region(b\"k2\").unwrap();\n\n    pd_client.must_add_peer(left.get_id(), new_peer(2, 2));\n    pd_client.must_add_peer(right.get_id(), new_peer(2, 4));\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k3\", b\"v3\");\n\n    let region = pd_client.get_region(b\"k1\").unwrap();\n    let target_region = pd_client.get_region(b\"k3\").unwrap();\n\n    let schedule_merge_fp = \"on_schedule_merge\";\n    fail::cfg(schedule_merge_fp, \"return()\").unwrap();\n\n    // The call is finished when prepare_merge is applied.\n    cluster.must_try_merge(region.get_id(), target_region.get_id());\n\n    // Add a peer to trigger rollback.\n    pd_client.must_add_peer(right.get_id(), new_peer(3, 5));\n    cluster.must_put(b\"k4\", b\"v4\");\n    must_get_equal(&cluster.get_engine(3), b\"k4\", b\"v4\");\n\n    let mut region = pd_client.get_region(b\"k1\").unwrap();\n    // After split and prepare_merge, version becomes 1 + 2 = 3;\n    assert_eq!(region.get_region_epoch().get_version(), 3);\n    // After ConfChange and prepare_merge, conf version becomes 1 + 2 = 3;\n    assert_eq!(region.get_region_epoch().get_conf_ver(), 3);\n    fail::remove(schedule_merge_fp);\n    // Wait till rollback.\n    cluster.must_put(b\"k11\", b\"v11\");\n\n    // After rollback, version becomes 3 + 1 = 4;\n    region.mut_region_epoch().set_version(4);\n    for i in 1..3 {\n        must_get_equal(&cluster.get_engine(i), b\"k11\", b\"v11\");\n        let state_key = keys::region_state_key(region.get_id());\n        let state: RegionLocalState = cluster\n            .get_engine(i)\n            .get_msg_cf(CF_RAFT, &state_key)\n            .unwrap()\n            .unwrap();\n        assert_eq!(state.get_state(), PeerState::Normal);\n        assert_eq!(*state.get_region(), region);\n    }\n\n    pd_client.must_remove_peer(right.get_id(), new_peer(3, 5));\n    fail::cfg(schedule_merge_fp, \"return()\").unwrap();\n\n    let target_region = pd_client.get_region(b\"k3\").unwrap();\n    cluster.must_try_merge(region.get_id(), target_region.get_id());\n    let mut region = pd_client.get_region(b\"k1\").unwrap();\n\n    // Split to trigger rollback.\n    cluster.must_split(&right, b\"k3\");\n    fail::remove(schedule_merge_fp);\n    // Wait till rollback.\n    cluster.must_put(b\"k12\", b\"v12\");\n\n    // After premerge and rollback, conf_ver becomes 3 + 1 = 4, version becomes 4 +\n    // 2 = 6;\n    region.mut_region_epoch().set_conf_ver(4);\n    region.mut_region_epoch().set_version(6);\n    for i in 1..3 {\n        must_get_equal(&cluster.get_engine(i), b\"k12\", b\"v12\");\n        let state_key = keys::region_state_key(region.get_id());\n        let state: RegionLocalState = cluster\n            .get_engine(i)\n            .get_msg_cf(CF_RAFT, &state_key)\n            .unwrap()\n            .unwrap();\n        assert_eq!(state.get_state(), PeerState::Normal);\n        assert_eq!(*state.get_region(), region);\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_csplit.rs::test_line_num_out_of_range3", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_line_num_out_of_range3() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"40\", \"{2}\"])\n        .fails()\n        .stdout_is(\"108\\n33\\n\")\n        .stderr_is(\"csplit: '40': line number out of range on repetition 1\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"there should be splits created\")\n        .count();\n    assert_eq!(count, 0);\n\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"40\", \"{2}\", \"-k\"])\n        .fails()\n        .stdout_is(\"108\\n33\\n\")\n        .stderr_is(\"csplit: '40': line number out of range on repetition 1\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"there should be splits created\")\n        .count();\n    assert_eq!(count, 2);\n    assert_eq!(at.read(\"xx00\"), generate(1, 40));\n    assert_eq!(at.read(\"xx01\"), generate(40, 51));\n}"}
{"test_id": "wasmerio-wasmer/wasmerio-wasmer-7cb550d/tests/integration/cli/tests/msrv.rs::wasi_web_is_up_to_date", "code": "fn ensure_file_contents(path: impl AsRef<Path>, contents: impl AsRef<str>) {\n    let path = path.as_ref();\n    let contents = contents.as_ref();\n\n    if let Ok(old_contents) = std::fs::read_to_string(path) {\n        if contents == old_contents {\n            // File is already up to date\n            return;\n        }\n    }\n\n    let display_path = path.strip_prefix(project_root()).unwrap_or(path);\n\n    eprintln!(\"{} was not up-to-date, updating...\", display_path.display());\n\n    if std::env::var(\"CI\").is_ok() {\n        eprintln!(\"Note: run `cargo test` locally and commit the updated files\");\n    }\n\n    if let Some(parent) = path.parent() {\n        let _ = std::fs::create_dir_all(parent);\n    }\n    std::fs::write(&path, contents).unwrap();\n    panic!(\n        \"\\\"{}\\\" was not up to date and has been updated. Please commit the changes and re-run the tests.\",\n        path.strip_prefix(project_root()).unwrap_or(path).display()\n    );\n}", "test": "fn wasi_web_is_up_to_date() {\n    let pattern = Regex::new(r#\"rust-version\\s*=\\s*\"\\d\\.\\d\\d\"\"#).unwrap();\n    let rust_toolchain = project_root()\n        .join(\"lib\")\n        .join(\"wasi-web\")\n        .join(\"Cargo.toml\");\n\n    let replacement = format!(\"rust-version = \\\"{}\\\"\", MSRV.as_str());\n    let contents = std::fs::read_to_string(&rust_toolchain).unwrap();\n    let expected = pattern.replace_all(&contents, replacement);\n\n    ensure_file_contents(rust_toolchain, expected);\n}"}
{"test_id": "raphlinus-pulldown-cmark/raphlinus-pulldown-cmark-3da63d5/tests/suite/heading_attrs.rs::heading_attrs_test_27", "code": "pub fn test_markdown_html(input: &str, output: &str, smart_punct: bool) {\n    let mut s = String::new();\n\n    let mut opts = Options::empty();\n    opts.insert(Options::ENABLE_TABLES);\n    opts.insert(Options::ENABLE_FOOTNOTES);\n    opts.insert(Options::ENABLE_STRIKETHROUGH);\n    opts.insert(Options::ENABLE_TASKLISTS);\n    if smart_punct {\n        opts.insert(Options::ENABLE_SMART_PUNCTUATION);\n    }\n    opts.insert(Options::ENABLE_HEADING_ATTRIBUTES);\n\n    let p = Parser::new_ext(input, opts);\n    pulldown_cmark::html::push_html(&mut s, p);\n\n    assert_eq!(normalize_html(output), normalize_html(&s));\n}", "test": "fn heading_attrs_test_27() {\n    let original = r##\"## H2 {} ##\n\"##;\n    let expected = r##\"<h2>H2 {}</h2>\n\"##;\n\n    test_markdown_html(original, expected, false);\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/mod.rs::identifier_op", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn identifier_op() {\n    run_test_actions([TestAction::assert_native_error(\n        \"break = 1\",\n        JsNativeErrorKind::Syntax,\n        r#\"expected token 'identifier', got '=' in identifier parsing at line 1, col 7\"#,\n    )]);\n}"}
{"test_id": "serde-rs-json/serde-rs-json-66f862f/tests/test.rs::test_parse_string", "code": "pub fn to_string<T>(value: &T) -> Result<String>\nwhere\n    T: ?Sized + Serialize,\n{\n    let vec = tri!(to_vec(value));\n    let string = unsafe {\n        // We do not emit invalid UTF-8.\n        String::from_utf8_unchecked(vec)\n    };\n    Ok(string)\n}", "test": "fn test_parse_string() {\n    test_parse_err::<String>(&[\n        (\"\\\"\", \"EOF while parsing a string at line 1 column 1\"),\n        (\"\\\"lol\", \"EOF while parsing a string at line 1 column 4\"),\n        (\"\\\"lol\\\"a\", \"trailing characters at line 1 column 6\"),\n        (\n            \"\\\"\\\\uD83C\\\\uFFFF\\\"\",\n            \"lone leading surrogate in hex escape at line 1 column 13\",\n        ),\n        (\n            \"\\\"\\n\\\"\",\n            \"control character (\\\\u0000-\\\\u001F) found while parsing a string at line 2 column 0\",\n        ),\n        (\n            \"\\\"\\x1F\\\"\",\n            \"control character (\\\\u0000-\\\\u001F) found while parsing a string at line 1 column 2\",\n        ),\n    ]);\n\n    test_parse_slice_err::<String>(&[\n        (\n            &[b'\"', 159, 146, 150, b'\"'],\n            \"invalid unicode code point at line 1 column 5\",\n        ),\n        (\n            &[b'\"', b'\\\\', b'n', 159, 146, 150, b'\"'],\n            \"invalid unicode code point at line 1 column 7\",\n        ),\n        (\n            &[b'\"', b'\\\\', b'u', 48, 48, 51],\n            \"EOF while parsing a string at line 1 column 6\",\n        ),\n        (\n            &[b'\"', b'\\\\', b'u', 250, 48, 51, 48, b'\"'],\n            \"invalid escape at line 1 column 4\",\n        ),\n        (\n            &[b'\"', b'\\\\', b'u', 48, 250, 51, 48, b'\"'],\n            \"invalid escape at line 1 column 5\",\n        ),\n        (\n            &[b'\"', b'\\\\', b'u', 48, 48, 250, 48, b'\"'],\n            \"invalid escape at line 1 column 6\",\n        ),\n        (\n            &[b'\"', b'\\\\', b'u', 48, 48, 51, 250, b'\"'],\n            \"invalid escape at line 1 column 7\",\n        ),\n        (\n            &[b'\"', b'\\n', b'\"'],\n            \"control character (\\\\u0000-\\\\u001F) found while parsing a string at line 2 column 0\",\n        ),\n        (\n            &[b'\"', b'\\x1F', b'\"'],\n            \"control character (\\\\u0000-\\\\u001F) found while parsing a string at line 1 column 2\",\n        ),\n    ]);\n\n    test_parse_ok(vec![\n        (\"\\\"\\\"\", String::new()),\n        (\"\\\"foo\\\"\", \"foo\".to_string()),\n        (\" \\\"foo\\\" \", \"foo\".to_string()),\n        (\"\\\"\\\\\\\"\\\"\", \"\\\"\".to_string()),\n        (\"\\\"\\\\b\\\"\", \"\\x08\".to_string()),\n        (\"\\\"\\\\n\\\"\", \"\\n\".to_string()),\n        (\"\\\"\\\\r\\\"\", \"\\r\".to_string()),\n        (\"\\\"\\\\t\\\"\", \"\\t\".to_string()),\n        (\"\\\"\\\\u12ab\\\"\", \"\\u{12ab}\".to_string()),\n        (\"\\\"\\\\uAB12\\\"\", \"\\u{AB12}\".to_string()),\n        (\"\\\"\\\\uD83C\\\\uDF95\\\"\", \"\\u{1F395}\".to_string()),\n    ]);\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/externals.rs::create_get_set_funcref_tables_via_api", "code": "pub fn get(&self, index: u32) -> Option<TableElement> {\n        self.elements()\n            .get(index as usize)\n            .map(|p| unsafe { TableElement::clone_from_table_value(self.element_type(), *p) })\n    }", "test": "fn create_get_set_funcref_tables_via_api() -> anyhow::Result<()> {\n    let mut cfg = Config::new();\n    cfg.wasm_reference_types(true);\n    let engine = Engine::new(&cfg)?;\n    let mut store = Store::new(&engine, ());\n\n    let table_ty = TableType::new(ValType::FuncRef, 10, None);\n    let init = Val::FuncRef(Some(Func::wrap(&mut store, || {})));\n    let table = Table::new(&mut store, table_ty, init)?;\n\n    assert!(table.get(&mut store, 5).unwrap().unwrap_funcref().is_some());\n    table.set(&mut store, 5, Val::FuncRef(None))?;\n    assert!(table.get(&mut store, 5).unwrap().unwrap_funcref().is_none());\n\n    Ok(())\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_csplit.rs::test_line_num_range_with_up_to_match3", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_line_num_range_with_up_to_match3() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"10\", \"/10/\", \"-k\"])\n        .fails()\n        .stderr_is(\"csplit: '/10/': match not found\\n\")\n        .stdout_is(\"18\\n123\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"there should be splits created\")\n        .count();\n    assert_eq!(count, 2);\n    assert_eq!(at.read(\"xx00\"), generate(1, 10));\n    assert_eq!(at.read(\"xx01\"), generate(10, 51));\n\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"/10/\", \"10\"])\n        .succeeds()\n        .stdout_only(\"18\\n0\\n123\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"there should be splits created\")\n        .count();\n    assert_eq!(count, 3);\n    assert_eq!(at.read(\"xx00\"), generate(1, 10));\n    assert_eq!(at.read(\"xx01\"), \"\");\n    assert_eq!(at.read(\"xx02\"), generate(10, 51));\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_replica_read.rs::test_replica_read_on_hibernate", "code": "pub fn get_msg_type(&self) -> MessageType {\n        self.msg_type\n    }", "test": "fn test_replica_read_on_hibernate() {\n    let mut cluster = new_node_cluster(0, 3);\n\n    configure_for_lease_read(&mut cluster.cfg, Some(50), Some(20));\n\n    cluster.pd_client.disable_default_operator();\n    let r1 = cluster.run_conf_change();\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.pd_client.must_add_peer(r1, new_peer(2, 2));\n    must_get_equal(&cluster.get_engine(2), b\"k1\", b\"v1\");\n    cluster.pd_client.must_add_peer(r1, new_peer(3, 3));\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n\n    let filter = Box::new(\n        RegionPacketFilter::new(1, 3)\n            .direction(Direction::Recv)\n            .msg_type(MessageType::MsgReadIndex),\n    );\n    cluster.sim.wl().add_recv_filter(3, filter);\n    cluster.must_transfer_leader(1, new_peer(3, 3));\n\n    let r1 = cluster.get_region(b\"k1\");\n\n    // Read index on follower should be blocked.\n    let mut resp1_ch = async_read_on_peer(&mut cluster, new_peer(1, 1), r1, b\"k1\", true, true);\n    block_on_timeout(resp1_ch.as_mut(), Duration::from_secs(1)).unwrap_err();\n\n    let (tx, rx) = mpsc::sync_channel(1024);\n    let cb = Arc::new(move |msg: &RaftMessage| {\n        let _ = tx.send(msg.clone());\n    }) as Arc<dyn Fn(&RaftMessage) + Send + Sync>;\n    for i in 1..=3 {\n        let filter = Box::new(\n            RegionPacketFilter::new(1, i)\n                .when(Arc::new(AtomicBool::new(false)))\n                .set_msg_callback(Arc::clone(&cb)),\n        );\n        cluster.sim.wl().add_send_filter(i, filter);\n    }\n\n    // In the loop, peer 1 will keep sending read index messages to 3,\n    // but peer 3 and peer 2 will hibernate later. So, peer 1 will start\n    // a new election finally because it always ticks.\n    let start = Instant::now();\n    loop {\n        if start.saturating_elapsed() >= Duration::from_secs(6) {\n            break;\n        }\n        match rx.recv_timeout(Duration::from_secs(2)) {\n            Ok(m) => {\n                let m = m.get_message();\n                if m.get_msg_type() == MessageType::MsgRequestPreVote && m.from == 1 {\n                    break;\n                }\n            }\n            Err(RecvTimeoutError::Timeout) => panic!(\"shouldn't hibernate\"),\n            Err(_) => unreachable!(),\n        }\n    }\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/cranelift/jit/tests/basic.rs::error_on_incompatible_sig_in_declare_function", "code": "pub fn err(&self) -> Option<Type> {\n        Some(Type::from(\n            self.0.types[self.0.index].err.as_ref()?,\n            &self.0.instance(),\n        ))\n    }", "test": "fn error_on_incompatible_sig_in_declare_function() {\n    let mut flag_builder = settings::builder();\n    flag_builder.set(\"use_colocated_libcalls\", \"false\").unwrap();\n    // FIXME set back to true once the x64 backend supports it.\n    flag_builder.set(\"is_pic\", \"false\").unwrap();\n    let isa_builder = cranelift_native::builder().unwrap_or_else(|msg| {\n        panic!(\"host machine is not supported: {}\", msg);\n    });\n    let isa = isa_builder\n        .finish(settings::Flags::new(flag_builder))\n        .unwrap();\n    let mut module = JITModule::new(JITBuilder::with_isa(isa, default_libcall_names()));\n\n    let mut sig = Signature {\n        params: vec![AbiParam::new(types::I64)],\n        returns: vec![],\n        call_conv: CallConv::SystemV,\n    };\n    module\n        .declare_function(\"abc\", Linkage::Local, &sig)\n        .unwrap();\n    sig.params[0] = AbiParam::new(types::I32);\n    module\n        .declare_function(\"abc\", Linkage::Local, &sig)\n        .err()\n        .unwrap(); // Make sure this is an error\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_tty.rs::test_wrong_argument", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_wrong_argument() {\n    new_ucmd!().args(&[\"a\"]).fails().code_is(2);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_date.rs::test_date_utc", "code": "pub fn succeeds(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.success();\n        cmd_result\n    }", "test": "fn test_date_utc() {\n    for param in [\"--universal\", \"--utc\", \"--uni\", \"--u\"] {\n        new_ucmd!().arg(param).succeeds();\n    }\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_multi.rs::test_multi_node_cluster_restart", "code": "fn test_multi_cluster_restart<T: Simulator>(cluster: &mut Cluster<T>) {\n    cluster.run();\n\n    let (key, value) = (b\"k1\", b\"v1\");\n\n    assert_eq!(cluster.get(key), None);\n    cluster.must_put(key, value);\n\n    assert_eq!(cluster.get(key), Some(value.to_vec()));\n\n    cluster.shutdown();\n\n    // avoid TIMEWAIT\n    sleep_ms(500);\n\n    cluster.start().unwrap();\n\n    assert_eq!(cluster.get(key), Some(value.to_vec()));\n}", "test": "fn test_multi_node_cluster_restart() {\n    let count = 5;\n    let mut cluster = new_node_cluster(0, count);\n    test_multi_cluster_restart(&mut cluster)\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/resource_metering/test_pubsub.rs::test_basic", "code": "pub fn contains(&self, op: IoOp) -> bool {\n        match *self {\n            IoRateLimitMode::WriteOnly => op == IoOp::Write,\n            IoRateLimitMode::ReadOnly => op == IoOp::Read,\n            _ => true,\n        }\n    }", "test": "pub fn test_basic() {\n    let mut test_suite = TestSuite::new(resource_metering::Config {\n        report_receiver_interval: ReadableDuration::secs(3),\n        precision: ReadableDuration::secs(1),\n        ..Default::default()\n    });\n\n    // Workload\n    // [req-1, req-2]\n    test_suite.setup_workload(vec![\"req-1\", \"req-2\"]);\n\n    let (_client, stream) = test_suite.subscribe();\n    let tags = stream.take(4).map(|record| {\n        String::from_utf8_lossy(record.unwrap().get_record().get_resource_group_tag()).into_owned()\n    });\n    let res = block_on(tags.collect::<HashSet<_>>());\n\n    assert!(res.contains(\"req-1\"));\n    assert!(res.contains(\"req-2\"));\n}"}
{"test_id": "raphlinus-pulldown-cmark/raphlinus-pulldown-cmark-3da63d5/tests/lib.rs::leaves_necessary_whitespace_alone_weird", "code": "fn normalize_html(s: &str) -> String {\n    let parser = make_html_parser();\n    let dom = parser.one(s);\n    let body: SerializableHandle = normalize_dom(&dom).into();\n    let opts = SerializeOpts::default();\n    let mut ret_val = Vec::new();\n    serialize(&mut ret_val, &body, opts)\n        .expect(\"Writing to a string shouldn't fail (expect on OOM)\");\n    String::from_utf8(ret_val).expect(\"html5ever should always produce UTF8\")\n}", "test": "fn leaves_necessary_whitespace_alone_weird() {\n    assert_eq!(\n        \"<u>a </u>b <u>c</u>\",\n        normalize_html(\" <u>a </u>b <u>c</u>\")\n    )\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_common.rs::parse_select_all", "code": "pub fn one_statement_parses_to(&self, sql: &str, canonical: &str) -> Statement {\n        let mut statements = self.parse_sql_statements(sql).expect(sql);\n        assert_eq!(statements.len(), 1);\n\n        if !canonical.is_empty() && sql != canonical {\n            assert_eq!(self.parse_sql_statements(canonical).unwrap(), statements);\n        }\n\n        let only_statement = statements.pop().unwrap();\n        if !canonical.is_empty() {\n            assert_eq!(canonical, only_statement.to_string())\n        }\n        only_statement\n    }", "test": "fn parse_select_all() {\n    one_statement_parses_to(\"SELECT ALL name FROM customer\", \"SELECT name FROM customer\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/pd/test_rpc_client.rs::test_pd_client_heartbeat_send_failed", "code": "fn is_ok(&self) -> bool {\n        let count = self.count.fetch_add(1, Ordering::SeqCst);\n        if count != 0 && count % self.retry == 0 {\n            // it's ok.\n            return true;\n        }\n        // let's sleep awhile, so that client will update its connection.\n        thread::sleep(REQUEST_RECONNECT_INTERVAL);\n        false\n    }", "test": "fn test_pd_client_heartbeat_send_failed() {\n    let rt = setup_runtime();\n    let _g = rt.enter();\n    let pd_client_send_fail_fp = \"region_heartbeat_send_failed\";\n    fail::cfg(pd_client_send_fail_fp, \"return()\").unwrap();\n    let server = MockServer::with_case(1, Arc::new(AlreadyBootstrapped));\n    let eps = server.bind_addrs();\n\n    let mut client = new_client_v2(eps, None);\n\n    let (tx, mut responses) = client\n        .create_region_heartbeat_stream(WakePolicy::Immediately)\n        .unwrap();\n\n    let mut heartbeat_send_fail = |ok| {\n        let mut region = metapb::Region::default();\n        region.set_id(1);\n        let mut req = pdpb::RegionHeartbeatRequest::default();\n        req.set_region(region);\n        tx.send(req).unwrap();\n\n        let rsp = block_on(tokio::time::timeout(\n            Duration::from_millis(100),\n            responses.next(),\n        ));\n        if ok {\n            assert!(rsp.is_ok());\n            assert_eq!(rsp.unwrap().unwrap().unwrap().get_region_id(), 1);\n        } else {\n            rsp.unwrap_err();\n        }\n\n        let region = block_on(client.get_region_by_id(1));\n        if ok {\n            assert!(region.is_ok());\n            let r = region.unwrap();\n            assert!(r.is_some());\n            assert_eq!(1, r.unwrap().get_id());\n        } else {\n            region.unwrap_err();\n        }\n    };\n    // send fail if network is block.\n    heartbeat_send_fail(false);\n    fail::remove(pd_client_send_fail_fp);\n    // send success after network recovered.\n    heartbeat_send_fail(true);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/pd/test_rpc_client.rs::test_cluster_version", "code": "pub fn can_enable(&self, feature: Feature) -> bool {\n        self.version.load(Ordering::Relaxed) >= feature.ver\n    }", "test": "fn test_cluster_version() {\n    let server = MockServer::<Service>::new(3);\n    let eps = server.bind_addrs();\n\n    let feature_a = Feature::require(0, 0, 1);\n    let feature_b = Feature::require(5, 0, 0);\n    let feature_c = Feature::require(5, 0, 1);\n\n    let mut client = new_client_v2(eps, None);\n    let feature_gate = client.feature_gate().clone();\n    assert!(!feature_gate.can_enable(feature_a));\n\n    let mut client_clone = client.clone();\n    let mut emit_heartbeat = || {\n        let req = pdpb::StoreStats::default();\n        block_on(client_clone.store_heartbeat(req, /* store_report= */ None, None)).unwrap();\n    };\n\n    let set_cluster_version = |version: &str| {\n        let h = server.default_handler();\n        h.set_cluster_version(version.to_owned());\n    };\n\n    // Empty version string will be treated as invalid.\n    emit_heartbeat();\n    assert!(!feature_gate.can_enable(feature_a));\n\n    // Explicitly invalid version string.\n    set_cluster_version(\"invalid-version\");\n    emit_heartbeat();\n    assert!(!feature_gate.can_enable(feature_a));\n\n    // Correct version string.\n    set_cluster_version(\"5.0.0\");\n    emit_heartbeat();\n    assert!(feature_gate.can_enable(feature_a));\n    assert!(feature_gate.can_enable(feature_b));\n    assert!(!feature_gate.can_enable(feature_c));\n\n    // Version can't go backwards.\n    set_cluster_version(\"4.99\");\n    emit_heartbeat();\n    assert!(feature_gate.can_enable(feature_b));\n    assert!(!feature_gate.can_enable(feature_c));\n\n    // After reconnect the version should be still accessable.\n    // The GLOBAL_RECONNECT_INTERVAL is 0.1s so sleeps 0.2s here.\n    thread::sleep(Duration::from_millis(200));\n    client.reconnect().unwrap();\n    assert!(feature_gate.can_enable(feature_b));\n    assert!(!feature_gate.can_enable(feature_c));\n\n    // Version can go forwards.\n    set_cluster_version(\"5.0.1\");\n    emit_heartbeat();\n    assert!(feature_gate.can_enable(feature_c));\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/catalog_tests.rs::test_non_authoritive_nx_refused", "code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "async fn test_non_authoritive_nx_refused() {\n    let example = create_example();\n    let origin = example.origin().clone();\n\n    let mut catalog: Catalog = Catalog::new();\n    catalog.upsert(origin, Box::new(Arc::new(example)));\n\n    let mut question: Message = Message::new();\n\n    let mut query: Query = Query::new();\n    query.set_name(Name::parse(\"com.\", None).unwrap());\n    query.set_query_type(RecordType::SOA);\n\n    question.add_query(query);\n\n    // temp request\n    let question_bytes = question.to_bytes().unwrap();\n    let question_req = MessageRequest::from_bytes(&question_bytes).unwrap();\n    let question_req = Request::new(question_req, ([127, 0, 0, 1], 5553).into(), Protocol::Udp);\n\n    let response_handler = TestResponseHandler::new();\n    catalog\n        .lookup(&question_req, None, response_handler.clone())\n        .await;\n    let result = response_handler.into_message().await;\n\n    assert_eq!(result.response_code(), ResponseCode::Refused);\n    assert_eq!(result.message_type(), MessageType::Response);\n    assert!(!result.header().authoritative());\n\n    assert_eq!(result.name_servers().len(), 0);\n    assert_eq!(result.answers().len(), 0);\n    assert_eq!(result.additionals().len(), 0);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_install.rs::test_install_mode_failing", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_mode_failing() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"target_dir\";\n    let file = \"source_file\";\n    let mode_arg = \"--mode=999\";\n\n    at.touch(file);\n    at.mkdir(dir);\n    ucmd.arg(file)\n        .arg(dir)\n        .arg(mode_arg)\n        .fails()\n        .stderr_contains(\"Invalid mode string: invalid digit found in string\");\n\n    let dest_file = &format!(\"{dir}/{file}\");\n    assert!(at.file_exists(file));\n    assert!(!at.file_exists(dest_file));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_df.rs::test_include_exclude_same_type", "code": "pub fn stderr_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stderr_str(), msg.as_ref());\n        self\n    }", "test": "fn test_include_exclude_same_type() {\n    new_ucmd!()\n        .args(&[\"-t\", \"ext4\", \"-x\", \"ext4\"])\n        .fails()\n        .stderr_is(\"df: file system type 'ext4' both selected and excluded\\n\");\n    new_ucmd!()\n        .args(&[\"-t\", \"ext4\", \"-x\", \"ext4\", \"-t\", \"ext3\", \"-x\", \"ext3\"])\n        .fails()\n        .stderr_is(\n            \"df: file system type 'ext4' both selected and excluded\\n\\\n             df: file system type 'ext3' both selected and excluded\\n\",\n        );\n}"}
{"test_id": "ordinals-ord/ordinals-ord-8090538/tests/list.rs::no_satoshi_index", "code": "pub(crate) fn run_and_extract_stdout(self) -> String {\n    self.run().1\n  }", "test": "fn no_satoshi_index() {\n  let rpc_server = test_bitcoincore_rpc::spawn();\n  CommandBuilder::new(\"list 4a5e1e4baab89f3a32518a88c31bc87f618f76673e2cc77ab2127b7afdeda33b:0\")\n    .rpc_server(&rpc_server)\n    .expected_stderr(\"error: list requires index created with `--index-sats` flag\\n\")\n    .expected_exit_code(1)\n    .run_and_extract_stdout();\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_snap.rs::test_gen_during_heavy_recv", "code": "pub fn join(&self, meta: &SstMeta) -> Result<ImportPath> {\n        let file_name = sst_meta_to_path(meta)?;\n        self.get_import_path(file_name.to_str().unwrap())\n    }", "test": "fn test_gen_during_heavy_recv() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.server.snap_io_max_bytes_per_sec = ReadableSize(1024 * 1024);\n    cluster.cfg.raft_store.snap_mgr_gc_tick_interval = ReadableDuration(Duration::from_secs(100));\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n    let r1 = cluster.run_conf_change();\n\n    // 1M random value to ensure the region snapshot is large enough.\n    cluster.must_put(b\"key-0000\", b\"value\");\n    for i in 1..1024 {\n        let key = format!(\"key-{:04}\", i).into_bytes();\n        cluster.must_put(&key, &random_long_vec(1024));\n    }\n    // Another 1M random value because the region will split later.\n    cluster.must_put(b\"zzz-0000\", b\"value\");\n    for i in 1..1024 {\n        let key = format!(\"zzz-{:04}\", i).into_bytes();\n        cluster.must_put(&key, &random_long_vec(1024));\n    }\n\n    pd_client.must_add_peer(r1, new_peer(2, 2));\n    must_get_equal(&cluster.get_engine(2), b\"key-0000\", b\"value\");\n\n    // The new region can be used to keep sending snapshots to store 1.\n    let r2 = {\n        let r = cluster.get_region(b\"key\");\n        cluster.must_split(&r, b\"zzz\");\n        cluster.get_region(b\"key\").get_id()\n    };\n    cluster.must_transfer_leader(r2, new_peer(2, 1002));\n\n    let snap_mgr = cluster.get_snap_mgr(2);\n    let engine = cluster.engines[&2].kv.clone();\n    let snap_term = cluster.raft_local_state(r2, 2).get_hard_state().term;\n    let snap_apply_state = cluster.apply_state(r2, 2);\n    let mut snap_index = snap_apply_state.applied_index;\n\n    let snap = do_snapshot(\n        snap_mgr.clone(),\n        &engine,\n        engine.snapshot(),\n        r2,\n        snap_term,\n        snap_apply_state,\n        true,\n        true,\n        UnixSecs::now(),\n    )\n    .unwrap();\n\n    // Keep sending snapshots to store 1.\n    let s1_addr = cluster.sim.rl().get_addr(1);\n    let sec_mgr = cluster.sim.rl().security_mgr.clone();\n    let snap_dir = cluster.sim.rl().get_snap_dir(2);\n    let th = std::thread::spawn(move || {\n        loop {\n            for suffix in &[\".meta\", \"_default.sst\"] {\n                let f = format!(\"gen_{}_{}_{}{}\", r2, snap_term, snap_index, suffix);\n                let mut src = PathBuf::from(&snap_dir);\n                src.push(&f);\n\n                let f = format!(\"gen_{}_{}_{}{}\", r2, snap_term, snap_index + 1, suffix);\n                let mut dst = PathBuf::from(&snap_dir);\n                dst.push(&f);\n\n                fs::hard_link(&src, &dst).unwrap();\n            }\n\n            let snap_mgr = snap_mgr.clone();\n            let sec_mgr = sec_mgr.clone();\n            let s = snap.clone();\n            if let Err(e) =\n                send_a_large_snapshot(snap_mgr, sec_mgr, &s1_addr, r2, s, snap_index, snap_term)\n            {\n                info!(\"send_a_large_snapshot fail: {}\", e);\n                break;\n            }\n            snap_index += 1;\n        }\n    });\n\n    // While store 1 keeps receiving snapshots, it should still can generate a\n    // snapshot on time.\n    pd_client.must_add_peer(r1, new_learner_peer(3, 3));\n    sleep_ms(500);\n    must_get_equal(&cluster.get_engine(3), b\"zzz-0000\", b\"value\");\n\n    // store 1 and store 2 must send snapshot, so stats should record the snapshot.\n    let send_stats = cluster.get_snap_mgr(1).stats();\n    let recv_stats = cluster.get_snap_mgr(2).stats();\n    assert_eq!(send_stats.sending_count, 0);\n    assert_eq!(recv_stats.receiving_count, 0);\n    assert_ne!(send_stats.stats.len(), 0);\n    assert_ne!(recv_stats.stats.len(), 0);\n    drop(cluster);\n    let _ = th.join();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_install.rs::test_install_chown_file_invalid", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_install_chown_file_invalid() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_1 = \"source_file1\";\n    at.touch(file_1);\n\n    scene\n        .ucmd()\n        .arg(\"-o\")\n        .arg(\"test_invalid_user\")\n        .arg(file_1)\n        .arg(\"target_file1\")\n        .fails()\n        .stderr_contains(\"install: invalid user: 'test_invalid_user'\");\n\n    scene\n        .ucmd()\n        .arg(\"-g\")\n        .arg(\"test_invalid_group\")\n        .arg(file_1)\n        .arg(\"target_file1\")\n        .fails()\n        .stderr_contains(\"install: invalid group: 'test_invalid_group'\");\n\n    scene\n        .ucmd()\n        .arg(\"-o\")\n        .arg(\"test_invalid_user\")\n        .arg(\"-g\")\n        .arg(\"test_invalid_group\")\n        .arg(file_1)\n        .arg(\"target_file1\")\n        .fails()\n        .stderr_contains(\"install: invalid user: 'test_invalid_user'\");\n\n    scene\n        .ucmd()\n        .arg(\"-g\")\n        .arg(\"test_invalid_group\")\n        .arg(\"-o\")\n        .arg(\"test_invalid_user\")\n        .arg(file_1)\n        .arg(\"target_file1\")\n        .fails()\n        .stderr_contains(\"install: invalid user: 'test_invalid_user'\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_transaction.rs::test_read_index_with_max_ts", "code": "fn is_none(&self) -> bool {\n        false\n    }", "test": "fn test_read_index_with_max_ts() {\n    let mut cluster = new_server_cluster(0, 3);\n    // Increase the election tick to make this test case running reliably.\n    // Use async apply prewrite to let tikv response before applying on the leader\n    // peer.\n    configure_for_lease_read(&mut cluster.cfg, Some(50), Some(10_000));\n    cluster.cfg.storage.enable_async_apply_prewrite = true;\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    let k0 = b\"k0\";\n    let v0 = b\"v0\";\n    let r1 = cluster.run_conf_change();\n    let p2 = new_peer(2, 2);\n    cluster.pd_client.must_add_peer(r1, p2.clone());\n    let p3 = new_peer(3, 3);\n    cluster.pd_client.must_add_peer(r1, p3.clone());\n    cluster.must_put(k0, v0);\n    cluster.pd_client.must_none_pending_peer(p2.clone());\n    cluster.pd_client.must_none_pending_peer(p3.clone());\n\n    let region = cluster.get_region(k0);\n    cluster.must_transfer_leader(region.get_id(), p3.clone());\n\n    // Block all write cmd applying of Peer 3(leader), then start to write to it.\n    let k1 = b\"k1\";\n    let v1 = b\"v1\";\n    let mut ctx_p3 = Context::default();\n    ctx_p3.set_region_id(region.get_id());\n    ctx_p3.set_region_epoch(region.get_region_epoch().clone());\n    ctx_p3.set_peer(p3.clone());\n    let mut ctx_p2 = ctx_p3.clone();\n    ctx_p2.set_peer(p2.clone());\n\n    let start_ts = 10;\n    let mut mutation = pb::Mutation::default();\n    mutation.set_op(Op::Put);\n    mutation.key = k1.to_vec();\n    mutation.value = v1.to_vec();\n    let mut req = PrewriteRequest::default();\n    req.set_context(ctx_p3);\n    req.set_mutations(vec![mutation].into());\n    req.set_start_version(start_ts);\n    req.try_one_pc = true;\n    req.set_primary_lock(k1.to_vec());\n\n    let env = Arc::new(Environment::new(1));\n    let channel =\n        ChannelBuilder::new(env.clone()).connect(&cluster.sim.rl().get_addr(p3.get_store_id()));\n    let client_p3 = TikvClient::new(channel);\n    fail::cfg(\"on_apply_write_cmd\", \"sleep(2000)\").unwrap();\n    client_p3.kv_prewrite(&req).unwrap();\n\n    // The apply is blocked on leader, so the read index request with max ts should\n    // see the memory lock as it would be dropped after finishing apply.\n    let channel = ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(p2.get_store_id()));\n    let client_p2 = TikvClient::new(channel);\n    let mut req = GetRequest::new();\n    req.key = k1.to_vec();\n    req.version = u64::MAX;\n    ctx_p2.replica_read = true;\n    req.set_context(ctx_p2);\n    let resp = client_p2.kv_get(&req).unwrap();\n    assert!(resp.region_error.is_none());\n    assert_eq!(resp.error.unwrap().locked.unwrap().lock_version, start_ts);\n    fail::remove(\"on_apply_write_cmd\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_link.rs::test_link_one_argument", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_link_one_argument() {\n    let (_, mut ucmd) = at_and_ucmd!();\n    let file = \"test_link_argument\";\n    ucmd.args(&[file])\n        .fails()\n        .stderr_contains(\"2 values required\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_dd.rs::cated_record() {\n    ", "code": "pub fn stderr_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stderr_str(), msg.as_ref());\n        self\n    }", "test": "runcated_record() {\n    new_ucmd!()\n        .args(&[\"cbs=1\", \"conv=block\", \"status=noxfer\"])\n        .pipe_in(\"ab\")\n        .succeeds()\n        .stdout_is(\"a\")\n        .stderr_is(\"0+1 records in\\n0+1 records out\\n1 truncated record\\n\");\n    new_ucmd!()\n        .args(&[\"cbs=1\", \"conv=block\", \"status=noxfer\"])\n        .pipe_in(\"ab\\ncd\\n\")\n        .succeeds()\n        .stdout_is(\"ac\")\n        .stderr_is(\"0+1 records in\\n0+1 records out\\n2 truncated records\\n\");\n}\n\n/// Tes"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/lint.rs::maximum_diagnostics", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn maximum_diagnostics() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n    let file_path = Path::new(\"check.js\");\n    fs.insert(file_path.into(), ERRORS.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"lint\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let messages = &console.out_buffer;\n\n    assert_eq!(\n        messages\n            .iter()\n            .filter(|m| m.level == LogLevel::Error)\n            .count(),\n        20_usize\n    );\n\n    assert!(messages\n        .iter()\n        .filter(|m| m.level == LogLevel::Log)\n        .any(|m| {\n            let content = format!(\"{:?}\", m.content);\n            content.contains(\"The number of diagnostics exceeds the number allowed by Biome\")\n                && content.contains(\"Diagnostics not shown\")\n                && content.contains(\"77\")\n        }));\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"maximum_diagnostics\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cat.rs::test_directory", "code": "pub fn stderr_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stderr_str(), msg.as_ref());\n        self\n    }", "test": "fn test_directory() {\n    let s = TestScenario::new(util_name!());\n    s.fixtures.mkdir(\"test_directory\");\n    s.ucmd()\n        .args(&[\"test_directory\"])\n        .fails()\n        .stderr_is(\"cat: test_directory: Is a directory\\n\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_bootstrap.rs::test_bootstrap_half_way_failure_after_prepare_bootstrap_cluster", "code": "fn test_bootstrap_half_way_failure() {\n    let server = test_pd::Server::new(1);\n    let eps = server.bind_addrs();\n    let pd_client = test_pd::util::new_client(eps, None);\n    let path = TempDir::new().unwrap();\n    let engines = engine_test::new_temp_engine(&path);\n    let bootstrap = || {\n        let logger = slog_global::borrow_global().new(o!());\n        let mut bootstrap = Bootstrap::new(&engines.raft, 0, &pd_client, logger);\n        match bootstrap.bootstrap_store() {\n            Ok(store_id) => {\n                let mut store = Store::default();\n                store.set_id(store_id);\n                bootstrap.bootstrap_first_region(&store, store_id)\n            }\n            Err(e) => Err(e),\n        }\n    };\n\n    // Try to start this node, return after persisted some keys.\n    fail::cfg(\"node_after_bootstrap_store\", \"return\").unwrap();\n    let s = format!(\"{}\", bootstrap().unwrap_err());\n    assert!(s.contains(\"node_after_bootstrap_store\"), \"{}\", s);\n    assert_matches!(engines.raft.get_prepare_bootstrap_region(), Ok(None));\n\n    let ident = engines.raft.get_store_ident().unwrap().unwrap();\n    assert_ne!(ident.get_store_id(), 0);\n\n    // Check whether it can bootstrap cluster successfully.\n    fail::remove(\"node_after_bootstrap_store\");\n    fail::cfg(\"node_after_prepare_bootstrap_cluster\", \"return\").unwrap();\n    let s = format!(\"{}\", bootstrap().unwrap_err());\n    assert!(s.contains(\"node_after_prepare_bootstrap_cluster\"), \"{}\", s);\n    assert_matches!(engines.raft.get_prepare_bootstrap_region(), Ok(Some(_)));\n\n    fail::remove(\"node_after_prepare_bootstrap_cluster\");\n    fail::cfg(\"node_after_bootstrap_cluster\", \"return\").unwrap();\n    let s = format!(\"{}\", bootstrap().unwrap_err());\n    assert!(s.contains(\"node_after_bootstrap_cluster\"), \"{}\", s);\n    assert_matches!(engines.raft.get_prepare_bootstrap_region(), Ok(Some(_)));\n\n    // Although aborted by error, rebootstrap should continue.\n    bootstrap().unwrap().unwrap();\n    assert_matches!(engines.raft.get_prepare_bootstrap_region(), Ok(None));\n\n    // Second bootstrap should be noop.\n    assert_eq!(bootstrap().unwrap(), None);\n\n    assert_matches!(engines.raft.get_prepare_bootstrap_region(), Ok(None));\n}", "test": "fn test_bootstrap_half_way_failure_after_prepare_bootstrap_cluster() {\n    let fp = \"node_after_prepare_bootstrap_cluster\";\n    test_bootstrap_half_way_failure(fp);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_true.rs::test_help", "code": "pub fn stdout_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stdout_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stdout_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_help() {\n    new_ucmd!()\n        .args(&[\"--help\"])\n        .succeeds()\n        .stdout_contains(\"true\");\n}"}
{"test_id": "rust-bitcoin-rust-bitcoin/rust-bitcoin-rust-bitcoin-5ee33ea/bitcoin/tests/serde.rs::serde_regression_extended_pub_key", "code": "pub fn serialize(&self) -> Vec<u8> {\n        let mut buf: Vec<u8> = Vec::new();\n\n        //  <magic>\n        buf.extend_from_slice(b\"psbt\");\n\n        buf.push(0xff_u8);\n\n        buf.extend(self.serialize_map());\n\n        for i in &self.inputs {\n            buf.extend(i.serialize_map());\n        }\n\n        for i in &self.outputs {\n            buf.extend(i.serialize_map());\n        }\n\n        buf\n    }", "test": "fn serde_regression_extended_pub_key() {\n    let s = include_str!(\"data/serde/extended_pub_key\");\n    let key = Xpub::from_str(s.trim()).unwrap();\n    let got = serialize(&key).unwrap();\n    let want = include_bytes!(\"data/serde/extended_pub_key_bincode\") as &[_];\n    assert_eq!(got, want)\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_timeout.rs::test_invalid_signal", "code": "pub fn usage_error<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.stderr_only(format!(\n            \"{0}: {2}\\nTry '{1} {0} --help' for more information.\\n\",\n            self.util_name.as_ref().unwrap(), // This shouldn't be called using a normal command\n            self.bin_path.display(),\n            msg.as_ref()\n        ))\n    }", "test": "fn test_invalid_signal() {\n    new_ucmd!()\n        .args(&[\"-s\", \"invalid\", \"1\", \"sleep\", \"0\"])\n        .fails()\n        .usage_error(\"'invalid': invalid signal\");\n}"}
{"test_id": "astral-sh-ruff/astral-sh-ruff-1a6898a/crates/ruff_python_ast/tests/preorder.rs::function_positional_only_with_default", "code": "fn trace_preorder_visitation(source: &str) -> String {\n    let tokens = lex(source, Mode::Module);\n    let parsed = parse_tokens(tokens, source, Mode::Module, \"test.py\").unwrap();\n\n    let mut visitor = RecordVisitor::default();\n    visitor.visit_mod(&parsed);\n\n    visitor.output\n}", "test": "fn function_positional_only_with_default() {\n    let source = r#\"def a(b, c = 34,/, e = 20, *args): pass\"#;\n\n    let trace = trace_preorder_visitation(source);\n\n    assert_snapshot!(trace);\n}"}
{"test_id": "ordinals-ord/ordinals-ord-8090538/tests/wallet/sats.rs::requires_sat_index", "code": "pub(crate) fn run_and_extract_stdout(self) -> String {\n    self.run().1\n  }", "test": "fn requires_sat_index() {\n  let rpc_server = test_bitcoincore_rpc::spawn();\n  create_wallet(&rpc_server);\n\n  CommandBuilder::new(\"wallet sats\")\n    .rpc_server(&rpc_server)\n    .expected_exit_code(1)\n    .expected_stderr(\"error: sats requires index created with `--index-sats` flag\\n\")\n    .run_and_extract_stdout();\n}"}
{"test_id": "astral-sh-ruff/astral-sh-ruff-1a6898a/crates/ruff_python_ast/tests/visitor.rs::dict_comprehension", "code": "fn trace_visitation(source: &str) -> String {\n    let tokens = lex(source, Mode::Module);\n    let parsed = parse_tokens(tokens, source, Mode::Module, \"test.py\").unwrap();\n\n    let mut visitor = RecordVisitor::default();\n    walk_module(&mut visitor, &parsed);\n\n    visitor.output\n}", "test": "fn dict_comprehension() {\n    let source = \"{x: x**2 for x in numbers}\";\n\n    let trace = trace_visitation(source);\n\n    assert_snapshot!(trace);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_transaction.rs::test_concurrent_write_after_transfer_leader_invalidates_locks", "code": "pub fn get_locked(&self) -> &super::kvrpcpb::LockInfo {\n        self.locked.as_ref().unwrap_or_else(|| super::kvrpcpb::LockInfo::default_instance())\n    }", "test": "fn test_concurrent_write_after_transfer_leader_invalidates_locks() {\n    let mut cluster = new_server_cluster(0, 1);\n    cluster.cfg.pessimistic_txn.pipelined = true;\n    cluster.cfg.pessimistic_txn.in_memory = true;\n    cluster.run();\n\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    let txn_ext = cluster\n        .must_get_snapshot_of_region(1)\n        .ext()\n        .get_txn_ext()\n        .unwrap()\n        .clone();\n\n    let lock = PessimisticLock {\n        primary: b\"key\".to_vec().into_boxed_slice(),\n        start_ts: 10.into(),\n        ttl: 3000,\n        for_update_ts: 20.into(),\n        min_commit_ts: 30.into(),\n        last_change_ts: 5.into(),\n        versions_to_last_change: 3,\n    };\n    txn_ext\n        .pessimistic_locks\n        .write()\n        .insert(vec![(Key::from_raw(b\"key\"), lock.clone())])\n        .unwrap();\n\n    let region = cluster.get_region(b\"\");\n    let leader = region.get_peers()[0].clone();\n    fail::cfg(\"invalidate_locks_before_transfer_leader\", \"pause\").unwrap();\n\n    let env = Arc::new(Environment::new(1));\n    let channel =\n        ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(leader.get_store_id()));\n    let client = TikvClient::new(channel);\n\n    let mut ctx = Context::default();\n    ctx.set_region_id(region.get_id());\n    ctx.set_region_epoch(region.get_region_epoch().clone());\n    ctx.set_peer(leader);\n\n    let mut mutation = pb::Mutation::default();\n    mutation.set_op(Op::Put);\n    mutation.key = b\"key\".to_vec();\n    let mut req = PrewriteRequest::default();\n    req.set_context(ctx);\n    req.set_mutations(vec![mutation].into());\n    // Set a different start_ts. It should fail because the memory lock is still\n    // visible.\n    req.set_start_version(20);\n    req.set_primary_lock(b\"key\".to_vec());\n\n    // Prewrite should not be blocked because we have downgrade the write lock\n    // to a read lock, and it should return a locked error because it encounters\n    // the memory lock.\n    let resp = client.kv_prewrite(&req).unwrap();\n    assert_eq!(\n        resp.get_errors()[0].get_locked(),\n        &lock.into_lock().into_lock_info(b\"key\".to_vec())\n    );\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-util/tests/skip_tests.rs::test_skip_iter_iltc", "code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn test_skip_iter_iltc() {\n    // Test iterators that skip multiple digit separators.\n    pub const FORMAT: u128 = NumberFormatBuilder::new()\n        .digit_separator(num::NonZeroU8::new(b'_'))\n        .integer_internal_digit_separator(true)\n        .integer_leading_digit_separator(true)\n        .integer_trailing_digit_separator(true)\n        .integer_consecutive_digit_separator(true)\n        .build();\n    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());\n\n    skip_iter_eq::<{ FORMAT }>(b\"123.45\", b\"123.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e45\", b\"1e45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e\", b\"1e\");\n    skip_iter_eq::<{ FORMAT }>(b\"1\", b\"1\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_\", b\"4\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__\", b\"4\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_.\", b\"4.\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__.\", b\"4.\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_5\", b\"455\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__5\", b\"455\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45_5\", b\".455\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45__5\", b\".455\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_.5\", b\"45.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__.5\", b\"45.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_.56\", b\"45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__.56\", b\"45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_.56\", b\"45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__.56\", b\"45.56\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_hashsum.rs::test_invalid_arg", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_invalid_arg() {\n    new_ucmd!().arg(\"--definitely-invalid\").fails().code_is(1);\n}"}
{"test_id": "Keats-tera/Keats-tera-1f95878/src/renderer/tests/basic.rs::render_variable_block_lit_expr", "code": "fn render_template(content: &str, context: &Context) -> Result<String> {\n    let mut tera = Tera::default();\n    tera.add_raw_template(\"hello.html\", content).unwrap();\n    tera.register_function(\"get_number\", |_: &HashMap<String, Value>| Ok(Value::Number(10.into())));\n    tera.register_function(\"get_true\", |_: &HashMap<String, Value>| Ok(Value::Bool(true)));\n    tera.register_function(\"get_string\", |_: &HashMap<String, Value>| {\n        Ok(Value::String(\"Hello\".to_string()))\n    });\n\n    tera.render(\"hello.html\", context)\n}", "test": "fn render_variable_block_lit_expr() {\n    let inputs = vec![\n        (\"{{ 1 }}\", \"1\"),\n        (\"{{ 3.18 }}\", \"3.18\"),\n        (\"{{ \\\"hey\\\" }}\", \"hey\"),\n        (r#\"{{ \"{{ hey }}\" }}\"#, \"{{ hey }}\"),\n        (\"{{ true }}\", \"true\"),\n        (\"{{ false }}\", \"false\"),\n        (\"{{ false and true or true }}\", \"true\"),\n        (\"{{ 1 + 1 }}\", \"2\"),\n        (\"{{ 1 + 1.1 }}\", \"2.1\"),\n        (\"{{ 3 - 1 }}\", \"2\"),\n        (\"{{ 3 - 1.1 }}\", \"1.9\"),\n        (\"{{ 2 * 5 }}\", \"10\"),\n        (\"{{ 10 / 5 }}\", \"2\"),\n        (\"{{ 2.1 * 5 }}\", \"10.5\"),\n        (\"{{ 2.1 * 5.05 }}\", \"10.605\"),\n        (\"{{ 2 / 0.5 }}\", \"4\"),\n        (\"{{ 2.1 / 0.5 }}\", \"4.2\"),\n        (\"{{ 2 + 1 * 2 }}\", \"4\"),\n        (\"{{ (2 + 1) * 2 }}\", \"6\"),\n        (\"{{ 2 * 4 % 8 }}\", \"0\"),\n        (\"{{ 2.8 * 2 | round }}\", \"6\"),\n        (\"{{ 1 / 0 }}\", \"NaN\"),\n        (\"{{ true and 10 }}\", \"true\"),\n        (\"{{ true and not 10 }}\", \"false\"),\n        (\"{{ not true }}\", \"false\"),\n        (\"{{ [1, 2, 3] }}\", \"[1, 2, 3]\"),\n    ];\n\n    for (input, expected) in inputs {\n        println!(\"{:?} -> {:?}\", input, expected);\n        assert_eq!(render_template(input, &Context::new()).unwrap(), expected);\n    }\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/storage/test_storage.rs::test_txn_store_rawkv", "code": "pub fn to_vec(self) -> Vec<u8> {\n        if self.is_empty() {\n            return vec![];\n        }\n        let ctx = self.bits();\n        vec![ctx]\n    }", "test": "fn test_txn_store_rawkv() {\n    let store = AssertionStorage::default();\n    store.raw_get_ok(\"\".to_string(), b\"key\".to_vec(), None);\n    store.raw_put_ok(\"\".to_string(), b\"key\".to_vec(), b\"value\".to_vec());\n    store.raw_get_ok(\"\".to_string(), b\"key\".to_vec(), Some(b\"value\".to_vec()));\n    store.raw_put_ok(\"\".to_string(), b\"key\".to_vec(), b\"v2\".to_vec());\n    store.raw_get_ok(\"\".to_string(), b\"key\".to_vec(), Some(b\"v2\".to_vec()));\n    store.raw_delete_ok(\"\".to_string(), b\"key\".to_vec());\n    store.raw_get_ok(\"\".to_string(), b\"key\".to_vec(), None);\n\n    store.raw_put_ok(\"\".to_string(), b\"k1\".to_vec(), b\"v1\".to_vec());\n    store.raw_put_ok(\"\".to_string(), b\"k2\".to_vec(), b\"v2\".to_vec());\n    store.raw_put_ok(\"\".to_string(), b\"k3\".to_vec(), b\"v3\".to_vec());\n    store.raw_scan_ok(\"\".to_string(), b\"\".to_vec(), None, 1, vec![(b\"k1\", b\"v1\")]);\n    store.raw_scan_ok(\n        \"\".to_string(),\n        b\"k1\".to_vec(),\n        None,\n        1,\n        vec![(b\"k1\", b\"v1\")],\n    );\n    store.raw_scan_ok(\n        \"\".to_string(),\n        b\"k10\".to_vec(),\n        None,\n        1,\n        vec![(b\"k2\", b\"v2\")],\n    );\n    store.raw_scan_ok(\n        \"\".to_string(),\n        b\"\".to_vec(),\n        None,\n        2,\n        vec![(b\"k1\", b\"v1\"), (b\"k2\", b\"v2\")],\n    );\n    store.raw_scan_ok(\n        \"\".to_string(),\n        b\"k1\".to_vec(),\n        None,\n        5,\n        vec![(b\"k1\", b\"v1\"), (b\"k2\", b\"v2\"), (b\"k3\", b\"v3\")],\n    );\n    store.raw_scan_ok(\"\".to_string(), b\"\".to_vec(), None, 0, vec![]);\n    store.raw_scan_ok(\"\".to_string(), b\"k5\".to_vec(), None, 1, vec![]);\n}"}
{"test_id": "Keats-tera/Keats-tera-1f95878/src/parser/tests/whitespace.rs::remove_next_ws_if_single_opening_tag_requires_it", "code": "pub fn remove_whitespace(nodes: Vec<Node>, body_ws: Option<WS>) -> Vec<Node> {\n    let mut res = Vec::with_capacity(nodes.len());\n\n    // Whether the node we just added to res is a Text node\n    let mut previous_was_text = false;\n    // Whether the previous block ended wth `-%}` and we need to trim left the next text node\n    let mut trim_left_next = body_ws.map_or(false, |ws| ws.left);\n\n    for n in nodes {\n        match n {\n            Node::Text(s) => {\n                previous_was_text = true;\n\n                if !trim_left_next {\n                    res.push(Node::Text(s));\n                    continue;\n                }\n                trim_left_next = false;\n\n                let new_val = s.trim_start();\n                if !new_val.is_empty() {\n                    res.push(Node::Text(new_val.to_string()));\n                }\n                // empty text nodes will be skipped\n                continue;\n            }\n            Node::VariableBlock(ws, _)\n            | Node::ImportMacro(ws, _, _)\n            | Node::Extends(ws, _)\n            | Node::Include(ws, _, _)\n            | Node::Set(ws, _)\n            | Node::Break(ws)\n            | Node::Comment(ws, _)\n            | Node::Continue(ws) => {\n                trim_right_previous!(previous_was_text && ws.left, res);\n                trim_left_next = ws.right;\n            }\n            Node::Raw(start_ws, ref s, end_ws) => {\n                trim_right_previous!(previous_was_text && start_ws.left, res);\n                previous_was_text = false;\n                trim_left_next = end_ws.right;\n\n                if start_ws.right || end_ws.left {\n                    let val = if start_ws.right && end_ws.left {\n                        s.trim()\n                    } else if start_ws.right {\n                        s.trim_start()\n                    } else {\n                        s.trim_end()\n                    };\n\n                    res.push(Node::Raw(start_ws, val.to_string(), end_ws));\n                    continue;\n                }\n            }\n            // Those nodes have a body surrounded by 2 tags\n            Node::Forloop(start_ws, _, end_ws)\n            | Node::MacroDefinition(start_ws, _, end_ws)\n            | Node::FilterSection(start_ws, _, end_ws)\n            | Node::Block(start_ws, _, end_ws) => {\n                trim_right_previous!(previous_was_text && start_ws.left, res);\n                previous_was_text = false;\n                trim_left_next = end_ws.right;\n\n                // let's remove ws from the bodies now and append the cleaned up node\n                let body_ws = WS { left: start_ws.right, right: end_ws.left };\n                match n {\n                    Node::Forloop(_, mut forloop, _) => {\n                        forloop.body = remove_whitespace(forloop.body, Some(body_ws));\n                        res.push(Node::Forloop(start_ws, forloop, end_ws));\n                    }\n                    Node::MacroDefinition(_, mut macro_def, _) => {\n                        macro_def.body = remove_whitespace(macro_def.body, Some(body_ws));\n                        res.push(Node::MacroDefinition(start_ws, macro_def, end_ws));\n                    }\n                    Node::FilterSection(_, mut filter_section, _) => {\n                        filter_section.body = remove_whitespace(filter_section.body, Some(body_ws));\n                        res.push(Node::FilterSection(start_ws, filter_section, end_ws));\n                    }\n                    Node::Block(_, mut block, _) => {\n                        block.body = remove_whitespace(block.body, Some(body_ws));\n                        res.push(Node::Block(start_ws, block, end_ws));\n                    }\n                    _ => unreachable!(),\n                };\n                continue;\n            }\n            // The ugly one\n            Node::If(If { conditions, otherwise }, end_ws) => {\n                trim_left_next = end_ws.right;\n                let mut new_conditions: Vec<(_, _, Vec<_>)> = Vec::with_capacity(conditions.len());\n\n                for mut condition in conditions {\n                    if condition.0.left {\n                        // We need to trim the text node before the if tag\n                        if new_conditions.is_empty() && previous_was_text {\n                            trim_right_previous!(res);\n                        } else if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                            trim_right_previous!(body);\n                        }\n                    }\n\n                    // we can't peek at the next one to know whether we need to trim right since\n                    // are consuming conditions. We'll find out at the next iteration.\n                    condition.2 = remove_whitespace(\n                        condition.2,\n                        Some(WS { left: condition.0.right, right: false }),\n                    );\n                    new_conditions.push(condition);\n                }\n\n                previous_was_text = false;\n\n                // We now need to look for the last potential `{%-` bit for if/elif\n\n                // That can be a `{%- else`\n                if let Some((else_ws, body)) = otherwise {\n                    if else_ws.left {\n                        if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                            trim_right_previous!(body);\n                        }\n                    }\n                    let mut else_body =\n                        remove_whitespace(body, Some(WS { left: else_ws.right, right: false }));\n                    // if we have an `else`, the `endif` will affect the else node so we need to check\n                    if end_ws.left {\n                        trim_right_previous!(else_body);\n                    }\n                    res.push(Node::If(\n                        If { conditions: new_conditions, otherwise: Some((else_ws, else_body)) },\n                        end_ws,\n                    ));\n                    continue;\n                }\n\n                // Or `{%- endif`\n                if end_ws.left {\n                    if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                        trim_right_previous!(true, body);\n                    }\n                }\n\n                res.push(Node::If(If { conditions: new_conditions, otherwise }, end_ws));\n                continue;\n            }\n            Node::Super => (),\n        };\n\n        // If we are there, that means it's not a text node and we didn't have to modify the node\n        previous_was_text = false;\n        res.push(n);\n    }\n\n    if let Some(whitespace) = body_ws {\n        trim_right_previous!(whitespace.right, res);\n    }\n\n    res\n}", "test": "fn remove_next_ws_if_single_opening_tag_requires_it() {\n    let ws = WS { left: true, right: true };\n    let ast = vec![\n        Node::ImportMacro(ws, \"hey \".to_string(), \"ho\".to_string()),\n        Node::Text(\"  hey\".to_string()),\n    ];\n\n    assert_eq!(\n        remove_whitespace(ast, None),\n        vec![\n            Node::ImportMacro(ws, \"hey \".to_string(), \"ho\".to_string()),\n            Node::Text(\"hey\".to_string()), // it removed the leading space\n        ]\n    );\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/lookup_tests.rs::test_lookup", "code": "fn next(&mut self) -> Option<Self::Item> {\n        self.0.next().and_then(Record::data)\n    }", "test": "fn test_lookup() {\n    let authority = create_example();\n    let mut catalog = Catalog::new();\n    catalog.upsert(authority.origin().clone(), Box::new(Arc::new(authority)));\n\n    let io_loop = Runtime::new().unwrap();\n    let (stream, sender) = TestClientStream::new(Arc::new(StdMutex::new(catalog)));\n    let dns_conn = DnsMultiplexer::new(stream, sender, NoopMessageFinalizer::new());\n    let client = DnsExchange::connect::<_, _, TokioTime>(dns_conn);\n\n    let (client, bg) = io_loop.block_on(client).expect(\"client failed to connect\");\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    let lookup = LookupFuture::lookup(\n        vec![Name::from_str(\"www.example.com.\").unwrap()],\n        RecordType::A,\n        Default::default(),\n        CachingClient::new(0, client, false),\n    );\n    let lookup = io_loop.block_on(lookup).unwrap();\n\n    assert_eq!(\n        *lookup.iter().next().unwrap(),\n        RData::A(A::new(93, 184, 216, 34))\n    );\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/storage/test_storage.rs::test_txn_store_gc2_with_long_key_prefix", "code": "fn test_txn_store_gc_multiple_keys(key_prefix_len: usize, n: usize) {\n    let prefix = String::from_utf8(vec![b'k'; key_prefix_len]).unwrap();\n    test_txn_store_gc_multiple_keys_cluster_storage(n, prefix.clone());\n    test_txn_store_gc_multiple_keys_single_storage(n, prefix);\n}", "test": "fn test_txn_store_gc2_with_long_key_prefix() {\n    test_txn_store_gc_multiple_keys(1024, MAX_TXN_WRITE_SIZE / 1024 * 3);\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/crates/proto/tests/openssl_tests.rs::test_tls_client_stream_ipv4", "code": "fn tls_client_stream_test(server_addr: IpAddr, mtls: bool) {\n    let succeeded = Arc::new(atomic::AtomicBool::new(false));\n    let succeeded_clone = succeeded.clone();\n    thread::Builder::new()\n        .name(\"thread_killer\".to_string())\n        .spawn(move || {\n            let succeeded = succeeded_clone;\n            for _ in 0..15 {\n                thread::sleep(time::Duration::from_secs(1));\n                if succeeded.load(atomic::Ordering::Relaxed) {\n                    return;\n                }\n            }\n\n            println!(\"Thread Killer has been awoken, killing process\");\n            std::process::exit(-1);\n        })\n        .unwrap();\n\n    let (root_pkey, root_name, root_cert) = root_ca();\n    let root_cert_der = root_cert.to_der().unwrap();\n\n    // Generate X509 certificate\n    let subject_name = \"ns.example.com\";\n    let (_ /*server_pkey*/, _ /*server_cert*/, pkcs12) =\n        cert(subject_name, &root_pkey, &root_name, &root_cert);\n\n    let server_pkcs12_der = pkcs12.to_der().unwrap();\n\n    // TODO: need a timeout on listen\n    let server = std::net::TcpListener::bind(SocketAddr::new(server_addr, 0)).unwrap();\n    let server_addr = server.local_addr().unwrap();\n\n    let send_recv_times = 4;\n\n    // an in and out server\n    let root_cert_der_copy = root_cert_der.clone();\n\n    let server_handle = thread::Builder::new()\n        .name(\"test_tls_client_stream:server\".to_string())\n        .spawn(move || {\n            let pkcs12 = Pkcs12::from_der(&server_pkcs12_der)\n                .and_then(|p| p.parse2(\"mypass\"))\n                .expect(\"Pkcs12::from_der\");\n            let mut tls =\n                SslAcceptor::mozilla_modern(SslMethod::tls()).expect(\"mozilla_modern failed\");\n\n            if let Some(pkey) = pkcs12.pkey.as_ref() {\n                tls.set_private_key(pkey).expect(\"failed to associated key\");\n            }\n            if let Some(cert) = pkcs12.cert.as_ref() {\n                tls.set_certificate(cert)\n                    .expect(\"failed to associated cert\");\n            }\n\n            if let Some(ref chain) = pkcs12.ca {\n                for cert in chain {\n                    tls.add_extra_chain_cert(cert.to_owned())\n                        .expect(\"failed to add chain\");\n                }\n            }\n\n            {\n                let mut openssl_ctx_builder = &mut tls;\n\n                let mut mode = SslVerifyMode::empty();\n\n                // FIXME: mtls tests hang on Linux...\n                if mtls {\n                    mode = SslVerifyMode::PEER | SslVerifyMode::FAIL_IF_NO_PEER_CERT;\n\n                    let mut store = X509StoreBuilder::new().unwrap();\n                    let root_ca = X509::from_der(&root_cert_der_copy).unwrap();\n                    store.add_cert(root_ca).unwrap();\n                    openssl_ctx_builder\n                        .set_verify_cert_store(store.build())\n                        .unwrap();\n                } else {\n                    mode.insert(SslVerifyMode::NONE);\n                }\n\n                openssl_ctx_builder.set_verify(mode);\n            }\n\n            // FIXME: add CA on macOS\n\n            let tls = tls.build();\n\n            // server_barrier.wait();\n            let (socket, _) = server.accept().expect(\"tcp accept failed\");\n            socket\n                .set_read_timeout(Some(std::time::Duration::from_secs(5)))\n                .unwrap(); // should receive something within 5 seconds...\n            socket\n                .set_write_timeout(Some(std::time::Duration::from_secs(5)))\n                .unwrap(); // should receive something within 5 seconds...\n\n            let mut socket = tls.accept(socket).expect(\"tls accept failed\");\n\n            for _ in 0..send_recv_times {\n                // wait for some bytes...\n                let mut len_bytes = [0_u8; 2];\n                socket\n                    .read_exact(&mut len_bytes)\n                    .expect(\"SERVER: receive failed\");\n                let length =\n                    u16::from(len_bytes[0]) << 8 & 0xFF00 | u16::from(len_bytes[1]) & 0x00FF;\n                assert_eq!(length as usize, TEST_BYTES_LEN);\n\n                let mut buffer = [0_u8; TEST_BYTES_LEN];\n                socket.read_exact(&mut buffer).unwrap();\n\n                // println!(\"read bytes iter: {}\", i);\n                assert_eq!(&buffer, TEST_BYTES);\n\n                // bounce them right back...\n                socket\n                    .write_all(&len_bytes)\n                    .expect(\"SERVER: send length failed\");\n                socket\n                    .write_all(&buffer)\n                    .expect(\"SERVER: send buffer failed\");\n                // println!(\"wrote bytes iter: {}\", i);\n                std::thread::yield_now();\n            }\n        })\n        .unwrap();\n\n    // let the server go first\n    std::thread::yield_now();\n\n    // setup the client, which is going to run on the testing thread...\n    let mut io_loop = Runtime::new().unwrap();\n\n    // the tests should run within 5 seconds... right?\n    // TODO: add timeout here, so that test never hangs...\n    // let timeout = Timeout::new(Duration::from_secs(5));\n\n    let trust_chain = X509::from_der(&root_cert_der).unwrap();\n\n    // barrier.wait();\n    let mut builder = TlsStreamBuilder::<AsyncIoTokioAsStd<TokioTcpStream>>::new();\n    builder.add_ca(trust_chain);\n\n    if mtls {\n        config_mtls(&root_pkey, &root_name, &root_cert, &mut builder);\n    }\n\n    let (stream, mut sender) = builder.build(server_addr, subject_name.to_string());\n\n    // TODO: there is a race failure here... a race with the server thread most likely...\n    let mut stream = io_loop.block_on(stream).expect(\"run failed to get stream\");\n\n    for _ in 0..send_recv_times {\n        // test once\n        sender\n            .send(SerialMessage::new(TEST_BYTES.to_vec(), server_addr))\n            .expect(\"send failed\");\n        let (buffer, stream_tmp) = io_loop.block_on(stream.into_future());\n        stream = stream_tmp;\n        let message = buffer\n            .expect(\"no buffer received\")\n            .expect(\"error receiving bytes\");\n        assert_eq!(message.bytes(), TEST_BYTES);\n    }\n\n    succeeded.store(true, std::sync::atomic::Ordering::Relaxed);\n    server_handle.join().expect(\"server thread failed\");\n}", "test": "fn test_tls_client_stream_ipv4() {\n    tls_client_stream_test(IpAddr::V4(Ipv4Addr::new(127, 0, 0, 1)), false)\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_shred.rs::test_hex", "code": "pub fn succeeds(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.success();\n        cmd_result\n    }", "test": "fn test_hex() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let file = \"test_hex\";\n\n    at.touch(file);\n\n    ucmd.arg(\"--size=0x10\").arg(file).succeeds();\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/traps.rs::parse_dwarf_info", "code": "pub fn name(&self) -> Option<&str> {\n        self.compiled_module().module().name.as_deref()\n    }", "test": "fn parse_dwarf_info() -> Result<()> {\n    let wasm = rustc(\n        \"\n            fn main() {\n                panic!();\n            }\n        \",\n    );\n    let mut config = Config::new();\n    config.wasm_backtrace_details(WasmBacktraceDetails::Enable);\n    let engine = Engine::new(&config)?;\n    let module = Module::new(&engine, &wasm)?;\n    let mut linker = Linker::new(&engine);\n    wasmtime_wasi::add_to_linker(&mut linker, |s| s)?;\n    let mut store = Store::new(\n        &engine,\n        wasmtime_wasi::sync::WasiCtxBuilder::new()\n            .inherit_stdio()\n            .build(),\n    );\n    linker.module(&mut store, \"\", &module)?;\n    let run = linker.get_default(&mut store, \"\")?;\n    let trap = run.call(&mut store, &[], &mut []).unwrap_err();\n\n    let mut found = false;\n    let frames = trap.downcast_ref::<WasmBacktrace>().unwrap().frames();\n    for frame in frames {\n        for symbol in frame.symbols() {\n            if let Some(file) = symbol.file() {\n                if file.ends_with(\"input.rs\") {\n                    found = true;\n                    assert!(symbol.name().unwrap().contains(\"main\"));\n                    assert_eq!(symbol.line(), Some(3));\n                }\n            }\n        }\n    }\n    assert!(found);\n    Ok(())\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_storage.rs::test_atomic_cas_lock_by_latch", "code": "pub fn load(&self, ctx: TabletContext, create: bool) -> Result<CachedTablet<EK>>\n    where\n        EK: Clone,\n    {\n        assert!(ctx.suffix.is_some());\n        let id = ctx.id;\n        let path = self.tablet_path(id, ctx.suffix.unwrap());\n        if !create && !self.tablets.factory.exists(&path) {\n            return Err(Error::Other(box_err!(\n                \"tablet ({}, {:?}) doesn't exist\",\n                id,\n                ctx.suffix\n            )));\n        }\n        // TODO: use compaction filter to trim range.\n        let tablet = self.tablets.factory.open_tablet(ctx, &path)?;\n        let mut cached = self.get_or_default(id);\n        cached.set(tablet);\n        Ok(cached)\n    }", "test": "fn test_atomic_cas_lock_by_latch() {\n    let mut cluster = new_server_cluster(0, 1);\n    cluster.run();\n\n    let engine = cluster\n        .sim\n        .read()\n        .unwrap()\n        .storages\n        .get(&1)\n        .unwrap()\n        .clone();\n    let storage = TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine, MockLockManager::new())\n        .build()\n        .unwrap();\n\n    let mut ctx = Context::default();\n    ctx.set_region_id(1);\n    ctx.set_region_epoch(cluster.get_region_epoch(1));\n    ctx.set_peer(cluster.leader_of_region(1).unwrap());\n\n    let latch_acquire_success_fp = \"txn_scheduler_acquire_success\";\n    let latch_acquire_fail_fp = \"txn_scheduler_acquire_fail\";\n    let pending_cas_fp = \"txn_commands_compare_and_swap\";\n    let wakeup_latch_fp = \"txn_scheduler_try_to_wake_up\";\n    let acquire_flag = Arc::new(AtomicBool::new(false));\n    let acquire_flag1 = acquire_flag.clone();\n    let acquire_flag_fail = Arc::new(AtomicBool::new(false));\n    let acquire_flag_fail1 = acquire_flag_fail.clone();\n    let wakeup_latch_flag = Arc::new(AtomicBool::new(false));\n    let wakeup1 = wakeup_latch_flag.clone();\n\n    fail::cfg(pending_cas_fp, \"pause\").unwrap();\n    fail::cfg_callback(latch_acquire_success_fp, move || {\n        acquire_flag1.store(true, Ordering::Release);\n    })\n    .unwrap();\n    fail::cfg_callback(latch_acquire_fail_fp, move || {\n        acquire_flag_fail1.store(true, Ordering::Release);\n    })\n    .unwrap();\n    fail::cfg_callback(wakeup_latch_fp, move || {\n        wakeup1.store(true, Ordering::Release);\n    })\n    .unwrap();\n    let (cb, f1) = paired_future_callback();\n    storage\n        .raw_compare_and_swap_atomic(\n            ctx.clone(),\n            \"\".to_string(),\n            b\"key\".to_vec(),\n            None,\n            b\"v1\".to_vec(),\n            0,\n            cb,\n        )\n        .unwrap();\n    thread::sleep(Duration::from_secs(1));\n    assert!(acquire_flag.load(Ordering::Acquire));\n    assert!(!acquire_flag_fail.load(Ordering::Acquire));\n    acquire_flag.store(false, Ordering::Release);\n    let (cb, f2) = paired_future_callback();\n    storage\n        .raw_compare_and_swap_atomic(\n            ctx.clone(),\n            \"\".to_string(),\n            b\"key\".to_vec(),\n            Some(b\"v1\".to_vec()),\n            b\"v2\".to_vec(),\n            0,\n            cb,\n        )\n        .unwrap();\n    thread::sleep(Duration::from_secs(1));\n    assert!(acquire_flag_fail.load(Ordering::Acquire));\n    assert!(!acquire_flag.load(Ordering::Acquire));\n    fail::remove(pending_cas_fp);\n    let _ = block_on(f1).unwrap();\n    let (prev_val, succeed) = block_on(f2).unwrap().unwrap();\n    assert!(wakeup_latch_flag.load(Ordering::Acquire));\n    assert!(succeed);\n    assert_eq!(prev_val, Some(b\"v1\".to_vec()));\n    let f = storage.raw_get(ctx, \"\".to_string(), b\"key\".to_vec());\n    let ret = block_on(f).unwrap().unwrap();\n    assert_eq!(b\"v2\".to_vec(), ret);\n}"}
{"test_id": "serde-rs-json/serde-rs-json-66f862f/tests/lexical/rounding.rs::lower_n_mask_test", "code": "pub(crate) fn lower_n_mask(n: u64) -> u64 {\n    let bits: u64 = mem::size_of::<u64>() as u64 * 8;\n    debug_assert!(n <= bits, \"lower_n_mask() overflow in shl.\");\n\n    if n == bits {\n        u64::max_value()\n    } else {\n        (1 << n) - 1\n    }\n}", "test": "fn lower_n_mask_test() {\n    assert_eq!(lower_n_mask(0u64), 0b0);\n    assert_eq!(lower_n_mask(1u64), 0b1);\n    assert_eq!(lower_n_mask(2u64), 0b11);\n    assert_eq!(lower_n_mask(10u64), 0b1111111111);\n    assert_eq!(lower_n_mask(32u64), 0b11111111111111111111111111111111);\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/name_server_pool_tests.rs::test_user_provided_server_order", "code": "pub fn answers(answers: LookupRecords, additionals: Option<LookupRecords>) -> Self {\n        Self::Records {\n            answers,\n            additionals,\n        }\n    }", "test": "fn test_user_provided_server_order() {\n    use hickory_proto::rr::Record;\n\n    let mut options = ResolverOpts::default();\n\n    options.num_concurrent_reqs = 1;\n    options.server_ordering_strategy = ServerOrderingStrategy::UserProvidedOrder;\n\n    let query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n\n    let preferred_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 1));\n    let secondary_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 2));\n\n    let preferred_server_records = vec![preferred_record; 10];\n    let secondary_server_records = vec![secondary_record; 10];\n\n    let to_dns_response = |records: Vec<Record>| -> Vec<Result<DnsResponse, ResolveError>> {\n        records\n            .iter()\n            .map(|record| {\n                Ok(DnsResponse::from_message(message(\n                    query.clone(),\n                    vec![record.clone()],\n                    vec![],\n                    vec![],\n                ))\n                .unwrap())\n            })\n            .collect()\n    };\n\n    // Specify different IP addresses for each name server to ensure that they\n    // are considered separately.\n    let preferred_nameserver = mock_nameserver_with_addr(\n        to_dns_response(preferred_server_records.clone()),\n        Ipv4Addr::new(128, 0, 0, 1).into(),\n        Default::default(),\n    );\n    let secondary_nameserver = mock_nameserver_with_addr(\n        to_dns_response(secondary_server_records.clone()),\n        Ipv4Addr::new(129, 0, 0, 1).into(),\n        Default::default(),\n    );\n\n    let pool = mock_nameserver_pool(\n        vec![preferred_nameserver, secondary_nameserver],\n        vec![],\n        None,\n        options,\n    );\n\n    // The returned records should consistently be from the preferred name\n    // server until the configured records are exhausted. Subsequently, the\n    // secondary server should be used.\n    preferred_server_records\n        .into_iter()\n        .chain(secondary_server_records)\n        .for_each(|expected_record| {\n            let request = message(query.clone(), vec![], vec![], vec![]);\n            let future = pool.send(request).first_answer();\n\n            let response = block_on(future).unwrap();\n            assert_eq!(response.answers()[0], expected_record);\n        });\n}"}
{"test_id": "ron-rs-ron/ron-rs-ron-eafa2b6/tests/preserve_sequence.rs::test_sequence_ex1", "code": "fn read_original(source: &str) -> String {\n    source.to_string().replace(\"\\r\\n\", \"\\n\")\n}", "test": "fn test_sequence_ex1() {\n    let file = include_str!(\"preserve_sequence_ex1.ron\");\n    assert_eq!(read_original(file), make_roundtrip(file));\n}"}
{"test_id": "mitsuhiko-minijinja/mitsuhiko-minijinja-5f2c1e8/minijinja-contrib/tests/datetime.rs::test_dateformat_time_rs", "code": "pub fn eval<S: Serialize>(&self, ctx: S) -> Result<Value, Error> {\n        // reduce total amount of code faling under mono morphization into\n        // this function, and share the rest in _eval.\n        self._eval(Value::from_serializable(&ctx))\n    }", "test": "fn test_dateformat_time_rs() {\n    let mut env = minijinja::Environment::new();\n    env.add_global(\"TIMEZONE\", \"Europe/Vienna\");\n    env.add_global(\"DATE_FORMAT\", \"[year]-[month]\");\n    minijinja_contrib::add_to_environment(&mut env);\n\n    let expr = env\n        .compile_expression(\"d|dateformat(format=format)\")\n        .unwrap();\n\n    let d = time::Date::from_ordinal_date(2023, 42).unwrap();\n    assert_eq!(\n        expr.eval(context!(d, format => \"short\"))\n            .unwrap()\n            .to_string(),\n        \"2023-02-11\"\n    );\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/resource_metering/tests/summary_test.rs::test_summary", "code": "pub fn is_none(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_none(),\n            }\n        }\n    }", "test": "fn test_summary() {\n    let cfg = Config {\n        report_receiver_interval: ReadableDuration::millis(REPORT_INTERVAL_MS),\n        precision: ReadableDuration::millis(PRECISION_MS),\n        ..Default::default()\n    };\n\n    let (_, collector_reg_handle, resource_tag_factory, mut recorder_worker) =\n        init_recorder(cfg.precision.as_millis());\n    let (_, data_sink_reg_handle, mut reporter_worker) = init_reporter(cfg, collector_reg_handle);\n\n    let data_sink = MockDataSink::default();\n\n    // At this point we are ready for everything except turning on the switch.\n\n    // expect no data\n    {\n        let tf = resource_tag_factory.clone();\n        let data_sink = data_sink.clone();\n        thread::spawn(move || {\n            {\n                let mut ctx = Context::default();\n                ctx.set_resource_group_tag(b\"TAG-1\".to_vec());\n                let tag = tf.new_tag(&ctx);\n                let _g = tag.attach();\n                resource_metering::record_read_keys(123);\n                resource_metering::record_write_keys(456);\n            }\n            thread::sleep(Duration::from_millis(REPORT_INTERVAL_MS + 500)); // wait report\n            assert!(data_sink.get(b\"TAG-1\").is_none());\n            data_sink.clear();\n        })\n        .join()\n        .unwrap();\n    }\n\n    // turn on\n    let reg_guard = data_sink_reg_handle.register(Box::new(data_sink.clone()));\n\n    // expect can get data\n    {\n        let tf = resource_tag_factory.clone();\n        let data_sink = data_sink.clone();\n        thread::spawn(move || {\n            {\n                let mut ctx = Context::default();\n                ctx.set_resource_group_tag(b\"TAG-1\".to_vec());\n                let tag = tf.new_tag(&ctx);\n                let _g = tag.attach();\n                thread::sleep(Duration::from_millis(PRECISION_MS * 2)); // wait config apply\n                resource_metering::record_read_keys(123);\n                resource_metering::record_write_keys(456);\n            }\n            thread::sleep(Duration::from_millis(REPORT_INTERVAL_MS + 500)); // wait report\n\n            let r = data_sink.get(b\"TAG-1\").unwrap();\n            assert_eq!(\n                r.get_record()\n                    .get_items()\n                    .iter()\n                    .map(|item| item.read_keys)\n                    .sum::<u32>(),\n                123\n            );\n            assert_eq!(\n                r.get_record()\n                    .get_items()\n                    .iter()\n                    .map(|item| item.write_keys)\n                    .sum::<u32>(),\n                456\n            );\n            data_sink.clear();\n        })\n        .join()\n        .unwrap();\n    }\n\n    // turn off\n    drop(reg_guard);\n\n    // expect no data\n    thread::spawn(move || {\n        {\n            let mut ctx = Context::default();\n            ctx.set_resource_group_tag(b\"TAG-1\".to_vec());\n            let tag = resource_tag_factory.new_tag(&ctx);\n            let _g = tag.attach();\n            thread::sleep(Duration::from_millis(PRECISION_MS * 2)); // wait config apply\n            resource_metering::record_read_keys(123);\n            resource_metering::record_write_keys(456);\n        }\n        thread::sleep(Duration::from_millis(REPORT_INTERVAL_MS + 500)); // wait report\n        assert!(data_sink.get(b\"TAG-1\").is_none());\n        data_sink.clear();\n    })\n    .join()\n    .unwrap();\n\n    // stop worker\n    recorder_worker.stop();\n    reporter_worker.stop();\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_multi.rs::test_server_batch_write", "code": "fn test_batch_write<T: Simulator>(cluster: &mut Cluster<T>) {\n    cluster.run();\n    let r = cluster.get_region(b\"\");\n    cluster.must_split(&r, b\"k3\");\n    // update epoch.\n    let r = cluster.get_region(b\"\");\n\n    let req = new_request(\n        r.get_id(),\n        r.get_region_epoch().clone(),\n        vec![new_put_cmd(b\"k1\", b\"v1\"), new_put_cmd(b\"k2\", b\"v2\")],\n        false,\n    );\n    let resp = cluster\n        .call_command_on_leader(req, Duration::from_secs(3))\n        .unwrap();\n    assert!(!resp.get_header().has_error());\n    assert_eq!(cluster.must_get(b\"k1\"), Some(b\"v1\".to_vec()));\n    assert_eq!(cluster.must_get(b\"k2\"), Some(b\"v2\".to_vec()));\n\n    let req = new_request(\n        r.get_id(),\n        r.get_region_epoch().clone(),\n        vec![new_put_cmd(b\"k1\", b\"v3\"), new_put_cmd(b\"k3\", b\"v3\")],\n        false,\n    );\n    let resp = cluster\n        .call_command_on_leader(req, Duration::from_secs(3))\n        .unwrap();\n    assert!(resp.get_header().has_error());\n    assert_eq!(cluster.must_get(b\"k1\"), Some(b\"v1\".to_vec()));\n    assert_eq!(cluster.must_get(b\"k3\"), None);\n}", "test": "fn test_server_batch_write() {\n    let mut cluster = new_server_cluster(0, 3);\n    test_batch_write(&mut cluster);\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/fuel.rs::manual_edge_cases", "code": "pub fn fuel_consumed(&self) -> Option<u64> {\n        self.inner.fuel_consumed()\n    }", "test": "fn manual_edge_cases() {\n    let mut config = Config::new();\n    config.consume_fuel(true);\n    let engine = Engine::new(&config).unwrap();\n    let mut store = Store::new(&engine, ());\n    store.add_fuel(u64::MAX).unwrap();\n    assert_eq!(store.fuel_consumed(), Some(0));\n    assert!(store.consume_fuel(u64::MAX).is_err());\n    assert!(store.consume_fuel(i64::MAX as u64 + 1).is_err());\n    assert_eq!(store.consume_fuel(i64::MAX as u64).unwrap(), 0);\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-parse-float/tests/options_tests.rs::invalid_exponent_test", "code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn invalid_exponent_test() {\n    let mut builder = OptionsBuilder::default();\n    builder = builder.exponent(b'\\x00');\n    assert!(!builder.is_valid());\n    builder = builder.exponent(b'\\x7f');\n    assert!(!builder.is_valid());\n    assert!(builder.build().is_err());\n    builder = builder.exponent(b'^');\n    assert!(builder.is_valid());\n    assert!(builder.build().is_ok());\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_common.rs::test_revoke", "code": "pub fn assert_eq_vec<T: ToString>(expected: &[&str], actual: &[T]) {\n    assert_eq!(\n        expected,\n        actual.iter().map(ToString::to_string).collect::<Vec<_>>()\n    );\n}", "test": "fn test_revoke() {\n    let sql = \"REVOKE ALL PRIVILEGES ON users, auth FROM analyst CASCADE\";\n    match verified_stmt(sql) {\n        Statement::Revoke {\n            privileges,\n            objects: GrantObjects::Tables(tables),\n            grantees,\n            cascade,\n            granted_by,\n        } => {\n            assert_eq!(\n                Privileges::All {\n                    with_privileges_keyword: true\n                },\n                privileges\n            );\n            assert_eq_vec(&[\"users\", \"auth\"], &tables);\n            assert_eq_vec(&[\"analyst\"], &grantees);\n            assert!(cascade);\n            assert_eq!(None, granted_by);\n        }\n        _ => unreachable!(),\n    }\n}"}
{"test_id": "gimli-rs-gimli/gimli-rs-gimli-3947879/tests/convert_self.rs::test_convert_debug_info", "code": "pub fn count(&self) -> usize {\n        self.units.len()\n    }", "test": "fn test_convert_debug_info() {\n    // Convert existing sections\n    let debug_abbrev = read_section(\"debug_abbrev\");\n    let debug_abbrev = read::DebugAbbrev::new(&debug_abbrev, LittleEndian);\n\n    let debug_info = read_section(\"debug_info\");\n    let debug_info = read::DebugInfo::new(&debug_info, LittleEndian);\n\n    let debug_line = read_section(\"debug_line\");\n    let debug_line = read::DebugLine::new(&debug_line, LittleEndian);\n\n    let debug_str = read_section(\"debug_str\");\n    let debug_str = read::DebugStr::new(&debug_str, LittleEndian);\n\n    let debug_ranges = read_section(\"debug_ranges\");\n    let debug_ranges = read::DebugRanges::new(&debug_ranges, LittleEndian);\n\n    let debug_rnglists = read::DebugRngLists::new(&[], LittleEndian);\n\n    let ranges = gimli::RangeLists::new(debug_ranges, debug_rnglists);\n\n    let debug_loc = read_section(\"debug_loc\");\n    let debug_loc = read::DebugLoc::new(&debug_loc, LittleEndian);\n\n    let debug_loclists = read::DebugLocLists::new(&[], LittleEndian);\n\n    let locations = gimli::LocationLists::new(debug_loc, debug_loclists);\n\n    let dwarf = read::Dwarf {\n        debug_abbrev,\n        debug_info,\n        debug_line,\n        debug_str,\n        ranges,\n        locations,\n        ..Default::default()\n    };\n\n    let mut dwarf = write::Dwarf::from(&dwarf, &|address| Some(Address::Constant(address)))\n        .expect(\"Should convert DWARF information\");\n\n    assert_eq!(dwarf.units.count(), 23);\n    let entries: usize = (0..dwarf.units.count())\n        .map(|i| dwarf.units.get(dwarf.units.id(i)).count())\n        .sum();\n    assert_eq!(entries, 29_560);\n    assert_eq!(dwarf.line_strings.count(), 0);\n    assert_eq!(dwarf.strings.count(), 3921);\n\n    // Write to new sections\n    let mut write_sections = write::Sections::new(EndianVec::new(LittleEndian));\n    dwarf\n        .write(&mut write_sections)\n        .expect(\"Should write DWARF information\");\n    let debug_info_data = write_sections.debug_info.slice();\n    let debug_abbrev_data = write_sections.debug_abbrev.slice();\n    let debug_line_data = write_sections.debug_line.slice();\n    let debug_ranges_data = write_sections.debug_ranges.slice();\n    let debug_loc_data = write_sections.debug_loc.slice();\n    let debug_str_data = write_sections.debug_str.slice();\n    assert_eq!(debug_info_data.len(), 394_930);\n    assert_eq!(debug_abbrev_data.len(), 9701);\n    assert_eq!(debug_line_data.len(), 105_797);\n    assert_eq!(debug_ranges_data.len(), 155_712);\n    assert_eq!(debug_loc_data.len(), 245_168);\n    assert_eq!(debug_str_data.len(), 144_731);\n\n    // Convert new sections\n    let debug_abbrev = read::DebugAbbrev::new(debug_abbrev_data, LittleEndian);\n    let debug_info = read::DebugInfo::new(debug_info_data, LittleEndian);\n    let debug_line = read::DebugLine::new(debug_line_data, LittleEndian);\n    let debug_str = read::DebugStr::new(debug_str_data, LittleEndian);\n    let debug_ranges = read::DebugRanges::new(debug_ranges_data, LittleEndian);\n    let debug_rnglists = read::DebugRngLists::new(&[], LittleEndian);\n    let debug_loc = read::DebugLoc::new(debug_loc_data, LittleEndian);\n    let debug_loclists = read::DebugLocLists::new(&[], LittleEndian);\n\n    let ranges = gimli::RangeLists::new(debug_ranges, debug_rnglists);\n    let locations = gimli::LocationLists::new(debug_loc, debug_loclists);\n\n    let dwarf = read::Dwarf {\n        debug_abbrev,\n        debug_info,\n        debug_line,\n        debug_str,\n        ranges,\n        locations,\n        ..Default::default()\n    };\n\n    let dwarf = write::Dwarf::from(&dwarf, &|address| Some(Address::Constant(address)))\n        .expect(\"Should convert DWARF information\");\n\n    assert_eq!(dwarf.units.count(), 23);\n    let entries: usize = (0..dwarf.units.count())\n        .map(|i| dwarf.units.get(dwarf.units.id(i)).count())\n        .sum();\n    assert_eq!(entries, 29_560);\n    assert_eq!(dwarf.strings.count(), 3921);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_seq.rs::test_trailing_whitespace_error", "code": "pub fn usage_error<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.stderr_only(format!(\n            \"{0}: {2}\\nTry '{1} {0} --help' for more information.\\n\",\n            self.util_name.as_ref().unwrap(), // This shouldn't be called using a normal command\n            self.bin_path.display(),\n            msg.as_ref()\n        ))\n    }", "test": "fn test_trailing_whitespace_error() {\n    // In some locales, the GNU error message has curly quotes (\u2018)\n    // instead of straight quotes ('). We just test the straight single\n    // quotes.\n    new_ucmd!()\n        .arg(\"1 \")\n        .fails()\n        .usage_error(\"invalid floating point argument: '1 '\");\n}\n\n"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_split.rs::test_split_separator_nul_number_l", "code": "fn file_read(at: &AtPath, filename: &str) -> String {\n    let mut s = String::new();\n    at.open(filename).read_to_string(&mut s).unwrap();\n    s\n}", "test": "fn test_split_separator_nul_number_l() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"--number=l/3\", \"--separator=\\\\0\", \"separator_nul.txt\"])\n        .succeeds();\n\n    assert_eq!(file_read(&at, \"xaa\"), \"1\\x002\\0\");\n    assert_eq!(file_read(&at, \"xab\"), \"3\\x004\\0\");\n    assert_eq!(file_read(&at, \"xac\"), \"5\\0\");\n    assert!(!at.plus(\"xad\").exists());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_mkfifo.rs::test_create_one_fifo_with_invalid_mode", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_create_one_fifo_with_invalid_mode() {\n    new_ucmd!()\n        .arg(\"abcd\")\n        .arg(\"-m\")\n        .arg(\"invalid\")\n        .fails()\n        .stderr_contains(\"invalid mode\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_logname.rs::test_invalid_arg", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_invalid_arg() {\n    new_ucmd!().arg(\"--definitely-invalid\").fails().code_is(1);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_seq.rs::test_count_down_floats", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_count_down_floats() {\n    new_ucmd!()\n        .args(&[\"--\", \"5\", \"-1.0\", \"1\"])\n        .run()\n        .stdout_is(\"5.0\\n4.0\\n3.0\\n2.0\\n1.0\\n\");\n    new_ucmd!()\n        .args(&[\"5\", \"-1\", \"1.0\"])\n        .run()\n        .stdout_is(\"5\\n4\\n3\\n2\\n1\\n\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_expand.rs::test_tabs_with_too_large_size", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_tabs_with_too_large_size() {\n    let arg = format!(\"--tabs={}\", u128::MAX);\n    let expected_error = format!(\"tab stop is too large '{}'\", u128::MAX);\n\n    new_ucmd!().arg(arg).fails().stderr_contains(expected_error);\n}"}
{"test_id": "web-infra-dev-oxc/oxc-project-oxc-884a819/crates/oxc_minifier/tests/closure/substitute_alternate_syntax.rs::fold_return_result", "code": "fn test(args: &[&str]) -> LintResult {\n        let mut new_args = vec![\"--quiet\"];\n        new_args.extend(args);\n        let options = lint_command().run_inner(new_args.as_slice()).unwrap().lint_options;\n        let CliRunResult::LintResult(lint_result) = LintRunner::new(options).run() else {\n            unreachable!()\n        };\n        lint_result\n    }", "test": "fn fold_return_result() {\n    test(\"function f(){return !1;}\", \"function f(){return !1}\");\n    test(\"function f(){return null;}\", \"function f(){return null}\");\n    test(\"function f(){return void 0;}\", \"function f(){return}\");\n    test(\"function f(){return void foo();}\", \"function f(){return void foo()}\");\n    test(\"function f(){return undefined;}\", \"function f(){return}\");\n    test(\"function f(){if(a()){return undefined;}}\", \"function f(){if(a())return}\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_sst_recovery.rs::test_sst_recovery_atomic_when_adding_peer", "code": "pub fn must_get_equal<EK: KvEngine>(engine: &impl RawEngine<EK>, key: &[u8], value: &[u8]) {\n    must_get(engine, \"default\", key, Some(value));\n}", "test": "fn test_sst_recovery_atomic_when_adding_peer() {\n    let (mut cluster, pd_client, engine1) = create_tikv_cluster_with_one_node_damaged();\n\n    // To validate atomic of sst recovery.\n    fail::cfg(\"sst_recovery_before_delete_files\", \"pause\").unwrap();\n\n    // Remove peers for safe deletion of files in sst recovery.\n    let region = cluster.get_region(b\"2\");\n    let peer = find_peer(&region, 1).unwrap();\n    pd_client.must_remove_peer(region.id, peer.clone());\n    let region = cluster.get_region(b\"4\");\n    let peer = find_peer(&region, 1).unwrap();\n    pd_client.must_remove_peer(region.id, peer.clone());\n\n    std::thread::sleep(CHECK_DURATION);\n    must_get_equal(&engine1, b\"1\", b\"val\");\n    must_get_equal(&engine1, b\"7\", b\"val\");\n    // delete file action is paused before.\n    assert_corruption(engine1.get_value(b\"z4\"));\n\n    let region = cluster.get_region(b\"3\");\n    // add peer back on store 1 to validate atomic of sst recovery.\n    pd_client.must_add_peer(region.id, new_peer(1, 1099));\n\n    // store meta should be locked in sst recovery so conf change can't be finished.\n    cluster.must_region_not_exist(region.id, 1);\n    fail::remove(\"sst_recovery_before_delete_files\");\n    std::thread::sleep(CHECK_DURATION);\n    cluster.must_region_exist(region.id, 1);\n\n    must_get_equal(&engine1, b\"3\", b\"val\");\n}"}
{"test_id": "serde-rs-json/serde-rs-json-66f862f/tests/lexical/rounding.rs::round_nearest_test", "code": "pub(crate) fn round_nearest(fp: &mut ExtendedFloat, shift: i32) -> (bool, bool) {\n    // Extract the truncated bits using mask.\n    // Calculate if the value of the truncated bits are either above\n    // the mid-way point, or equal to it.\n    //\n    // For example, for 4 truncated bytes, the mask would be b1111\n    // and the midway point would be b1000.\n    let mask: u64 = lower_n_mask(shift as u64);\n    let halfway: u64 = lower_n_halfway(shift as u64);\n\n    let truncated_bits = fp.mant & mask;\n    let is_above = truncated_bits > halfway;\n    let is_halfway = truncated_bits == halfway;\n\n    // Bit shift so the leading bit is in the hidden bit.\n    overflowing_shr(fp, shift);\n\n    (is_above, is_halfway)\n}", "test": "fn round_nearest_test() {\n    // Check exactly halfway (b'1100000')\n    let mut fp = ExtendedFloat { mant: 0x60, exp: 0 };\n    let (above, halfway) = round_nearest(&mut fp, 6);\n    assert!(!above);\n    assert!(halfway);\n    assert_eq!(fp.mant, 1);\n\n    // Check above halfway (b'1100001')\n    let mut fp = ExtendedFloat { mant: 0x61, exp: 0 };\n    let (above, halfway) = round_nearest(&mut fp, 6);\n    assert!(above);\n    assert!(!halfway);\n    assert_eq!(fp.mant, 1);\n\n    // Check below halfway (b'1011111')\n    let mut fp = ExtendedFloat { mant: 0x5F, exp: 0 };\n    let (above, halfway) = round_nearest(&mut fp, 6);\n    assert!(!above);\n    assert!(!halfway);\n    assert_eq!(fp.mant, 1);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_rm.rs::test_rm_invalid_symlink", "code": "pub fn succeeds(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.success();\n        cmd_result\n    }", "test": "fn test_rm_invalid_symlink() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let link = \"test_rm_invalid_symlink\";\n\n    at.symlink_file(link, link);\n\n    ucmd.arg(link).succeeds();\n}"}
{"test_id": "web-infra-dev-oxc/oxc-project-oxc-884a819/crates/oxc_minifier/tests/closure/fold_constants.rs::test_boolean_boolean_comparison", "code": "pub(crate) fn test_same(source_text: &str) {\n    test(source_text, source_text);\n}", "test": "fn test_boolean_boolean_comparison() {\n    test_same(\"!x==!y;\");\n    test_same(\"!x<!y;\");\n    test_same(\"!x!==!y;\");\n\n    test_same(\"!x==!x;\"); // foldable\n    test_same(\"!x<!x;\"); // foldable\n    test_same(\"!x!==!x;\"); // foldable\n}"}
{"test_id": "tafia-quick-xml/tafia-quick-xml-120e074/tests/test.rs::test_attributes_empty", "code": "fn next(&mut self) -> Option<Self::Item> {\n        match self.state.next(self.bytes) {\n            None => None,\n            Some(Ok(a)) => Some(Ok(a.map(|range| &self.bytes[range]).into())),\n            Some(Err(e)) => Some(Err(e)),\n        }\n    }", "test": "fn test_attributes_empty() {\n    let src = \"<a att1='a' att2='b'/>\";\n    let mut r = Reader::from_str(src);\n    r.trim_text(true);\n    match r.read_event() {\n        Ok(Empty(e)) => {\n            let mut attrs = e.attributes();\n            assert_eq!(\n                attrs.next(),\n                Some(Ok(Attribute {\n                    key: QName(b\"att1\"),\n                    value: Cow::Borrowed(b\"a\"),\n                }))\n            );\n            assert_eq!(\n                attrs.next(),\n                Some(Ok(Attribute {\n                    key: QName(b\"att2\"),\n                    value: Cow::Borrowed(b\"b\"),\n                }))\n            );\n            assert_eq!(attrs.next(), None);\n        }\n        e => panic!(\"Expecting Empty event, got {:?}\", e),\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_pwd.rs::test_deleted_dir", "code": "pub fn success(&self) -> &Self {\n        assert!(\n            self.succeeded(),\n            \"Command was expected to succeed.\\nstdout = {}\\n stderr = {}\",\n            self.stdout_str(),\n            self.stderr_str()\n        );\n        self\n    }", "test": "fn test_deleted_dir() {\n    use std::process::Command;\n\n    let ts = TestScenario::new(util_name!());\n    let at = ts.fixtures;\n    let output = Command::new(\"sh\")\n        .arg(\"-c\")\n        .arg(format!(\n            \"cd '{}'; mkdir foo; cd foo; rmdir ../foo; exec '{}' {}\",\n            at.root_dir_resolved(),\n            ts.bin_path.to_str().unwrap(),\n            ts.util_name,\n        ))\n        .output()\n        .unwrap();\n    assert!(!output.status.success());\n    assert!(output.stdout.is_empty());\n    assert_eq!(\n        output.stderr,\n        b\"pwd: failed to get current directory: No such file or directory\\n\"\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_mv.rs::test_mv_arg_update_older_dest_not_older", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_mv_arg_update_older_dest_not_older() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let old = \"test_mv_arg_update_none_file1\";\n    let new = \"test_mv_arg_update_none_file2\";\n    let old_content = \"file1 content\\n\";\n    let new_content = \"file2 content\\n\";\n\n    at.write(old, old_content);\n\n    sleep(Duration::from_secs(1));\n\n    at.write(new, new_content);\n\n    ucmd.arg(old)\n        .arg(new)\n        .arg(\"--update=older\")\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    assert_eq!(at.read(new), new_content);\n}"}
{"test_id": "raphlinus-pulldown-cmark/raphlinus-pulldown-cmark-3da63d5/tests/suite/table.rs::table_test_5", "code": "pub fn test_markdown_html(input: &str, output: &str, smart_punct: bool) {\n    let mut s = String::new();\n\n    let mut opts = Options::empty();\n    opts.insert(Options::ENABLE_TABLES);\n    opts.insert(Options::ENABLE_FOOTNOTES);\n    opts.insert(Options::ENABLE_STRIKETHROUGH);\n    opts.insert(Options::ENABLE_TASKLISTS);\n    if smart_punct {\n        opts.insert(Options::ENABLE_SMART_PUNCTUATION);\n    }\n    opts.insert(Options::ENABLE_HEADING_ATTRIBUTES);\n\n    let p = Parser::new_ext(input, opts);\n    pulldown_cmark::html::push_html(&mut s, p);\n\n    assert_eq!(normalize_html(output), normalize_html(&s));\n}", "test": "fn table_test_5() {\n    let original = r##\"|Col 1|Col 2|\n|-----|-----|\n|R1C1 |R1C2 |\n|R2C1 |R2C2 |\n\"##;\n    let expected = r##\"<table><thead><tr><th>Col 1</th><th>Col 2</th></tr></thead>\n<tr><td>R1C1 </td><td>R1C2 </td></tr>\n<tr><td>R2C1 </td><td>R2C2 </td></tr>\n</table>\n\"##;\n\n    test_markdown_html(original, expected, false);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_csplit.rs::test_skip_to_no_match5", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_skip_to_no_match5() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"%nope%\", \"{*}\"])\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"counting splits\")\n        .count();\n    assert_eq!(count, 0);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_touch.rs::test_touch_set_cymdhm_time", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_cymdhm_time() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_cymdhm_time\";\n\n    ucmd.args(&[\"-t\", \"201501011234\", file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n\n    let start_of_year = str_to_filetime(\"%Y%m%d%H%M\", \"201501010000\");\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, mtime);\n    assert_eq!(atime.unix_seconds() - start_of_year.unix_seconds(), 45240);\n    assert_eq!(mtime.unix_seconds() - start_of_year.unix_seconds(), 45240);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_lease_read.rs::test_not_leader_read_lease", "code": "pub fn recv_timeout<S, I>(s: &mut S, dur: std::time::Duration) -> Result<Option<I>, ()>\nwhere\n    S: Stream<Item = I> + Unpin,\n{\n    poll_timeout(&mut s.next(), dur)\n}", "test": "fn test_not_leader_read_lease() {\n    let mut cluster = new_node_cluster(0, 3);\n    // Avoid triggering the log compaction in this test case.\n    cluster.cfg.raft_store.raft_log_gc_threshold = 100;\n    // Increase the Raft tick interval to make this test case running reliably.\n    configure_for_lease_read(&mut cluster.cfg, Some(50), None);\n    let heartbeat_interval = cluster.cfg.raft_store.raft_heartbeat_interval();\n\n    cluster.run();\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    cluster.must_put(b\"k2\", b\"v2\");\n    must_get_equal(&cluster.get_engine(3), b\"k2\", b\"v2\");\n\n    // Add a filter to delay heartbeat response until transfer leader begins.\n    cluster.sim.wl().add_recv_filter(\n        1,\n        Box::new(LeadingFilter::new(\n            MessageType::MsgHeartbeatResponse,\n            MessageType::MsgRequestVote,\n        )),\n    );\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(1, 2)\n            .direction(Direction::Recv)\n            .msg_type(MessageType::MsgAppend),\n    ));\n\n    let mut region = cluster.get_region(b\"k1\");\n    let region_id = region.get_id();\n    let mut req = new_request(\n        region_id,\n        region.take_region_epoch(),\n        vec![new_get_cmd(b\"k2\")],\n        true,\n    );\n    req.mut_header().set_peer(new_peer(1, 1));\n    let (cb, mut rx) = make_cb(&req);\n    cluster.sim.rl().async_command_on_node(1, req, cb).unwrap();\n\n    cluster.must_transfer_leader(region_id, new_peer(3, 3));\n    // Even the leader steps down, it should respond to read index in time.\n    rx.recv_timeout(heartbeat_interval).unwrap();\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_hibernate.rs::test_leader_demoted_when_hibernated", "code": "pub fn must_put(&mut self, key: &[u8], value: &[u8]) {\n        self.must_put_cf(CF_DEFAULT, key, value);\n    }", "test": "fn test_leader_demoted_when_hibernated() {\n    let mut cluster = new_node_cluster(0, 4);\n    configure_for_hibernate(&mut cluster.cfg);\n    cluster.pd_client.disable_default_operator();\n    let r = cluster.run_conf_change();\n    cluster.pd_client.must_add_peer(r, new_peer(2, 2));\n    cluster.pd_client.must_add_peer(r, new_peer(3, 3));\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n\n    cluster.must_transfer_leader(r, new_peer(1, 1));\n    // Demote a follower to learner.\n    cluster.pd_client.must_joint_confchange(\n        r,\n        vec![\n            (ConfChangeType::AddLearnerNode, new_learner_peer(3, 3)),\n            (ConfChangeType::AddLearnerNode, new_learner_peer(4, 4)),\n        ],\n    );\n    // So old leader will not commit the demote request.\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(r, 1)\n            .msg_type(MessageType::MsgAppendResponse)\n            .direction(Direction::Recv),\n    ));\n    // So new leader will not commit the demote request.\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(r, 3)\n            .msg_type(MessageType::MsgAppendResponse)\n            .direction(Direction::Recv),\n    ));\n\n    // So only peer 3 can become leader.\n    for id in 1..=2 {\n        cluster.add_send_filter(CloneFilterFactory(\n            RegionPacketFilter::new(r, id)\n                .msg_type(MessageType::MsgRequestPreVote)\n                .direction(Direction::Send),\n        ));\n    }\n    // Leave joint.\n    cluster.async_exit_joint(r).unwrap();\n    // Ensure peer 3 can campaign.\n    cluster.wait_last_index(r, 3, 11, Duration::from_secs(5));\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(r, 1)\n            .msg_type(MessageType::MsgHeartbeat)\n            .direction(Direction::Send),\n    ));\n    // Wait some time to ensure the request has been delivered.\n    thread::sleep(Duration::from_millis(100));\n    // Peer 3 should start campaign.\n    let timer = Instant::now();\n    loop {\n        cluster.reset_leader_of_region(r);\n        let cur_leader = cluster.leader_of_region(r);\n        if let Some(ref cur_leader) = cur_leader {\n            if cur_leader.get_id() == 3 && cur_leader.get_store_id() == 3 {\n                break;\n            }\n        }\n        if timer.saturating_elapsed() > Duration::from_secs(5) {\n            panic!(\"peer 3 is still not leader after 5 seconds.\");\n        }\n        let region = cluster.get_region(b\"k1\");\n        let mut request = new_request(\n            region.get_id(),\n            region.get_region_epoch().clone(),\n            vec![new_put_cf_cmd(\"default\", b\"k1\", b\"v1\")],\n            false,\n        );\n        request.mut_header().set_peer(new_peer(3, 3));\n        // In case peer 3 is hibernated.\n        let (cb, _rx) = make_cb(&request);\n        cluster\n            .sim\n            .rl()\n            .async_command_on_node(3, request, cb)\n            .unwrap();\n    }\n\n    cluster.clear_send_filters();\n    // If there is no leader in the region, the cluster can't write two kvs\n    // successfully. The first one is possible to succeed if it's committed with\n    // the conf change at the same time, but the second one can't be committed\n    // or accepted because conf change should be applied and the leader should\n    // be demoted as learner.\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k2\", b\"v2\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_chroot.rs::test_chroot_skip_chdir", "code": "pub fn stdout_str(&self) -> &str {\n        std::str::from_utf8(&self.stdout).unwrap()\n    }", "test": "fn test_chroot_skip_chdir() {\n    let ts = TestScenario::new(util_name!());\n    let at = ts.fixtures.clone();\n    let dirs = [\"/\", \"/.\", \"/..\", \"isroot\"];\n    at.symlink_file(\"/\", \"isroot\");\n    for dir in dirs {\n        let env_cd = std::env::current_dir().unwrap();\n        if let Ok(result) = run_ucmd_as_root(&ts, &[dir, \"--skip-chdir\"]) {\n            // Should return the same path\n            assert_eq!(\n                result.success().no_stderr().stdout_str(),\n                env_cd.to_str().unwrap()\n            );\n        } else {\n            print!(\"Test skipped; requires root user\");\n        }\n    }\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_replication_mode.rs::test_update_group_id", "code": "pub fn must_put(&mut self, key: &[u8], value: &[u8]) {\n        self.must_put_cf(CF_DEFAULT, key, value);\n    }", "test": "fn test_update_group_id() {\n    let mut cluster = new_server_cluster(0, 2);\n    let pd_client = cluster.pd_client.clone();\n    cluster.add_label(1, \"zone\", \"ES\");\n    cluster.add_label(2, \"zone\", \"WS\");\n    pd_client.disable_default_operator();\n    pd_client.configure_dr_auto_sync(\"zone\");\n    cluster.cfg.raft_store.pd_store_heartbeat_tick_interval = ReadableDuration::millis(50);\n    cluster.cfg.raft_store.raft_log_gc_threshold = 10;\n    cluster.run_conf_change();\n    cluster.must_put(b\"k1\", b\"v0\");\n    let region = pd_client.get_region(b\"k1\").unwrap();\n    cluster.must_split(&region, b\"k2\");\n    let left = pd_client.get_region(b\"k0\").unwrap();\n    let right = pd_client.get_region(b\"k2\").unwrap();\n    // When a node is started, all store information are loaded at once, so we need\n    // an extra node to verify resolve will assign group id.\n    cluster.add_label(3, \"zone\", \"WS\");\n    cluster.add_new_engine();\n    pd_client.must_add_peer(left.id, new_peer(2, 2));\n    pd_client.must_add_peer(left.id, new_learner_peer(3, 3));\n    pd_client.must_add_peer(left.id, new_peer(3, 3));\n    // If node 3's group id is not assigned, leader will make commit index as the\n    // smallest last index of all followers.\n    cluster.add_send_filter(IsolationFilterFactory::new(2));\n    cluster.must_put(b\"k11\", b\"v11\");\n    must_get_equal(&cluster.get_engine(3), b\"k11\", b\"v11\");\n    must_get_equal(&cluster.get_engine(1), b\"k11\", b\"v11\");\n\n    // So both node 1 and node 3 have fully resolved all stores. Further updates to\n    // group ID have to be done when applying conf change and snapshot.\n    cluster.clear_send_filters();\n    pd_client.must_add_peer(right.id, new_peer(2, 4));\n    pd_client.must_add_peer(right.id, new_learner_peer(3, 5));\n    pd_client.must_add_peer(right.id, new_peer(3, 5));\n    cluster.add_send_filter(IsolationFilterFactory::new(2));\n    cluster.must_put(b\"k3\", b\"v3\");\n    cluster.must_transfer_leader(right.id, new_peer(3, 5));\n    cluster.must_put(b\"k4\", b\"v4\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_expand.rs::test_with_trailing_tab", "code": "pub fn stdout_does_not_contain<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            !self.stdout_str().contains(cmp.as_ref()),\n            \"'{}' contains '{}' but should not\",\n            self.stdout_str(),\n            cmp.as_ref(),\n        );\n        self\n    }", "test": "fn test_with_trailing_tab() {\n    new_ucmd!()\n        .arg(\"with-trailing-tab.txt\")\n        .succeeds()\n        .stdout_contains(\"with tabs=>  \")\n        .stdout_does_not_contain(\"\\t\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/server/lock_manager.rs::test_detect_deadlock_when_transfer_leader", "code": "fn must_detect_deadlock(cluster: &mut Cluster<ServerCluster>, key: &[u8], ts: u64) {\n    // Sometimes, deadlocks can't be detected at once due to leader change, but it\n    // will be detected.\n    for _ in 0..5 {\n        let (client, ctx) = build_leader_client(cluster, key);\n        if deadlock(&client, ctx, key, ts) {\n            return;\n        }\n    }\n    panic!(\"failed to detect deadlock\");\n}", "test": "fn test_detect_deadlock_when_transfer_leader() {\n    let mut cluster = new_cluster_for_deadlock_test(3);\n    // Transfer the leader of region 1 to store(2).\n    // The leader of deadlock detector should also be transfered to store(2).\n    must_transfer_leader(&mut cluster, b\"\", 2);\n    deadlock_detector_leader_must_be(&mut cluster, 2);\n    must_detect_deadlock(&mut cluster, b\"k\", 10);\n}"}
{"test_id": "mitsuhiko-minijinja/mitsuhiko-minijinja-5f2c1e8/minijinja/tests/test_tests.rs::test_basics", "code": "pub fn empty_state(&self) -> State<'_, '_> {\n        State::new_for_env(self)\n    }", "test": "fn test_basics() {\n    fn test(_: &State, a: u32, b: u32) -> bool {\n        assert_eq!(a, 23);\n        a == b\n    }\n\n    let mut env = Environment::new();\n    env.add_test(\"test\", test);\n    let state = env.empty_state();\n    assert!(state.perform_test(\"test\", args!(23, 23)).unwrap());\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/edit.rs::editor_working_directory", "code": "pub(crate) fn assert_stdout(output: &std::process::Output, stdout: &str) {\n  assert_success(output);\n  assert_eq!(String::from_utf8_lossy(&output.stdout), stdout);\n}", "test": "fn editor_working_directory() {\n  let tmp = temptree! {\n    justfile: JUSTFILE,\n    child: {},\n    editor: \"#!/usr/bin/env sh\\ncat $1\\npwd\",\n  };\n\n  let editor = tmp.path().join(\"editor\");\n\n  let permissions = std::os::unix::fs::PermissionsExt::from_mode(0o700);\n  fs::set_permissions(&editor, permissions).unwrap();\n\n  let output = Command::new(executable_path(\"just\"))\n    .current_dir(tmp.path().join(\"child\"))\n    .arg(\"--edit\")\n    .env(\"VISUAL\", &editor)\n    .output()\n    .unwrap();\n\n  let want = format!(\n    \"{JUSTFILE}{}\\n\",\n    tmp.path().canonicalize().unwrap().display()\n  );\n\n  assert_stdout(&output, &want);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_csplit.rs::test_skip_to_match_repeat_always", "code": "pub fn plus_as_string<P: AsRef<Path>>(&self, name: P) -> String {\n        self.plus(name).display().to_string()\n    }", "test": "fn test_skip_to_match_repeat_always() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"%0$%\", \"{*}\"])\n        .succeeds()\n        .no_stdout();\n\n    let count = glob(&at.plus_as_string(\"xx*\")).unwrap().count();\n    assert_eq!(count, 0);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_basename.rs::test_zero_param", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_zero_param() {\n    for zero_param in [\"-z\", \"--zero\", \"--ze\"] {\n        let path = \"/foo/bar/baz\";\n        new_ucmd!()\n            .args(&[zero_param, \"-a\", path, path])\n            .succeeds()\n            .stdout_only(\"baz\\0baz\\0\");\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_dd.rs::s_iseek_bytes_iflag() {\n    ", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "ytes_iseek_bytes_iflag() {\n    new_ucmd!()\n        .args(&[\"iseek=10\", \"iflag=skip_bytes\", \"bs=2\"])\n        .pipe_in(\"0123456789abcdefghijklm\")\n        .succeeds()\n        .stdout_is(\"abcdefghijklm\");\n}\n\n#[test]"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/name_server_pool_tests.rs::test_concurrent_requests_2_conns", "code": "pub fn answers(answers: LookupRecords, additionals: Option<LookupRecords>) -> Self {\n        Self::Records {\n            answers,\n            additionals,\n        }\n    }", "test": "fn test_concurrent_requests_2_conns() {\n    let mut options = ResolverOpts::default();\n\n    // there are only 2 conns, so this matches that count\n    options.num_concurrent_reqs = 2;\n\n    // we want to make sure that both udp connections are called\n    //   this will count down to 0 only if both are called.\n    let on_send = OnSendBarrier::new(2);\n\n    let query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n\n    let udp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 1));\n\n    let udp_message = message(query.clone(), vec![udp_record.clone()], vec![], vec![]);\n\n    let udp1_nameserver = mock_nameserver_on_send(\n        vec![Ok(DnsResponse::from_message(udp_message).unwrap())],\n        options.clone(),\n        on_send.clone(),\n    );\n    let udp2_nameserver = mock_nameserver_on_send(vec![], options.clone(), on_send);\n\n    let pool = mock_nameserver_pool_on_send(\n        vec![udp2_nameserver, udp1_nameserver],\n        vec![],\n        None,\n        options,\n    );\n\n    // lookup on UDP succeeds, any other would fail\n    let request = message(query, vec![], vec![], vec![]);\n    let future = pool.send(request).first_answer();\n\n    // there's no actual network traffic happening, 1 sec should be plenty\n    //   TODO: for some reason this timeout doesn't work, not clear why...\n    // let future = Timeout::new(future, Duration::from_secs(1));\n\n    let response = block_on(future).unwrap();\n    assert_eq!(response.answers()[0], udp_record);\n}"}
{"test_id": "cberner-redb/cberner-redb-267b473/tests/basic_tests.rs::drain_filter_lifetime", "code": "fn next(\n        self,\n        reverse: bool,\n        manager: &'a TransactionalMemory,\n    ) -> Result<Option<RangeIterState>> {\n        match self {\n            Leaf {\n                page,\n                fixed_key_size,\n                fixed_value_size,\n                entry,\n                parent,\n            } => {\n                let accessor = LeafAccessor::new(page.memory(), fixed_key_size, fixed_value_size);\n                let direction = if reverse { -1 } else { 1 };\n                let next_entry = isize::try_from(entry).unwrap() + direction;\n                if 0 <= next_entry && next_entry < accessor.num_pairs().try_into().unwrap() {\n                    Ok(Some(Leaf {\n                        page,\n                        fixed_key_size,\n                        fixed_value_size,\n                        entry: next_entry.try_into().unwrap(),\n                        parent,\n                    }))\n                } else {\n                    Ok(parent.map(|x| *x))\n                }\n            }\n            Internal {\n                page,\n                fixed_key_size,\n                fixed_value_size,\n                child,\n                mut parent,\n            } => {\n                let accessor = BranchAccessor::new(&page, fixed_key_size);\n                let child_page = accessor.child_page(child).unwrap();\n                let child_page = manager.get_page(child_page)?;\n                let direction = if reverse { -1 } else { 1 };\n                let next_child = isize::try_from(child).unwrap() + direction;\n                if 0 <= next_child && next_child < accessor.count_children().try_into().unwrap() {\n                    parent = Some(Box::new(Internal {\n                        page,\n                        fixed_key_size,\n                        fixed_value_size,\n                        child: next_child.try_into().unwrap(),\n                        parent,\n                    }));\n                }\n                match child_page.memory()[0] {\n                    LEAF => {\n                        let child_accessor = LeafAccessor::new(\n                            child_page.memory(),\n                            fixed_key_size,\n                            fixed_value_size,\n                        );\n                        let entry = if reverse {\n                            child_accessor.num_pairs() - 1\n                        } else {\n                            0\n                        };\n                        Ok(Some(Leaf {\n                            page: child_page,\n                            fixed_key_size,\n                            fixed_value_size,\n                            entry,\n                            parent,\n                        }))\n                    }\n                    BRANCH => {\n                        let child_accessor = BranchAccessor::new(&child_page, fixed_key_size);\n                        let child = if reverse {\n                            child_accessor.count_children() - 1\n                        } else {\n                            0\n                        };\n                        Ok(Some(Internal {\n                            page: child_page,\n                            fixed_key_size,\n                            fixed_value_size,\n                            child,\n                            parent,\n                        }))\n                    }\n                    _ => unreachable!(),\n                }\n            }\n        }\n    }", "test": "fn drain_filter_lifetime() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let definition: TableDefinition<&str, &str> = TableDefinition::new(\"x\");\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(definition).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let txn = db.begin_write().unwrap();\n    let mut table = txn.open_table(definition).unwrap();\n\n    let mut iter = {\n        let start = \"hello\".to_string();\n        table.drain_filter(start.as_str().., |_, _| true).unwrap()\n    };\n    assert_eq!(iter.next().unwrap().unwrap().1.value(), \"world\");\n    assert!(iter.next().is_none());\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/coprocessor/test_select.rs::test_handle_truncate", "code": "pub fn has_error(&self) -> bool {\n        self.error.is_some()\n    }", "test": "fn test_handle_truncate() {\n    use tidb_query_datatype::{FieldTypeAccessor, FieldTypeTp};\n    let data = vec![\n        (1, Some(\"name:0\"), 2),\n        (2, Some(\"name:4\"), 3),\n        (4, Some(\"name:3\"), 1),\n        (5, Some(\"name:1\"), 4),\n    ];\n\n    let product = ProductTable::new();\n    let (_, endpoint) = init_with_data(&product, &data);\n    let cols = product.columns_info();\n    let cases = vec![\n        {\n            // count > \"2x\"\n            let mut col = Expr::default();\n            col.set_tp(ExprType::ColumnRef);\n            col.mut_field_type()\n                .as_mut_accessor()\n                .set_tp(FieldTypeTp::LongLong);\n            let count_offset = offset_for_column(&cols, product[\"count\"].id);\n            col.mut_val().encode_i64(count_offset).unwrap();\n\n            // \"2x\" will be truncated.\n            let mut value = Expr::default();\n            value\n                .mut_field_type()\n                .as_mut_accessor()\n                .set_tp(FieldTypeTp::String);\n            value.set_tp(ExprType::String);\n            value.set_val(String::from(\"2x\").into_bytes());\n\n            let mut right = Expr::default();\n            right\n                .mut_field_type()\n                .as_mut_accessor()\n                .set_tp(FieldTypeTp::LongLong);\n            right.set_tp(ExprType::ScalarFunc);\n            right.set_sig(ScalarFuncSig::CastStringAsInt);\n            right.mut_children().push(value);\n\n            let mut cond = Expr::default();\n            cond.mut_field_type()\n                .as_mut_accessor()\n                .set_tp(FieldTypeTp::LongLong);\n            cond.set_tp(ExprType::ScalarFunc);\n            cond.set_sig(ScalarFuncSig::LtInt);\n            cond.mut_children().push(col);\n            cond.mut_children().push(right);\n            cond\n        },\n        {\n            // id\n            let mut col_id = Expr::default();\n            col_id\n                .mut_field_type()\n                .as_mut_accessor()\n                .set_tp(FieldTypeTp::LongLong);\n            col_id.set_tp(ExprType::ColumnRef);\n            let id_offset = offset_for_column(&cols, product[\"id\"].id);\n            col_id.mut_val().encode_i64(id_offset).unwrap();\n\n            // \"3x\" will be truncated.\n            let mut value = Expr::default();\n            value\n                .mut_field_type()\n                .as_mut_accessor()\n                .set_tp(FieldTypeTp::String);\n            value.set_tp(ExprType::String);\n            value.set_val(String::from(\"3x\").into_bytes());\n\n            let mut int_3 = Expr::default();\n            int_3\n                .mut_field_type()\n                .as_mut_accessor()\n                .set_tp(FieldTypeTp::LongLong);\n            int_3.set_tp(ExprType::ScalarFunc);\n            int_3.set_sig(ScalarFuncSig::CastStringAsInt);\n            int_3.mut_children().push(value);\n\n            // count\n            let mut col_count = Expr::default();\n            col_count\n                .mut_field_type()\n                .as_mut_accessor()\n                .set_tp(FieldTypeTp::LongLong);\n            col_count.set_tp(ExprType::ColumnRef);\n            let count_offset = offset_for_column(&cols, product[\"count\"].id);\n            col_count.mut_val().encode_i64(count_offset).unwrap();\n\n            // \"3x\" + count\n            let mut plus = Expr::default();\n            plus.mut_field_type()\n                .as_mut_accessor()\n                .set_tp(FieldTypeTp::LongLong);\n            plus.set_tp(ExprType::ScalarFunc);\n            plus.set_sig(ScalarFuncSig::PlusInt);\n            plus.mut_children().push(int_3);\n            plus.mut_children().push(col_count);\n\n            // id = \"3x\" + count\n            let mut cond = Expr::default();\n            cond.mut_field_type()\n                .as_mut_accessor()\n                .set_tp(FieldTypeTp::LongLong);\n            cond.set_tp(ExprType::ScalarFunc);\n            cond.set_sig(ScalarFuncSig::EqInt);\n            cond.mut_children().push(col_id);\n            cond.mut_children().push(plus);\n            cond\n        },\n    ];\n\n    for cond in cases {\n        // Ignore truncate error.\n        let req = DagSelect::from(&product)\n            .where_expr(cond.clone())\n            .build_with(Context::default(), &[FLAG_IGNORE_TRUNCATE]);\n        let resp = handle_select(&endpoint, req);\n        assert!(!resp.has_error());\n        assert!(resp.get_warnings().is_empty());\n\n        // truncate as warning\n        let req = DagSelect::from(&product)\n            .where_expr(cond.clone())\n            .build_with(Context::default(), &[FLAG_TRUNCATE_AS_WARNING]);\n        let mut resp = handle_select(&endpoint, req);\n        assert!(!resp.has_error());\n        assert!(!resp.get_warnings().is_empty());\n        // check data\n        let mut spliter = DagChunkSpliter::new(resp.take_chunks().into(), 3);\n        let row = spliter.next().unwrap();\n        let (id, name, cnt) = data[2];\n        let name_datum = name.map(|s| s.as_bytes()).into();\n        let expected_encoded = datum::encode_value(\n            &mut EvalContext::default(),\n            &[Datum::I64(id), name_datum, cnt.into()],\n        )\n        .unwrap();\n        let result_encoded = datum::encode_value(&mut EvalContext::default(), &row).unwrap();\n        assert_eq!(&*result_encoded, &*expected_encoded);\n        assert_eq!(spliter.next().is_none(), true);\n\n        // Do NOT ignore truncate error.\n        let req = DagSelect::from(&product).where_expr(cond.clone()).build();\n        let resp = handle_select(&endpoint, req);\n        assert!(resp.has_error());\n        assert!(resp.get_warnings().is_empty());\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_printf.rs::escaped_tab", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn escaped_tab() {\n    new_ucmd!()\n        .args(&[\"hello\\\\t world\"])\n        .succeeds()\n        .stdout_only(\"hello\\t world\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_chroot.rs::test_chroot_skip_chdir_not_root", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_chroot_skip_chdir_not_root() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let dir = \"foobar\";\n    at.mkdir(dir);\n\n    ucmd.arg(\"--skip-chdir\")\n        .arg(dir)\n        .fails()\n        .stderr_contains(\"chroot: option --skip-chdir only permitted if NEWROOT is old '/'\")\n        .code_is(125);\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_common.rs::parse_alter_table_add_column_if_not_exists", "code": "pub fn verified_stmt(&self, sql: &str) -> Statement {\n        self.one_statement_parses_to(sql, sql)\n    }", "test": "fn parse_alter_table_add_column_if_not_exists() {\n    let dialects = TestedDialects {\n        dialects: vec![\n            Box::new(PostgreSqlDialect {}),\n            Box::new(BigQueryDialect {}),\n            Box::new(GenericDialect {}),\n            Box::new(DuckDbDialect {}),\n        ],\n        options: None,\n    };\n\n    match alter_table_op(dialects.verified_stmt(\"ALTER TABLE tab ADD IF NOT EXISTS foo TEXT\")) {\n        AlterTableOperation::AddColumn { if_not_exists, .. } => {\n            assert!(if_not_exists);\n        }\n        _ => unreachable!(),\n    };\n\n    match alter_table_op(\n        dialects.verified_stmt(\"ALTER TABLE tab ADD COLUMN IF NOT EXISTS foo TEXT\"),\n    ) {\n        AlterTableOperation::AddColumn {\n            column_keyword,\n            if_not_exists,\n            ..\n        } => {\n            assert!(column_keyword);\n            assert!(if_not_exists);\n        }\n        _ => unreachable!(),\n    };\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/component_model/func.rs::bools", "code": "pub fn call(&self, arguments: &[DataValue]) -> Vec<DataValue> {\n        let mut values = UnboxedValues::make_arguments(arguments, &self.func_signature);\n        let arguments_address = values.as_mut_ptr();\n\n        let function_ptr = self.module.get_finalized_function(self.func_id);\n        let trampoline_ptr = self.module.get_finalized_function(self.trampoline_id);\n\n        let callable_trampoline: fn(*const u8, *mut u128) -> () =\n            unsafe { mem::transmute(trampoline_ptr) };\n        callable_trampoline(function_ptr, arguments_address);\n\n        values.collect_returns(&self.func_signature)\n    }", "test": "fn bools() -> Result<()> {\n    let component = r#\"\n        (component\n            (core module $m\n                (func (export \"pass\") (param i32) (result i32) local.get 0)\n            )\n            (core instance $i (instantiate $m))\n\n            (func (export \"u32-to-bool\") (param \"a\" u32) (result bool)\n                (canon lift (core func $i \"pass\"))\n            )\n            (func (export \"bool-to-u32\") (param \"a\" bool) (result u32)\n                (canon lift (core func $i \"pass\"))\n            )\n        )\n    \"#;\n\n    let engine = super::engine();\n    let component = Component::new(&engine, component)?;\n    let mut store = Store::new(&engine, ());\n    let instance = Linker::new(&engine).instantiate(&mut store, &component)?;\n    let u32_to_bool = instance.get_typed_func::<(u32,), (bool,)>(&mut store, \"u32-to-bool\")?;\n    let bool_to_u32 = instance.get_typed_func::<(bool,), (u32,)>(&mut store, \"bool-to-u32\")?;\n\n    assert_eq!(bool_to_u32.call(&mut store, (false,))?, (0,));\n    bool_to_u32.post_return(&mut store)?;\n    assert_eq!(bool_to_u32.call(&mut store, (true,))?, (1,));\n    bool_to_u32.post_return(&mut store)?;\n    assert_eq!(u32_to_bool.call(&mut store, (0,))?, (false,));\n    u32_to_bool.post_return(&mut store)?;\n    assert_eq!(u32_to_bool.call(&mut store, (1,))?, (true,));\n    u32_to_bool.post_return(&mut store)?;\n    assert_eq!(u32_to_bool.call(&mut store, (2,))?, (true,));\n    u32_to_bool.post_return(&mut store)?;\n\n    Ok(())\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_unlink.rs::test_unlink_directory", "code": "pub fn stderr_str(&self) -> &str {\n        std::str::from_utf8(&self.stderr).unwrap()\n    }", "test": "fn test_unlink_directory() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"dir\";\n\n    at.mkdir(dir);\n\n    let res = ucmd.arg(dir).fails();\n    let stderr = res.stderr_str();\n    assert!(\n        stderr == \"unlink: cannot unlink 'dir': Is a directory\\n\"\n            || stderr == \"unlink: cannot unlink 'dir': Permission denied\\n\"\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_fmt.rs::test_fmt_invalid_width", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_fmt_invalid_width() {\n    for param in [\"-w\", \"--width\"] {\n        new_ucmd!()\n            .args(&[\"one-word-per-line.txt\", param, \"invalid\"])\n            .fails()\n            .code_is(1)\n            .stderr_contains(\"invalid value 'invalid'\");\n    }\n}"}
{"test_id": "dtolnay-syn/dtolnay-syn-b1a038c/tests/test_pat.rs::test_group", "code": "fn parse2(self, tokens: TokenStream) -> Result<T> {\n        let buf = TokenBuffer::new2(tokens);\n        let state = tokens_to_parse_buffer(&buf);\n        let node = self(&state)?;\n        state.check_unexpected()?;\n        if let Some(unexpected_span) = span_of_unexpected_ignoring_nones(state.cursor()) {\n            Err(Error::new(unexpected_span, \"unexpected token\"))\n        } else {\n            Ok(node)\n        }\n    }", "test": "fn test_group() {\n    let group = Group::new(Delimiter::None, quote!(Some(_)));\n    let tokens = TokenStream::from_iter(vec![TokenTree::Group(group)]);\n    let pat = Pat::parse_single.parse2(tokens).unwrap();\n\n    snapshot!(pat, @r###\"\n    Pat::TupleStruct {\n        path: Path {\n            segments: [\n                PathSegment {\n                    ident: \"Some\",\n                },\n            ],\n        },\n        elems: [\n            Pat::Wild,\n        ],\n    }\n    \"###);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_split.rs::test_number_n", "code": "fn file_read(at: &AtPath, filename: &str) -> String {\n    let mut s = String::new();\n    at.open(filename).read_to_string(&mut s).unwrap();\n    s\n}", "test": "fn test_number_n() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_read = |f| {\n        let mut s = String::new();\n        at.open(f).read_to_string(&mut s).unwrap();\n        s\n    };\n    ucmd.args(&[\"-n\", \"5\", \"asciilowercase.txt\"]).succeeds();\n    assert_eq!(file_read(\"xaa\"), \"abcde\");\n    assert_eq!(file_read(\"xab\"), \"fghij\");\n    assert_eq!(file_read(\"xac\"), \"klmno\");\n    assert_eq!(file_read(\"xad\"), \"pqrst\");\n    assert_eq!(file_read(\"xae\"), \"uvwxyz\\n\");\n    #[cfg(unix)]\n    new_ucmd!()\n        .args(&[\"--number=100\", \"/dev/null\"])\n        .succeeds()\n        .stdout_only(\"\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_touch.rs::test_touch_set_date2", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_date2() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_date\";\n\n    ucmd.args(&[\"-d\", \"2000-01-23\", file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n\n    let start_of_year = str_to_filetime(\"%Y%m%d%H%M\", \"200001230000\");\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, mtime);\n    assert_eq!(atime, start_of_year);\n    assert_eq!(mtime, start_of_year);\n}"}
{"test_id": "raphlinus-pulldown-cmark/raphlinus-pulldown-cmark-3da63d5/tests/suite/heading_attrs.rs::heading_attrs_test_35", "code": "pub fn test_markdown_html(input: &str, output: &str, smart_punct: bool) {\n    let mut s = String::new();\n\n    let mut opts = Options::empty();\n    opts.insert(Options::ENABLE_TABLES);\n    opts.insert(Options::ENABLE_FOOTNOTES);\n    opts.insert(Options::ENABLE_STRIKETHROUGH);\n    opts.insert(Options::ENABLE_TASKLISTS);\n    if smart_punct {\n        opts.insert(Options::ENABLE_SMART_PUNCTUATION);\n    }\n    opts.insert(Options::ENABLE_HEADING_ATTRIBUTES);\n\n    let p = Parser::new_ext(input, opts);\n    pulldown_cmark::html::push_html(&mut s, p);\n\n    assert_eq!(normalize_html(output), normalize_html(&s));\n}", "test": "fn heading_attrs_test_35() {\n    let original = r##\"# H1 {#foo #}\n# H1 {.foo . . .bar}\n\"##;\n    let expected = r##\"<h1 id=\"foo\">H1</h1>\n<h1 class=\"foo bar\">H1</h1>\n\"##;\n\n    test_markdown_html(original, expected, false);\n}"}
{"test_id": "weggli-rs-weggli/weggli-rs-weggli-ad8d424/tests/query.rs::test_display", "code": "fn parse_and_match(needle: &str, source: &str) -> usize {\n    parse_and_match_helper(needle, source, false).len()\n}", "test": "fn test_display() {\n    let needle = r#\"do {\n        $buf[_+_]=_;\n      } while(_);\"#;\n\n    let source = r#\"\n    void loop (char *b){\n        int i = 0;\n        do {\n            b[i+i] = 0;\n            i += 1;\n        } while (i < 10);\n    }\n    \"#;\n\n    let matches = parse_and_match(needle, source);\n    assert_eq!(matches, 1);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_expand.rs::test_tabs_comma_separated_no_numbers", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_tabs_comma_separated_no_numbers() {\n    new_ucmd!()\n        .arg(\"--tabs=+,/,+,/\")\n        .pipe_in(\"\\ta\\tb\\tc\")\n        .succeeds()\n        .stdout_is(\"        a       b       c\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_backup.rs::backup_blocked_by_memory_lock", "code": "pub fn has_locked(&self) -> bool {\n        self.locked.is_some()\n    }", "test": "fn backup_blocked_by_memory_lock() {\n    let suite = TestSuite::new(1, 144 * 1024 * 1024, ApiVersion::V1);\n\n    fail::cfg(\"raftkv_async_write_finish\", \"pause\").unwrap();\n    let tikv_cli = suite.tikv_cli.clone();\n    let (k, v) = (b\"my_key\", b\"my_value\");\n    let mut mutation = Mutation::default();\n    mutation.set_op(Op::Put);\n    mutation.key = k.to_vec();\n    mutation.value = v.to_vec();\n    let mut prewrite_req = PrewriteRequest::default();\n    prewrite_req.set_context(suite.context.clone());\n    prewrite_req.mut_mutations().push(mutation);\n    prewrite_req.set_primary_lock(k.to_vec());\n    prewrite_req.set_start_version(20);\n    prewrite_req.set_lock_ttl(2000);\n    prewrite_req.set_use_async_commit(true);\n    let th = thread::spawn(move || tikv_cli.kv_prewrite(&prewrite_req).unwrap());\n\n    thread::sleep(Duration::from_millis(200));\n\n    // Trigger backup request.\n    let tmp = Builder::new().tempdir().unwrap();\n    let backup_ts = TimeStamp::from(21);\n    let storage_path = make_unique_dir(tmp.path());\n    let rx = suite.backup(\n        b\"a\".to_vec(), // start\n        b\"z\".to_vec(), // end\n        0.into(),      // begin_ts\n        backup_ts,\n        &storage_path,\n    );\n    let resp = block_on(rx.collect::<Vec<_>>());\n    match &resp[0].get_error().detail {\n        Some(Error_oneof_detail::KvError(key_error)) => {\n            assert!(key_error.has_locked());\n        }\n        _ => panic!(\"unexpected response\"),\n    }\n\n    fail::remove(\"raftkv_async_write_finish\");\n    th.join().unwrap();\n\n    suite.stop();\n}"}
{"test_id": "weggli-rs-weggli/weggli-rs-weggli-ad8d424/tests/query.rs::identifier_complex", "code": "fn parse_and_match(needle: &str, source: &str) -> usize {\n    parse_and_match_helper(needle, source, false).len()\n}", "test": "fn identifier_complex() {\n    let source = r#\"\n        void foo() {\n            abc = 1;\n            def = 1;\n\n            if (def > 1) {\n                def = 10;\n            }\n            \n        }\"#;\n\n    let needle = \"{$x = 1; if ($x >1) {def = 10;}}\";\n    let matches = parse_and_match(needle, source);\n\n    assert_eq!(matches, 1);\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/cli_tests.rs::exit2_wasi_snapshot1", "code": "fn code(&self, pc: usize) -> Option<(&LoadedCode, usize)> {\n        let (end, (start, code)) = self.loaded_code.range(pc..).next()?;\n        if pc < *start || *end < pc {\n            return None;\n        }\n        Some((code, pc - *start))\n    }", "test": "fn exit2_wasi_snapshot1() -> Result<()> {\n    let wasm = build_wasm(\"tests/all/cli_tests/exit2_wasi_snapshot1.wat\")?;\n    let output = run_wasmtime_for_output(&[\"-Ccache=n\", wasm.path().to_str().unwrap()], None)?;\n    assert_eq!(output.status.code().unwrap(), 2);\n    Ok(())\n}"}
{"test_id": "tafia-quick-xml/tafia-quick-xml-120e074/tests/unit_tests.rs::test_closing_bracket_in_double_quote_mixed", "code": "fn next(&mut self) -> Option<Self::Item> {\n        match self.state.next(self.bytes) {\n            None => None,\n            Some(Ok(a)) => Some(Ok(a.map(|range| &self.bytes[range]).into())),\n            Some(Err(e)) => Some(Err(e)),\n        }\n    }", "test": "fn test_closing_bracket_in_double_quote_mixed() {\n    let mut r = Reader::from_str(r#\"<a attr=\"'>'\" check=\"'2'\"></a>\"#);\n    r.trim_text(true);\n    match r.read_event() {\n        Ok(Start(e)) => {\n            let mut attrs = e.attributes();\n            assert_eq!(\n                attrs.next(),\n                Some(Ok(Attribute {\n                    key: QName(b\"attr\"),\n                    value: Cow::Borrowed(b\"'>'\"),\n                }))\n            );\n            assert_eq!(\n                attrs.next(),\n                Some(Ok(Attribute {\n                    key: QName(b\"check\"),\n                    value: Cow::Borrowed(b\"'2'\"),\n                }))\n            );\n            assert_eq!(attrs.next(), None);\n        }\n        x => panic!(\"expected <a attr='>'>, got {:?}\", x),\n    }\n    next_eq!(r, End, b\"a\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_uname.rs::test_uname_hardware_platform", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_uname_hardware_platform() {\n    new_ucmd!()\n        .arg(\"-i\")\n        .succeeds()\n        .stdout_str_apply(str::trim_end)\n        .stdout_only(\"unknown\");\n}"}
{"test_id": "rust-bitcoin-rust-bitcoin/rust-bitcoin-rust-bitcoin-5ee33ea/bitcoin/tests/serde.rs::serde_regression_address", "code": "pub fn serialize(&self) -> Vec<u8> {\n        let mut buf: Vec<u8> = Vec::new();\n\n        //  <magic>\n        buf.extend_from_slice(b\"psbt\");\n\n        buf.push(0xff_u8);\n\n        buf.extend(self.serialize_map());\n\n        for i in &self.inputs {\n            buf.extend(i.serialize_map());\n        }\n\n        for i in &self.outputs {\n            buf.extend(i.serialize_map());\n        }\n\n        buf\n    }", "test": "fn serde_regression_address() {\n    let s = include_str!(\"data/serde/public_key_hex\");\n    let pk = PublicKey::from_str(s.trim()).unwrap();\n    let addr = Address::p2pkh(&pk, Network::Bitcoin);\n\n    let got = serialize(&addr).unwrap();\n    let want = include_bytes!(\"data/serde/address_bincode\") as &[_];\n    assert_eq!(got, want)\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/format.rs::fs_error_read_only", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn fs_error_read_only() {\n    let mut fs = MemoryFileSystem::new_read_only();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"test.js\");\n    fs.insert(file_path.into(), *b\"content\");\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"format\"),\n                (\"--write\"),\n                file_path.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    // Do not store the content of the file in the snapshot\n    fs.remove(file_path);\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"fs_error_read_only\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_prevote.rs::test_server_isolated_follower_leader_does_not_change", "code": "fn test_isolated_follower_leader_does_not_change<T: Simulator>(cluster: &mut Cluster<T>) {\n    cluster.run();\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    cluster.must_put(b\"k1\", b\"v1\");\n    let region_status = new_status_request(1, new_peer(1, 1), new_region_leader_cmd());\n    let resp = cluster\n        .call_command(region_status.clone(), Duration::from_secs(5))\n        .unwrap();\n    let term = resp.get_header().get_current_term();\n    // Isolate peer5.\n    cluster.partition(vec![1, 2, 3, 4], vec![5]);\n    let election_timeout = cluster.cfg.raft_store.raft_base_tick_interval.0\n        * cluster.cfg.raft_store.raft_election_timeout_ticks as u32;\n    // Peer5 should not increase its term.\n    thread::sleep(election_timeout * 2);\n    // Now peer5 can send messages to others\n    cluster.clear_send_filters();\n    thread::sleep(election_timeout * 2);\n    cluster.must_put(b\"k1\", b\"v1\");\n    // Peer1 is still the leader.\n    let leader = cluster.leader_of_region(1);\n    assert_eq!(leader, Some(new_peer(1, 1)));\n    // And the term is not changed.\n    let resp = cluster\n        .call_command(region_status, Duration::from_secs(5))\n        .unwrap();\n    let current_term = resp.get_header().get_current_term();\n    assert_eq!(term, current_term);\n}", "test": "fn test_server_isolated_follower_leader_does_not_change() {\n    let mut cluster = new_server_cluster(0, 5);\n    test_isolated_follower_leader_does_not_change(&mut cluster);\n}"}
{"test_id": "ron-rs-ron/ron-rs-ron-eafa2b6/tests/123_enum_representation.rs::test_internally_a_roundtrip", "code": "fn test_roundtrip<T>(value: T)\nwhere\n    T: Serialize + for<'a> Deserialize<'a> + Debug + PartialEq,\n{\n    let s = to_string(&value).expect(\"Failed to serialize\");\n    let actual: Result<T, _> = from_str(&s);\n    assert_eq!(actual, Ok(value));\n}", "test": "fn test_internally_a_roundtrip() {\n    let v = EnumStructInternally::VariantA {\n        foo: 1,\n        bar: 2,\n        different: 3,\n    };\n    test_roundtrip(v);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_compact_log.rs::test_node_compact_many_times", "code": "fn test_compact_many_times<T: Simulator>(cluster: &mut Cluster<T>) {\n    let gc_limit: u64 = 100;\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(gc_limit);\n    cluster.cfg.raft_store.raft_log_gc_threshold = 500;\n    cluster.cfg.raft_store.raft_log_gc_tick_interval = ReadableDuration::millis(100);\n    cluster.run();\n\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    let mut before_states = HashMap::default();\n\n    for (&id, engines) in &cluster.engines {\n        must_get_equal(&engines.kv, b\"k1\", b\"v1\");\n        let mut state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        let state = state.take_truncated_state();\n        // compact should not start\n        assert_eq!(RAFT_INIT_LOG_INDEX, state.get_index());\n        assert_eq!(RAFT_INIT_LOG_TERM, state.get_term());\n        before_states.insert(id, state);\n    }\n\n    for i in 1..500 {\n        let k = i.to_string().into_bytes();\n        let v = k.clone();\n        cluster.must_put(&k, &v);\n        let v2 = cluster.get(&k);\n        assert_eq!(v2, Some(v));\n\n        if i >= 200\n            && check_compacted(\n                &cluster.engines,\n                &before_states,\n                gc_limit * 2,\n                false, // must_compacted\n            )\n        {\n            return;\n        }\n    }\n\n    check_compacted(\n        &cluster.engines,\n        &before_states,\n        gc_limit * 2,\n        true, // must_compacted\n    );\n}", "test": "fn test_node_compact_many_times() {\n    let count = 5;\n    let mut cluster = new_node_cluster(0, count);\n    test_compact_many_times(&mut cluster);\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_common.rs::parse_merge", "code": "pub fn verified_stmt(&self, sql: &str) -> Statement {\n        self.one_statement_parses_to(sql, sql)\n    }", "test": "fn parse_merge() {\n    let sql = \"MERGE INTO s.bar AS dest USING (SELECT * FROM s.foo) AS stg ON dest.D = stg.D AND dest.E = stg.E WHEN NOT MATCHED THEN INSERT (A, B, C) VALUES (stg.A, stg.B, stg.C) WHEN MATCHED AND dest.A = 'a' THEN UPDATE SET dest.F = stg.F, dest.G = stg.G WHEN MATCHED THEN DELETE\";\n    let sql_no_into = \"MERGE s.bar AS dest USING (SELECT * FROM s.foo) AS stg ON dest.D = stg.D AND dest.E = stg.E WHEN NOT MATCHED THEN INSERT (A, B, C) VALUES (stg.A, stg.B, stg.C) WHEN MATCHED AND dest.A = 'a' THEN UPDATE SET dest.F = stg.F, dest.G = stg.G WHEN MATCHED THEN DELETE\";\n    match (verified_stmt(sql), verified_stmt(sql_no_into)) {\n        (\n            Statement::Merge {\n                into,\n                table,\n                source,\n                on,\n                clauses,\n            },\n            Statement::Merge {\n                into: no_into,\n                table: table_no_into,\n                source: source_no_into,\n                on: on_no_into,\n                clauses: clauses_no_into,\n            },\n        ) => {\n            assert!(into);\n            assert!(!no_into);\n\n            assert_eq!(\n                table,\n                TableFactor::Table {\n                    name: ObjectName(vec![Ident::new(\"s\"), Ident::new(\"bar\")]),\n                    alias: Some(TableAlias {\n                        name: Ident::new(\"dest\"),\n                        columns: vec![],\n                    }),\n                    args: None,\n                    with_hints: vec![],\n                    version: None,\n                    partitions: vec![],\n                }\n            );\n            assert_eq!(table, table_no_into);\n\n            assert_eq!(\n                source,\n                TableFactor::Derived {\n                    lateral: false,\n                    subquery: Box::new(Query {\n                        with: None,\n                        body: Box::new(SetExpr::Select(Box::new(Select {\n                            distinct: None,\n                            top: None,\n                            projection: vec![SelectItem::Wildcard(\n                                WildcardAdditionalOptions::default()\n                            )],\n                            into: None,\n                            from: vec![TableWithJoins {\n                                relation: TableFactor::Table {\n                                    name: ObjectName(vec![Ident::new(\"s\"), Ident::new(\"foo\")]),\n                                    alias: None,\n                                    args: None,\n                                    with_hints: vec![],\n                                    version: None,\n                                    partitions: vec![],\n                                },\n                                joins: vec![],\n                            }],\n                            lateral_views: vec![],\n                            selection: None,\n                            group_by: GroupByExpr::Expressions(vec![]),\n                            cluster_by: vec![],\n                            distribute_by: vec![],\n                            sort_by: vec![],\n                            having: None,\n                            named_window: vec![],\n                            qualify: None,\n                        }))),\n                        order_by: vec![],\n                        limit: None,\n                        limit_by: vec![],\n                        offset: None,\n                        fetch: None,\n                        locks: vec![],\n                    }),\n                    alias: Some(TableAlias {\n                        name: Ident {\n                            value: \"stg\".to_string(),\n                            quote_style: None,\n                        },\n                        columns: vec![],\n                    }),\n                }\n            );\n            assert_eq!(source, source_no_into);\n\n            assert_eq!(\n                on,\n                Box::new(Expr::BinaryOp {\n                    left: Box::new(Expr::BinaryOp {\n                        left: Box::new(Expr::CompoundIdentifier(vec![\n                            Ident::new(\"dest\"),\n                            Ident::new(\"D\"),\n                        ])),\n                        op: BinaryOperator::Eq,\n                        right: Box::new(Expr::CompoundIdentifier(vec![\n                            Ident::new(\"stg\"),\n                            Ident::new(\"D\"),\n                        ])),\n                    }),\n                    op: BinaryOperator::And,\n                    right: Box::new(Expr::BinaryOp {\n                        left: Box::new(Expr::CompoundIdentifier(vec![\n                            Ident::new(\"dest\"),\n                            Ident::new(\"E\"),\n                        ])),\n                        op: BinaryOperator::Eq,\n                        right: Box::new(Expr::CompoundIdentifier(vec![\n                            Ident::new(\"stg\"),\n                            Ident::new(\"E\"),\n                        ])),\n                    }),\n                })\n            );\n            assert_eq!(on, on_no_into);\n\n            assert_eq!(\n                clauses,\n                vec![\n                    MergeClause::NotMatched {\n                        predicate: None,\n                        columns: vec![Ident::new(\"A\"), Ident::new(\"B\"), Ident::new(\"C\")],\n                        values: Values {\n                            explicit_row: false,\n                            rows: vec![vec![\n                                Expr::CompoundIdentifier(vec![Ident::new(\"stg\"), Ident::new(\"A\")]),\n                                Expr::CompoundIdentifier(vec![Ident::new(\"stg\"), Ident::new(\"B\")]),\n                                Expr::CompoundIdentifier(vec![Ident::new(\"stg\"), Ident::new(\"C\")]),\n                            ]]\n                        },\n                    },\n                    MergeClause::MatchedUpdate {\n                        predicate: Some(Expr::BinaryOp {\n                            left: Box::new(Expr::CompoundIdentifier(vec![\n                                Ident::new(\"dest\"),\n                                Ident::new(\"A\"),\n                            ])),\n                            op: BinaryOperator::Eq,\n                            right: Box::new(Expr::Value(Value::SingleQuotedString(\n                                \"a\".to_string()\n                            ))),\n                        }),\n                        assignments: vec![\n                            Assignment {\n                                id: vec![Ident::new(\"dest\"), Ident::new(\"F\")],\n                                value: Expr::CompoundIdentifier(vec![\n                                    Ident::new(\"stg\"),\n                                    Ident::new(\"F\"),\n                                ]),\n                            },\n                            Assignment {\n                                id: vec![Ident::new(\"dest\"), Ident::new(\"G\")],\n                                value: Expr::CompoundIdentifier(vec![\n                                    Ident::new(\"stg\"),\n                                    Ident::new(\"G\"),\n                                ]),\n                            },\n                        ],\n                    },\n                    MergeClause::MatchedDelete(None),\n                ]\n            );\n            assert_eq!(clauses, clauses_no_into);\n        }\n        _ => unreachable!(),\n    }\n}"}
{"test_id": "hyperium-http/hyperium-http-818269d/tests/status_code.rs::is_redirection", "code": "fn is_redirection() {\n    assert!(status_code(300).is_redirection());\n    assert!(status_code(399).is_redirection());\n\n    assert!(!status_code(299).is_redirection());\n    assert!(!status_code(400).is_redirection());\n}", "test": "fn is_redirection() {\n    assert!(status_code(300).is_redirection());\n    assert!(status_code(399).is_redirection());\n\n    assert!(!status_code(299).is_redirection());\n    assert!(!status_code(400).is_redirection());\n}"}
{"test_id": "quinn-rs-quinn/quinn-rs-quinn-83e4f46/quinn-proto/src/tests/mod.rs::handshake_anti_deadlock_probe", "code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn handshake_anti_deadlock_probe() {\n    let _guard = subscribe();\n\n    let (cert, key) = big_cert_and_key();\n    let server = server_config_with_cert(cert.clone(), key);\n    let client = client_config_with_certs(vec![cert]);\n    let mut pair = Pair::new(Default::default(), server);\n\n    let client_ch = pair.begin_connect(client);\n    // Client sends initial\n    pair.drive_client();\n    // Server sends first flight, gets blocked on anti-amplification\n    pair.drive_server();\n    // Client acks...\n    pair.drive_client();\n    // ...but it's lost, so the server doesn't get anti-amplification credit from it\n    pair.server.inbound.clear();\n    // Client sends an anti-deadlock probe, and the handshake completes as usual.\n    pair.drive();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Connected { .. })\n    );\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/operators.rs::assignmentoperator_lhs_not_defined", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn assignmentoperator_lhs_not_defined() {\n    run_test_actions([TestAction::assert_native_error(\n        \"a += 5\",\n        JsNativeErrorKind::Reference,\n        \"a is not defined\",\n    )]);\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/init.rs::fmt_compatibility", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn fmt_compatibility() {\n  let output = Test::new()\n    .no_justfile()\n    .arg(\"--init\")\n    .stderr_regex(\"Wrote justfile to `.*`\\n\")\n    .run();\n  Test::with_tempdir(output.tempdir)\n    .no_justfile()\n    .arg(\"--unstable\")\n    .arg(\"--check\")\n    .arg(\"--fmt\")\n    .status(EXIT_SUCCESS)\n    .run();\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_storage.rs::test_scheduler_pool_auto_switch_for_resource_ctl", "code": "fn is_ok(&self) -> bool {\n        let count = self.count.fetch_add(1, Ordering::SeqCst);\n        if count != 0 && count % self.retry == 0 {\n            // it's ok.\n            return true;\n        }\n        // let's sleep awhile, so that client will update its connection.\n        thread::sleep(REQUEST_RECONNECT_INTERVAL);\n        false\n    }", "test": "fn test_scheduler_pool_auto_switch_for_resource_ctl() {\n    let mut cluster = new_server_cluster(0, 1);\n    cluster.run();\n\n    let engine = cluster\n        .sim\n        .read()\n        .unwrap()\n        .storages\n        .get(&1)\n        .unwrap()\n        .clone();\n    let resource_manager = ResourceGroupManager::default();\n    let resource_ctl = resource_manager.derive_controller(\"test\".to_string(), true);\n\n    let storage = TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine, MockLockManager::new())\n        .config(cluster.cfg.tikv.storage.clone())\n        .build_for_resource_controller(resource_ctl)\n        .unwrap();\n\n    let region = cluster.get_region(b\"k1\");\n    let mut ctx = Context::default();\n    ctx.set_region_id(region.id);\n    ctx.set_region_epoch(region.get_region_epoch().clone());\n    ctx.set_peer(cluster.leader_of_region(region.id).unwrap());\n\n    let do_prewrite = |key: &[u8], val: &[u8]| {\n        // prewrite\n        let (prewrite_tx, prewrite_rx) = channel();\n        storage\n            .sched_txn_command(\n                commands::Prewrite::new(\n                    vec![Mutation::make_put(Key::from_raw(key), val.to_vec())],\n                    key.to_vec(),\n                    10.into(),\n                    100,\n                    false,\n                    2,\n                    TimeStamp::default(),\n                    TimeStamp::default(),\n                    None,\n                    false,\n                    AssertionLevel::Off,\n                    ctx.clone(),\n                ),\n                Box::new(move |res: storage::Result<_>| {\n                    let _ = prewrite_tx.send(res);\n                }),\n            )\n            .unwrap();\n        prewrite_rx.recv_timeout(Duration::from_secs(2))\n    };\n\n    let (sender, receiver) = channel();\n    let priority_queue_sender = Mutex::new(sender.clone());\n    let single_queue_sender = Mutex::new(sender);\n    fail::cfg_callback(\"priority_pool_task\", move || {\n        let sender = priority_queue_sender.lock().unwrap();\n        sender.send(\"priority_queue\").unwrap();\n    })\n    .unwrap();\n    fail::cfg_callback(\"single_queue_pool_task\", move || {\n        let sender = single_queue_sender.lock().unwrap();\n        sender.send(\"single_queue\").unwrap();\n    })\n    .unwrap();\n\n    // Default is use single queue\n    assert_eq!(do_prewrite(b\"k1\", b\"v1\").is_ok(), true);\n    assert_eq!(\n        receiver.recv_timeout(Duration::from_millis(500)).unwrap(),\n        \"single_queue\"\n    );\n\n    // Add group use priority queue\n    use kvproto::resource_manager::{GroupMode, GroupRequestUnitSettings, ResourceGroup};\n    let mut group = ResourceGroup::new();\n    group.set_name(\"rg1\".to_string());\n    group.set_mode(GroupMode::RuMode);\n    let mut ru_setting = GroupRequestUnitSettings::new();\n    ru_setting.mut_r_u().mut_settings().set_fill_rate(100000);\n    group.set_r_u_settings(ru_setting);\n    resource_manager.add_resource_group(group);\n    thread::sleep(Duration::from_millis(200));\n    assert_eq!(do_prewrite(b\"k2\", b\"v2\").is_ok(), true);\n    assert_eq!(\n        receiver.recv_timeout(Duration::from_millis(500)).unwrap(),\n        \"priority_queue\"\n    );\n\n    // Delete group use single queue\n    resource_manager.remove_resource_group(\"rg1\");\n    thread::sleep(Duration::from_millis(200));\n    assert_eq!(do_prewrite(b\"k3\", b\"v3\").is_ok(), true);\n    assert_eq!(\n        receiver.recv_timeout(Duration::from_millis(500)).unwrap(),\n        \"single_queue\"\n    );\n\n    // Scale pool size\n    let scheduler = storage.get_scheduler();\n    let pool = scheduler.get_sched_pool();\n    assert_eq!(pool.get_pool_size(CommandPri::Normal), 1);\n    pool.scale_pool_size(2);\n    assert_eq!(pool.get_pool_size(CommandPri::Normal), 2);\n}"}
{"test_id": "ron-rs-ron/ron-rs-ron-eafa2b6/tests/min_max.rs::test_i32_max", "code": "pub fn to_string<T>(&self, value: &T) -> Result<String>\n    where\n        T: ?Sized + ser::Serialize,\n    {\n        let mut output = Vec::new();\n        let mut s = Serializer::with_options(&mut output, None, self.clone())?;\n        value.serialize(&mut s)?;\n        Ok(String::from_utf8(output).expect(\"Ron should be utf-8\"))\n    }", "test": "fn test_i32_max() {\n    assert_eq!(\n        std::i32::MAX,\n        from_str(&to_string(&std::i32::MAX).unwrap()).unwrap()\n    );\n}"}
{"test_id": "tafia-calamine/tafia-calamine-5a5804d/tests/test.rs::xlsx", "code": "fn worksheet_range(&mut self, name: &str) -> Option<Result<Range<DataType>, XlsError>> {\n        self.sheets.get(name).map(|r| Ok(r.0.clone()))\n    }", "test": "fn xlsx() {\n    setup();\n\n    let path = format!(\"{}/tests/issues.xlsx\", env!(\"CARGO_MANIFEST_DIR\"));\n    let mut excel: Xlsx<_> = open_workbook(&path).unwrap();\n\n    let range = excel.worksheet_range(\"issue2\").unwrap().unwrap();\n    range_eq!(\n        range,\n        [\n            [Float(1.), String(\"a\".to_string())],\n            [Float(2.), String(\"b\".to_string())],\n            [Float(3.), String(\"c\".to_string())]\n        ]\n    );\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/choose.rs::override_variable", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn override_variable() {\n  Test::new()\n    .arg(\"--choose\")\n    .arg(\"baz=B\")\n    .env(\"JUST_CHOOSER\", \"head -n1\")\n    .justfile(\n      \"\n        baz := 'A'\n\n        foo:\n          echo foo\n\n        bar:\n          echo {{baz}}\n      \",\n    )\n    .stderr(\"echo B\\n\")\n    .stdout(\"B\\n\")\n    .run();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_realpath.rs::test_realpath_file_and_links_zero", "code": "pub fn stdout_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stdout_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stdout_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_realpath_file_and_links_zero() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    at.touch(\"foo\");\n    at.symlink_file(\"foo\", \"bar\");\n\n    scene\n        .ucmd()\n        .arg(\"foo\")\n        .arg(\"-z\")\n        .succeeds()\n        .stdout_contains(\"foo\\u{0}\");\n\n    scene\n        .ucmd()\n        .arg(\"bar\")\n        .arg(\"-z\")\n        .succeeds()\n        .stdout_contains(\"foo\\u{0}\");\n}"}
{"test_id": "ordinals-ord/ordinals-ord-8090538/tests/wallet/inscribe.rs::try_reinscribe_without_flag", "code": "pub fn descriptors(&self) -> Vec<String> {\n    self.state().descriptors.clone()\n  }", "test": "fn try_reinscribe_without_flag() {\n  let rpc_server = test_bitcoincore_rpc::spawn();\n  rpc_server.mine_blocks(1);\n\n  assert_eq!(rpc_server.descriptors().len(), 0);\n\n  create_wallet(&rpc_server);\n\n  let reveal_txid = CommandBuilder::new(\"wallet inscribe --file tulip.png --fee-rate 5.0 \")\n    .write(\"tulip.png\", [1; 520])\n    .rpc_server(&rpc_server)\n    .run_and_deserialize_output::<Inscribe>()\n    .reveal;\n\n  assert_eq!(rpc_server.descriptors().len(), 3);\n\n  rpc_server.mine_blocks(1);\n\n  CommandBuilder::new(format!(\n    \"wallet inscribe --file orchid.png --fee-rate 1.1 --satpoint {reveal_txid}:0:0\"\n  ))\n  .write(\"orchid.png\", [1; 520])\n  .rpc_server(&rpc_server)\n  .expected_exit_code(1)\n  .stderr_regex(format!(\n    \"error: sat at {reveal_txid}:0:0 already inscribed.*\"\n  ))\n  .run_and_extract_stdout();\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/search_arguments.rs::argument_with_different_path_prefix_is_allowed", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn argument_with_different_path_prefix_is_allowed() {\n  Test::new()\n    .justfile(\"foo bar:\")\n    .args([\"./foo\", \"../bar\"])\n    .run();\n}"}
{"test_id": "tafia-quick-xml/tafia-quick-xml-120e074/tests/unit_tests.rs::test_offset_err_comment_trim_text", "code": "pub fn buffer_position(&self) -> usize {\n        // when internal state is OpenedTag, we have actually read until '<',\n        // which we don't want to show\n        if let ParseState::OpenedTag = self.state.state {\n            self.state.offset - 1\n        } else {\n            self.state.offset\n        }\n    }", "test": "fn test_offset_err_comment_trim_text() {\n    let mut r = Reader::from_str(\"<a>\\r\\n <!--b>\");\n    r.trim_text(true);\n\n    next_eq!(r, Start, b\"a\");\n    assert_eq!(r.buffer_position(), 3);\n\n    match r.read_event() {\n        // error at char 7: no closing --> tag found\n        Err(e) => assert_eq!(\n            r.buffer_position(),\n            7,\n            \"expecting buf_pos = 7, found {}, err {:?}\",\n            r.buffer_position(),\n            e\n        ),\n        e => panic!(\"expecting error, found {:?}\", e),\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_split.rs::test_split_obs_lines_within_combined_shorts", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_obs_lines_within_combined_shorts() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let name = \"obs-lines-within-shorts\";\n    RandomFile::new(at, name).add_lines(400);\n\n    scene\n        .ucmd()\n        .args(&[\"-x200de\", name])\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n    let glob = Glob::new(at, \".\", r\"x\\d\\d$\");\n    assert_eq!(glob.count(), 2);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"test_id": "rustls-rustls/rustls-rustls-ae583bd/rustls/tests/api.rs::server_complete_io_for_handshake", "code": "pub fn is_handshaking(&self) -> bool {\n        !(self.may_send_application_data && self.may_receive_application_data)\n    }", "test": "fn server_complete_io_for_handshake() {\n    for kt in ALL_KEY_TYPES.iter() {\n        let (mut client, mut server) = make_pair(*kt);\n\n        assert!(server.is_handshaking());\n        let (rdlen, wrlen) = server\n            .complete_io(&mut OtherSession::new(&mut client))\n            .unwrap();\n        assert!(rdlen > 0 && wrlen > 0);\n        assert!(!server.is_handshaking());\n        assert!(!server.wants_write());\n    }\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/retry_dns_handle_tests.rs::retry_on_retryable_error", "code": "pub fn id(&self) -> u16 {\n        self.id\n    }", "test": "fn retry_on_retryable_error() {\n    let handle = RetryDnsHandle::new(\n        TestClient {\n            retries: 1,\n            error_response: ResolveError::from(std::io::Error::from(std::io::ErrorKind::TimedOut)),\n            attempts: Arc::new(AtomicU16::new(0)),\n        },\n        2,\n    );\n    let test1 = Message::new();\n    let result = block_on(handle.send(test1).first_answer()).expect(\"should have succeeded\");\n    assert_eq!(result.id(), 1); // this is checking the number of iterations the TestClient ran\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_stale_peer.rs::test_node_stale_peer_out_of_region", "code": "fn test_stale_peer_out_of_region<T: Simulator>(cluster: &mut Cluster<T>) {\n    let pd_client = Arc::clone(&cluster.pd_client);\n    // Disable default max peer number check.\n    pd_client.disable_default_operator();\n\n    let r1 = cluster.run_conf_change();\n    pd_client.must_add_peer(r1, new_learner_peer(2, 2));\n    pd_client.must_add_peer(r1, new_peer(2, 2));\n    pd_client.must_add_peer(r1, new_learner_peer(3, 3));\n    pd_client.must_add_peer(r1, new_peer(3, 3));\n    let (key, value) = (b\"k1\", b\"v1\");\n    cluster.must_put(key, value);\n    assert_eq!(cluster.get(key), Some(value.to_vec()));\n\n    let engine_2 = cluster.get_engine(2);\n    must_get_equal(&engine_2, key, value);\n\n    // Isolate peer 2 from rest of the cluster.\n    cluster.add_send_filter(IsolationFilterFactory::new(2));\n\n    // In case 2 is leader, it will fail to pass the healthy nodes check,\n    // so remove isolated node first. Because 2 is isolated, so it can't remove\n    // itself.\n    pd_client.must_remove_peer(r1, new_peer(2, 2));\n\n    // Add peer [(4, 4), (5, 5), (6, 6)].\n    pd_client.must_add_peer(r1, new_learner_peer(4, 4));\n    pd_client.must_add_peer(r1, new_peer(4, 4));\n    pd_client.must_add_peer(r1, new_learner_peer(5, 5));\n    pd_client.must_add_peer(r1, new_peer(5, 5));\n    pd_client.must_add_peer(r1, new_learner_peer(6, 6));\n    pd_client.must_add_peer(r1, new_peer(6, 6));\n\n    // Remove peer [(1, 1), (3, 3)].\n    pd_client.must_remove_peer(r1, new_peer(1, 1));\n    pd_client.must_remove_peer(r1, new_peer(3, 3));\n\n    // Keep peer 2 isolated. Otherwise whether peer 3 is destroyed or not,\n    // it will handle the stale raft message from peer 2 and cause peer 2 to\n    // destroy itself earlier than this test case expects.\n\n    // Wait for max_leader_missing_duration to time out.\n    cluster.must_remove_region(2, r1);\n\n    // Check whether this region is still functional properly.\n    let (key2, value2) = (b\"k2\", b\"v2\");\n    cluster.must_put(key2, value2);\n    assert_eq!(cluster.get(key2), Some(value2.to_vec()));\n\n    // Check whether peer(2, 2) and its data are destroyed.\n    must_get_none(&engine_2, key);\n    must_get_none(&engine_2, key2);\n    let state_key = keys::region_state_key(1);\n    let state: RegionLocalState = engine_2.get_msg_cf(CF_RAFT, &state_key).unwrap().unwrap();\n    assert_eq!(state.get_state(), PeerState::Tombstone);\n}", "test": "fn test_node_stale_peer_out_of_region() {\n    let count = 6;\n    let mut cluster = new_node_cluster(0, count);\n    test_stale_peer_out_of_region(&mut cluster);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_kill.rs::test_kill_with_signal_name_new_form", "code": "fn wait_for_signal(&mut self) -> Option<i32> {\n        let sig = self.child.wait().expect(\"cannot wait on target\").signal();\n        self.killed = true;\n        sig\n    }", "test": "fn test_kill_with_signal_name_new_form() {\n    let mut target = Target::new();\n    new_ucmd!()\n        .arg(\"-s\")\n        .arg(\"KILL\")\n        .arg(format!(\"{}\", target.pid()))\n        .succeeds();\n    assert_eq!(target.wait_for_signal(), Some(libc::SIGKILL));\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/lint.rs::no_lint_if_files_are_listed_in_ignore_option", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn no_lint_if_files_are_listed_in_ignore_option() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"biome.json\");\n    fs.insert(file_path.into(), CONFIG_LINTER_AND_FILES_IGNORE.as_bytes());\n\n    let file_path_test1 = Path::new(\"test1.js\");\n    fs.insert(file_path_test1.into(), FIX_BEFORE.as_bytes());\n\n    let file_path_test2 = Path::new(\"test2.js\");\n    fs.insert(file_path_test2.into(), FIX_BEFORE.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"lint\"),\n                (\"--apply\"),\n                file_path_test1.as_os_str().to_str().unwrap(),\n                file_path_test2.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut buffer = String::new();\n    fs.open(file_path_test1)\n        .unwrap()\n        .read_to_string(&mut buffer)\n        .unwrap();\n\n    assert_eq!(buffer, FIX_BEFORE);\n\n    let mut buffer = String::new();\n    fs.open(file_path_test2)\n        .unwrap()\n        .read_to_string(&mut buffer)\n        .unwrap();\n\n    assert_eq!(buffer, FIX_BEFORE);\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"no_lint_if_files_are_listed_in_ignore_option\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-parse-integer/tests/algorithm_tests.rs::test_try_parse_4digits", "code": "pub fn parse<N: FromLexical, Bytes: AsRef<[u8]>>(bytes: Bytes) -> Result<N> {\n    N::from_lexical(bytes.as_ref())\n}", "test": "fn test_try_parse_4digits() {\n    let parse = |bytes: &[u8]| {\n        let mut digits = bytes.bytes::<{ STANDARD }>();\n        algorithm::try_parse_4digits::<u32, _, STANDARD>(&mut digits.integer_iter())\n    };\n    assert_eq!(parse(b\"1234\"), Some(1234));\n    assert_eq!(parse(b\"123\"), None);\n    assert_eq!(parse(b\"123\\x00\"), None);\n    assert_eq!(parse(b\"123.\"), None);\n    assert_eq!(parse(b\"123_\"), None);\n    assert_eq!(parse(b\"1234_\"), Some(1234));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_hashsum.rs::test_invalid_b2sum_length_option_not_multiple_of_8", "code": "pub fn join(&mut self) -> &mut Self {\n        if let Some(join_handle) = self.join_handle.take() {\n            join_handle\n                .join()\n                .expect(\"Error joining with the piping stdin thread\")\n                .unwrap();\n        }\n        self\n    }", "test": "fn test_invalid_b2sum_length_option_not_multiple_of_8() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    at.write(\"testf\", \"foobar\\n\");\n\n    scene\n        .ccmd(\"b2sum\")\n        .arg(\"--length=9\")\n        .arg(at.subdir.join(\"testf\"))\n        .fails()\n        .code_is(1);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_nice.rs::test_bare_adjustment", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_bare_adjustment() {\n    new_ucmd!()\n        .args(&[\"-1\", \"echo\", \"-n\", \"a\"])\n        .run()\n        .stdout_is(\"a\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/engine_traits_tests/src/write_batch.rs::save_point_rollback_two", "code": "pub fn is_none(&self) -> bool {\n        !self.is_some()\n    }", "test": "fn save_point_rollback_two() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch();\n\n    wb.set_save_point();\n    wb.put(b\"a\", b\"\").unwrap();\n    wb.set_save_point();\n    wb.put(b\"b\", b\"\").unwrap();\n\n    wb.rollback_to_save_point().unwrap();\n    wb.rollback_to_save_point().unwrap();\n\n    let err = wb.rollback_to_save_point();\n    assert_engine_error(err);\n    let err = wb.pop_save_point();\n    assert_engine_error(err);\n    wb.write().unwrap();\n    let a = db.engine.get_value(b\"a\").unwrap();\n    assert!(a.is_none());\n    let b = db.engine.get_value(b\"b\").unwrap();\n    assert!(b.is_none());\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(1024);\n    let max_keys = 256_usize;\n\n    wb.set_save_point();\n    for i in 0..max_keys {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"a\", b\"\").unwrap();\n    wb.set_save_point();\n    for i in max_keys..2 * max_keys {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"b\", b\"\").unwrap();\n\n    wb.rollback_to_save_point().unwrap();\n    wb.rollback_to_save_point().unwrap();\n\n    let err = wb.rollback_to_save_point();\n    assert_engine_error(err);\n    let err = wb.pop_save_point();\n    assert_engine_error(err);\n    wb.write().unwrap();\n    let a = db.engine.get_value(b\"a\").unwrap();\n    assert!(a.is_none());\n    let b = db.engine.get_value(b\"b\").unwrap();\n    assert!(b.is_none());\n    for i in 0..2 * max_keys {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_test.rs::test_non_existing_files", "code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_non_existing_files() {\n    let scenario = TestScenario::new(util_name!());\n\n    let result = scenario\n        .ucmd()\n        .args(&[\"newer_file\", \"-nt\", \"regular_file\"])\n        .fails();\n    assert!(result.stderr().is_empty());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_tee.rs::test_tee_append", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_tee_append() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let content = \"tee_sample_content\";\n    let file = \"tee_out\";\n\n    at.touch(file);\n    at.write(file, content);\n    assert_eq!(at.read(file), content);\n\n    ucmd.arg(\"-a\")\n        .arg(file)\n        .pipe_in(content)\n        .succeeds()\n        .stdout_is(content);\n    assert!(at.file_exists(file));\n    assert_eq!(at.read(file), content.repeat(2));\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/os_attributes.rs::all", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn all() {\n  Test::new()\n    .justfile(\n      \"\n      [macos]\n      [windows]\n      [linux]\n      [unix]\n      foo:\n        echo bar\n    \",\n    )\n    .stdout(\"bar\\n\")\n    .stderr(\"echo bar\\n\")\n    .run();\n}"}
{"test_id": "Alexhuszagh-minimal-lexical/Alexhuszagh-minimal-lexical-e997c46/tests/slow_tests.rs::bh_test", "code": "fn bh<F: Float>(float: F) -> (u64, i32) {\n    let fp = slow::bh(float);\n    (fp.mant, fp.exp)\n}", "test": "fn bh_test() {\n    assert_eq!(bh(1e-45_f32), (3, -150));\n    assert_eq!(bh(5e-324_f64), (3, -1075));\n    assert_eq!(bh(1_f32), (16777217, -24));\n    assert_eq!(bh(1_f64), (9007199254740993, -53));\n    assert_eq!(bh(1e38_f32), (19721523, 102));\n    assert_eq!(bh(1e308_f64), (10020841800044865, 970));\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_import_service.rs::test_ingest_reentrant", "code": "pub fn has_error(&self) -> bool {\n        self.error.is_some()\n    }", "test": "fn test_ingest_reentrant() {\n    let (cluster, ctx, _tikv, import) = new_cluster_and_tikv_import_client();\n\n    let temp_dir = Builder::new()\n        .prefix(\"test_ingest_reentrant\")\n        .tempdir()\n        .unwrap();\n\n    let sst_path = temp_dir.path().join(\"test.sst\");\n    let sst_range = (0, 100);\n    let (mut meta, data) = gen_sst_file(sst_path, sst_range);\n    meta.set_region_id(ctx.get_region_id());\n    meta.set_region_epoch(ctx.get_region_epoch().clone());\n    upload_sst(&import, &meta, &data).unwrap();\n\n    let mut ingest = IngestRequest::default();\n    ingest.set_context(ctx);\n    ingest.set_sst(meta.clone());\n\n    // Don't delete ingested sst file or we cannot find sst file in next ingest.\n    fail::cfg(\"dont_delete_ingested_sst\", \"1*return\").unwrap();\n\n    let node_id = *cluster.sim.rl().get_node_ids().iter().next().unwrap();\n    // Use sst save path to track the sst file checksum.\n    let save_path = cluster\n        .sim\n        .rl()\n        .importers\n        .get(&node_id)\n        .unwrap()\n        .get_path(&meta);\n\n    let checksum1 = calc_crc32(save_path.clone()).unwrap();\n    // Do ingest and it will ingest successs.\n    let resp = import.ingest(&ingest).unwrap();\n    assert!(!resp.has_error());\n\n    let checksum2 = calc_crc32(save_path).unwrap();\n    // TODO: Remove this once write_global_seqno is deprecated.\n    // Checksums are the same since the global seqno in the SST file no longer gets\n    // updated with the default setting, which is write_global_seqno=false.\n    assert_eq!(checksum1, checksum2);\n    // Do ingest again and it can be reentrant\n    let resp = import.ingest(&ingest).unwrap();\n    assert!(!resp.has_error());\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-parse-float/tests/libm_tests.rs::fabsf_spec_test", "code": "fn is_nan(self) -> bool {\n        self.is_special() && (self.to_bits() & Self::MANTISSA_MASK) != Self::Unsigned::ZERO\n    }", "test": "fn fabsf_spec_test() {\n    assert!(libm::fabsf(f32::NAN).is_nan());\n    for f in [0.0, -0.0].iter().copied() {\n        assert_eq!(libm::fabsf(f), 0.0);\n    }\n    for f in [f32::INFINITY, f32::NEG_INFINITY].iter().copied() {\n        assert_eq!(libm::fabsf(f), f32::INFINITY);\n    }\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/engine_traits_tests/src/iterator.rs::iter_reverse_then_forward_snapshot", "code": "fn iterator(&self, cf: &str) -> Result<Self::Iterator> {\n        self.iterator_opt(cf, IterOptions::default())\n    }", "test": "fn iter_reverse_then_forward_snapshot() {\n    let db = default_engine();\n    iter_reverse_then_forward(&db.engine, |e| e.snapshot().iterator(CF_DEFAULT).unwrap());\n}"}
{"test_id": "dtolnay-syn/dtolnay-syn-b1a038c/tests/test_attribute.rs::test_meta_item_bool_value", "code": "fn test(input: &str) -> Meta {\n    let attrs = Attribute::parse_outer.parse_str(input).unwrap();\n\n    assert_eq!(attrs.len(), 1);\n    let attr = attrs.into_iter().next().unwrap();\n\n    attr.meta\n}", "test": "fn test_meta_item_bool_value() {\n    let meta = test(\"#[foo = true]\");\n\n    snapshot!(meta, @r###\"\n    Meta::NameValue {\n        path: Path {\n            segments: [\n                PathSegment {\n                    ident: \"foo\",\n                },\n            ],\n        },\n        value: Expr::Lit {\n            lit: Lit::Bool {\n                value: true,\n            },\n        },\n    }\n    \"###);\n\n    let meta = test(\"#[foo = false]\");\n\n    snapshot!(meta, @r###\"\n    Meta::NameValue {\n        path: Path {\n            segments: [\n                PathSegment {\n                    ident: \"foo\",\n                },\n            ],\n        },\n        value: Expr::Lit {\n            lit: Lit::Bool {\n                value: false,\n            },\n        },\n    }\n    \"###);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_multi.rs::test_multi_node_random_latency", "code": "fn test_multi_random_latency<T: Simulator>(cluster: &mut Cluster<T>) {\n    cluster.run();\n    cluster.add_send_filter(CloneFilterFactory(RandomLatencyFilter::new(50)));\n    test_multi_base_after_bootstrap(cluster);\n}", "test": "fn test_multi_node_random_latency() {\n    let count = 5;\n    let mut cluster = new_node_cluster(0, count);\n    test_multi_random_latency(&mut cluster);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_dirname.rs::test_root", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_root() {\n    new_ucmd!().arg(\"/\").run().stdout_is(\"/\\n\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_du.rs::test_du_no_exec_permission", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_du_no_exec_permission() {\n    let ts = TestScenario::new(util_name!());\n    let at = &ts.fixtures;\n\n    at.mkdir_all(\"d/no-x/y\");\n\n    ts.ccmd(\"chmod\").arg(\"u=rw\").arg(\"d/no-x\").succeeds();\n\n    let result = ts.ucmd().arg(\"d/no-x\").fails();\n    result.stderr_contains(\"du: cannot access 'd/no-x/y': Permission denied\");\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/mod.rs::identifier_on_global_object_undefined", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn identifier_on_global_object_undefined() {\n    run_test_actions([TestAction::assert_native_error(\n        \"bar;\",\n        JsNativeErrorKind::Reference,\n        \"bar is not defined\",\n    )]);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_realpath.rs::test_realpath_dangling", "code": "pub fn plus_as_string<P: AsRef<Path>>(&self, name: P) -> String {\n        self.plus(name).display().to_string()\n    }", "test": "fn test_realpath_dangling() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    at.symlink_file(\"nonexistent-file\", \"link\");\n    ucmd.arg(\"link\")\n        .succeeds()\n        .stdout_contains(at.plus_as_string(\"nonexistent-file\\n\"));\n}"}
{"test_id": "cberner-redb/cberner-redb-267b473/tests/integration_tests.rs::delete_all_tables", "code": "pub(crate) fn list_tables(&self, table_type: TableType) -> Result<Vec<String>> {\n        let iter = self.tree.range::<RangeFull, &str>(&(..))?;\n        let iter = TableNameIter {\n            inner: iter,\n            table_type,\n        };\n        let mut result = vec![];\n        for table in iter {\n            result.push(table?);\n        }\n        Ok(result)\n    }", "test": "fn delete_all_tables() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let x_def: TableDefinition<&str, &str> = TableDefinition::new(\"x\");\n    let y_def: TableDefinition<&str, &str> = TableDefinition::new(\"y\");\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(x_def).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n        let mut table = write_txn.open_table(y_def).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    assert_eq!(2, read_txn.list_tables().unwrap().count());\n\n    let write_txn = db.begin_write().unwrap();\n    for table in write_txn.list_tables().unwrap() {\n        write_txn.delete_table(table).unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    assert_eq!(0, read_txn.list_tables().unwrap().count());\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_split_region.rs::test_refresh_region_bucket_keys", "code": "fn clone(&self) -> Self {\n        Self {\n            regions: self.regions.clone(),\n            meta_cli: self.meta_cli.clone(),\n            // We should manually call Arc::clone here or rustc complains that `PDC` isn't `Clone`.\n            pd_client: Arc::clone(&self.pd_client),\n            range_router: self.range_router.clone(),\n            scheduler: self.scheduler.clone(),\n            observer: self.observer.clone(),\n            subs: self.subs.clone(),\n            messenger: self.messenger.clone(),\n            scan_pool_handle: self.scan_pool_handle.clone(),\n            scans: CallbackWaitGroup::new(),\n        }\n    }", "test": "fn test_refresh_region_bucket_keys() {\n    let count = 5;\n    let mut cluster = new_server_cluster(0, count);\n    cluster.run();\n    let pd_client = Arc::clone(&cluster.pd_client);\n\n    cluster.must_put(b\"k11\", b\"v1\");\n    let mut region = pd_client.get_region(b\"k11\").unwrap();\n\n    let bucket = Bucket {\n        keys: vec![b\"k11\".to_vec()],\n        size: 1024 * 1024 * 200,\n    };\n\n    let mut expected_buckets = metapb::Buckets::default();\n    expected_buckets.set_keys(bucket.clone().keys.into());\n    expected_buckets\n        .keys\n        .insert(0, region.get_start_key().to_vec());\n    expected_buckets.keys.push(region.get_end_key().to_vec());\n    let buckets = vec![bucket];\n    let bucket_version = cluster.refresh_region_bucket_keys(\n        &region,\n        buckets,\n        Option::None,\n        Some(expected_buckets.clone()),\n    );\n    let conf_ver = region.get_region_epoch().get_conf_ver() + 1;\n    region.mut_region_epoch().set_conf_ver(conf_ver);\n\n    let bucket = Bucket {\n        keys: vec![b\"k12\".to_vec()],\n        size: 1024 * 1024 * 200,\n    };\n    expected_buckets.set_keys(bucket.clone().keys.into());\n    expected_buckets\n        .keys\n        .insert(0, region.get_start_key().to_vec());\n    expected_buckets.keys.push(region.get_end_key().to_vec());\n    let buckets = vec![bucket];\n    let bucket_version2 = cluster.refresh_region_bucket_keys(\n        &region,\n        buckets.clone(),\n        Option::None,\n        Some(expected_buckets.clone()),\n    );\n    assert_eq!(bucket_version2, bucket_version + 1);\n\n    let conf_ver = 0;\n    region.mut_region_epoch().set_conf_ver(conf_ver);\n    let bucket_version3 = cluster.refresh_region_bucket_keys(\n        &region,\n        buckets,\n        Option::None,\n        Some(expected_buckets.clone()),\n    );\n    assert_eq!(bucket_version3, bucket_version2);\n\n    // now the buckets is [\"\", \"k12\", \"\"]. further split [\"\", k12], [k12, \"\"]\n    // buckets into more buckets\n    let region = pd_client.get_region(b\"k11\").unwrap();\n    let bucket_ranges = vec![\n        BucketRange(vec![], b\"k12\".to_vec()),\n        BucketRange(b\"k12\".to_vec(), vec![]),\n    ];\n    let buckets = vec![\n        Bucket {\n            keys: vec![b\"k0\".to_vec(), b\"k10\".to_vec(), b\"k11\".to_vec()],\n            size: 1024 * 1024 * 200,\n        },\n        Bucket {\n            keys: vec![b\"k121\".to_vec(), b\"k122\".to_vec()],\n            size: 1024 * 1024 * 200,\n        },\n    ];\n    expected_buckets.set_keys(\n        vec![\n            vec![],\n            b\"k0\".to_vec(),\n            b\"k10\".to_vec(),\n            b\"k11\".to_vec(),\n            b\"k12\".to_vec(),\n            b\"k121\".to_vec(),\n            b\"k122\".to_vec(),\n            vec![],\n        ]\n        .into(),\n    );\n    let bucket_version4 = cluster.refresh_region_bucket_keys(\n        &region,\n        buckets,\n        Some(bucket_ranges),\n        Some(expected_buckets.clone()),\n    );\n    assert_eq!(bucket_version4, bucket_version3 + 1);\n\n    // remove k11~k12, k12~k121, k122~[] bucket\n    let buckets = vec![\n        Bucket {\n            keys: vec![],\n            size: 1, // small enough to merge with left bucket\n        },\n        Bucket {\n            keys: vec![],\n            size: 1024 * 1024 * 65, // not small enough to merge with left\n        },\n        Bucket {\n            keys: vec![],\n            size: 1024 * 1024, // small enough to merge with left bucket\n        },\n    ];\n\n    let bucket_ranges = vec![\n        BucketRange(b\"k11\".to_vec(), b\"k12\".to_vec()),\n        BucketRange(b\"k121\".to_vec(), b\"k122\".to_vec()),\n        BucketRange(b\"k122\".to_vec(), vec![]),\n    ];\n    expected_buckets.set_keys(\n        vec![\n            vec![],\n            b\"k0\".to_vec(),\n            b\"k10\".to_vec(),\n            b\"k12\".to_vec(),\n            b\"k121\".to_vec(), // k121~k122 cannot be merged to left as it's too big\n            vec![],\n        ]\n        .into(),\n    );\n    let bucket_version5 = cluster.refresh_region_bucket_keys(\n        &region,\n        buckets,\n        Some(bucket_ranges),\n        Some(expected_buckets.clone()),\n    );\n\n    assert_eq!(bucket_version5, bucket_version4 + 1);\n\n    // split the region\n    pd_client.must_split_region(region, pdpb::CheckPolicy::Usekey, vec![b\"k11\".to_vec()]);\n    let mut buckets = vec![Bucket {\n        keys: vec![b\"k10\".to_vec()],\n        size: 1024 * 1024 * 65, // not small enough to merge with left\n    }];\n\n    expected_buckets.set_keys(vec![vec![], b\"k10\".to_vec(), b\"k11\".to_vec()].into());\n\n    let mut region = pd_client.get_region(b\"k10\").unwrap();\n    let left_id = region.get_id();\n    let right = pd_client.get_region(b\"k12\").unwrap();\n    if region.get_id() != 1 {\n        region = right.clone();\n        buckets = vec![Bucket {\n            keys: vec![b\"k12\".to_vec()],\n            size: 1024 * 1024 * 65, // not small enough to merge with left\n        }];\n        expected_buckets.set_keys(vec![b\"k11\".to_vec(), b\"k12\".to_vec(), vec![]].into());\n    }\n\n    let bucket_version6 =\n        cluster.refresh_region_bucket_keys(&region, buckets, None, Some(expected_buckets.clone()));\n    assert_eq!(bucket_version6, bucket_version5 + 1);\n\n    // merge the region\n    pd_client.must_merge(left_id, right.get_id());\n    let region = pd_client.get_region(b\"k10\").unwrap();\n    let buckets = vec![Bucket {\n        keys: vec![b\"k10\".to_vec()],\n        size: 1024 * 1024 * 65, // not small enough to merge with left\n    }];\n\n    expected_buckets.set_keys(vec![vec![], b\"k10\".to_vec(), vec![]].into());\n    let bucket_version7 =\n        cluster.refresh_region_bucket_keys(&region, buckets, None, Some(expected_buckets.clone()));\n    assert_eq!(bucket_version7, bucket_version6 + 1);\n\n    let bucket_version8 = cluster.refresh_region_bucket_keys(\n        &region,\n        vec![],\n        Some(vec![]),\n        Some(expected_buckets.clone()),\n    );\n    // no change on buckets, the bucket version is not changed.\n    assert_eq!(bucket_version8, bucket_version7)\n}"}
{"test_id": "raphlinus-pulldown-cmark/raphlinus-pulldown-cmark-3da63d5/tests/lib.rs::leaves_nonempty_tbody", "code": "fn normalize_html(s: &str) -> String {\n    let parser = make_html_parser();\n    let dom = parser.one(s);\n    let body: SerializableHandle = normalize_dom(&dom).into();\n    let opts = SerializeOpts::default();\n    let mut ret_val = Vec::new();\n    serialize(&mut ret_val, &body, opts)\n        .expect(\"Writing to a string shouldn't fail (expect on OOM)\");\n    String::from_utf8(ret_val).expect(\"html5ever should always produce UTF8\")\n}", "test": "fn leaves_nonempty_tbody() {\n    let input = \"<table><thead><tr><td>hi</td></tr></thead><tbody><tr></tr></tbody></table>\";\n    assert_eq!(input, normalize_html(input))\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_fold.rs::test_fold_at_word_boundary_preserve_final_newline", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_fold_at_word_boundary_preserve_final_newline() {\n    new_ucmd!()\n        .args(&[\"-w4\", \"-s\"])\n        .pipe_in(\"one two\\n\")\n        .succeeds()\n        .stdout_is(\"one \\ntwo\\n\");\n}"}
{"test_id": "raphlinus-pulldown-cmark/raphlinus-pulldown-cmark-3da63d5/tests/lib.rs::strip_inline_internal_text", "code": "fn normalize_html(s: &str) -> String {\n    let parser = make_html_parser();\n    let dom = parser.one(s);\n    let body: SerializableHandle = normalize_dom(&dom).into();\n    let opts = SerializeOpts::default();\n    let mut ret_val = Vec::new();\n    serialize(&mut ret_val, &body, opts)\n        .expect(\"Writing to a string shouldn't fail (expect on OOM)\");\n    String::from_utf8(ret_val).expect(\"html5ever should always produce UTF8\")\n}", "test": "fn strip_inline_internal_text() {\n    assert_eq!(\n        \"<u>a </u>b <u>c</u>\",\n        normalize_html(\"<u> a </u> b <u> c </u>\")\n    )\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_seq.rs::test_drop_negative_zero_end", "code": "pub fn no_stderr(&self) -> &Self {\n        assert!(\n            self.stderr.is_empty(),\n            \"Expected stderr to be empty, but it's:\\n{}\",\n            self.stderr_str()\n        );\n        self\n    }", "test": "fn test_drop_negative_zero_end() {\n    new_ucmd!()\n        .args(&[\"1\", \"-1\", \"-0\"])\n        .succeeds()\n        .stdout_is(\"1\\n0\\n\")\n        .no_stderr();\n}"}
{"test_id": "quinn-rs-quinn/quinn-rs-quinn-83e4f46/quinn-proto/src/tests/mod.rs::stream_id_limit", "code": "fn open<'a>(\n        &self,\n        data: &'a mut [u8],\n        additional_data: &[u8],\n    ) -> Result<&'a mut [u8], CryptoError> {\n        let aad = ring::aead::Aad::from(additional_data);\n        let zero_nonce = ring::aead::Nonce::assume_unique_for_key([0u8; 12]);\n        Ok(self.open_in_place(zero_nonce, aad, data)?)\n    }", "test": "fn stream_id_limit() {\n    let _guard = subscribe();\n    let server = ServerConfig {\n        transport: Arc::new(TransportConfig {\n            max_concurrent_uni_streams: 1u32.into(),\n            ..TransportConfig::default()\n        }),\n        ..server_config()\n    };\n    let mut pair = Pair::new(Default::default(), server);\n    let (client_ch, server_ch) = pair.connect();\n\n    let s = pair\n        .client\n        .connections\n        .get_mut(&client_ch)\n        .unwrap()\n        .streams()\n        .open(Dir::Uni)\n        .expect(\"couldn't open first stream\");\n    assert_eq!(\n        pair.client_streams(client_ch).open(Dir::Uni),\n        None,\n        \"only one stream is permitted at a time\"\n    );\n    // Generate some activity to allow the server to see the stream\n    const MSG: &[u8] = b\"hello\";\n    pair.client_send(client_ch, s).write(MSG).unwrap();\n    pair.client_send(client_ch, s).finish().unwrap();\n    pair.drive();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Stream(StreamEvent::Finished { id })) if id == s\n    );\n    assert_eq!(\n        pair.client_streams(client_ch).open(Dir::Uni),\n        None,\n        \"server does not immediately grant additional credit\"\n    );\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))\n    );\n    assert_matches!(pair.server_streams(server_ch).accept(Dir::Uni), Some(stream) if stream == s);\n\n    let mut recv = pair.server_recv(server_ch, s);\n    let mut chunks = recv.read(false).unwrap();\n    assert_matches!(\n        chunks.next(usize::MAX),\n        Ok(Some(chunk)) if chunk.offset == 0 && chunk.bytes == MSG\n    );\n    assert_eq!(chunks.next(usize::MAX), Ok(None));\n    let _ = chunks.finalize();\n\n    // Server will only send MAX_STREAM_ID now that the application's been notified\n    pair.drive();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Stream(StreamEvent::Available { dir: Dir::Uni }))\n    );\n    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);\n\n    // Try opening the second stream again, now that we've made room\n    let s = pair\n        .client\n        .connections\n        .get_mut(&client_ch)\n        .unwrap()\n        .streams()\n        .open(Dir::Uni)\n        .expect(\"didn't get stream id budget\");\n    pair.client_send(client_ch, s).finish().unwrap();\n    pair.drive();\n    // Make sure the server actually processes data on the newly-available stream\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))\n    );\n    assert_matches!(pair.server_streams(server_ch).accept(Dir::Uni), Some(stream) if stream == s);\n    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);\n\n    let mut recv = pair.server_recv(server_ch, s);\n    let mut chunks = recv.read(false).unwrap();\n    assert_matches!(chunks.next(usize::MAX), Ok(None));\n    let _ = chunks.finalize();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_touch.rs::test_touch_set_only_mtime_failed", "code": "pub fn fails(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.failure();\n        cmd_result\n    }", "test": "fn test_touch_set_only_mtime_failed() {\n    let (_at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_only_mtime\";\n\n    ucmd.args(&[\"-t\", \"2015010112342\", \"-m\", file]).fails();\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_rawkv.rs::test_leader_transfer", "code": "pub fn must_raw_get(&self, k: Vec<u8>, cf: String) -> Vec<u8> {\n        let mut request = RawGetRequest::default();\n        let mut context = self.context.clone();\n        if context.api_version == ApiVersion::V1ttl {\n            context.api_version = ApiVersion::V1;\n        }\n        request.set_context(context);\n        request.set_key(k);\n        request.set_cf(cf);\n        let mut response = self.tikv_cli.raw_get(&request).unwrap();\n        retry_req!(\n            self.tikv_cli.raw_get(&request).unwrap(),\n            !response.has_region_error() && response.error.is_empty(),\n            response,\n            10,   // retry 10 times\n            1000  // 1s timeout\n        );\n        assert!(response.error.is_empty(), \"{:?}\", response.get_error());\n        response.take_value()\n    }", "test": "fn test_leader_transfer() {\n    let mut suite = TestSuite::new(3, ApiVersion::V2);\n    let key1 = b\"rk1\";\n    let region = suite.cluster.get_region(key1);\n\n    // Transfer leader and write to store 1.\n    {\n        suite.must_transfer_leader(&region, 1);\n        let leader1 = suite.must_leader_on_store(key1, 1);\n\n        suite.must_raw_put(key1, b\"v1\");\n        suite.must_raw_put(key1, b\"v2\");\n        suite.must_raw_put(key1, b\"v3\");\n        suite.flush_timestamp(leader1.get_store_id()); // Flush to make ts bigger than other stores.\n        suite.must_raw_put(key1, b\"v4\");\n        assert_eq!(suite.must_raw_get(key1), Some(b\"v4\".to_vec()));\n    }\n\n    // Make causal_ts_provider.async_flush() & handle_update_max_timestamp fail.\n    fail::cfg(FP_GET_TSO, \"return(50)\").unwrap();\n\n    // Transfer leader and write to store 2.\n    {\n        suite.must_transfer_leader(&region, 2);\n        suite.must_leader_on_store(key1, 2);\n\n        // Store 2 has a TSO batch smaller than store 1.\n        suite.raw_put_err_by_timestamp_not_synced(key1, b\"v5\");\n        assert_eq!(suite.must_raw_get(key1), Some(b\"v4\".to_vec()));\n        suite.raw_put_err_by_timestamp_not_synced(key1, b\"v6\");\n        assert_eq!(suite.must_raw_get(key1), Some(b\"v4\".to_vec()));\n    }\n\n    // Transfer leader back.\n    suite.must_transfer_leader(&region, 1);\n    suite.must_leader_on_store(key1, 1);\n    // Make handle_update_max_timestamp succeed.\n    fail::cfg(FP_GET_TSO, \"off\").unwrap();\n    // Transfer leader and write to store 2 again.\n    {\n        suite.must_transfer_leader(&region, 2);\n        suite.must_leader_on_store(key1, 2);\n\n        suite.must_raw_put(key1, b\"v7\");\n        assert_eq!(suite.must_raw_get(key1), Some(b\"v7\".to_vec()));\n        suite.must_raw_put(key1, b\"v8\");\n        assert_eq!(suite.must_raw_get(key1), Some(b\"v8\".to_vec()));\n    }\n\n    fail::remove(FP_GET_TSO);\n    suite.stop();\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/threads.rs::test_export_shared_memory", "code": "pub fn size(&self, store: impl AsContext) -> u64 {\n        self.internal_size(store.as_context().0)\n    }", "test": "fn test_export_shared_memory() -> Result<()> {\n    let wat = r#\"(module (memory (export \"memory\") 1 5 shared))\"#;\n    let mut config = Config::new();\n    config.wasm_threads(true);\n    let engine = Engine::new(&config)?;\n    let module = Module::new(&engine, wat)?;\n    let mut store = Store::new(&engine, ());\n    let instance = Instance::new(&mut store, &module, &[])?;\n    let shared_memory = instance.get_shared_memory(&mut store, \"memory\").unwrap();\n\n    assert_eq!(shared_memory.size(), 1);\n    assert!(shared_memory.ty().is_shared());\n    assert_eq!(shared_memory.ty().maximum(), Some(5));\n\n    Ok(())\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/cases/config_extends.rs::extends_config_ok_linter_not_formatter", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn extends_config_ok_linter_not_formatter() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let rome_json = Path::new(\"biome.json\");\n    fs.insert(\n        rome_json.into(),\n        r#\"{ \"extends\": [\"format.json\", \"linter.json\"] }\"#,\n    );\n    let format = Path::new(\"format.json\");\n    fs.insert(format.into(), r#\"{ \"formatter\": { \"enabled\": true } }\"#);\n    let lint = Path::new(\"linter.json\");\n    fs.insert(\n        lint.into(),\n        r#\"{\n  \"linter\": {\n    \"rules\": {\n      \"all\": false,\n      \"suspicious\": {\n        \"noDebugger\": \"warn\"\n      }\n    }\n  }\n}\n        \"#,\n    );\n\n    let test_file = Path::new(\"test.js\");\n    fs.insert(test_file.into(), r#\"debugger; console.log(\"string\"); \"#);\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"check\"), test_file.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"extends_config_ok_linter_not_formatter\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_coprocessor.rs::test_region_error_in_scan", "code": "pub fn contains(&self, op: IoOp) -> bool {\n        match *self {\n            IoRateLimitMode::WriteOnly => op == IoOp::Write,\n            IoRateLimitMode::ReadOnly => op == IoOp::Read,\n            _ => true,\n        }\n    }", "test": "fn test_region_error_in_scan() {\n    let data = vec![\n        (1, Some(\"name:0\"), 2),\n        (2, Some(\"name:4\"), 3),\n        (4, Some(\"name:3\"), 1),\n        (5, Some(\"name:1\"), 4),\n    ];\n\n    let product = ProductTable::new();\n    let (_cluster, raft_engine, mut ctx) = new_raft_engine(1, \"\");\n    ctx.set_isolation_level(IsolationLevel::Si);\n\n    let (_, endpoint, _) =\n        init_data_with_engine_and_commit(ctx.clone(), raft_engine, &product, &data, true);\n\n    fail::cfg(\"region_snapshot_seek\", \"return()\").unwrap();\n    let req = DagSelect::from(&product).build_with(ctx, &[0]);\n    let resp = handle_request(&endpoint, req);\n\n    assert!(\n        resp.get_region_error()\n            .get_message()\n            .contains(\"region seek error\")\n    );\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/engine_traits_tests/src/misc.rs::path", "code": "pub fn path(mut self, path: impl AsRef<Path>) -> Self {\n        self.path = Some(path.as_ref().to_path_buf());\n        self\n    }", "test": "fn path() {\n    let db = default_engine();\n    let path = db.tempdir.path().to_str().unwrap();\n    assert_eq!(db.engine.path(), path);\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/control_flow/loops.rs::while_loop_late_break", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn while_loop_late_break() {\n    // Ordering with statement before the break.\n    run_test_actions([TestAction::assert_eq(\n        indoc! {r#\"\n            let a = 1;\n            while (a < 5) {\n                a++;\n                if (a == 3) {\n                    break;\n                }\n            }\n            a;\n        \"#},\n        3,\n    )]);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_seq.rs::test_rejects_non_floats", "code": "pub fn usage_error<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.stderr_only(format!(\n            \"{0}: {2}\\nTry '{1} {0} --help' for more information.\\n\",\n            self.util_name.as_ref().unwrap(), // This shouldn't be called using a normal command\n            self.bin_path.display(),\n            msg.as_ref()\n        ))\n    }", "test": "fn test_rejects_non_floats() {\n    new_ucmd!()\n        .arg(\"foo\")\n        .fails()\n        .usage_error(\"invalid floating point argument: 'foo'\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_multiple_files", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_multiple_files() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .arg(TEST_COPY_TO_FOLDER)\n        .succeeds();\n\n    assert_eq!(at.read(TEST_COPY_TO_FOLDER_FILE), \"Hello, World!\\n\");\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_DEST), \"How are you?\\n\");\n}"}
{"test_id": "dtolnay-syn/dtolnay-syn-b1a038c/tests/test_parse_stream.rs::test_peek", "code": "fn peek(cursor: Cursor) -> bool {\n            if let Some((ident, _rest)) = cursor.ident() {\n                accept_as_ident(&ident)\n            } else {\n                false\n            }\n        }", "test": "fn test_peek() {\n    let _ = |input: ParseStream| {\n        let _ = input.peek(Ident);\n        let _ = input.peek(Ident::peek_any);\n        let _ = input.peek(Token![::]);\n    };\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/server/kv_service.rs::test_double_run_node", "code": "pub fn contains(&self, op: IoOp) -> bool {\n        match *self {\n            IoRateLimitMode::WriteOnly => op == IoOp::Write,\n            IoRateLimitMode::ReadOnly => op == IoOp::Read,\n            _ => true,\n        }\n    }", "test": "fn test_double_run_node() {\n    let count = 1;\n    let mut cluster = new_node_cluster(0, count);\n    cluster.run();\n    let id = *cluster.engines.keys().next().unwrap();\n    let engines = cluster.engines.values().next().unwrap().clone();\n    let router = cluster.sim.rl().get_router(id).unwrap();\n    let mut sim = cluster.sim.wl();\n    let node = sim.get_node(id).unwrap();\n    let pd_worker = LazyWorker::new(\"test-pd-worker\");\n    let simulate_trans = SimulateTransport::new(ChannelTransport::new());\n    let tmp = Builder::new().prefix(\"test_cluster\").tempdir().unwrap();\n    let snap_mgr = SnapManager::new(tmp.path().to_str().unwrap());\n    let coprocessor_host = CoprocessorHost::new(router, raftstore::coprocessor::Config::default());\n    let importer = {\n        let dir = Path::new(MiscExt::path(&engines.kv)).join(\"import-sst\");\n        Arc::new(SstImporter::new(&ImportConfig::default(), dir, None, ApiVersion::V1).unwrap())\n    };\n    let (split_check_scheduler, _) = dummy_scheduler();\n\n    let store_meta = Arc::new(Mutex::new(StoreMeta::new(20)));\n    let e = node\n        .start(\n            engines,\n            simulate_trans,\n            snap_mgr,\n            pd_worker,\n            store_meta,\n            coprocessor_host,\n            importer,\n            split_check_scheduler,\n            AutoSplitController::default(),\n            ConcurrencyManager::new(1.into()),\n            CollectorRegHandle::new_for_test(),\n            None,\n            Arc::new(AtomicU64::new(0)),\n        )\n        .unwrap_err();\n    assert!(format!(\"{:?}\", e).contains(\"already started\"), \"{:?}\", e);\n    drop(sim);\n    cluster.shutdown();\n}"}
{"test_id": "web-infra-dev-oxc/oxc-project-oxc-884a819/crates/oxc_minifier/tests/terser/mod.rs::test", "code": "pub fn is_empty(&self) -> bool {\n        self.body.is_empty() && self.directives.is_empty()\n    }", "test": "fn test() {\n    let files = WalkDir::new(\"tests/terser/fixtures\")\n        .into_iter()\n        .filter_map(Result::ok)\n        .filter(|e| !e.file_type().is_dir())\n        .collect::<Vec<_>>();\n    assert!(!files.is_empty());\n    for file in files {\n        let path = file.path();\n        let source_text = std::fs::read_to_string(path).unwrap();\n        let source_type = SourceType::from_path(path).unwrap();\n        let allocator = Allocator::default();\n        let parser_return = Parser::new(&allocator, &source_text, source_type).parse();\n        let program = allocator.alloc(parser_return.program);\n        TestSuite::from_program(&source_text, program).execute_tests();\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_fold.rs::test_bytewise_should_preserve_final_newline_when_line_longer_than_fold", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_bytewise_should_preserve_final_newline_when_line_longer_than_fold() {\n    new_ucmd!()\n        .args(&[\"-w2\", \"-b\"])\n        .pipe_in(\"1234\\n\")\n        .succeeds()\n        .stdout_is(\"12\\n34\\n\");\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/check.rs::maximum_diagnostics", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn maximum_diagnostics() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n    let file_path = Path::new(\"check.js\");\n    fs.insert(file_path.into(), ERRORS.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"check\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let messages = &console.out_buffer;\n\n    assert_eq!(\n        messages\n            .iter()\n            .filter(|m| m.level == LogLevel::Error)\n            .count(),\n        20_usize\n    );\n\n    assert!(messages\n        .iter()\n        .filter(|m| m.level == LogLevel::Log)\n        .any(|m| {\n            let content = format!(\"{:?}\", m.content);\n            content.contains(\"The number of diagnostics exceeds the number allowed by Biome\")\n                && content.contains(\"Diagnostics not shown\")\n                && content.contains(\"79\")\n        }));\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"maximum_diagnostics\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "cberner-redb/cberner-redb-267b473/tests/basic_tests.rs::owned_get_signatures", "code": "fn get<'a>(&self, key: impl Borrow<K::SelfType<'a>>) -> Result<MultimapValue<V>>\n    where\n        K: 'a,\n    {\n        let iter = if let Some(collection) = self.tree.get(key.borrow())? {\n            DynamicCollection::iter(collection, self.mem)?\n        } else {\n            MultimapValue::new_subtree(BtreeRangeIter::new::<RangeFull, &V::SelfType<'_>>(\n                &(..),\n                None,\n                self.mem,\n            )?)\n        };\n\n        Ok(iter)\n    }", "test": "fn owned_get_signatures() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let definition: TableDefinition<u32, u32> = TableDefinition::new(\"x\");\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(definition).unwrap();\n        for i in 0..10 {\n            table.insert(&i, &(i + 1)).unwrap();\n        }\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(definition).unwrap();\n\n    assert_eq!(2, table.get(&1).unwrap().unwrap().value());\n\n    let mut iter: Range<u32, u32> = table.range::<u32>(..).unwrap();\n    for i in 0..10 {\n        assert_eq!(iter.next().unwrap().unwrap().1.value(), i + 1);\n    }\n    assert!(iter.next().is_none());\n    let mut iter: Range<u32, u32> = table.range(0..10).unwrap();\n    for i in 0..10 {\n        assert_eq!(iter.next().unwrap().unwrap().1.value(), i + 1);\n    }\n    assert!(iter.next().is_none());\n    let mut iter = table.range::<&u32>(&0..&10).unwrap();\n    for i in 0..10 {\n        assert_eq!(iter.next().unwrap().unwrap().1.value(), i + 1);\n    }\n    assert!(iter.next().is_none());\n}"}
{"test_id": "cberner-redb/cberner-redb-267b473/tests/basic_tests.rs::array_type", "code": "fn get<'a>(&self, key: impl Borrow<K::SelfType<'a>>) -> Result<MultimapValue<V>>\n    where\n        K: 'a,\n    {\n        let iter = if let Some(collection) = self.tree.get(key.borrow())? {\n            DynamicCollection::iter(collection, self.mem)?\n        } else {\n            MultimapValue::new_subtree(BtreeRangeIter::new::<RangeFull, &V::SelfType<'_>>(\n                &(..),\n                None,\n                self.mem,\n            )?)\n        };\n\n        Ok(iter)\n    }", "test": "fn array_type() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let definition: TableDefinition<&[u8; 5], &[u8; 9]> = TableDefinition::new(\"x\");\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(definition).unwrap();\n        table.insert(b\"hello\", b\"world_123\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(definition).unwrap();\n    let hello = b\"hello\";\n    assert_eq!(b\"world_123\", table.get(hello).unwrap().unwrap().value());\n\n    let mut iter: Range<&[u8; 5], &[u8; 9]> = table.range::<&[u8; 5]>(..).unwrap();\n    assert_eq!(iter.next().unwrap().unwrap().1.value(), b\"world_123\");\n    assert!(iter.next().is_none());\n}"}
{"test_id": "cberner-redb/cberner-redb-267b473/tests/integration_tests.rs::regression10", "code": "fn new () -> Self { Self { savepoints : vec ! [] , uncommitted_persistent : Default :: default () , persistent_countdown : MAX_PERSISTENT_SAVEPOINTS , } }", "test": "fn regression10() {\n    let tmpfile = create_tempfile();\n\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let table_def: TableDefinition<u64, &[u8]> = TableDefinition::new(\"x\");\n\n    let tx = db.begin_write().unwrap();\n    {\n        let mut t = tx.open_table(table_def).unwrap();\n        let v = vec![0u8; 1043];\n        t.insert(&118749, v.as_slice()).unwrap();\n    }\n    tx.commit().unwrap();\n\n    let tx = db.begin_write().unwrap();\n    {\n        let mut t = tx.open_table(table_def).unwrap();\n        let v = vec![0u8; 952];\n        t.insert(&118757, v.as_slice()).unwrap();\n    }\n    tx.abort().unwrap();\n\n    let tx = db.begin_write().unwrap();\n    {\n        let t = tx.open_table(table_def).unwrap();\n        t.get(&829513).unwrap();\n    }\n    tx.abort().unwrap();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_split.rs::test_split_str_prefixed_chunks_by_bytes", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_str_prefixed_chunks_by_bytes() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"split_str_prefixed_chunks_by_bytes\";\n    RandomFile::new(&at, name).add_bytes(10000);\n    // Important that this is less than 1024 since that's our internal buffer\n    // size. Good to test that we don't overshoot.\n    ucmd.args(&[\"-b\", \"1000\", name, \"b\"]).succeeds();\n\n    let glob = Glob::new(&at, \".\", r\"b[[:alpha:]][[:alpha:]]$\");\n    assert_eq!(glob.count(), 10);\n    for filename in glob.collect() {\n        assert_eq!(glob.directory.metadata(&filename).len(), 1000);\n    }\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/functions.rs::path_exists_subdir", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn path_exists_subdir() {\n  Test::new()\n    .tree(tree! {\n      foo: \"\",\n      bar: {\n      }\n    })\n    .justfile(\"x := path_exists('foo')\")\n    .current_dir(\"bar\")\n    .args([\"--evaluate\", \"x\"])\n    .stdout(\"true\")\n    .run();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_pathchk.rs::test_default_mode", "code": "pub fn no_stdout(&self) -> &Self {\n        assert!(\n            self.stdout.is_empty(),\n            \"Expected stdout to be empty, but it's:\\n{}\",\n            self.stdout_str()\n        );\n        self\n    }", "test": "fn test_default_mode() {\n    // test the default mode\n\n    // accept some reasonable default\n    new_ucmd!().args(&[\"dir/file\"]).succeeds().no_stdout();\n\n    // accept non-portable chars\n    new_ucmd!().args(&[\"dir#/$file\"]).succeeds().no_stdout();\n\n    // accept empty path\n    new_ucmd!().args(&[\"\"]).succeeds().no_stdout();\n\n    // fail on long path\n    new_ucmd!()\n        .args(&[\"dir\".repeat(libc::PATH_MAX as usize + 1)])\n        .fails()\n        .no_stdout();\n\n    // fail on long filename\n    new_ucmd!()\n        .args(&[format!(\n            \"dir/{}\",\n            \"file\".repeat(libc::FILENAME_MAX as usize + 1)\n        )])\n        .fails()\n        .no_stdout();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cut.rs::test_invalid_arg", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_invalid_arg() {\n    new_ucmd!().arg(\"--definitely-invalid\").fails().code_is(1);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_du.rs::test_du_soft_link", "code": "pub fn stdout_str(&self) -> &str {\n        std::str::from_utf8(&self.stdout).unwrap()\n    }", "test": "fn test_du_soft_link() {\n    let ts = TestScenario::new(util_name!());\n    let at = &ts.fixtures;\n\n    at.symlink_file(SUB_FILE, SUB_LINK);\n\n    let result = ts.ucmd().arg(SUB_DIR_LINKS).succeeds();\n\n    #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n    {\n        let result_reference = unwrap_or_return!(expected_result(&ts, &[SUB_DIR_LINKS]));\n        if result_reference.succeeded() {\n            assert_eq!(result.stdout_str(), result_reference.stdout_str());\n            return;\n        }\n    }\n    _du_soft_link(result.stdout_str());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_sparse_invalid_option", "code": "pub fn fails(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.failure();\n        cmd_result\n    }", "test": "fn test_cp_sparse_invalid_option() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    at.make_file(\"src_file1\");\n\n    ucmd.args(&[\"--sparse=invalid\", \"src_file1\", \"dst_file\"])\n        .fails();\n}"}
{"test_id": "tafia-calamine/tafia-calamine-5a5804d/tests/test.rs::special_cells", "code": "fn worksheet_range(&mut self, name: &str) -> Option<Result<Range<DataType>, XlsError>> {\n        self.sheets.get(name).map(|r| Ok(r.0.clone()))\n    }", "test": "fn special_cells() {\n    let path = format!(\"{}/tests/special_cells.ods\", env!(\"CARGO_MANIFEST_DIR\"));\n    let mut excel: Ods<_> = open_workbook(&path).unwrap();\n\n    let range = excel.worksheet_range(\"sheet1\").unwrap().unwrap();\n    range_eq!(\n        range,\n        [\n            [String(\"Split\\nLine\".to_string())],\n            [String(\"Value  With spaces\".to_string())],\n            [String(\"Value   With 3 spaces\".to_string())],\n            [String(\" Value   With spaces before and after \".to_string())],\n            [String(\n                \"  Value   With 2 spaces before and after  \".to_string()\n            )],\n        ]\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_dd.rs::test_oversized_bs_32_bit", "code": "pub fn stderr_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stderr_str(), msg.as_ref());\n        self\n    }", "test": "fn test_oversized_bs_32_bit() {\n    for bs_param in [\"bs\", \"ibs\", \"obs\", \"cbs\"] {\n        new_ucmd!()\n            .args(&[format!(\"{}=5GB\", bs_param)])\n            .run()\n            .no_stdout()\n            .failure()\n            .code_is(1)\n            .stderr_is(format!(\"dd: {}=N cannot fit into memory\\n\", bs_param));\n    }\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/raftstore-v2/tests/integrations/test_conf_change.rs::test_remove_by_conf_change", "code": "pub fn has_error(&self) -> bool {\n        self.error.is_some()\n    }", "test": "fn test_remove_by_conf_change() {\n    let cluster = Cluster::with_node_count(2, None);\n    let (region_id, peer_id, offset_id) = (2, 10, 1);\n    let mut req = add_learner(&cluster, offset_id, region_id, peer_id);\n\n    // write one kv to make flow control replicated.\n    let (key, val) = (b\"key\", b\"value\");\n    write_kv(&cluster, region_id, key, val);\n\n    let new_conf_ver = req.get_header().get_region_epoch().get_conf_ver() + 1;\n    req.mut_header()\n        .mut_region_epoch()\n        .set_conf_ver(new_conf_ver);\n    req.mut_admin_request()\n        .mut_change_peer()\n        .set_change_type(ConfChangeType::RemoveNode);\n    let (admin_msg, admin_sub) = PeerMsg::admin_command(req.clone());\n    // write one kv after removal\n    let (key, val) = (b\"key1\", b\"value\");\n    let header = Box::new(cluster.routers[0].new_request_for(region_id).take_header());\n    let mut put = SimpleWriteEncoder::with_capacity(64);\n    put.put(CF_DEFAULT, key, val);\n    let (msg, sub) = PeerMsg::simple_write(header, put.encode());\n    // Send them at the same time so they will be all sent to learner.\n    cluster.routers[0].send(region_id, admin_msg).unwrap();\n    cluster.routers[0].send(region_id, msg).unwrap();\n    let resp = block_on(admin_sub.result()).unwrap();\n    assert!(!resp.get_header().has_error(), \"{:?}\", resp);\n    let resp = block_on(sub.result()).unwrap();\n    assert!(!resp.get_header().has_error(), \"{:?}\", resp);\n\n    // Dispatch messages so the learner will receive conf remove and write at the\n    // same time.\n    cluster.dispatch(region_id, vec![]);\n    cluster.routers[1].wait_flush(region_id, Duration::from_millis(300));\n    // Wait for apply.\n    std::thread::sleep(Duration::from_millis(100));\n    let raft_engine = &cluster.node(1).running_state().unwrap().raft_engine;\n    let region_state = raft_engine\n        .get_region_state(region_id, u64::MAX)\n        .unwrap()\n        .unwrap();\n    assert_eq!(region_state.get_state(), PeerState::Tombstone);\n    assert_eq!(raft_engine.get_raft_state(region_id).unwrap(), None);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_ln.rs::test_symlink_implicit_target_dir", "code": "pub fn no_stderr(&self) -> &Self {\n        assert!(\n            self.stderr.is_empty(),\n            \"Expected stderr to be empty, but it's:\\n{}\",\n            self.stderr_str()\n        );\n        self\n    }", "test": "fn test_symlink_implicit_target_dir() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_symlink_implicit_target_dir\";\n    // On windows, slashes aren't allowed in symlink targets, so use\n    // PathBuf to construct `file` instead of simple \"dir/file\".\n    let filename = \"test_symlink_implicit_target_file\";\n    let path = PathBuf::from(dir).join(filename);\n    let file = &path.to_string_lossy();\n\n    at.mkdir(dir);\n    at.touch(&path);\n\n    ucmd.args(&[\"-s\", file]).succeeds().no_stderr();\n\n    assert!(at.file_exists(filename));\n    assert!(at.is_symlink(filename));\n    assert_eq!(at.resolve_link(filename), *file);\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_gc/src/test/allocation.rs::gc_basic_cell_allocation", "code": "pub fn borrow_mut(&self) -> GcRefMut<'_, T> {\n        match self.try_borrow_mut() {\n            Ok(value) => value,\n            Err(e) => panic!(\"{}\", e),\n        }\n    }", "test": "fn gc_basic_cell_allocation() {\n    run_test(|| {\n        let gc_cell = Gc::new(GcRefCell::new(16_u16));\n\n        force_collect();\n        Harness::assert_collections(1);\n        Harness::assert_bytes_allocated();\n        assert_eq!(*gc_cell.borrow_mut(), 16);\n    });\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/storage/test_raft_storage.rs::test_raft_storage_get_after_lease", "code": "pub fn to_vec(self) -> Vec<u8> {\n        if self.is_empty() {\n            return vec![];\n        }\n        let ctx = self.bits();\n        vec![ctx]\n    }", "test": "fn test_raft_storage_get_after_lease() {\n    let (cluster, storage, ctx) = new_raft_storage();\n    let key = b\"key\";\n    let value = b\"value\";\n    assert_eq!(\n        storage\n            .raw_get(ctx.clone(), \"\".to_string(), key.to_vec())\n            .unwrap(),\n        None\n    );\n    storage\n        .raw_put(ctx.clone(), \"\".to_string(), key.to_vec(), value.to_vec())\n        .unwrap();\n    assert_eq!(\n        storage\n            .raw_get(ctx.clone(), \"\".to_string(), key.to_vec())\n            .unwrap()\n            .unwrap(),\n        value.to_vec()\n    );\n\n    // Sleep until the leader lease is expired.\n    thread::sleep(cluster.cfg.raft_store.raft_store_max_leader_lease.0);\n    assert_eq!(\n        storage\n            .raw_get(ctx, \"\".to_string(), key.to_vec())\n            .unwrap()\n            .unwrap(),\n        value.to_vec()\n    );\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_coprocessor.rs::test_parse_request_failed", "code": "pub fn contains(&self, op: IoOp) -> bool {\n        match *self {\n            IoRateLimitMode::WriteOnly => op == IoOp::Write,\n            IoRateLimitMode::ReadOnly => op == IoOp::Read,\n            _ => true,\n        }\n    }", "test": "fn test_parse_request_failed() {\n    let product = ProductTable::new();\n    let (_, endpoint) = init_with_data(&product, &[]);\n    let req = DagSelect::from(&product).build();\n\n    fail::cfg(\"coprocessor_parse_request\", \"return()\").unwrap();\n    let resp = handle_request(&endpoint, req);\n\n    assert!(resp.get_other_error().contains(\"unsupported tp\"));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_test.rs::test_negative_int_compare", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_negative_int_compare() {\n    let scenario = TestScenario::new(util_name!());\n\n    let tests = [\n        [\"-1\", \"-eq\", \"-1\"],\n        [\"-1\", \"-ne\", \"-2\"],\n        [\"-3720\", \"-lt\", \"-421\"],\n        [\"-10\", \"-le\", \"-10\"],\n        [\"-21\", \"-gt\", \"-22\"],\n        [\"-128\", \"-ge\", \"-256\"],\n        [\"-9223372036854775808\", \"-le\", \"-9223372036854775807\"],\n    ];\n\n    for test in &tests {\n        scenario.ucmd().args(&test[..]).succeeds();\n    }\n\n    // run the inverse of all these tests\n    for test in &tests {\n        scenario.ucmd().arg(\"!\").args(&test[..]).run().code_is(1);\n    }\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/format.rs::file_too_large_config_limit", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn file_too_large_config_limit() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    fs.insert(PathBuf::from(\"biome.json\"), CONFIG_FILE_SIZE_LIMIT);\n\n    let file_path = Path::new(\"format.js\");\n    fs.insert(file_path.into(), \"statement1();\\nstatement2();\");\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"format\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"file_too_large_config_limit\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/engine_traits_tests/src/write_batch.rs::write_batch_delete_range_after_put", "code": "fn get_value(&self, key: &[u8]) -> Result<Option<Self::DbVector>> {\n        self.get_value_opt(&ReadOptions::default(), key)\n    }", "test": "fn write_batch_delete_range_after_put() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch();\n\n    wb.put(b\"a\", b\"\").unwrap();\n    wb.put(b\"b\", b\"\").unwrap();\n    wb.put(b\"c\", b\"\").unwrap();\n    wb.put(b\"d\", b\"\").unwrap();\n    wb.put(b\"e\", b\"\").unwrap();\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"d\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"e\").unwrap().is_some());\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(1024);\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"a\", b\"\").unwrap();\n    wb.put(b\"b\", b\"\").unwrap();\n    wb.put(b\"c\", b\"\").unwrap();\n    wb.put(b\"d\", b\"\").unwrap();\n    wb.put(b\"e\", b\"\").unwrap();\n    wb.delete_range(&1_usize.to_be_bytes(), &255_usize.to_be_bytes())\n        .unwrap();\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.write().unwrap();\n\n    assert!(\n        db.engine\n            .get_value(&0_usize.to_be_bytes())\n            .unwrap()\n            .is_some()\n    );\n    for i in 1..255_usize {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n    assert!(\n        db.engine\n            .get_value(&255_usize.to_be_bytes())\n            .unwrap()\n            .is_some()\n    );\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"d\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"e\").unwrap().is_some());\n}"}
{"test_id": "serde-rs-json/serde-rs-json-66f862f/tests/test.rs::test_effectively_string_keys", "code": "fn test_parse_ok<T>(tests: Vec<(&str, T)>)\nwhere\n    T: Clone + Debug + PartialEq + ser::Serialize + de::DeserializeOwned,\n{\n    for (s, value) in tests {\n        let v: T = from_str(s).unwrap();\n        assert_eq!(v, value.clone());\n\n        let v: T = from_slice(s.as_bytes()).unwrap();\n        assert_eq!(v, value.clone());\n\n        // Make sure we can deserialize into a `Value`.\n        let json_value: Value = from_str(s).unwrap();\n        assert_eq!(json_value, to_value(&value).unwrap());\n\n        // Make sure we can deserialize from a `&Value`.\n        let v = T::deserialize(&json_value).unwrap();\n        assert_eq!(v, value);\n\n        // Make sure we can deserialize from a `Value`.\n        let v: T = from_value(json_value.clone()).unwrap();\n        assert_eq!(v, value);\n\n        // Make sure we can round trip back to `Value`.\n        let json_value2: Value = from_value(json_value.clone()).unwrap();\n        assert_eq!(json_value2, json_value);\n\n        // Make sure we can fully ignore.\n        let twoline = s.to_owned() + \"\\n3735928559\";\n        let mut de = Deserializer::from_str(&twoline);\n        IgnoredAny::deserialize(&mut de).unwrap();\n        assert_eq!(0xDEAD_BEEF, u64::deserialize(&mut de).unwrap());\n\n        // Make sure every prefix is an EOF error, except that a prefix of a\n        // number may be a valid number.\n        if !json_value.is_number() {\n            for (i, _) in s.trim_end().char_indices() {\n                assert!(from_str::<Value>(&s[..i]).unwrap_err().is_eof());\n                assert!(from_str::<IgnoredAny>(&s[..i]).unwrap_err().is_eof());\n            }\n        }\n    }\n}", "test": "fn test_effectively_string_keys() {\n    #[derive(Eq, PartialEq, Ord, PartialOrd, Debug, Clone, Serialize, Deserialize)]\n    enum Enum {\n        One,\n        Two,\n    }\n    let map = treemap! {\n        Enum::One => 1,\n        Enum::Two => 2,\n    };\n    let expected = r#\"{\"One\":1,\"Two\":2}\"#;\n    test_encode_ok(&[(&map, expected)]);\n    test_parse_ok(vec![(expected, map)]);\n\n    #[derive(Eq, PartialEq, Ord, PartialOrd, Debug, Clone, Serialize, Deserialize)]\n    struct Wrapper(String);\n    let map = treemap! {\n        Wrapper(\"zero\".to_owned()) => 0,\n        Wrapper(\"one\".to_owned()) => 1,\n    };\n    let expected = r#\"{\"one\":1,\"zero\":0}\"#;\n    test_encode_ok(&[(&map, expected)]);\n    test_parse_ok(vec![(expected, map)]);\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/fallback.rs::multiple_levels_of_fallback_work", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn multiple_levels_of_fallback_work() {\n  Test::new()\n    .tree(tree! {\n      a: {\n        b: {\n          justfile: \"\n            set fallback := true\n\n            foo:\n              echo subdir\n          \"\n        },\n        justfile: \"\n          set fallback := true\n\n          bar:\n            echo subdir\n        \"\n      }\n    })\n    .justfile(\n      \"\n      baz:\n        echo root\n    \",\n    )\n    .args([\"baz\"])\n    .current_dir(\"a/b\")\n    .stdout(\"root\\n\")\n    .stderr(\n      \"\n      echo root\n    \",\n    )\n    .run();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_wc.rs::test_utf8_bytes_chars_lines", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_utf8_bytes_chars_lines() {\n    new_ucmd!()\n        .arg(\"-cml\")\n        .pipe_in_fixture(\"UTF_8_weirdchars.txt\")\n        .run()\n        .stdout_is(\"     25     442     513\\n\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_merge.rs::test_node_merge_crash_before_snapshot_then_catch_up_logs", "code": "pub fn get_id(&self) -> u32 {\n        self.id\n    }", "test": "fn test_node_merge_crash_before_snapshot_then_catch_up_logs() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.cfg.raft_store.merge_max_log_gap = 10;\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(11);\n    cluster.cfg.raft_store.raft_log_gc_tick_interval = ReadableDuration::millis(50);\n    // Make merge check resume quickly.\n    cluster.cfg.raft_store.raft_base_tick_interval = ReadableDuration::millis(10);\n    cluster.cfg.raft_store.raft_election_timeout_ticks = 10;\n    // election timeout must be greater than lease\n    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(90);\n    cluster.cfg.raft_store.merge_check_tick_interval = ReadableDuration::millis(100);\n    cluster.cfg.raft_store.peer_stale_state_check_interval = ReadableDuration::millis(500);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    let on_raft_gc_log_tick_fp = \"on_raft_gc_log_tick\";\n    fail::cfg(on_raft_gc_log_tick_fp, \"return()\").unwrap();\n\n    cluster.run();\n\n    let mut region = pd_client.get_region(b\"k1\").unwrap();\n    cluster.must_split(&region, b\"k2\");\n\n    let left = pd_client.get_region(b\"k1\").unwrap();\n    let right = pd_client.get_region(b\"k2\").unwrap();\n\n    let left_on_store1 = find_peer(&left, 1).unwrap().to_owned();\n    cluster.must_transfer_leader(left.get_id(), left_on_store1);\n    let right_on_store1 = find_peer(&right, 1).unwrap().to_owned();\n    cluster.must_transfer_leader(right.get_id(), right_on_store1);\n\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    cluster.add_send_filter(IsolationFilterFactory::new(3));\n\n    pd_client.must_merge(left.get_id(), right.get_id());\n\n    region = pd_client.get_region(b\"k1\").unwrap();\n    // Write some logs and the logs' number is greater than\n    // `raft_log_gc_count_limit` for latter log compaction\n    for i in 2..15 {\n        cluster.must_put(format!(\"k{}\", i).as_bytes(), b\"v\");\n    }\n\n    // Aim at making peer 2 only know the compact log but do not know it is\n    // committed\n    let condition = Arc::new(AtomicBool::new(false));\n    let recv_filter = Box::new(\n        RegionPacketFilter::new(region.get_id(), 2)\n            .direction(Direction::Recv)\n            .when(condition.clone())\n            .set_msg_callback(Arc::new(move |msg: &RaftMessage| {\n                if !condition.load(Ordering::Acquire)\n                    && msg.get_message().get_msg_type() == MessageType::MsgAppend\n                    && !msg.get_message().get_entries().is_empty()\n                {\n                    condition.store(true, Ordering::Release);\n                }\n            })),\n    );\n    cluster.sim.wl().add_recv_filter(2, recv_filter);\n\n    let state1 = cluster.truncated_state(region.get_id(), 1);\n    // Remove log compaction failpoint\n    fail::remove(on_raft_gc_log_tick_fp);\n    // Wait to trigger compact raft log\n    cluster.wait_log_truncated(region.get_id(), 1, state1.get_index() + 1);\n\n    let peer_on_store3 = find_peer(&region, 3).unwrap().to_owned();\n    assert_eq!(peer_on_store3.get_id(), 3);\n    // Make peer 3 do not handle snapshot ready\n    // In previous implementation, destroying its source peer and applying snapshot\n    // is not atomic. So making its source peer be destroyed and do not apply\n    // snapshot to reproduce the problem\n    let before_handle_snapshot_ready_3_fp = \"before_handle_snapshot_ready_3\";\n    fail::cfg(before_handle_snapshot_ready_3_fp, \"return()\").unwrap();\n\n    cluster.clear_send_filters();\n    // Peer 1 will send snapshot to peer 3\n    // Source peer sends msg to others to get target region info until the election\n    // timeout. The max election timeout is 2 * 10 * 10 = 200ms\n    let election_timeout = 2\n        * cluster.cfg.raft_store.raft_base_tick_interval.as_millis()\n        * cluster.cfg.raft_store.raft_election_timeout_ticks as u64;\n    sleep_ms(election_timeout + 100);\n\n    cluster.stop_node(1);\n    cluster.stop_node(3);\n\n    cluster.sim.wl().clear_recv_filters(2);\n    fail::remove(before_handle_snapshot_ready_3_fp);\n    cluster.run_node(3).unwrap();\n    // Peer 2 will become leader and it don't know the compact log is committed.\n    // So it will send logs not snapshot to peer 3\n    for i in 20..30 {\n        cluster.must_put(format!(\"k{}\", i).as_bytes(), b\"v\");\n    }\n    must_get_equal(&cluster.get_engine(3), b\"k29\", b\"v\");\n}"}
{"test_id": "ron-rs-ron/ron-rs-ron-eafa2b6/tests/123_enum_representation.rs::test_untagged_a_de", "code": "fn test_de<T>(s: &str, expected: T)\nwhere\n    T: for<'a> Deserialize<'a> + Debug + PartialEq,\n{\n    let actual: Result<T, _> = from_str(s);\n    assert_eq!(actual, Ok(expected));\n}", "test": "fn test_untagged_a_de() {\n    let s = \"(foo:1,bar:2,different:3)\";\n    let e = EnumStructUntagged::VariantA {\n        foo: 1,\n        bar: 2,\n        different: 3,\n    };\n    test_de(s, e);\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/limits.rs::test_custom_table_limiter", "code": "pub fn data(&self) -> &T {\n        self.inner.data()\n    }", "test": "fn test_custom_table_limiter() -> Result<()> {\n    let engine = Engine::default();\n    let linker = Linker::new(&engine);\n\n    let module = Module::new(&engine, r#\"(module (table (export \"t\") 0 anyfunc))\"#)?;\n\n    let context = TableContext {\n        elements_used: 0,\n        element_limit: 10,\n        limit_exceeded: false,\n    };\n\n    let mut store = Store::new(&engine, context);\n    store.limiter(|s| s as &mut dyn ResourceLimiter);\n    let instance = linker.instantiate(&mut store, &module)?;\n    let table = instance.get_table(&mut store, \"t\").unwrap();\n\n    // Grow the table by 10 elements\n    table.grow(&mut store, 3, Val::FuncRef(None))?;\n    table.grow(&mut store, 5, Val::FuncRef(None))?;\n    table.grow(&mut store, 2, Val::FuncRef(None))?;\n\n    assert!(!store.data().limit_exceeded);\n\n    // Table is at the maximum, but the limit hasn't been exceeded\n    assert!(!store.data().limit_exceeded);\n\n    // Try to grow the memory again\n    assert_eq!(\n        table\n            .grow(&mut store, 1, Val::FuncRef(None))\n            .map_err(|e| e.to_string())\n            .unwrap_err(),\n        \"failed to grow table by `1`\"\n    );\n\n    assert!(store.data().limit_exceeded);\n\n    Ok(())\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-write-integer/tests/api_tests.rs::u32_pow10_test", "code": "pub fn roundtrip<F>(float: F, buffer: &mut [u8]) -> Result<(), String>\nwhere\n    F: RawFloat + ToLexical + std::str::FromStr + std::string::ToString,\n{\n    let bytes = float.to_lexical(buffer);\n    let string = unsafe { std::str::from_utf8_unchecked(bytes) };\n    let roundtrip = string.parse::<F>().map_err(|_| float.to_string())?;\n    let is_equal = if float.is_nan() {\n        roundtrip.is_nan()\n    } else {\n        float == roundtrip\n    };\n    if !is_equal {\n        return Err(float.to_string());\n    }\n    Ok(())\n}", "test": "fn u32_pow10_test() {\n    let values: &[u32] = &[\n        0, 1, 5, 9, 10, 11, 15, 99, 100, 101, 105, 999, 1000, 1001, 1005, 9999, 10000, 10001,\n        10005, 99999, 100000, 100001, 100005, 999999, 1000000, 1000001, 1000005, 9999999, 10000000,\n        10000001, 10000005, 99999999, 100000000, 100000001, 100000005, 999999999, 1000000000,\n        1000000001, 1000000005,\n    ];\n    for &i in values.iter() {\n        assert_eq!(i, roundtrip(i));\n    }\n}"}
{"test_id": "web-infra-dev-oxc/oxc-project-oxc-884a819/crates/oxc_minifier/tests/closure/fold_constants.rs::test_undefined_comparison3", "code": "fn test(args: &[&str]) -> LintResult {\n        let mut new_args = vec![\"--quiet\"];\n        new_args.extend(args);\n        let options = lint_command().run_inner(new_args.as_slice()).unwrap().lint_options;\n        let CliRunResult::LintResult(lint_result) = LintRunner::new(options).run() else {\n            unreachable!()\n        };\n        lint_result\n    }", "test": "fn test_undefined_comparison3() {\n    test(\"'123' !== undefined\", \"!0;\");\n    test(\"'123' === undefined\", \"!1;\");\n\n    test(\"undefined !== '123'\", \"!0;\");\n    test(\"undefined === '123'\", \"!1;\");\n}"}
{"test_id": "ron-rs-ron/ron-rs-ron-eafa2b6/tests/floats.rs::test_inf_and_nan", "code": "pub fn from_str<'a, T>(&self, s: &'a str) -> SpannedResult<T>\n    where\n        T: de::Deserialize<'a>,\n    {\n        self.from_bytes(s.as_bytes())\n    }", "test": "fn test_inf_and_nan() {\n    assert_eq!(from_str(\"inf\"), Ok(std::f64::INFINITY));\n    assert_eq!(from_str(\"-inf\"), Ok(std::f64::NEG_INFINITY));\n    assert_eq!(from_str::<f64>(\"NaN\").map(|n| n.is_nan()), Ok(true))\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_df.rs::test_order_same", "code": "pub fn stdout_move_str(self) -> String {\n        String::from_utf8(self.stdout).unwrap()\n    }", "test": "fn test_order_same() {\n    let output1 = new_ucmd!()\n        .arg(\"--output=source\")\n        .succeeds()\n        .stdout_move_str();\n    let output2 = new_ucmd!()\n        .arg(\"--output=source\")\n        .succeeds()\n        .stdout_move_str();\n    assert_eq!(output1, output2);\n}"}
{"test_id": "Lokathor-tinyvec/Lokathor-tinyvec-6e1bbaf/tests/tinyvec.rs::TinyVec_reserve_exact", "code": "pub fn capacity(&self) -> usize {\n    // Note: This shouldn't use A::CAPACITY, because unsafe code can't rely on\n    // any Array invariants. This ensures that at the very least, the returned\n    // value is a valid length for a subslice of the backing array.\n    self.data.as_slice().len()\n  }", "test": "fn TinyVec_reserve_exact() {\n  let mut tv: TinyVec<[i32; 4]> = Default::default();\n  assert_eq!(tv.capacity(), 4);\n\n  tv.extend_from_slice(&[1, 2]);\n  assert_eq!(tv.capacity(), 4);\n  tv.reserve_exact(2);\n  assert_eq!(tv.capacity(), 4);\n  tv.reserve_exact(4);\n  assert!(tv.capacity() >= 6);\n  tv.extend_from_slice(&[3, 4, 5, 6]);\n  tv.reserve_exact(4);\n  assert!(tv.capacity() >= 10);\n}"}
{"test_id": "quinn-rs-quinn/quinn-rs-quinn-83e4f46/quinn-proto/src/tests/mod.rs::reject_missing_client_cert", "code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn reject_missing_client_cert() {\n    let _guard = subscribe();\n\n    let key = rustls::PrivateKey(CERTIFICATE.serialize_private_key_der());\n    let cert = util::CERTIFICATE.serialize_der().unwrap();\n\n    let config = rustls::ServerConfig::builder()\n        .with_safe_default_cipher_suites()\n        .with_safe_default_kx_groups()\n        .with_protocol_versions(&[&rustls::version::TLS13])\n        .unwrap()\n        .with_client_cert_verifier(Arc::new(rustls::server::AllowAnyAuthenticatedClient::new(\n            rustls::RootCertStore::empty(),\n        )))\n        .with_single_cert(vec![rustls::Certificate(cert)], key)\n        .unwrap();\n\n    let mut pair = Pair::new(\n        Default::default(),\n        ServerConfig::with_crypto(Arc::new(config)),\n    );\n\n    info!(\"connecting\");\n    let client_ch = pair.begin_connect(client_config());\n    pair.drive();\n\n    // The client completes the connection, but finds it immediately closed\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Connected)\n    );\n    assert_matches!(pair.client_conn_mut(client_ch).poll(),\n                    Some(Event::ConnectionLost { reason: ConnectionError::ConnectionClosed(ref close)})\n                    if close.error_code == TransportErrorCode::crypto(AlertDescription::CertificateRequired.get_u8()));\n\n    // The server never completes the connection\n    let server_ch = pair.server.assert_accept();\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    assert_matches!(pair.server_conn_mut(server_ch).poll(),\n                    Some(Event::ConnectionLost { reason: ConnectionError::TransportError(ref error)})\n                    if error.code == TransportErrorCode::crypto(AlertDescription::CertificateRequired.get_u8()));\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/name.rs::test_module_name", "code": "pub fn name(&self) -> Option<&str> {\n        self.compiled_module().module().name.as_deref()\n    }", "test": "fn test_module_name() -> anyhow::Result<()> {\n    let engine = Engine::default();\n    let wat = r#\"\n        (module $from_name_section\n        (func (export \"run\") (nop))\n        )\n    \"#;\n\n    let module = Module::new(&engine, wat)?;\n    assert_eq!(module.name(), Some(\"from_name_section\"));\n\n    Ok(())\n}"}
{"test_id": "astral-sh-ruff/astral-sh-ruff-1a6898a/crates/ruff_python_ast/tests/visitor.rs::match_class_pattern", "code": "fn trace_visitation(source: &str) -> String {\n    let tokens = lex(source, Mode::Module);\n    let parsed = parse_tokens(tokens, source, Mode::Module, \"test.py\").unwrap();\n\n    let mut visitor = RecordVisitor::default();\n    walk_module(&mut visitor, &parsed);\n\n    visitor.output\n}", "test": "fn match_class_pattern() {\n    let source = r#\"\nmatch x:\n    case Point2D(0, 0):\n        ...\n    case Point3D(x=0, y=0, z=0):\n        ...\n\"#;\n\n    let trace = trace_visitation(source);\n\n    assert_snapshot!(trace);\n}"}
{"test_id": "tafia-quick-xml/tafia-quick-xml-120e074/tests/unit_tests.rs::test_closing_bracket_in_double_quote_attr", "code": "fn next(&mut self) -> Option<Self::Item> {\n        match self.state.next(self.bytes) {\n            None => None,\n            Some(Ok(a)) => Some(Ok(a.map(|range| &self.bytes[range]).into())),\n            Some(Err(e)) => Some(Err(e)),\n        }\n    }", "test": "fn test_closing_bracket_in_double_quote_attr() {\n    let mut r = Reader::from_str(r#\"<a attr=\">\" check=\"2\"></a>\"#);\n    r.trim_text(true);\n    match r.read_event() {\n        Ok(Start(e)) => {\n            let mut attrs = e.attributes();\n            assert_eq!(\n                attrs.next(),\n                Some(Ok(Attribute {\n                    key: QName(b\"attr\"),\n                    value: Cow::Borrowed(b\">\"),\n                }))\n            );\n            assert_eq!(\n                attrs.next(),\n                Some(Ok(Attribute {\n                    key: QName(b\"check\"),\n                    value: Cow::Borrowed(b\"2\"),\n                }))\n            );\n            assert_eq!(attrs.next(), None);\n        }\n        x => panic!(\"expected <a attr='>'>, got {:?}\", x),\n    }\n    next_eq!(r, End, b\"a\");\n}"}
{"test_id": "Lokathor-tinyvec/Lokathor-tinyvec-6e1bbaf/tests/arrayvec.rs::test_a_vec", "code": "pub fn push(&mut self, val: T) {\n    if self.len < self.capacity() {\n      self.data[self.len] = val;\n      self.len += 1;\n    } else {\n      panic!(\"SliceVec::push> capacity overflow\")\n    }\n  }", "test": "fn test_a_vec() {\n  let mut expected: ArrayVec<[i32; 4]> = Default::default();\n  expected.push(1);\n  expected.push(2);\n  expected.push(3);\n\n  let actual = array_vec!(1, 2, 3);\n\n  assert_eq!(expected, actual);\n\n  assert_eq!(array_vec![0u8; 4], array_vec!(0u8, 0u8, 0u8, 0u8));\n  assert_eq!(array_vec![0u8; 4], array_vec!([u8; 4] => 0, 0, 0, 0));\n  assert_eq!(array_vec![0; 4], array_vec!(0, 0, 0, 0));\n  assert_eq!(array_vec![0; 4], array_vec!([u8; 4] => 0, 0, 0, 0));\n\n  let expected2 = array_vec![1.1; 3];\n  let actual2 = array_vec!([f32; 3] => 1.1, 1.1, 1.1);\n  assert_eq!(expected2, actual2);\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/call_hook.rs::call_wrapped_async_func", "code": "pub fn data(&self) -> &[u8] {\n        // N.B.: we emit every section into the .text section as far as\n        // the `CodeSink` is concerned; we do not bother to segregate\n        // the contents into the actual program text, the jumptable and the\n        // rodata (constant pool). This allows us to generate code assuming\n        // that these will not be relocated relative to each other, and avoids\n        // having to designate each section as belonging in one of the three\n        // fixed categories defined by `CodeSink`. If this becomes a problem\n        // later (e.g. because of memory permissions or similar), we can\n        // add this designation and segregate the output; take care, however,\n        // to add the appropriate relocations in this case.\n\n        &self.data[..]\n    }", "test": "async fn call_wrapped_async_func() -> Result<(), Error> {\n    let mut config = Config::new();\n    config.async_support(true);\n    let engine = Engine::new(&config)?;\n    let mut store = Store::new(&engine, State::default());\n    store.call_hook(State::call_hook);\n    let f = Func::wrap4_async(\n        &mut store,\n        |caller: Caller<State>, a: i32, b: i64, c: f32, d: f64| {\n            Box::new(async move {\n                // Calling this func will switch context into wasm, then back to host:\n                assert_eq!(caller.data().context, vec![Context::Wasm, Context::Host]);\n\n                assert_eq!(\n                    caller.data().calls_into_host,\n                    caller.data().returns_from_host + 1\n                );\n                assert_eq!(\n                    caller.data().calls_into_wasm,\n                    caller.data().returns_from_wasm + 1\n                );\n\n                assert_eq!(a, 1);\n                assert_eq!(b, 2);\n                assert_eq!(c, 3.0);\n                assert_eq!(d, 4.0);\n            })\n        },\n    );\n\n    f.call_async(\n        &mut store,\n        &[Val::I32(1), Val::I64(2), 3.0f32.into(), 4.0f64.into()],\n        &mut [],\n    )\n    .await?;\n\n    // One switch from vm to host to call f, another in return from f.\n    assert_eq!(store.data().calls_into_host, 1);\n    assert_eq!(store.data().returns_from_host, 1);\n    assert_eq!(store.data().calls_into_wasm, 1);\n    assert_eq!(store.data().returns_from_wasm, 1);\n\n    f.typed::<(i32, i64, f32, f64), ()>(&store)?\n        .call_async(&mut store, (1, 2, 3.0, 4.0))\n        .await?;\n\n    assert_eq!(store.data().calls_into_host, 2);\n    assert_eq!(store.data().returns_from_host, 2);\n    assert_eq!(store.data().calls_into_wasm, 2);\n    assert_eq!(store.data().returns_from_wasm, 2);\n\n    Ok(())\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_merge.rs::test_merge_with_concurrent_pessimistic_locking", "code": "pub fn has_region_error(&self) -> bool {\n        matches!(\n            self,\n            Error::Kv(KvError(box EngineErrorInner::Request(_)))\n                | Error::Txn(TxnError(box TxnErrorInner::Engine(KvError(\n                    box EngineErrorInner::Request(_),\n                ))))\n                | Error::Txn(TxnError(box TxnErrorInner::Mvcc(MvccError(\n                    box MvccErrorInner::Kv(KvError(box EngineErrorInner::Request(_))),\n                ))))\n                | Error::Request(_)\n        )\n    }", "test": "fn test_merge_with_concurrent_pessimistic_locking() {\n    let mut cluster = new_server_cluster(0, 2);\n    configure_for_merge(&mut cluster.cfg);\n    cluster.cfg.pessimistic_txn.pipelined = true;\n    cluster.cfg.pessimistic_txn.in_memory = true;\n    cluster.run();\n\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k3\", b\"v3\");\n\n    let region = cluster.get_region(b\"k1\");\n    cluster.must_split(&region, b\"k2\");\n    let left = cluster.get_region(b\"k1\");\n    let right = cluster.get_region(b\"k3\");\n\n    // Transfer the leader of the right region to store 2. The leaders of source and\n    // target regions don't need to be on the same store.\n    cluster.must_transfer_leader(right.id, new_peer(2, 2));\n\n    let snapshot = cluster.must_get_snapshot_of_region(left.id);\n    let txn_ext = snapshot.txn_ext.unwrap();\n    txn_ext\n        .pessimistic_locks\n        .write()\n        .insert(vec![(\n            Key::from_raw(b\"k0\"),\n            PessimisticLock {\n                primary: b\"k0\".to_vec().into_boxed_slice(),\n                start_ts: 10.into(),\n                ttl: 3000,\n                for_update_ts: 20.into(),\n                min_commit_ts: 30.into(),\n                last_change_ts: 15.into(),\n                versions_to_last_change: 3,\n            },\n        )])\n        .unwrap();\n\n    let addr = cluster.sim.rl().get_addr(1);\n    let env = Arc::new(Environment::new(1));\n    let channel = ChannelBuilder::new(env).connect(&addr);\n    let client = TikvClient::new(channel);\n\n    fail::cfg(\"before_propose_locks_on_region_merge\", \"pause\").unwrap();\n\n    // 1. Locking before proposing pessimistic locks in the source region can\n    // succeed.\n    let client2 = client.clone();\n    let mut mutation = Mutation::default();\n    mutation.set_op(Op::PessimisticLock);\n    mutation.key = b\"k1\".to_vec();\n    let mut req = PessimisticLockRequest::default();\n    req.set_context(cluster.get_ctx(b\"k1\"));\n    req.set_mutations(vec![mutation].into());\n    req.set_start_version(10);\n    req.set_for_update_ts(10);\n    req.set_primary_lock(b\"k1\".to_vec());\n    fail::cfg(\"txn_before_process_write\", \"pause\").unwrap();\n    let res = thread::spawn(move || client2.kv_pessimistic_lock(&req).unwrap());\n    thread::sleep(Duration::from_millis(150));\n    cluster.merge_region(left.id, right.id, Callback::None);\n    thread::sleep(Duration::from_millis(150));\n    fail::remove(\"txn_before_process_write\");\n    let resp = res.join().unwrap();\n    assert!(!resp.has_region_error());\n    fail::remove(\"before_propose_locks_on_region_merge\");\n\n    // 2. After locks are proposed, later pessimistic lock request should fail.\n    let mut mutation = Mutation::default();\n    mutation.set_op(Op::PessimisticLock);\n    mutation.key = b\"k11\".to_vec();\n    let mut req = PessimisticLockRequest::default();\n    req.set_context(cluster.get_ctx(b\"k11\"));\n    req.set_mutations(vec![mutation].into());\n    req.set_start_version(10);\n    req.set_for_update_ts(10);\n    req.set_primary_lock(b\"k11\".to_vec());\n    fail::cfg(\"txn_before_process_write\", \"pause\").unwrap();\n    let res = thread::spawn(move || client.kv_pessimistic_lock(&req).unwrap());\n    thread::sleep(Duration::from_millis(200));\n    fail::remove(\"txn_before_process_write\");\n    let resp = res.join().unwrap();\n    assert!(resp.has_region_error());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_pinky.rs::test_invalid_arg", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_invalid_arg() {\n    new_ucmd!().arg(\"--definitely-invalid\").fails().code_is(1);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_stat.rs::test_terse_normal_format", "code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_terse_normal_format() {\n    // note: contains birth/creation date which increases test fragility\n    // * results may vary due to built-in `stat` limitations as well as linux kernel and rust version capability variations\n    let args = [\"-t\", \"/\"];\n    let ts = TestScenario::new(util_name!());\n    let actual = ts.ucmd().args(&args).succeeds().stdout_move_str();\n    let expect = unwrap_or_return!(expected_result(&ts, &args)).stdout_move_str();\n    println!(\"actual: {actual:?}\");\n    println!(\"expect: {expect:?}\");\n    let v_actual: Vec<&str> = actual.trim().split(' ').collect();\n    let mut v_expect: Vec<&str> = expect.trim().split(' ').collect();\n    assert!(!v_expect.is_empty());\n\n    // uu_stat does not support selinux\n    if v_actual.len() == v_expect.len() - 1 && v_expect[v_expect.len() - 1].contains(':') {\n        // assume last element contains: `SELinux security context string`\n        v_expect.pop();\n    }\n\n    // * allow for inequality if `stat` (aka, expect) returns \"0\" (unknown value)\n    assert!(\n        expect == \"0\"\n            || expect == \"0\\n\"\n            || v_actual\n                .iter()\n                .zip(v_expect.iter())\n                .all(|(a, e)| a == e || *e == \"0\" || *e == \"0\\n\")\n    );\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_mssql.rs::parse_delimited_identifiers", "code": "pub fn verified_stmt(&self, sql: &str) -> Statement {\n        self.one_statement_parses_to(sql, sql)\n    }", "test": "fn parse_delimited_identifiers() {\n    // check that quoted identifiers in any position remain quoted after serialization\n    let select = ms_and_generic().verified_only_select(\n        r#\"SELECT \"alias\".\"bar baz\", \"myfun\"(), \"simple id\" AS \"column alias\" FROM \"a table\" AS \"alias\"\"#,\n    );\n    // check FROM\n    match only(select.from).relation {\n        TableFactor::Table {\n            name,\n            alias,\n            args,\n            with_hints,\n            version,\n            partitions: _,\n        } => {\n            assert_eq!(vec![Ident::with_quote('\"', \"a table\")], name.0);\n            assert_eq!(Ident::with_quote('\"', \"alias\"), alias.unwrap().name);\n            assert!(args.is_none());\n            assert!(with_hints.is_empty());\n            assert!(version.is_none());\n        }\n        _ => panic!(\"Expecting TableFactor::Table\"),\n    }\n    // check SELECT\n    assert_eq!(3, select.projection.len());\n    assert_eq!(\n        &Expr::CompoundIdentifier(vec![\n            Ident::with_quote('\"', \"alias\"),\n            Ident::with_quote('\"', \"bar baz\"),\n        ]),\n        expr_from_projection(&select.projection[0]),\n    );\n    assert_eq!(\n        &Expr::Function(Function {\n            name: ObjectName(vec![Ident::with_quote('\"', \"myfun\")]),\n            args: vec![],\n            null_treatment: None,\n            filter: None,\n            over: None,\n            distinct: false,\n            special: false,\n            order_by: vec![],\n        }),\n        expr_from_projection(&select.projection[1]),\n    );\n    match &select.projection[2] {\n        SelectItem::ExprWithAlias { expr, alias } => {\n            assert_eq!(&Expr::Identifier(Ident::with_quote('\"', \"simple id\")), expr);\n            assert_eq!(&Ident::with_quote('\"', \"column alias\"), alias);\n        }\n        _ => panic!(\"Expected ExprWithAlias\"),\n    }\n\n    ms_and_generic().verified_stmt(r#\"CREATE TABLE \"foo\" (\"bar\" \"int\")\"#);\n    ms_and_generic().verified_stmt(r#\"ALTER TABLE foo ADD CONSTRAINT \"bar\" PRIMARY KEY (baz)\"#);\n    //TODO verified_stmt(r#\"UPDATE foo SET \"bar\" = 5\"#);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_stty.rs::save_and_all", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn save_and_all() {\n    new_ucmd!()\n        .args(&[\"--save\", \"--all\"])\n        .fails()\n        .stderr_contains(\n            \"the options for verbose and stty-readable output styles are mutually exclusive\",\n        );\n\n    new_ucmd!()\n        .args(&[\"--all\", \"--save\"])\n        .fails()\n        .stderr_contains(\n            \"the options for verbose and stty-readable output styles are mutually exclusive\",\n        );\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/engine_traits_tests/src/write_batch.rs::save_point_pop_after_write", "code": "pub fn is_some(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_some(),\n            }\n        }\n    }", "test": "fn save_point_pop_after_write() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch();\n\n    wb.set_save_point();\n    wb.put(b\"a\", b\"\").unwrap();\n\n    wb.write().unwrap();\n\n    let val = db.engine.get_value(b\"a\").unwrap();\n    assert!(val.is_some());\n\n    db.engine.delete(b\"a\").unwrap();\n\n    let val = db.engine.get_value(b\"a\").unwrap();\n    assert!(val.is_none());\n\n    wb.pop_save_point().unwrap();\n    wb.write().unwrap();\n\n    let val = db.engine.get_value(b\"a\").unwrap();\n    assert!(val.is_some());\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(1024);\n    let max_keys = 256_usize;\n\n    wb.set_save_point();\n    wb.put(b\"a\", b\"\").unwrap();\n    for i in 0..max_keys {\n        wb.put(&i.to_be_bytes(), b\"\").unwrap();\n    }\n\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    for i in 0..max_keys {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_some());\n    }\n\n    db.engine.delete(b\"a\").unwrap();\n    for i in 0..max_keys {\n        db.engine.delete(&i.to_be_bytes()).unwrap();\n    }\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_none());\n    for i in 0..max_keys {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n\n    wb.pop_save_point().unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    for i in 0..max_keys {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_some());\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_dd.rs::test_ys_to_stdout", "code": "pub fn success(&self) -> &Self {\n        assert!(\n            self.succeeded(),\n            \"Command was expected to succeed.\\nstdout = {}\\n stderr = {}\",\n            self.stdout_str(),\n            self.stderr_str()\n        );\n        self\n    }", "test": "fn test_ys_to_stdout() {\n    let output: Vec<_> = String::from(\"y\\n\").bytes().cycle().take(1024).collect();\n    let output = String::from_utf8(output).unwrap();\n\n    new_ucmd!()\n        .args(&[\"status=none\", \"if=y-nl-1k.txt\"])\n        .run()\n        .no_stderr()\n        .stdout_is(output)\n        .success();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_mv.rs::test_mv_move_file_into_dir", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_move_file_into_dir() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_mv_move_file_into_dir_dir\";\n    let file = \"test_mv_move_file_into_dir_file\";\n\n    at.mkdir(dir);\n    at.touch(file);\n\n    ucmd.arg(file).arg(dir).succeeds().no_stderr();\n\n    assert!(at.file_exists(format!(\"{dir}/{file}\")));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_arg_target_directory", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_arg_target_directory() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(\"-t\")\n        .arg(TEST_COPY_TO_FOLDER)\n        .succeeds();\n\n    assert_eq!(at.read(TEST_COPY_TO_FOLDER_FILE), \"Hello, World!\\n\");\n}"}
{"test_id": "Keats-tera/Keats-tera-1f95878/src/renderer/tests/errors.rs::error_string_concat_math_logic", "code": "pub fn render(&self, template_name: &str, context: &Context) -> Result<String> {\n        let template = self.get_template(template_name)?;\n        let renderer = Renderer::new(template, self, context);\n        renderer.render()\n    }", "test": "fn error_string_concat_math_logic() {\n    let mut tera = Tera::default();\n    tera.add_raw_templates(vec![(\"tpl\", \"{{ 'ho' ~ name < 10 }}\")]).unwrap();\n    let mut context = Context::new();\n    context.insert(\"name\", &\"john\");\n\n    let result = tera.render(\"tpl\", &context);\n\n    assert_eq!(\n        result.unwrap_err().source().unwrap().to_string(),\n        \"Tried to do math with a string concatenation: 'ho' ~ name\"\n    );\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/storage/test_storage.rs::test_txn_store_resolve_lock2", "code": "fn test_txn_store_resolve_lock_batch(key_prefix_len: usize, n: usize) {\n    let prefix = String::from_utf8(vec![b'k'; key_prefix_len]).unwrap();\n    let keys: Vec<String> = (0..n).map(|i| format!(\"{}{}\", prefix, i)).collect();\n\n    let store = AssertionStorage::default();\n    for k in &keys {\n        store.prewrite_ok(\n            vec![Mutation::make_put(\n                Key::from_raw(k.as_bytes()),\n                b\"v\".to_vec(),\n            )],\n            b\"k1\",\n            5,\n        );\n    }\n    store.resolve_lock_ok(5, Some(10));\n    for k in &keys {\n        store.get_ok(k.as_bytes(), 30, b\"v\");\n        store.get_none(k.as_bytes(), 8);\n    }\n}", "test": "fn test_txn_store_resolve_lock2() {\n    for &i in &[\n        0,\n        1,\n        RESOLVE_LOCK_BATCH_SIZE - 1,\n        RESOLVE_LOCK_BATCH_SIZE,\n        RESOLVE_LOCK_BATCH_SIZE + 1,\n        RESOLVE_LOCK_BATCH_SIZE * 2,\n    ] {\n        test_txn_store_resolve_lock_batch(1, i);\n    }\n\n    for &i in &[1, 512, 1024] {\n        test_txn_store_resolve_lock_batch(i, 50);\n    }\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/cdc/tests/integrations/test_cdc.rs::test_resolved_ts_cluster_upgrading", "code": "pub fn stop(&mut self) {\n        self.mut_store().cancel_applying_snap();\n        self.pending_reads.clear_all(None);\n    }", "test": "fn test_resolved_ts_cluster_upgrading() {\n    let cluster = new_server_cluster(0, 3);\n    cluster.pd_client.disable_default_operator();\n    unsafe {\n        cluster\n            .pd_client\n            .feature_gate()\n            .reset_version(\"4.0.0\")\n            .unwrap();\n    }\n    let mut suite = TestSuiteBuilder::new().cluster(cluster).build();\n\n    let region = suite.cluster.get_region(&[]);\n    let req = suite.new_changedata_request(region.id);\n    let (mut req_tx, event_feed_wrap, receive_event) =\n        new_event_feed(suite.get_region_cdc_client(region.id));\n    block_on(req_tx.send((req, WriteFlags::default()))).unwrap();\n    let event = receive_event(true);\n    if let Some(resolved_ts) = event.resolved_ts.as_ref() {\n        assert!(resolved_ts.regions == vec![region.id]);\n        assert_eq!(CDC_RESOLVED_TS_ADVANCE_METHOD.get(), 0);\n    }\n    suite\n        .cluster\n        .pd_client\n        .feature_gate()\n        .set_version(\"5.0.0\")\n        .unwrap();\n\n    loop {\n        let event = receive_event(true);\n        if let Some(resolved_ts) = event.resolved_ts.as_ref() {\n            assert!(resolved_ts.regions == vec![region.id]);\n            if CDC_RESOLVED_TS_ADVANCE_METHOD.get() == 1 {\n                break;\n            }\n        }\n    }\n\n    event_feed_wrap.replace(None);\n    suite.stop();\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/iterators.rs::iterator_close_in_continue_before_jobs", "code": "fn run_jobs(&self, context: &mut boa_engine::Context<'_>) {\n        // Early return in case there were no jobs scheduled.\n        if self.jobs.borrow().is_empty() && self.futures.borrow().is_empty() {\n            return;\n        }\n\n        let context = RefCell::new(context);\n\n        future::block_on(self.executor.run(async move {\n            // Used to sync the finalization of both tasks\n            let finished = Cell::new(0b00u8);\n\n            let fqueue = async {\n                loop {\n                    if self.futures.borrow().is_empty() {\n                        finished.set(finished.get() | 0b01);\n                        if finished.get() >= 0b11 {\n                            // All possible futures and jobs were completed. Exit.\n                            return;\n                        }\n                        // All possible jobs were completed, but `jqueue` could have\n                        // pending jobs. Yield to the executor to try to progress on\n                        // `jqueue` until we have more pending futures.\n                        future::yield_now().await;\n                        continue;\n                    }\n                    finished.set(finished.get() & 0b10);\n\n                    // Blocks on all the enqueued futures, driving them all to completion.\n                    let futures = &mut std::mem::take(&mut *self.futures.borrow_mut());\n                    while let Some(job) = futures.next().await {\n                        // Important to schedule the returned `job` into the job queue, since that's\n                        // what allows updating the `Promise` seen by ECMAScript for when the future\n                        // completes.\n                        self.enqueue_promise_job(job, &mut context.borrow_mut());\n                    }\n                }\n            };\n\n            let jqueue = async {\n                loop {\n                    if self.jobs.borrow().is_empty() {\n                        finished.set(finished.get() | 0b10);\n                        if finished.get() >= 0b11 {\n                            // All possible futures and jobs were completed. Exit.\n                            return;\n                        }\n                        // All possible jobs were completed, but `fqueue` could have\n                        // pending futures. Yield to the executor to try to progress on\n                        // `fqueue` until we have more pending jobs.\n                        future::yield_now().await;\n                        continue;\n                    };\n                    finished.set(finished.get() & 0b01);\n\n                    let jobs = std::mem::take(&mut *self.jobs.borrow_mut());\n                    for job in jobs {\n                        if let Err(e) = job.call(&mut context.borrow_mut()) {\n                            eprintln!(\"Uncaught {e}\");\n                        }\n                        future::yield_now().await;\n                    }\n                }\n            };\n\n            // Wait for both queues to complete\n            future::zip(fqueue, jqueue).await;\n        }))\n    }", "test": "fn iterator_close_in_continue_before_jobs() {\n    run_test_actions([\n        TestAction::run_harness(),\n        TestAction::run(indoc! {r#\"\n            var actual = [];\n\n            var iter = {\n                [Symbol.iterator]() {\n                    return this;\n                },\n                next() {\n                    actual.push(\"call next\");\n                    return {\n                        done: false,\n                    };\n                },\n                get return() {\n                    actual.push(\"get return\");\n                    return function () {\n                        actual.push(\"return call\");\n                        return {\n                            done: true\n                        }\n                    }\n                }\n            };\n\n            Promise.resolve(0)\n                .then(() => actual.push(\"tick 1\"))\n                .then(() => actual.push(\"tick 2\"));\n\n            void async function f() {\n                actual.push(\"async fn start\");\n                let count = 0;\n                loop: while (count === 0) {\n                    count++;\n                    for (_ of iter) {\n                        continue loop;\n                    }\n                }\n                actual.push(\"async fn end\");\n            }();\n        \"#}),\n        #[allow(clippy::redundant_closure_for_method_calls)]\n        TestAction::inspect_context(|ctx| ctx.run_jobs()),\n        TestAction::assert(indoc! {r#\"\n            arrayEquals(\n                actual,\n                [\n                    \"async fn start\",\n                    \"call next\",\n                    \"get return\",\n                    \"return call\",\n                    \"async fn end\",\n                    \"tick 1\",\n                    \"tick 2\",\n                ]\n            )\n            \"#}),\n    ]);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_expand.rs::test_with_space", "code": "pub fn stdout_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stdout_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stdout_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_with_space() {\n    new_ucmd!()\n        .arg(\"with-spaces.txt\")\n        .succeeds()\n        .stdout_contains(\"    return\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_numfmt.rs::test_header_error_if_0", "code": "pub fn stderr_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stderr_str(), msg.as_ref());\n        self\n    }", "test": "fn test_header_error_if_0() {\n    new_ucmd!()\n        .args(&[\"--header=0\"])\n        .run()\n        .stderr_is(\"numfmt: invalid header value '0'\\n\");\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_common.rs::parse_select_order_by_limit", "code": "pub fn verified_query(&self, sql: &str) -> Query {\n        match self.verified_stmt(sql) {\n            Statement::Query(query) => *query,\n            _ => panic!(\"Expected Query\"),\n        }\n    }", "test": "fn parse_select_order_by_limit() {\n    let sql = \"SELECT id, fname, lname FROM customer WHERE id < 5 \\\n               ORDER BY lname ASC, fname DESC LIMIT 2\";\n    let select = verified_query(sql);\n    assert_eq!(\n        vec![\n            OrderByExpr {\n                expr: Expr::Identifier(Ident::new(\"lname\")),\n                asc: Some(true),\n                nulls_first: None,\n            },\n            OrderByExpr {\n                expr: Expr::Identifier(Ident::new(\"fname\")),\n                asc: Some(false),\n                nulls_first: None,\n            },\n        ],\n        select.order_by\n    );\n    assert_eq!(Some(Expr::Value(number(\"2\"))), select.limit);\n}"}
{"test_id": "ordinals-ord/ordinals-ord-8090538/tests/wallet/inscribe.rs::batch_inscribe_can_create_one_inscription", "code": "pub fn descriptors(&self) -> Vec<String> {\n    self.state().descriptors.clone()\n  }", "test": "fn batch_inscribe_can_create_one_inscription() {\n  let rpc_server = test_bitcoincore_rpc::spawn();\n  rpc_server.mine_blocks(1);\n\n  assert_eq!(rpc_server.descriptors().len(), 0);\n\n  create_wallet(&rpc_server);\n\n  let output = CommandBuilder::new(\"wallet inscribe --fee-rate 2.1 --batch batch.yaml\")\n    .write(\"inscription.txt\", \"Hello World\")\n    .write(\n      \"batch.yaml\",\n      \"mode: shared-output\\ninscriptions:\\n- file: inscription.txt\\n  metadata: 123\\n  metaprotocol: foo\",\n    )\n    .rpc_server(&rpc_server)\n    .run_and_deserialize_output::<Inscribe>();\n\n  rpc_server.mine_blocks(1);\n\n  assert_eq!(rpc_server.descriptors().len(), 3);\n\n  let ord_server = TestServer::spawn_with_args(&rpc_server, &[]);\n\n  let request = ord_server.request(format!(\"/content/{}\", output.inscriptions[0].id));\n\n  assert_eq!(request.status(), 200);\n  assert_eq!(\n    request.headers().get(\"content-type\").unwrap(),\n    \"text/plain;charset=utf-8\"\n  );\n  assert_eq!(request.text().unwrap(), \"Hello World\");\n\n  ord_server.assert_response_regex(\n    format!(\"/inscription/{}\", output.inscriptions[0].id),\n    r\".*<dt>metadata</dt>\\s*<dd>\\n    123\\n  </dd>.*<dt>metaprotocol</dt>\\s*<dd>foo</dd>.*\",\n  );\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/fallback.rs::runs_recipe_in_parent_if_not_found_in_current", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn runs_recipe_in_parent_if_not_found_in_current() {\n  Test::new()\n    .tree(tree! {\n      bar: {\n        justfile: \"\n          set fallback := true\n\n          baz:\n            echo subdir\n        \"\n      }\n    })\n    .justfile(\n      \"\n      foo:\n        echo root\n    \",\n    )\n    .args([\"foo\"])\n    .current_dir(\"bar\")\n    .stderr(\n      \"\n      echo root\n    \",\n    )\n    .stdout(\"root\\n\")\n    .run();\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_witness.rs::test_witness_replica_read", "code": "fn read(&mut self, request: RaftCmdRequest, timeout: Duration) -> Result<RaftCmdResponse> {\n        let node_id = request.get_header().get_peer().get_store_id();\n        let timeout_f = GLOBAL_TIMER_HANDLE\n            .delay(std::time::Instant::now() + timeout)\n            .compat();\n        futures::executor::block_on(async move {\n            futures::select! {\n                res = self.async_read(node_id, request).fuse() => res,\n                e = timeout_f.fuse() => {\n                    Err(Error::Timeout(format!(\"request timeout for {:?}: {:?}\", timeout,e)))\n                },\n            }\n        })\n    }", "test": "fn test_witness_replica_read() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.must_put(b\"k0\", b\"v0\");\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1);\n    // nonwitness -> witness\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![true],\n    );\n\n    // make sure the peer_on_store3 has completed applied to witness\n    std::thread::sleep(Duration::from_millis(200));\n\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_get_cmd(b\"k0\")],\n        false,\n    );\n    request.mut_header().set_peer(peer_on_store3);\n    request.mut_header().set_replica_read(true);\n\n    let resp = cluster\n        .read(None, request, Duration::from_millis(100))\n        .unwrap();\n    assert_eq!(\n        resp.get_header().get_error().get_is_witness(),\n        &kvproto::errorpb::IsWitness {\n            region_id: region.get_id(),\n            ..Default::default()\n        }\n    );\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-parse-float/tests/lemire_tests.rs::compute_float_f32_rounding", "code": "pub fn compute_float32(q: i64, w: u64) -> (i32, u64) {\n    let num = Number {\n        exponent: q,\n        mantissa: w,\n        is_negative: false,\n        many_digits: false,\n        integer: &[],\n        fraction: None,\n    };\n    let fp = bellerophon::<f32, { STANDARD }>(&num, false);\n    (fp.exp, fp.mant)\n}", "test": "fn compute_float_f32_rounding() {\n    // These test near-halfway cases for single-precision floats.\n    assert_eq!(compute_float32(0, 16777216), (151, 0));\n    assert_eq!(compute_float32(0, 16777217), (151, 0));\n    assert_eq!(compute_float32(0, 16777218), (151, 1));\n    assert_eq!(compute_float32(0, 16777219), (151, 2));\n    assert_eq!(compute_float32(0, 16777220), (151, 2));\n\n    // These are examples of the above tests, with\n    // digits from the exponent shifted to the mantissa.\n    assert_eq!(compute_float32(-10, 167772160000000000), (151, 0));\n    assert_eq!(compute_float32(-10, 167772170000000000), (151, 0));\n    assert_eq!(compute_float32(-10, 167772180000000000), (151, 1));\n    // Let's check the lines to see if anything is different in table...\n    assert_eq!(compute_float32(-10, 167772190000000000), (151, 2));\n    assert_eq!(compute_float32(-10, 167772200000000000), (151, 2));\n}"}
{"test_id": "mitsuhiko-minijinja/mitsuhiko-minijinja-5f2c1e8/minijinja/tests/test_fuel.rs::test_basic", "code": "pub fn fuel(&self) -> Option<u64> {\n        self.fuel\n    }", "test": "fn test_basic() {\n    let mut env = Environment::new();\n    assert_eq!(env.fuel(), None);\n    env.set_fuel(Some(100));\n    assert_eq!(env.fuel(), Some(100));\n    env.add_template(\"test\", \"{% for x in seq %}{{ x }}\\n{% endfor %}\")\n        .unwrap();\n    let t = env.get_template(\"test\").unwrap();\n\n    // this will still manage to run with 100 fuel\n    let rv = t\n        .render(context!(seq => (0..15).collect::<Vec<_>>()))\n        .unwrap();\n    assert_eq!(rv.lines().count(), 15);\n\n    // this is above the limit\n    let rv = t\n        .render(context!(seq => (0..20).collect::<Vec<_>>()))\n        .unwrap_err();\n    assert_eq!(rv.kind(), ErrorKind::OutOfFuel);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/pd/test_rpc_client.rs::test_incompatible_version", "code": "fn to_string(&self) -> String {\n        let (mut buf, word_start_idx, int_len, int_cnt, frac_cnt) = self.prepare_buf();\n        if self.negative {\n            buf.push(b'-');\n        }\n        let padding = int_len - cmp::max(int_cnt, 1);\n        buf.resize(padding as usize + buf.len(), b'0');\n        if int_cnt > 0 {\n            let base_idx = buf.len();\n            let mut idx = base_idx + int_cnt as usize;\n            let mut widx = word_start_idx + word_cnt!(int_cnt) as usize;\n            buf.resize(idx, 0);\n            while idx > base_idx {\n                widx -= 1;\n                let mut x = self.word_buf[widx];\n                for _ in 0..cmp::min((idx - base_idx) as u8, DIGITS_PER_WORD) {\n                    idx -= 1;\n                    buf[idx] = b'0' + (x % 10) as u8;\n                    x /= 10;\n                }\n            }\n        } else {\n            buf.push(b'0');\n        };\n        if frac_cnt > 0 {\n            buf.push(b'.');\n            let mut widx = word_start_idx + word_cnt!(int_cnt) as usize;\n            let exp_idx = buf.len() + frac_cnt as usize;\n            while buf.len() < exp_idx {\n                let mut x = self.word_buf[widx];\n                for _ in 0..cmp::min((exp_idx - buf.len()) as u8, DIGITS_PER_WORD) {\n                    buf.push((x / DIG_MASK) as u8 + b'0');\n                    x = (x % DIG_MASK) * 10;\n                }\n                widx += 1;\n            }\n            while buf.capacity() != buf.len() {\n                buf.push(b'0');\n            }\n        }\n        unsafe { String::from_utf8_unchecked(buf) }\n    }", "test": "fn test_incompatible_version() {\n    let incompatible = Arc::new(Incompatible);\n    let server = MockServer::with_case(1, incompatible);\n    let eps = server.bind_addrs();\n\n    let mut client = new_client_v2(eps, None);\n\n    let resp = block_on(client.ask_batch_split(metapb::Region::default(), 2));\n    assert_eq!(\n        resp.unwrap_err().to_string(),\n        PdError::Incompatible.to_string()\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_split.rs::test_elide_empty_files", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_elide_empty_files() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-e\", \"-n\", \"4\", \"threebytes.txt\"])\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"xaa\"), \"a\");\n    assert_eq!(at.read(\"xab\"), \"b\");\n    assert_eq!(at.read(\"xac\"), \"c\");\n    assert!(!at.plus(\"xad\").exists());\n}"}
{"test_id": "web-infra-dev-oxc/oxc-project-oxc-884a819/crates/oxc_minifier/tests/closure/fold_constants.rs::js_typeof", "code": "pub(crate) fn test_same(source_text: &str) {\n    test(source_text, source_text);\n}", "test": "fn js_typeof() {\n    test(\"x = typeof 1\", \"x='number';\");\n    test(\"x = typeof 'foo'\", \"x='string';\");\n    test(\"x = typeof true\", \"x='boolean';\");\n    test(\"x = typeof false\", \"x='boolean';\");\n    test(\"x = typeof null\", \"x='object';\");\n    test(\"x = typeof undefined\", \"x='undefined';\");\n    test(\"x = typeof void 0\", \"x='undefined';\");\n    test(\"x = typeof []\", \"x='object';\");\n    test(\"x = typeof [1]\", \"x='object';\");\n    test(\"x = typeof [1,[]]\", \"x='object';\");\n    test(\"x = typeof {}\", \"x='object';\");\n    test(\"x = typeof function() {}\", \"x='function';\");\n\n    test_same(\"x=typeof [1,[foo()]];\");\n    test_same(\"x=typeof {bathwater:baby()};\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_timeout.rs::test_verbose", "code": "pub fn stderr_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stdout().stderr_is(msg)\n    }", "test": "fn test_verbose() {\n    for verbose_flag in [\"-v\", \"--verbose\"] {\n        new_ucmd!()\n            .args(&[verbose_flag, \".1\", \"sleep\", \"10\"])\n            .fails()\n            .stderr_only(\"timeout: sending signal TERM to command 'sleep'\\n\");\n        new_ucmd!()\n            .args(&[verbose_flag, \"-s0\", \"-k.1\", \".1\", \"sleep\", \"10\"])\n            .fails()\n            .stderr_only(\"timeout: sending signal EXIT to command 'sleep'\\ntimeout: sending signal KILL to command 'sleep'\\n\");\n    }\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/engine_traits_tests/src/ctor.rs::new_engine_opt_renamed_dir", "code": "fn get_value_cf(&self, cf: &str, key: &[u8]) -> Result<Option<Self::DbVector>> {\n        self.get_value_cf_opt(&ReadOptions::default(), cf, key)\n    }", "test": "fn new_engine_opt_renamed_dir() {\n    use std::sync::Arc;\n    let dir = tempdir();\n    let root_path = dir.path();\n\n    let encryption_cfg = test_util::new_file_security_config(root_path);\n    let key_manager = Arc::new(\n        data_key_manager_from_config(&encryption_cfg, root_path.to_str().unwrap())\n            .unwrap()\n            .unwrap(),\n    );\n\n    let mut db_opts = DbOptions::default();\n    db_opts.set_key_manager(Some(key_manager.clone()));\n    let cf_opts: Vec<_> = ALL_CFS.iter().map(|cf| (*cf, CfOptions::new())).collect();\n\n    let path = root_path.join(\"missing\").to_str().unwrap().to_owned();\n    {\n        let db = KvTestEngine::new_kv_engine_opt(&path, db_opts.clone(), cf_opts.clone()).unwrap();\n        db.put(b\"foo\", b\"bar\").unwrap();\n        db.sync().unwrap();\n    }\n    let new_path = root_path.join(\"new\").to_str().unwrap().to_owned();\n    key_manager.link_file(&path, &new_path).unwrap();\n    fs::rename(&path, &new_path).unwrap();\n    key_manager.delete_file(&path).unwrap();\n    {\n        let db =\n            KvTestEngine::new_kv_engine_opt(&new_path, db_opts.clone(), cf_opts.clone()).unwrap();\n        assert_eq!(\n            db.get_value_cf(CF_DEFAULT, b\"foo\").unwrap().unwrap(),\n            b\"bar\"\n        );\n    }\n}"}
{"test_id": "cberner-redb/cberner-redb-267b473/tests/integration_tests.rs::range_query", "code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn range_query() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(U64_TABLE).unwrap();\n        for i in 0..10 {\n            table.insert(&i, &i).unwrap();\n        }\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(U64_TABLE).unwrap();\n    let mut iter = table.range(3..7).unwrap();\n    for i in 3..7u64 {\n        let (key, value) = iter.next().unwrap().unwrap();\n        assert_eq!(i, key.value());\n        assert_eq!(i, value.value());\n    }\n    assert!(iter.next().is_none());\n\n    let mut iter = table.range(3..=7).unwrap();\n    for i in 3..=7u64 {\n        let (key, value) = iter.next().unwrap().unwrap();\n        assert_eq!(i, key.value());\n        assert_eq!(i, value.value());\n    }\n    assert!(iter.next().is_none());\n\n    let total: u64 = table\n        .range(1..=3)\n        .unwrap()\n        .map(|item| item.unwrap().1.value())\n        .sum();\n    assert_eq!(total, 6);\n}"}
{"test_id": "raphlinus-pulldown-cmark/raphlinus-pulldown-cmark-3da63d5/tests/suite/heading_attrs.rs::heading_attrs_test_24", "code": "pub fn test_markdown_html(input: &str, output: &str, smart_punct: bool) {\n    let mut s = String::new();\n\n    let mut opts = Options::empty();\n    opts.insert(Options::ENABLE_TABLES);\n    opts.insert(Options::ENABLE_FOOTNOTES);\n    opts.insert(Options::ENABLE_STRIKETHROUGH);\n    opts.insert(Options::ENABLE_TASKLISTS);\n    if smart_punct {\n        opts.insert(Options::ENABLE_SMART_PUNCTUATION);\n    }\n    opts.insert(Options::ENABLE_HEADING_ATTRIBUTES);\n\n    let p = Parser::new_ext(input, opts);\n    pulldown_cmark::html::push_html(&mut s, p);\n\n    assert_eq!(normalize_html(output), normalize_html(&s));\n}", "test": "fn heading_attrs_test_24() {\n    let original = r##\"# H1 {.foo\\}\n\"##;\n    let expected = r##\"<h1>H1 {.foo}</h1>\n\"##;\n\n    test_markdown_html(original, expected, false);\n}"}
{"test_id": "weggli-rs-weggli/weggli-rs-weggli-ad8d424/tests/query.rs::_type", "code": "fn parse_and_match(needle: &str, source: &str) -> usize {\n    parse_and_match_helper(needle, source, false).len()\n}", "test": "fn _type() {\n    let source = r#\"\n        void foo() {\n            int x = 10;\n            unsigned char t = 0;\n        }\"#;\n\n    let needle = \"{unsigned char $x = _;}\";\n    let matches = parse_and_match(needle, source);\n    assert_eq!(matches, 1);\n\n    let needle = \"{int $x = _;}\";\n    let matches = parse_and_match(needle, source);\n    assert_eq!(matches, 1);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_dd.rs::_zero() {\n    ", "code": "pub fn stderr_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stderr_str(), msg.as_ref());\n        self\n    }", "test": "kip_zero() {\n    new_ucmd!()\n        .args(&[\"skip=0\", \"status=noxfer\"])\n        .succeeds()\n        .no_stdout()\n        .stderr_is(\"0+0 records in\\n0+0 records out\\n\");\n}\n\n#[test]"}
{"test_id": "astral-sh-ruff/astral-sh-ruff-1a6898a/crates/ruff_python_ast/tests/visitor.rs::function_positional_only_with_default", "code": "fn trace_visitation(source: &str) -> String {\n    let tokens = lex(source, Mode::Module);\n    let parsed = parse_tokens(tokens, source, Mode::Module, \"test.py\").unwrap();\n\n    let mut visitor = RecordVisitor::default();\n    walk_module(&mut visitor, &parsed);\n\n    visitor.output\n}", "test": "fn function_positional_only_with_default() {\n    let source = r#\"def a(b, c = 34,/, e = 20, *args): pass\"#;\n\n    let trace = trace_visitation(source);\n\n    assert_snapshot!(trace);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_date.rs::test_date_rfc_8601_invalid_arg", "code": "pub fn fails(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.failure();\n        cmd_result\n    }", "test": "fn test_date_rfc_8601_invalid_arg() {\n    for param in [\"--iso-8601\", \"--i\"] {\n        new_ucmd!().arg(format!(\"{param}=@\")).fails();\n    }\n}"}
{"test_id": "rustls-rustls/rustls-rustls-ae583bd/rustls/tests/api.rs::server_connection_is_debug", "code": "pub fn make_pair(kt: KeyType) -> (ClientConnection, ServerConnection) {\n    make_pair_for_configs(make_client_config(kt), make_server_config(kt))\n}", "test": "fn server_connection_is_debug() {\n    let (_, server) = make_pair(KeyType::Rsa);\n    println!(\"{:?}\", server);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_split.rs::test_short_combination", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_short_combination() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-dxen\", \"4\", \"threebytes.txt\"])\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"x00\"), \"a\");\n    assert_eq!(at.read(\"x01\"), \"b\");\n    assert_eq!(at.read(\"x02\"), \"c\");\n    assert!(!at.file_exists(\"x03\"));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_du.rs::test_du_symlink_fail", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_du_symlink_fail() {\n    let ts = TestScenario::new(util_name!());\n    let at = &ts.fixtures;\n\n    at.symlink_file(\"non-existing.txt\", \"target.txt\");\n\n    ts.ucmd().arg(\"-L\").arg(\"target.txt\").fails().code_is(1);\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/choose.rs::no_choosable_recipes", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn no_choosable_recipes() {\n  Test::new()\n    .arg(\"--choose\")\n    .justfile(\n      \"\n        _foo:\n          echo foo\n\n        bar BAR:\n          echo {{BAR}}\n      \",\n    )\n    .status(EXIT_FAILURE)\n    .stderr(\"error: Justfile contains no choosable recipes.\\n\")\n    .stdout(\"\")\n    .run();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_rmdir.rs::test_rmdir_nonempty_directory_no_parents", "code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rmdir_nonempty_directory_no_parents() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    at.mkdir(DIR);\n    at.touch(DIR_FILE);\n\n    ucmd.arg(DIR)\n        .fails()\n        .stderr_is(format!(\"rmdir: failed to remove 'dir': {NOT_EMPTY}\\n\"));\n\n    assert!(at.dir_exists(DIR));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_stat.rs::test_format_created_time", "code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_format_created_time() {\n    let args = [\"-c\", \"%w\", \"/bin\"];\n    let ts = TestScenario::new(util_name!());\n    let actual = ts.ucmd().args(&args).succeeds().stdout_move_str();\n    let expect = unwrap_or_return!(expected_result(&ts, &args)).stdout_move_str();\n    println!(\"actual: {actual:?}\");\n    println!(\"expect: {expect:?}\");\n    // note: using a regex instead of `split_whitespace()` in order to detect whitespace differences\n    let re = regex::Regex::new(r\"\\s\").unwrap();\n    let v_actual: Vec<&str> = re.split(&actual).collect();\n    let v_expect: Vec<&str> = re.split(&expect).collect();\n    assert!(!v_expect.is_empty());\n    // * allow for inequality if `stat` (aka, expect) returns \"-\" (unknown value)\n    assert!(\n        expect == \"-\"\n            || expect == \"-\\n\"\n            || v_actual\n                .iter()\n                .zip(v_expect.iter())\n                .all(|(a, e)| a == e || *e == \"-\" || *e == \"-\\n\")\n    );\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/control_flow/loops.rs::break_environment_gauntlet", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn break_environment_gauntlet() {\n    // test that break handles popping environments correctly.\n    let scenario = r#\"\n        let a = 0;\n\n        while(true) {\n            break;\n        }\n\n        while(true) break\n\n        do {break} while(true);\n\n        while (a < 3) {\n            let a = 1;\n            if (a == 1) {\n                break;\n            }\n\n            let b = 2;\n        }\n\n        {\n            b = 0;\n            do {\n                b = 2\n                if (b == 2) {\n                    break;\n                }\n                b++\n            } while( i < 3);\n\n            let c = 1;\n        }\n\n        {\n            for (let r = 0; r< 3; r++) {\n                if (r == 2) {\n                    break;\n                }\n            }\n        }\n\n        basic: for (let a = 0; a < 2; a++) {\n            break;\n        }\n\n        {\n            let result = true;\n            {\n                let x = 2;\n                L: {\n                    let x = 3;\n                    result &&= (x === 3);\n                    break L;\n                    result &&= (false);\n                }\n                result &&= (x === 2);\n            }\n            result;\n        }\n\n        {\n            var str = \"\";\n\n            far_outer: {\n                outer: for (let i = 0; i < 5; i++) {\n                    inner: for (let b = 5; b < 10; b++) {\n                        if (b === 7) {\n                            break far_outer;\n                        }\n                        str = str + b;\n                    }\n                    str = str + i;\n                }\n            }\n            str\n        }\n\n        {\n            for (let r = 0; r < 2; r++) {\n                str = str + r\n            }\n        }\n\n        {\n            let result = \"\";\n            lab_block: {\n                try {\n                    result = \"try_block\";\n                    break lab_block;\n                    result = \"did not break\"\n                } catch (err) {}\n            }\n            str = str + result\n            str\n        }\n    \"#;\n\n    run_test_actions([TestAction::assert_eq(scenario, \"5601try_block\")]);\n}"}
{"test_id": "dtolnay-ryu/dtolnay-ryu-2fc2d1c/tests/common_test.rs::test_log10_pow2", "code": "pub fn log10_pow2(e: i32) -> u32 /* or u32 -> u32 */ {\n    // The first value this approximation fails for is 2^1651 which is just greater than 10^297.\n    debug_assert!(e >= 0);\n    debug_assert!(e <= 1650);\n    (e as u32 * 78913) >> 18\n}", "test": "fn test_log10_pow2() {\n    assert_eq!(0, log10_pow2(0));\n    assert_eq!(0, log10_pow2(1));\n    assert_eq!(0, log10_pow2(2));\n    assert_eq!(0, log10_pow2(3));\n    assert_eq!(1, log10_pow2(4));\n    assert_eq!(496, log10_pow2(1650));\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_gc/src/test/weak_map.rs::weak_map_basic", "code": "pub fn has_weak_maps() -> bool {\n    BOA_GC.with(|current| {\n        let gc = current.borrow();\n\n        gc.weak_map_start.get().is_some()\n    })\n}", "test": "fn weak_map_basic() {\n    run_test(|| {\n        let key1 = Gc::new(String::from(\"key1\"));\n        let key2 = Gc::new(String::from(\"key2\"));\n        let key3 = Gc::new(String::from(\"key3\"));\n\n        assert!(!has_weak_maps());\n\n        let mut map = WeakMap::new();\n\n        assert!(has_weak_maps());\n\n        map.insert(&key1, ());\n        map.insert(&key2, ());\n        map.insert(&key3, ());\n\n        force_collect();\n        assert!(has_weak_maps());\n\n        assert!(map.contains_key(&key1));\n        assert!(map.contains_key(&key2));\n        assert!(map.contains_key(&key3));\n\n        drop(key1);\n\n        force_collect();\n        assert!(has_weak_maps());\n\n        assert!(map.contains_key(&key2));\n        assert!(map.contains_key(&key3));\n\n        drop(key2);\n\n        force_collect();\n        assert!(has_weak_maps());\n\n        assert!(map.contains_key(&key3));\n        assert!(has_weak_maps());\n\n        drop(key3);\n\n        assert!(has_weak_maps());\n\n        force_collect();\n        assert!(has_weak_maps());\n\n        drop(map);\n\n        force_collect();\n        assert!(!has_weak_maps());\n    });\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-parse-float/tests/libm_tests.rs::fabsd_spec_test", "code": "fn is_nan(self) -> bool {\n        self.is_special() && (self.to_bits() & Self::MANTISSA_MASK) != Self::Unsigned::ZERO\n    }", "test": "fn fabsd_spec_test() {\n    assert!(libm::fabsd(f64::NAN).is_nan());\n    for f in [0.0, -0.0].iter().copied() {\n        assert_eq!(libm::fabsd(f), 0.0);\n    }\n    for f in [f64::INFINITY, f64::NEG_INFINITY].iter().copied() {\n        assert_eq!(libm::fabsd(f), f64::INFINITY);\n    }\n}"}
{"test_id": "dtolnay-syn/dtolnay-syn-b1a038c/tests/test_ident.rs::ident_parse_underscore", "code": "pub fn parse() -> Result<types::Definitions> {\n    let tokens = load_token_file(TOKEN_SRC)?;\n\n    let mut lookup = Lookup {\n        items: BTreeMap::new(),\n        tokens,\n        aliases: BTreeMap::new(),\n    };\n\n    load_file(SYN_CRATE_ROOT, &[], &mut lookup)?;\n\n    let version = version::get()?;\n\n    let types = lookup\n        .items\n        .values()\n        .map(|item| introspect_item(item, &lookup))\n        .collect();\n\n    let tokens = lookup\n        .tokens\n        .into_iter()\n        .map(|(name, ty)| (ty, name))\n        .collect();\n\n    Ok(types::Definitions {\n        version,\n        types,\n        tokens,\n    })\n}", "test": "fn ident_parse_underscore() {\n    parse(\"_\").unwrap_err();\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_disk_full.rs::test_disk_full_followers_with_hibernate_regions", "code": "pub fn get_engine(&self, node_id: u64) -> WrapFactory<EK> {\n        WrapFactory::new(\n            self.pd_client.clone(),\n            self.raft_engines[&node_id].clone(),\n            self.tablet_registries[&node_id].clone(),\n        )\n    }", "test": "fn test_disk_full_followers_with_hibernate_regions() {\n    let mut cluster = new_node_cluster(0, 2);\n    // To ensure the thread has full store disk usage infomation.\n    cluster.cfg.raft_store.store_batch_system.pool_size = 1;\n    cluster.pd_client.disable_default_operator();\n    let _ = cluster.run_conf_change();\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    // Add a peer which is almost disk full should be allowed.\n    fail::cfg(get_fp(DiskUsage::AlmostFull, 2), \"return\").unwrap();\n    cluster.pd_client.must_add_peer(1, new_peer(2, 2));\n    must_get_equal(&cluster.get_engine(2), b\"k1\", b\"v1\");\n\n    let tick_dur = cluster.cfg.raft_store.raft_base_tick_interval.0;\n    let election_timeout = cluster.cfg.raft_store.raft_election_timeout_ticks;\n\n    thread::sleep(tick_dur * 2 * election_timeout as u32);\n    fail::remove(get_fp(DiskUsage::AlmostFull, 2));\n    thread::sleep(tick_dur * 2);\n\n    // The leader should know peer 2's disk usage changes, because it's keeping to\n    // tick.\n    cluster.must_put(b\"k2\", b\"v2\");\n    must_get_equal(&cluster.get_engine(2), b\"k2\", b\"v2\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_mv.rs::test_mv_backup_existing", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_backup_existing() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_backup_numbering_file_a\";\n    let file_b = \"test_mv_backup_numbering_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    ucmd.arg(\"--backup=existing\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}~\")));\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_unsafe_recovery.rs::test_unsafe_recovery_has_commit_merge", "code": "pub fn get_has_commit_merge(&self) -> bool {\n        self.has_commit_merge\n    }", "test": "fn test_unsafe_recovery_has_commit_merge() {\n    let mut cluster = new_node_cluster(0, 3);\n    configure_for_merge(&mut cluster.cfg);\n\n    cluster.run();\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k3\", b\"v3\");\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n    let region = pd_client.get_region(b\"k1\").unwrap();\n    cluster.must_split(&region, b\"k2\");\n\n    let left = pd_client.get_region(b\"k1\").unwrap();\n    let right = pd_client.get_region(b\"k3\").unwrap();\n\n    let left_on_store1 = find_peer(&left, 1).unwrap();\n    cluster.must_transfer_leader(left.get_id(), left_on_store1.clone());\n    let right_on_store1 = find_peer(&right, 1).unwrap();\n    cluster.must_transfer_leader(right.get_id(), right_on_store1.clone());\n\n    // Block the target region from receiving MsgAppendResponse, so that the commit\n    // merge message will only be replicated but not committed.\n    let recv_filter = Box::new(\n        RegionPacketFilter::new(right.get_id(), 1)\n            .direction(Direction::Recv)\n            .msg_type(MessageType::MsgAppendResponse),\n    );\n    cluster.sim.wl().add_recv_filter(1, recv_filter);\n\n    pd_client.merge_region(left.get_id(), right.get_id());\n    // Wait until the commit merge is proposed.\n    sleep_ms(300);\n    // Send a empty recovery plan to trigger report.\n    let plan = pdpb::RecoveryPlan::default();\n    pd_client.must_set_unsafe_recovery_plan(1, plan);\n    cluster.must_send_store_heartbeat(1);\n    let mut store_report = None;\n    for _ in 0..20 {\n        store_report = pd_client.must_get_store_report(1);\n        if store_report.is_some() {\n            break;\n        }\n        sleep_ms(200);\n    }\n    assert_ne!(store_report, None);\n    let mut has_commit_merge = false;\n    for peer_report in store_report.unwrap().get_peer_reports().iter() {\n        if peer_report.get_region_state().get_region().get_id() == right.get_id()\n            && peer_report.get_has_commit_merge()\n        {\n            has_commit_merge = true;\n        }\n    }\n    assert!(has_commit_merge);\n}"}
{"test_id": "serde-rs-json/serde-rs-json-66f862f/tests/lexical/math.rs::iadd_small_test", "code": "pub(crate) fn from_u32(x: &[u32]) -> Vec<Limb> {\n    x.iter().cloned().collect()\n}", "test": "fn iadd_small_test() {\n    // Overflow check (single)\n    // This should set all the internal data values to 0, the top\n    // value to (1<<31), and the bottom value to (4>>1).\n    // This is because the max_value + 1 leads to all 0s, we set the\n    // topmost bit to 1.\n    let mut x = Bigint {\n        data: from_u32(&[4294967295]),\n    };\n    x.iadd_small(5);\n    assert_eq!(x.data, from_u32(&[4, 1]));\n\n    // No overflow, single value\n    let mut x = Bigint {\n        data: from_u32(&[5]),\n    };\n    x.iadd_small(7);\n    assert_eq!(x.data, from_u32(&[12]));\n\n    // Single carry, internal overflow\n    let mut x = Bigint::from_u64(0x80000000FFFFFFFF);\n    x.iadd_small(7);\n    assert_eq!(x.data, from_u32(&[6, 0x80000001]));\n\n    // Double carry, overflow\n    let mut x = Bigint::from_u64(0xFFFFFFFFFFFFFFFF);\n    x.iadd_small(7);\n    assert_eq!(x.data, from_u32(&[6, 0, 1]));\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_text_size/tests/main.rs::math", "code": "fn size(x: u32) -> TextSize {\n    TextSize::from(x)\n}", "test": "fn math() {\n    assert_eq!(size(10) + size(5), size(15));\n    assert_eq!(size(10) - size(5), size(5));\n}"}
{"test_id": "ron-rs-ron/ron-rs-ron-eafa2b6/tests/123_enum_representation.rs::test_adjacently_b_de", "code": "fn test_de<T>(s: &str, expected: T)\nwhere\n    T: for<'a> Deserialize<'a> + Debug + PartialEq,\n{\n    let actual: Result<T, _> = from_str(s);\n    assert_eq!(actual, Ok(expected));\n}", "test": "fn test_adjacently_b_de() {\n    let s = \"(type:VariantB,content:(foo:1,bar:2))\";\n    let e = EnumStructAdjacently::VariantB { foo: 1, bar: 2 };\n    test_de(s, e);\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/undefined_variables.rs::unknown_second_variable_in_binary_call", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn unknown_second_variable_in_binary_call() {\n  Test::new()\n    .justfile(\n      \"\n    foo x=env_var_or_default('', b):\n  \",\n    )\n    .stderr(\n      \"\n      error: Variable `b` not defined\n        |\n      1 | foo x=env_var_or_default('', b):\n        |                              ^\n      \",\n    )\n    .status(EXIT_FAILURE)\n    .run();\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/slash_operator.rs::no_lhs_twice", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn no_lhs_twice() {\n  Test::new()\n    .justfile(\"x := / 'a' / 'b'\")\n    .args([\"--evaluate\", \"x\"])\n    .stdout(\"/a/b\")\n    .run();\n  Test::new()\n    .justfile(\"x := // 'a'\")\n    .args([\"--evaluate\", \"x\"])\n    .stdout(\"//a\")\n    .run();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_numfmt.rs::test_from_iec", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_from_iec() {\n    new_ucmd!()\n        .args(&[\"--from=iec\"])\n        .pipe_in(\"1024\\n1.1M\\n0.1G\")\n        .run()\n        .stdout_is(\"1024\\n1153434\\n107374183\\n\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_compact_lock_cf.rs::test_server_compact_lock_cf", "code": "fn test_compact_lock_cf<T: Simulator>(cluster: &mut Cluster<T>) {\n    let interval = 500;\n    // Set lock_cf_compact_interval.\n    cluster.cfg.raft_store.lock_cf_compact_interval = ReadableDuration::millis(interval);\n    // Set lock_cf_compact_bytes_threshold.\n    cluster.cfg.raft_store.lock_cf_compact_bytes_threshold = ReadableSize(100);\n    cluster.cfg.rocksdb.lockcf.disable_auto_compactions = true;\n    cluster.run();\n\n    // Write 40 bytes, not reach lock_cf_compact_bytes_threshold, so there is no\n    // compaction.\n    for i in 0..5 {\n        let (k, v) = (format!(\"k{}\", i), format!(\"value{}\", i));\n        cluster.must_put_cf(CF_LOCK, k.as_bytes(), v.as_bytes());\n    }\n    // Generate one sst, if there are datas only in one memtable, no compactions\n    // will be triggered.\n    flush(cluster);\n\n    // Write more 40 bytes, still not reach lock_cf_compact_bytes_threshold,\n    // so there is no compaction.\n    for i in 5..10 {\n        let (k, v) = (format!(\"k{}\", i), format!(\"value{}\", i));\n        cluster.must_put_cf(CF_LOCK, k.as_bytes(), v.as_bytes());\n    }\n    // Generate another sst.\n    flush_then_check(cluster, interval, false);\n\n    // Write more 50 bytes, reach lock_cf_compact_bytes_threshold.\n    for i in 10..15 {\n        let (k, v) = (format!(\"k{}\", i), format!(\"value{}\", i));\n        cluster.must_put_cf(CF_LOCK, k.as_bytes(), v.as_bytes());\n    }\n    flush_then_check(cluster, interval, true);\n}", "test": "fn test_server_compact_lock_cf() {\n    let count = 1;\n    let mut cluster = new_server_cluster(0, count);\n    test_compact_lock_cf(&mut cluster);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_dirname.rs::test_path_with_trailing_slashes", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_path_with_trailing_slashes() {\n    new_ucmd!()\n        .arg(\"/root/alpha/beta/gamma/delta/epsilon/omega//\")\n        .run()\n        .stdout_is(\"/root/alpha/beta/gamma/delta/epsilon\\n\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_pr.rs::test_without_any_options", "code": "pub fn stdout_is_templated_fixture<T: AsRef<OsStr>>(\n        &self,\n        file_rel_path: T,\n        template_vars: &[(&str, &str)],\n    ) -> &Self {\n        let mut contents =\n            String::from_utf8(read_scenario_fixture(&self.tmpd, file_rel_path)).unwrap();\n        for kv in template_vars {\n            contents = contents.replace(kv.0, kv.1);\n        }\n        self.stdout_is(contents)\n    }", "test": "fn test_without_any_options() {\n    let test_file_path = \"test_one_page.log\";\n    let expected_test_file_path = \"test_one_page.log.expected\";\n    let mut scenario = new_ucmd!();\n    let value = file_last_modified_time(&scenario, test_file_path);\n    scenario\n        .args(&[test_file_path])\n        .succeeds()\n        .stdout_is_templated_fixture(expected_test_file_path, &[(\"{last_modified_time}\", &value)]);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_mkdir.rs::test_mkdir_parent_mode", "code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mkdir_parent_mode() {\n    let _guard = TEST_MUTEX.lock();\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let default_umask: mode_t = 0o160;\n    let original_umask = unsafe { umask(default_umask) };\n\n    ucmd.arg(\"-p\").arg(\"a/b\").succeeds().no_stderr().no_stdout();\n\n    assert!(at.dir_exists(\"a\"));\n    // parents created by -p have permissions set to \"=rwx,u+wx\"\n    assert_eq!(\n        at.metadata(\"a\").permissions().mode() as mode_t,\n        ((!default_umask & 0o777) | 0o300) + 0o40000\n    );\n    assert!(at.dir_exists(\"a/b\"));\n    // sub directory's permission is determined only by the umask\n    assert_eq!(\n        at.metadata(\"a/b\").permissions().mode() as mode_t,\n        (!default_umask & 0o777) + 0o40000\n    );\n\n    unsafe {\n        umask(original_umask);\n    }\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_replica_stale_read.rs::test_stale_read_1pc_flow_replicate", "code": "pub fn has_data_is_not_ready(&self) -> bool {\n        self.data_is_not_ready.is_some()\n    }", "test": "fn test_stale_read_1pc_flow_replicate() {\n    let (mut cluster, pd_client, mut leader_client) = prepare_for_stale_read(new_peer(1, 1));\n    let mut follower_client2 = PeerClient::new(&cluster, 1, new_peer(2, 2));\n    // Set the `stale_read` flag\n    leader_client.ctx.set_stale_read(true);\n    follower_client2.ctx.set_stale_read(true);\n\n    let commit_ts1 = leader_client.must_kv_write(\n        &pd_client,\n        vec![new_mutation(Op::Put, &b\"key1\"[..], &b\"value1\"[..])],\n        b\"key1\".to_vec(),\n    );\n\n    // Can read `value1` with the newest ts\n    follower_client2.must_kv_read_equal(b\"key1\".to_vec(), b\"value1\".to_vec(), get_tso(&pd_client));\n\n    // Stop replicate data to follower 2\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(1, 2)\n            .direction(Direction::Recv)\n            .msg_type(MessageType::MsgAppend),\n    ));\n    // Update `key1`\n    leader_client.must_kv_prewrite_one_pc(\n        vec![new_mutation(Op::Put, &b\"key1\"[..], &b\"value2\"[..])],\n        b\"key1\".to_vec(),\n        get_tso(&pd_client),\n    );\n    let read_ts = get_tso(&pd_client);\n    // wait for advance_resolved_ts.\n    sleep_ms(200);\n    // Follower 2 can still read `value1`, but can not read `value2` due\n    // to it don't have enough data\n    follower_client2.must_kv_read_equal(b\"key1\".to_vec(), b\"value1\".to_vec(), commit_ts1);\n    let resp1 = follower_client2.kv_read(b\"key1\".to_vec(), read_ts);\n    assert!(resp1.get_region_error().has_data_is_not_ready());\n\n    // Leader have up to date data so it can read `value2`\n    leader_client.must_kv_read_equal(b\"key1\".to_vec(), b\"value2\".to_vec(), get_tso(&pd_client));\n\n    // clear the `MsgAppend` filter\n    cluster.clear_send_filters();\n\n    // Now we can read `value2` with the newest ts\n    follower_client2.must_kv_read_equal(b\"key1\".to_vec(), b\"value2\".to_vec(), get_tso(&pd_client));\n}"}
{"test_id": "ron-rs-ron/ron-rs-ron-eafa2b6/tests/min_max.rs::test_u128_min", "code": "pub fn to_string<T>(&self, value: &T) -> Result<String>\n    where\n        T: ?Sized + ser::Serialize,\n    {\n        let mut output = Vec::new();\n        let mut s = Serializer::with_options(&mut output, None, self.clone())?;\n        value.serialize(&mut s)?;\n        Ok(String::from_utf8(output).expect(\"Ron should be utf-8\"))\n    }", "test": "fn test_u128_min() {\n    assert_eq!(\n        std::u128::MIN,\n        from_str(&to_string(&std::u128::MIN).unwrap()).unwrap()\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_kill.rs::test_kill_with_signal_name_old_form", "code": "fn wait_for_signal(&mut self) -> Option<i32> {\n        let sig = self.child.wait().expect(\"cannot wait on target\").signal();\n        self.killed = true;\n        sig\n    }", "test": "fn test_kill_with_signal_name_old_form() {\n    let mut target = Target::new();\n    new_ucmd!()\n        .arg(\"-KILL\")\n        .arg(format!(\"{}\", target.pid()))\n        .succeeds();\n    assert_eq!(target.wait_for_signal(), Some(libc::SIGKILL));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_csplit.rs::test_skip_to_match_sequence3", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_skip_to_match_sequence3() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"%0$%\", \"{1}\", \"/^4/\"])\n        .succeeds()\n        .stdout_only(\"60\\n33\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"there should be splits created\")\n        .count();\n    assert_eq!(count, 2);\n    assert_eq!(at.read(\"xx00\"), generate(20, 40));\n    assert_eq!(at.read(\"xx01\"), generate(40, 51));\n}"}
{"test_id": "serde-rs-json/serde-rs-json-66f862f/tests/lexical/float.rs::round_to_f32_test", "code": "fn check_round_to_f32(mant: u64, exp: i32, r_mant: u64, r_exp: i32) {\n    let mut x = ExtendedFloat { mant, exp };\n    x.round_to_native::<f32, _>(round_nearest_tie_even);\n    assert_eq!(\n        x,\n        ExtendedFloat {\n            mant: r_mant,\n            exp: r_exp\n        }\n    );\n}", "test": "fn round_to_f32_test() {\n    // This is lossy, so some of these values are **slightly** rounded.\n\n    // underflow\n    check_round_to_f32(9223372036854775808, -213, 0, -149);\n\n    // min value\n    check_round_to_f32(9223372036854775808, -212, 1, -149);\n\n    // 1.0e-40\n    check_round_to_f32(10043308644012916736, -196, 71362, -149);\n\n    // 1.0e-20\n    check_round_to_f32(13611294244890214400, -130, 12379400, -90);\n\n    // 1.0\n    check_round_to_f32(9223372036854775808, -63, 8388608, -23);\n\n    // 1e20\n    check_round_to_f32(12500000250510966784, 3, 11368684, 43);\n\n    // max value\n    check_round_to_f32(18446740775174668288, 64, 16777213, 104);\n\n    // overflow\n    check_round_to_f32(18446740775174668288, 65, 16777213, 105);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_fold.rs::test_bytewise_backspace_should_be_preserved", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_bytewise_backspace_should_be_preserved() {\n    new_ucmd!()\n        .arg(\"-b\")\n        .pipe_in(\"\\x08\")\n        .succeeds()\n        .stdout_is(\"\\x08\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_ls.rs::test_ls_across", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_ls_across() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    at.touch(at.plus_as_string(\"test-across-1\"));\n    at.touch(at.plus_as_string(\"test-across-2\"));\n    at.touch(at.plus_as_string(\"test-across-3\"));\n    at.touch(at.plus_as_string(\"test-across-4\"));\n\n    for option in ACROSS_ARGS {\n        let result = scene.ucmd().arg(option).succeeds();\n        // Because the test terminal has width 0, this is the same output as\n        // the columns option.\n        result.stdout_only(\"test-across-1  test-across-2  test-across-3  test-across-4\\n\");\n    }\n\n    for option in ACROSS_ARGS {\n        // Because the test terminal has width 0, this is the same output as\n        // the columns option.\n        scene\n            .ucmd()\n            .arg(\"-w=30\")\n            .arg(option)\n            .succeeds()\n            .stdout_only(\"test-across-1  test-across-2\\ntest-across-3  test-across-4\\n\");\n    }\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/dotenv.rs::can_set_dotenv_path_from_justfile", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn can_set_dotenv_path_from_justfile() {\n  Test::new()\n    .justfile(\n      r#\"\n        set dotenv-path:= \"subdir/.env\"\n\n        foo:\n          @echo $NAME\n      \"#,\n    )\n    .tree(tree! {\n      subdir: {\n        \".env\": \"NAME=bar\"\n      }\n    })\n    .stdout(\"bar\\n\")\n    .status(EXIT_SUCCESS)\n    .run();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_seq.rs::test_neg_inf", "code": "pub fn run(&mut self) -> CmdResult {\n        self.run_no_wait().wait().unwrap()\n    }", "test": "fn test_neg_inf() {\n    run(&[\"--\", \"-inf\", \"0\"], b\"-inf\\n-inf\\n-inf\\n\");\n}"}
{"test_id": "raphlinus-pulldown-cmark/raphlinus-pulldown-cmark-3da63d5/tests/suite/table.rs::table_test_7", "code": "pub fn test_markdown_html(input: &str, output: &str, smart_punct: bool) {\n    let mut s = String::new();\n\n    let mut opts = Options::empty();\n    opts.insert(Options::ENABLE_TABLES);\n    opts.insert(Options::ENABLE_FOOTNOTES);\n    opts.insert(Options::ENABLE_STRIKETHROUGH);\n    opts.insert(Options::ENABLE_TASKLISTS);\n    if smart_punct {\n        opts.insert(Options::ENABLE_SMART_PUNCTUATION);\n    }\n    opts.insert(Options::ENABLE_HEADING_ATTRIBUTES);\n\n    let p = Parser::new_ext(input, opts);\n    pulldown_cmark::html::push_html(&mut s, p);\n\n    assert_eq!(normalize_html(output), normalize_html(&s));\n}", "test": "fn table_test_7() {\n    let original = r##\"| Col 1 | Col 2 |\n|-------|-------|\n|   x   |       |\n|       |    x  |\n\"##;\n    let expected = r##\"<table><thead><tr><th> Col 1 </th><th> Col 2 </th></tr></thead>\n<tr><td>   x   </td><td>       </td></tr>\n<tr><td>       </td><td>    x  </td></tr>\n</table>\n\"##;\n\n    test_markdown_html(original, expected, false);\n}"}
{"test_id": "dtolnay-serde-yaml/dtolnay-serde-yaml-f8adb28/tests/test_serde.rs::test_u128_small", "code": "fn test_serde<T>(thing: &T, yaml: &str)\nwhere\n    T: serde::Serialize + serde::de::DeserializeOwned + PartialEq + Debug,\n{\n    let serialized = serde_yaml::to_string(&thing).unwrap();\n    assert_eq!(yaml, serialized);\n\n    let value = serde_yaml::to_value(thing).unwrap();\n    let serialized = serde_yaml::to_string(&value).unwrap();\n    assert_eq!(yaml, serialized);\n\n    let deserialized: T = serde_yaml::from_str(yaml).unwrap();\n    assert_eq!(*thing, deserialized);\n\n    let value: Value = serde_yaml::from_str(yaml).unwrap();\n    let deserialized = T::deserialize(&value).unwrap();\n    assert_eq!(*thing, deserialized);\n\n    let deserialized: T = serde_yaml::from_value(value).unwrap();\n    assert_eq!(*thing, deserialized);\n\n    serde_yaml::from_str::<serde::de::IgnoredAny>(yaml).unwrap();\n}", "test": "fn test_u128_small() {\n    let thing: u128 = 256;\n    let yaml = indoc! {\"\n        256\n    \"};\n    test_serde(&thing, yaml);\n}"}
{"test_id": "weggli-rs-weggli/weggli-rs-weggli-ad8d424/tests/query.rs::test_strict_statement", "code": "fn parse_and_match(needle: &str, source: &str) -> usize {\n    parse_and_match_helper(needle, source, false).len()\n}", "test": "fn test_strict_statement() {\n    let needle = \"{strict: randomFunction('a', 10+20);}\";\n    let source = r\"\n    void func(){\n        x = randomFunction('a', 10+20); // no match\n        randomFunction('a', 10+20); // match\n        if (true) {\n            y = randomFunction('a', 10+20); // no match\n            randomFunction('a',10+20); // match\n        }\n    }\";\n\n    let matches = parse_and_match(needle, source);\n    assert_eq!(matches, 2);\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/line_prefixes.rs::quiet_after_infallible", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn quiet_after_infallible() {\n  Test::new()\n    .justfile(\n      \"\n        foo:\n          -@exit 1\n      \",\n    )\n    .run();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_touch.rs::test_touch_set_both_time_and_date", "code": "pub fn fails(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.failure();\n        cmd_result\n    }", "test": "fn test_touch_set_both_time_and_date() {\n    let (_at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_both_time_and_date\";\n\n    ucmd.args(&[\n        \"-t\",\n        \"2015010112342\",\n        \"-d\",\n        \"Thu Jan 01 12:34:00 2015\",\n        file,\n    ])\n    .fails();\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_common.rs::parse_fetch_variations", "code": "pub fn one_statement_parses_to(&self, sql: &str, canonical: &str) -> Statement {\n        let mut statements = self.parse_sql_statements(sql).expect(sql);\n        assert_eq!(statements.len(), 1);\n\n        if !canonical.is_empty() && sql != canonical {\n            assert_eq!(self.parse_sql_statements(canonical).unwrap(), statements);\n        }\n\n        let only_statement = statements.pop().unwrap();\n        if !canonical.is_empty() {\n            assert_eq!(canonical, only_statement.to_string())\n        }\n        only_statement\n    }", "test": "fn parse_fetch_variations() {\n    one_statement_parses_to(\n        \"SELECT foo FROM bar FETCH FIRST 10 ROW ONLY\",\n        \"SELECT foo FROM bar FETCH FIRST 10 ROWS ONLY\",\n    );\n    one_statement_parses_to(\n        \"SELECT foo FROM bar FETCH NEXT 10 ROW ONLY\",\n        \"SELECT foo FROM bar FETCH FIRST 10 ROWS ONLY\",\n    );\n    one_statement_parses_to(\n        \"SELECT foo FROM bar FETCH NEXT 10 ROWS WITH TIES\",\n        \"SELECT foo FROM bar FETCH FIRST 10 ROWS WITH TIES\",\n    );\n    one_statement_parses_to(\n        \"SELECT foo FROM bar FETCH NEXT ROWS WITH TIES\",\n        \"SELECT foo FROM bar FETCH FIRST ROWS WITH TIES\",\n    );\n    one_statement_parses_to(\n        \"SELECT foo FROM bar FETCH FIRST ROWS ONLY\",\n        \"SELECT foo FROM bar FETCH FIRST ROWS ONLY\",\n    );\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_common.rs::parse_alter_view_with_options", "code": "pub fn verified_stmt(&self, sql: &str) -> Statement {\n        self.one_statement_parses_to(sql, sql)\n    }", "test": "fn parse_alter_view_with_options() {\n    let sql = \"ALTER VIEW v WITH (foo = 'bar', a = 123) AS SELECT 1\";\n    match verified_stmt(sql) {\n        Statement::AlterView { with_options, .. } => {\n            assert_eq!(\n                vec![\n                    SqlOption {\n                        name: \"foo\".into(),\n                        value: Value::SingleQuotedString(\"bar\".into()),\n                    },\n                    SqlOption {\n                        name: \"a\".into(),\n                        value: number(\"123\"),\n                    },\n                ],\n                with_options\n            );\n        }\n        _ => unreachable!(),\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_dd.rs::test_stdin_stdout", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_stdin_stdout() {\n    let input = build_ascii_block(521);\n    let output = String::from_utf8(input.clone()).unwrap();\n    new_ucmd!()\n        .args(&[\"status=none\"])\n        .pipe_in(input)\n        .run()\n        .no_stderr()\n        .stdout_only(output);\n}"}
{"test_id": "dtolnay-syn/dtolnay-syn-b1a038c/tests/test_attribute.rs::test_meta_item_list_bool_value", "code": "fn test(input: &str) -> Meta {\n    let attrs = Attribute::parse_outer.parse_str(input).unwrap();\n\n    assert_eq!(attrs.len(), 1);\n    let attr = attrs.into_iter().next().unwrap();\n\n    attr.meta\n}", "test": "fn test_meta_item_list_bool_value() {\n    let meta = test(\"#[foo(bar = true)]\");\n\n    snapshot!(meta, @r###\"\n    Meta::List {\n        path: Path {\n            segments: [\n                PathSegment {\n                    ident: \"foo\",\n                },\n            ],\n        },\n        delimiter: MacroDelimiter::Paren,\n        tokens: TokenStream(`bar = true`),\n    }\n    \"###);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_fold.rs::test_backspaced_char_should_be_preserved", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_backspaced_char_should_be_preserved() {\n    new_ucmd!().pipe_in(\"x\\x08\").succeeds().stdout_is(\"x\\x08\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_mktemp.rs::test_tmpdir_absolute_path", "code": "pub fn stderr_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stdout().stderr_is(msg)\n    }", "test": "fn test_tmpdir_absolute_path() {\n    #[cfg(windows)]\n    let path = r\"C:\\XXX\";\n    #[cfg(not(windows))]\n    let path = \"/XXX\";\n    new_ucmd!()\n        .args(&[\"--tmpdir=a\", path])\n        .fails()\n        .stderr_only(format!(\n            \"mktemp: invalid template, '{path}'; with --tmpdir, it may not be absolute\\n\"\n        ));\n}"}
{"test_id": "dtolnay-semver/dtolnay-semver-750f0ac/tests/test_version_req.rs::test_multiple", "code": "pub(super) fn assert_to_string(value: impl Display, expected: &str) {\n    assert_eq!(value.to_string(), expected);\n}", "test": "pub fn test_multiple() {\n    let ref r = req(\"> 0.0.9, <= 2.5.3\");\n    assert_to_string(r, \">0.0.9, <=2.5.3\");\n    assert_match_all(r, &[\"0.0.10\", \"1.0.0\", \"2.5.3\"]);\n    assert_match_none(r, &[\"0.0.8\", \"2.5.4\"]);\n\n    let ref r = req(\"0.3.0, 0.4.0\");\n    assert_to_string(r, \"^0.3.0, ^0.4.0\");\n    assert_match_none(r, &[\"0.0.8\", \"0.3.0\", \"0.4.0\"]);\n\n    let ref r = req(\"<= 0.2.0, >= 0.5.0\");\n    assert_to_string(r, \"<=0.2.0, >=0.5.0\");\n    assert_match_none(r, &[\"0.0.8\", \"0.3.0\", \"0.5.1\"]);\n\n    let ref r = req(\"0.1.0, 0.1.4, 0.1.6\");\n    assert_to_string(r, \"^0.1.0, ^0.1.4, ^0.1.6\");\n    assert_match_all(r, &[\"0.1.6\", \"0.1.9\"]);\n    assert_match_none(r, &[\"0.1.0\", \"0.1.4\", \"0.2.0\"]);\n\n    let err = req_err(\"> 0.1.0,\");\n    assert_to_string(\n        err,\n        \"unexpected end of input while parsing major version number\",\n    );\n\n    let err = req_err(\"> 0.3.0, ,\");\n    assert_to_string(\n        err,\n        \"unexpected character ',' while parsing major version number\",\n    );\n\n    let ref r = req(\">=0.5.1-alpha3, <0.6\");\n    assert_to_string(r, \">=0.5.1-alpha3, <0.6\");\n    assert_match_all(\n        r,\n        &[\n            \"0.5.1-alpha3\",\n            \"0.5.1-alpha4\",\n            \"0.5.1-beta\",\n            \"0.5.1\",\n            \"0.5.5\",\n        ],\n    );\n    assert_match_none(\n        r,\n        &[\"0.5.1-alpha1\", \"0.5.2-alpha3\", \"0.5.5-pre\", \"0.5.0-pre\"],\n    );\n    assert_match_none(r, &[\"0.6.0\", \"0.6.0-pre\"]);\n\n    // https://github.com/steveklabnik/semver/issues/56\n    let err = req_err(\"1.2.3 - 2.3.4\");\n    assert_to_string(err, \"expected comma after patch version number, found '-'\");\n\n    let err = req_err(\">1, >2, >3, >4, >5, >6, >7, >8, >9, >10, >11, >12, >13, >14, >15, >16, >17, >18, >19, >20, >21, >22, >23, >24, >25, >26, >27, >28, >29, >30, >31, >32, >33\");\n    assert_to_string(err, \"excessive number of version comparators\");\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/memory.rs::dynamic_extra_growth_unchanged_pointer", "code": "pub fn data_ptr(&self, store: impl AsContext) -> *mut u8 {\n        unsafe { (*store.as_context()[self.0].definition).base }\n    }", "test": "fn dynamic_extra_growth_unchanged_pointer() -> Result<()> {\n    const EXTRA_PAGES: u64 = 5;\n    let mut config = Config::new();\n    config.static_memory_maximum_size(0);\n    // 5 wasm pages extra\n    config.dynamic_memory_reserved_for_growth(EXTRA_PAGES * (1 << 16));\n    let engine = Engine::new(&config)?;\n    let mut store = Store::new(&engine, ());\n\n    fn assert_behaves_well(store: &mut Store<()>, mem: &Memory) -> Result<()> {\n        let ptr = mem.data_ptr(&store);\n\n        // Each growth here should retain the same linear pointer in memory and the\n        // memory shouldn't get moved.\n        for _ in 0..EXTRA_PAGES {\n            mem.grow(&mut *store, 1)?;\n            assert_eq!(ptr, mem.data_ptr(&store));\n        }\n\n        // Growth afterwards though will be forced to move the pointer\n        mem.grow(&mut *store, 1)?;\n        let new_ptr = mem.data_ptr(&store);\n        assert_ne!(ptr, new_ptr);\n\n        for _ in 0..EXTRA_PAGES - 1 {\n            mem.grow(&mut *store, 1)?;\n            assert_eq!(new_ptr, mem.data_ptr(&store));\n        }\n        Ok(())\n    }\n\n    let mem = Memory::new(&mut store, MemoryType::new(10, None))?;\n    assert_behaves_well(&mut store, &mem)?;\n\n    let module = Module::new(&engine, r#\"(module (memory (export \"mem\") 10))\"#)?;\n    let instance = Instance::new(&mut store, &module, &[])?;\n    let mem = instance.get_memory(&mut store, \"mem\").unwrap();\n    assert_behaves_well(&mut store, &mem)?;\n\n    let module = Module::new(\n        &engine,\n        r#\"\n            (module\n                (memory (export \"mem\") 10)\n                (data (i32.const 0) \"\"))\n        \"#,\n    )?;\n    let instance = Instance::new(&mut store, &module, &[])?;\n    let mem = instance.get_memory(&mut store, \"mem\").unwrap();\n    assert_behaves_well(&mut store, &mem)?;\n\n    Ok(())\n}"}
{"test_id": "quinn-rs-quinn/quinn-rs-quinn-83e4f46/quinn-proto/src/tests/mod.rs::stop_opens_bidi", "code": "pub fn send_streams(&self) -> usize {\n        self.state.send_streams\n    }", "test": "fn stop_opens_bidi() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    let (client_ch, server_ch) = pair.connect();\n    assert_eq!(pair.client_streams(client_ch).send_streams(), 0);\n    let s = pair.client_streams(client_ch).open(Dir::Bi).unwrap();\n    assert_eq!(pair.client_streams(client_ch).send_streams(), 1);\n    const ERROR: VarInt = VarInt(42);\n    pair.client\n        .connections\n        .get_mut(&server_ch)\n        .unwrap()\n        .recv_stream(s)\n        .stop(ERROR)\n        .unwrap();\n    pair.drive();\n\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Bi }))\n    );\n    assert_eq!(pair.server_conn_mut(client_ch).streams().send_streams(), 0);\n    assert_matches!(pair.server_streams(server_ch).accept(Dir::Bi), Some(stream) if stream == s);\n    assert_eq!(pair.server_conn_mut(client_ch).streams().send_streams(), 1);\n\n    let mut recv = pair.server_recv(server_ch, s);\n    let mut chunks = recv.read(false).unwrap();\n    assert_matches!(chunks.next(usize::MAX), Err(ReadError::Blocked));\n    let _ = chunks.finalize();\n\n    assert_matches!(\n        pair.server_send(server_ch, s).write(b\"foo\"),\n        Err(WriteError::Stopped(ERROR))\n    );\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Stream(StreamEvent::Stopped {\n            id: _,\n            error_code: ERROR\n        }))\n    );\n    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-parse-float/tests/stackvec_tests.rs::shl_test", "code": "pub fn vec_from_u32<const SIZE: usize>(x: &[u32]) -> StackVec<SIZE> {\n    let mut vec = StackVec::<SIZE>::new();\n    #[cfg(not(all(target_pointer_width = \"64\", not(target_arch = \"sparc\"))))]\n    {\n        for &xi in x {\n            vec.try_push(xi as Limb).unwrap();\n        }\n    }\n\n    #[cfg(all(target_pointer_width = \"64\", not(target_arch = \"sparc\")))]\n    {\n        for xi in x.chunks(2) {\n            match xi.len() {\n                1 => vec.try_push(xi[0] as Limb).unwrap(),\n                2 => {\n                    let xi0 = xi[0] as Limb;\n                    let xi1 = xi[1] as Limb;\n                    vec.try_push((xi1 << 32) | xi0).unwrap()\n                },\n                _ => unreachable!(),\n            }\n        }\n    }\n\n    vec\n}", "test": "fn shl_test() {\n    // Pattern generated via `''.join([\"1\" +\"0\"*i for i in range(20)])`\n    let mut x = VecType::from_u32(0xD2210408);\n    bigint::shl(&mut x, 5);\n    let expected: VecType = vec_from_u32(&[0x44208100, 0x1A]);\n    assert_eq!(&*x, &*expected);\n\n    bigint::shl(&mut x, 32);\n    let expected: VecType = vec_from_u32(&[0, 0x44208100, 0x1A]);\n    assert_eq!(&*x, &*expected);\n\n    bigint::shl(&mut x, 27);\n    let expected: VecType = vec_from_u32(&[0, 0, 0xD2210408]);\n    assert_eq!(&*x, &*expected);\n\n    // 96-bits of previous pattern\n    let mut x: VecType = vec_from_u32(&[0x20020010, 0x8040100, 0xD2210408]);\n    bigint::shl(&mut x, 5);\n    let expected: VecType = vec_from_u32(&[0x400200, 0x802004, 0x44208101, 0x1A]);\n    assert_eq!(&*x, &*expected);\n\n    bigint::shl(&mut x, 32);\n    let expected: VecType = vec_from_u32(&[0, 0x400200, 0x802004, 0x44208101, 0x1A]);\n    assert_eq!(&*x, &*expected);\n\n    bigint::shl(&mut x, 27);\n    let expected: VecType = vec_from_u32(&[0, 0, 0x20020010, 0x8040100, 0xD2210408]);\n    assert_eq!(&*x, &*expected);\n}"}
{"test_id": "paritytech-wasmi/paritytech-wasmi-d66f271/crates/wasmi/tests/e2e/v1/fuel_consumption_mode.rs::lazy_consumption_mode", "code": "fn check_consumption_mode(mode: FuelConsumptionMode, given_fuel: u64, consumed_fuel: u64) {\n    assert!(given_fuel >= consumed_fuel);\n    let wasm = wat2wasm(test_module());\n    let (mut store, func) = default_test_setup(mode, &wasm);\n    let func = func.typed::<(), i32>(&store).unwrap();\n    // Now add enough fuel, so execution should succeed.\n    store.add_fuel(given_fuel).unwrap(); // this is just enough fuel for a successful `memory.grow`\n    assert_success(func.call(&mut store, ()));\n    assert_eq!(store.fuel_consumed(), Some(consumed_fuel));\n}", "test": "fn lazy_consumption_mode() {\n    check_consumption_mode(FuelConsumptionMode::Lazy, 1030, 4);\n}"}
{"test_id": "raphlinus-pulldown-cmark/raphlinus-pulldown-cmark-3da63d5/tests/suite/heading_attrs.rs::heading_attrs_test_34", "code": "pub fn test_markdown_html(input: &str, output: &str, smart_punct: bool) {\n    let mut s = String::new();\n\n    let mut opts = Options::empty();\n    opts.insert(Options::ENABLE_TABLES);\n    opts.insert(Options::ENABLE_FOOTNOTES);\n    opts.insert(Options::ENABLE_STRIKETHROUGH);\n    opts.insert(Options::ENABLE_TASKLISTS);\n    if smart_punct {\n        opts.insert(Options::ENABLE_SMART_PUNCTUATION);\n    }\n    opts.insert(Options::ENABLE_HEADING_ATTRIBUTES);\n\n    let p = Parser::new_ext(input, opts);\n    pulldown_cmark::html::push_html(&mut s, p);\n\n    assert_eq!(normalize_html(output), normalize_html(&s));\n}", "test": "fn heading_attrs_test_34() {\n    let original = r##\"# H1 {#}\n## H2 {.}\n\"##;\n    let expected = r##\"<h1>H1</h1>\n<h2>H2</h2>\n\"##;\n\n    test_markdown_html(original, expected, false);\n}"}
{"test_id": "Keats-tera/Keats-tera-1f95878/src/parser/tests/errors.rs::invalid_fn_call_missing_value", "code": "fn assert_err_msg(input: &str, needles: &[&str]) {\n    let res = parse(input);\n    assert!(res.is_err());\n    let err = res.unwrap_err();\n    let err_msg = err.to_string();\n    println!(\"{}\", err_msg);\n    println!(\"Looking for:\");\n    for needle in needles {\n        println!(\"{}\", needle);\n        assert!(err_msg.contains(needle));\n    }\n}", "test": "fn invalid_fn_call_missing_value() {\n    assert_err_msg(\n        \"{{ a | slice(start=) }}\",\n        &[\"1:20\", \"expected a value that can be negated or an array of values\"],\n    );\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_async_fetch.rs::test_node_async_fetch_leader_change", "code": "pub fn get_engine(&self, node_id: u64) -> WrapFactory<EK> {\n        WrapFactory::new(\n            self.pd_client.clone(),\n            self.raft_engines[&node_id].clone(),\n            self.tablet_registries[&node_id].clone(),\n        )\n    }", "test": "fn test_node_async_fetch_leader_change() {\n    let count = 5;\n    let mut cluster = new_node_cluster(0, count);\n    cluster.pd_client.disable_default_operator();\n\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(80);\n    cluster.cfg.raft_store.raft_log_gc_threshold = 50;\n    cluster.cfg.raft_store.raft_log_gc_size_limit = Some(ReadableSize::mb(20));\n    cluster.cfg.raft_store.raft_log_gc_tick_interval = ReadableDuration::millis(50);\n    cluster.cfg.raft_store.raft_log_reserve_max_ticks = 2;\n    cluster.cfg.raft_store.raft_entry_cache_life_time = ReadableDuration::millis(100);\n    cluster.run();\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n\n    // cause log lag and trigger async fetch\n    cluster.stop_node(5);\n    for i in 1..60 {\n        let k = i.to_string().into_bytes();\n        let v = k.clone();\n        cluster.must_put(&k, &v);\n    }\n    fail::cfg(\"worker_async_fetch_raft_log\", \"pause\").unwrap();\n    cluster.run_node(5).unwrap();\n\n    cluster.must_transfer_leader(1, new_peer(2, 2));\n    // make recent active\n    cluster.pd_client.must_remove_peer(1, new_peer(5, 5));\n    cluster.pd_client.must_add_peer(1, new_peer(5, 5));\n    // trigger log gc\n    for i in 60..100 {\n        let k = i.to_string().into_bytes();\n        let v = k.clone();\n        cluster.must_put(&k, &v);\n    }\n    sleep_ms(100);\n\n    // isolate node 1\n    cluster.add_send_filter(IsolationFilterFactory::new(1));\n    fail::cfg(\"apply_pending_snapshot\", \"return\").unwrap();\n    // cause log lag and trigger log gc and make node 1 requesting snapshot\n    for i in 100..200 {\n        let k = i.to_string().into_bytes();\n        let v = k.clone();\n        cluster.must_put(&k, &v);\n    }\n    // wait log gc.\n    sleep_ms(100);\n\n    // trigger applying snapshot\n    cluster.clear_send_filters();\n    sleep_ms(100);\n    fail::remove(\"worker_async_fetch_raft_log\");\n\n    sleep_ms(100);\n    fail::remove(\"apply_pending_snapshot\");\n\n    // logs should be replicated to node 1 successfully.\n    for i in 1..200 {\n        let k = i.to_string().into_bytes();\n        let v = k.clone();\n        must_get_equal(&cluster.get_engine(1), &k, &v);\n    }\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/name_server_pool_tests.rs::mock_nameserver_on_send", "code": "fn mock_nameserver_on_send_nx<O: OnSend + Unpin>(\n    messages: Vec<Result<DnsResponse, ResolveError>>,\n    options: ResolverOpts,\n    on_send: O,\n    addr: IpAddr,\n    trust_negative_responses: bool,\n) -> MockedNameServer<O> {\n    let conn_provider = MockConnProvider {\n        on_send: on_send.clone(),\n        _p: Default::default(),\n    };\n    let client = MockClientHandle::mock_on_send(messages, on_send);\n\n    NameServer::from_conn(\n        NameServerConfig {\n            socket_addr: SocketAddr::new(addr, 0),\n            protocol: Protocol::Udp,\n            tls_dns_name: None,\n            trust_negative_responses,\n            #[cfg(any(feature = \"dns-over-rustls\", feature = \"dns-over-https-rustls\"))]\n            tls_config: None,\n            bind_addr: None,\n        },\n        options,\n        client,\n        conn_provider,\n    )\n}", "test": "fn mock_nameserver_on_send<O: OnSend + Unpin>(\n    messages: Vec<Result<DnsResponse, ResolveError>>,\n    options: ResolverOpts,\n    on_send: O,\n) -> MockedNameServer<O> {\n    mock_nameserver_on_send_nx(messages, options, on_send, DEFAULT_SERVER_ADDR, false)\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_sort.rs::test_dictionary_order2", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_dictionary_order2() {\n    new_ucmd!()\n        .pipe_in(\"a\ud83d\udc66\ud83c\udffbaa\\tb\\naaaa\\tb\") // spell-checker:disable-line\n        .arg(\"-d\")\n        .succeeds()\n        .stdout_only(\"a\ud83d\udc66\ud83c\udffbaa\\tb\\naaaa\\tb\\n\"); // spell-checker:disable-line\n}\n\n#[test]\nfn"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/coprocessor/test_select.rs::test_batch_request", "code": "pub fn as_encoded(&self) -> &Vec<u8> {\n        &self.0\n    }", "test": "fn test_batch_request() {\n    let data = vec![\n        (1, Some(\"name:0\"), 2),\n        (2, Some(\"name:4\"), 3),\n        (4, Some(\"name:3\"), 1),\n        (5, Some(\"name:1\"), 4),\n        (9, Some(\"name:8\"), 7),\n        (10, Some(\"name:6\"), 8),\n    ];\n\n    let product = ProductTable::new();\n    let (mut cluster, raft_engine, ctx) = new_raft_engine(1, \"\");\n    let (_, endpoint, _) =\n        init_data_with_engine_and_commit(ctx.clone(), raft_engine, &product, &data, true);\n\n    // Split the region into [1, 2], [4, 5], [9, 10].\n    let region =\n        cluster.get_region(Key::from_raw(&product.get_record_range(1, 1).start).as_encoded());\n    let split_key = Key::from_raw(&product.get_record_range(3, 3).start);\n    cluster.must_split(&region, split_key.as_encoded());\n    let second_region =\n        cluster.get_region(Key::from_raw(&product.get_record_range(4, 4).start).as_encoded());\n    let second_split_key = Key::from_raw(&product.get_record_range(8, 8).start);\n    cluster.must_split(&second_region, second_split_key.as_encoded());\n\n    struct HandleRange {\n        start: i64,\n        end: i64,\n    }\n\n    enum QueryResult {\n        Valid(Vec<(i64, Option<&'static str>, i64)>),\n        ErrRegion,\n        ErrLocked,\n        ErrOther,\n    }\n\n    // Each case has four fields:\n    // 1. The input scan handle range.\n    // 2. The expected output results.\n    // 3. Should the coprocessor request contain invalid region epoch.\n    // 4. Should the scanned key be locked.\n    let cases = vec![\n        // Basic valid case.\n        (\n            vec![\n                HandleRange { start: 1, end: 2 },\n                HandleRange { start: 3, end: 5 },\n            ],\n            vec![\n                QueryResult::Valid(vec![(1_i64, Some(\"name:0\"), 2_i64), (2, Some(\"name:4\"), 3)]),\n                QueryResult::Valid(vec![(4, Some(\"name:3\"), 1), (5, Some(\"name:1\"), 4)]),\n            ],\n            false,\n            false,\n        ),\n        // Original task is valid, batch tasks are not all valid.\n        (\n            vec![\n                HandleRange { start: 1, end: 2 },\n                HandleRange { start: 4, end: 6 },\n                HandleRange { start: 9, end: 11 },\n                HandleRange { start: 1, end: 3 }, // Input range [1, 4) crosses two region ranges.\n                HandleRange { start: 4, end: 8 }, // Input range [4, 9] crosses two region ranges.\n            ],\n            vec![\n                QueryResult::Valid(vec![(1, Some(\"name:0\"), 2), (2, Some(\"name:4\"), 3)]),\n                QueryResult::Valid(vec![(4, Some(\"name:3\"), 1), (5, Some(\"name:1\"), 4)]),\n                QueryResult::Valid(vec![(9, Some(\"name:8\"), 7), (10, Some(\"name:6\"), 8)]),\n                QueryResult::ErrOther,\n                QueryResult::ErrOther,\n            ],\n            false,\n            false,\n        ),\n        // Original task is invalid, batch tasks are not all valid.\n        (\n            vec![HandleRange { start: 1, end: 3 }],\n            vec![QueryResult::ErrOther],\n            false,\n            false,\n        ),\n        // Invalid epoch case.\n        (\n            vec![\n                HandleRange { start: 1, end: 3 },\n                HandleRange { start: 4, end: 6 },\n            ],\n            vec![QueryResult::ErrRegion, QueryResult::ErrRegion],\n            true,\n            false,\n        ),\n        // Locked error case.\n        (\n            vec![\n                HandleRange { start: 1, end: 2 },\n                HandleRange { start: 4, end: 6 },\n            ],\n            vec![QueryResult::ErrLocked, QueryResult::ErrLocked],\n            false,\n            true,\n        ),\n    ];\n    let prepare_req =\n        |cluster: &mut Cluster<ServerCluster>, ranges: &Vec<HandleRange>| -> Request {\n            let original_range = ranges.get(0).unwrap();\n            let key_range = product.get_record_range(original_range.start, original_range.end);\n            let region_key = Key::from_raw(&key_range.start);\n            let mut req = DagSelect::from(&product)\n                .key_ranges(vec![key_range])\n                .build_with(ctx.clone(), &[0]);\n            let mut new_ctx = Context::default();\n            let new_region = cluster.get_region(region_key.as_encoded());\n            let leader = cluster.leader_of_region(new_region.get_id()).unwrap();\n            new_ctx.set_region_id(new_region.get_id());\n            new_ctx.set_region_epoch(new_region.get_region_epoch().clone());\n            new_ctx.set_peer(leader);\n            req.set_context(new_ctx);\n            req.set_start_ts(100);\n\n            let batch_handle_ranges = &ranges.as_slice()[1..];\n            for handle_range in batch_handle_ranges.iter() {\n                let range_start_key = Key::from_raw(\n                    &product\n                        .get_record_range(handle_range.start, handle_range.end)\n                        .start,\n                );\n                let batch_region = cluster.get_region(range_start_key.as_encoded());\n                let batch_leader = cluster.leader_of_region(batch_region.get_id()).unwrap();\n                let batch_key_ranges =\n                    vec![product.get_record_range(handle_range.start, handle_range.end)];\n                let mut store_batch_task = StoreBatchTask::new();\n                store_batch_task.set_region_id(batch_region.get_id());\n                store_batch_task.set_region_epoch(batch_region.get_region_epoch().clone());\n                store_batch_task.set_peer(batch_leader);\n                store_batch_task.set_ranges(batch_key_ranges.into());\n                req.tasks.push(store_batch_task);\n            }\n            req\n        };\n    let verify_response = |result: &QueryResult, resp: &Response| {\n        let (data, details, region_err, locked, other_err) = (\n            resp.get_data(),\n            resp.get_exec_details_v2(),\n            &resp.region_error,\n            &resp.locked,\n            &resp.other_error,\n        );\n        match result {\n            QueryResult::Valid(res) => {\n                let expected_len = res.len();\n                let mut sel_resp = SelectResponse::default();\n                sel_resp.merge_from_bytes(data).unwrap();\n                let mut row_count = 0;\n                let spliter = DagChunkSpliter::new(sel_resp.take_chunks().into(), 3);\n                for (row, (id, name, cnt)) in spliter.zip(res) {\n                    let name_datum = name.map(|s| s.as_bytes()).into();\n                    let expected_encoded = datum::encode_value(\n                        &mut EvalContext::default(),\n                        &[Datum::I64(*id), name_datum, Datum::I64(*cnt)],\n                    )\n                    .unwrap();\n                    let result_encoded =\n                        datum::encode_value(&mut EvalContext::default(), &row).unwrap();\n                    assert_eq!(result_encoded, &*expected_encoded);\n                    row_count += 1;\n                }\n                assert_eq!(row_count, expected_len);\n                assert!(region_err.is_none());\n                assert!(locked.is_none());\n                assert!(other_err.is_empty());\n                let scan_details = details.get_scan_detail_v2();\n                assert_eq!(scan_details.processed_versions, row_count as u64);\n                if row_count > 0 {\n                    assert!(scan_details.processed_versions_size > 0);\n                    assert!(scan_details.total_versions > 0);\n                }\n            }\n            QueryResult::ErrRegion => {\n                assert!(region_err.is_some());\n                assert!(locked.is_none());\n                assert!(other_err.is_empty());\n            }\n            QueryResult::ErrLocked => {\n                assert!(region_err.is_none());\n                assert!(locked.is_some());\n                assert!(other_err.is_empty());\n            }\n            QueryResult::ErrOther => {\n                assert!(region_err.is_none());\n                assert!(locked.is_none());\n                assert!(!other_err.is_empty())\n            }\n        }\n    };\n\n    let batch_resp_2_resp = |batch_resp: &mut StoreBatchTaskResponse| -> Response {\n        let mut response = Response::default();\n        response.set_data(batch_resp.take_data());\n        if let Some(err) = batch_resp.region_error.take() {\n            response.set_region_error(err);\n        }\n        if let Some(lock_info) = batch_resp.locked.take() {\n            response.set_locked(lock_info);\n        }\n        response.set_other_error(batch_resp.take_other_error());\n        response.set_exec_details_v2(batch_resp.take_exec_details_v2());\n        response\n    };\n\n    for (ranges, results, invalid_epoch, key_is_locked) in cases.iter() {\n        let mut req = prepare_req(&mut cluster, ranges);\n        if *invalid_epoch {\n            req.context\n                .as_mut()\n                .unwrap()\n                .region_epoch\n                .as_mut()\n                .unwrap()\n                .version -= 1;\n            for batch_task in req.tasks.iter_mut() {\n                batch_task.region_epoch.as_mut().unwrap().version -= 1;\n            }\n        } else if *key_is_locked {\n            for range in ranges.iter() {\n                let lock_key =\n                    Key::from_raw(&product.get_record_range(range.start, range.start).start);\n                let lock = Lock::new(\n                    LockType::Put,\n                    lock_key.as_encoded().clone(),\n                    10.into(),\n                    10,\n                    None,\n                    TimeStamp::zero(),\n                    1,\n                    TimeStamp::zero(),\n                );\n                cluster.must_put_cf(CF_LOCK, lock_key.as_encoded(), lock.to_bytes().as_slice());\n            }\n        }\n        let mut resp = handle_request(&endpoint, req);\n        let mut batch_results = resp.take_batch_responses().to_vec();\n        for (i, result) in results.iter().enumerate() {\n            if i == 0 {\n                verify_response(result, &resp);\n            } else {\n                let batch_resp = batch_results.get_mut(i - 1).unwrap();\n                verify_response(result, &batch_resp_2_resp(batch_resp));\n            };\n        }\n        if *key_is_locked {\n            for range in ranges.iter() {\n                let lock_key =\n                    Key::from_raw(&product.get_record_range(range.start, range.start).start);\n                cluster.must_delete_cf(CF_LOCK, lock_key.as_encoded());\n            }\n        }\n    }\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/server/status_server.rs::test_region_meta_endpoint", "code": "pub fn is_some(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_some(),\n            }\n        }\n    }", "test": "fn test_region_meta_endpoint() {\n    let mut cluster = new_server_cluster(0, 1);\n    cluster.run();\n    let region = cluster.get_region(b\"\");\n    let region_id = region.get_id();\n    let peer = region.get_peers().get(0);\n    assert!(peer.is_some());\n    let store_id = peer.unwrap().get_store_id();\n    let router = cluster.raft_extension(store_id);\n    let mut status_server = StatusServer::new(\n        1,\n        ConfigController::default(),\n        Arc::new(SecurityConfig::default()),\n        router,\n        std::env::temp_dir(),\n        None,\n        GrpcServiceManager::dummy(),\n    )\n    .unwrap();\n    let addr = format!(\"127.0.0.1:{}\", test_util::alloc_port());\n    status_server.start(addr).unwrap();\n    let check_task = check(status_server.listening_addr(), region_id);\n    let rt = tokio::runtime::Runtime::new().unwrap();\n    if let Err(err) = rt.block_on(check_task) {\n        panic!(\"{}\", err);\n    }\n    status_server.stop();\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/mod.rs::null_bool_in_object_pattern", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn null_bool_in_object_pattern() {\n    run_test_actions([\n        TestAction::run(indoc! {r#\"\n            let obj = {\n                null: 0,\n                true: 10,\n                false: 100\n            };\n\n            let { null: a, true: b, false: c } = obj;\n        \"#}),\n        TestAction::assert_eq(\"a\", 0),\n        TestAction::assert_eq(\"b\", 10),\n        TestAction::assert_eq(\"c\", 100),\n    ]);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_unsafe_recovery.rs::test_force_leader_twice_on_same_peer", "code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_force_leader_twice_on_same_peer() {\n    let mut cluster = new_node_cluster(0, 5);\n    cluster.pd_client.disable_default_operator();\n\n    cluster.run();\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    let region = cluster.get_region(b\"k1\");\n    cluster.must_split(&region, b\"k9\");\n    let region = cluster.get_region(b\"k2\");\n    let peer_on_store5 = find_peer(&region, 5).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store5.clone());\n\n    cluster.stop_node(3);\n    cluster.stop_node(4);\n    cluster.stop_node(5);\n\n    // restart to clean lease\n    cluster.stop_node(1);\n    cluster.run_node(1).unwrap();\n    cluster.stop_node(2);\n    cluster.run_node(2).unwrap();\n\n    cluster.must_enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);\n    cluster.must_enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);\n    // remove the peers on failed nodes\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 3).unwrap().clone());\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 4).unwrap().clone());\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 5).unwrap().clone());\n    cluster.exit_force_leader(region.get_id(), 1);\n\n    // quorum is formed, can propose command successfully now\n    cluster.must_put(b\"k4\", b\"v4\");\n    assert_eq!(cluster.must_get(b\"k4\"), Some(b\"v4\".to_vec()));\n}"}
{"test_id": "Keats-tera/Keats-tera-1f95878/src/parser/tests/errors.rs::invalid_include_no_string", "code": "fn assert_err_msg(input: &str, needles: &[&str]) {\n    let res = parse(input);\n    assert!(res.is_err());\n    let err = res.unwrap_err();\n    let err_msg = err.to_string();\n    println!(\"{}\", err_msg);\n    println!(\"Looking for:\");\n    for needle in needles {\n        println!(\"{}\", needle);\n        assert!(err_msg.contains(needle));\n    }\n}", "test": "fn invalid_include_no_string() {\n    assert_err_msg(\"{% include 1 %}\", &[\"1:12\", \"expected a string\"]);\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/mod.rs::var_decl_hoisting_with_initialization", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn var_decl_hoisting_with_initialization() {\n    run_test_actions([TestAction::assert_eq(\"x = 5; var x = 10; x\", 10)]);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_csplit.rs::test_negative_offset_at_start", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_negative_offset_at_start() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-\", \"/a/-1\", \"{*}\"])\n        .pipe_in(\"\\na\\n\")\n        .succeeds()\n        .stdout_only(\"0\\n3\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"there should be splits created\")\n        .count();\n    assert_eq!(count, 2);\n    assert_eq!(at.read(\"xx00\"), \"\");\n    assert_eq!(at.read(\"xx01\"), \"\\na\\n\");\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_bigquery.rs::parse_tuple_struct_literal", "code": "pub fn verified_only_select(&self, query: &str) -> Select {\n        match *self.verified_query(query).body {\n            SetExpr::Select(s) => *s,\n            _ => panic!(\"Expected SetExpr::Select\"),\n        }\n    }", "test": "fn parse_tuple_struct_literal() {\n    // tuple syntax: https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#tuple_syntax\n    // syntax: (expr1, expr2 [, ... ])\n    let sql = \"SELECT (1, 2, 3), (1, 1.0, '123', true)\";\n    let select = bigquery().verified_only_select(sql);\n    assert_eq!(2, select.projection.len());\n    assert_eq!(\n        &Expr::Tuple(vec![\n            Expr::Value(number(\"1\")),\n            Expr::Value(number(\"2\")),\n            Expr::Value(number(\"3\")),\n        ]),\n        expr_from_projection(&select.projection[0])\n    );\n    assert_eq!(\n        &Expr::Tuple(vec![\n            Expr::Value(number(\"1\")),\n            Expr::Value(number(\"1.0\")),\n            Expr::Value(Value::SingleQuotedString(\"123\".to_string())),\n            Expr::Value(Value::Boolean(true))\n        ]),\n        expr_from_projection(&select.projection[1])\n    );\n}"}
{"test_id": "Alexhuszagh-minimal-lexical/Alexhuszagh-minimal-lexical-e997c46/tests/vec_tests.rs::small_add_test", "code": "pub fn vec_from_u32(x: &[u32]) -> VecType {\n    let mut vec = VecType::new();\n    #[cfg(not(all(target_pointer_width = \"64\", not(target_arch = \"sparc\"))))]\n    {\n        for &xi in x {\n            vec.try_push(xi as bigint::Limb).unwrap();\n        }\n    }\n\n    #[cfg(all(target_pointer_width = \"64\", not(target_arch = \"sparc\")))]\n    {\n        for xi in x.chunks(2) {\n            match xi.len() {\n                1 => vec.try_push(xi[0] as bigint::Limb).unwrap(),\n                2 => {\n                    let xi0 = xi[0] as bigint::Limb;\n                    let xi1 = xi[1] as bigint::Limb;\n                    vec.try_push((xi1 << 32) | xi0).unwrap()\n                },\n                _ => unreachable!(),\n            }\n        }\n    }\n\n    vec\n}", "test": "fn small_add_test() {\n    let mut x = VecType::from_u64(4294967295);\n    bigint::small_add(&mut x, 5);\n    let expected: VecType = vec_from_u32(&[4, 1]);\n    assert_eq!(&*x, &*expected);\n\n    let mut x = VecType::from_u64(5);\n    bigint::small_add(&mut x, 7);\n    let expected = VecType::from_u64(12);\n    assert_eq!(&*x, &*expected);\n\n    // Single carry, internal overflow\n    let mut x = VecType::from_u64(0x80000000FFFFFFFF);\n    bigint::small_add(&mut x, 7);\n    let expected: VecType = vec_from_u32(&[6, 0x80000001]);\n    assert_eq!(&*x, &*expected);\n\n    // Double carry, overflow\n    let mut x = VecType::from_u64(0xFFFFFFFFFFFFFFFF);\n    bigint::small_add(&mut x, 7);\n    let expected: VecType = vec_from_u32(&[6, 0, 1]);\n    assert_eq!(&*x, &*expected);\n}"}
{"test_id": "tafia-quick-xml/tafia-quick-xml-120e074/tests/serde-issues.rs::issue540", "code": "pub fn to_string_with_root<T>(root_tag: &str, value: &T) -> Result<String, DeError>\nwhere\n    T: ?Sized + Serialize,\n{\n    let mut buffer = String::new();\n    to_writer_with_root(&mut buffer, root_tag, value)?;\n    Ok(buffer)\n}", "test": "fn issue540() {\n    #[derive(Serialize)]\n    pub enum Enum {\n        Variant {},\n    }\n\n    #[derive(Serialize)]\n    pub struct Struct {\n        #[serde(flatten)]\n        flatten: Enum,\n    }\n\n    assert_eq!(\n        to_string_with_root(\n            \"root\",\n            &Struct {\n                flatten: Enum::Variant {},\n            }\n        )\n        .unwrap(),\n        \"<root><Variant/></root>\"\n    );\n}"}
{"test_id": "mitsuhiko-minijinja/mitsuhiko-minijinja-5f2c1e8/minijinja/tests/test_templates.rs::test_auto_escaping", "code": "pub fn render<S: Serialize>(&self, ctx: S) -> Result<String, Error> {\n        // reduce total amount of code faling under mono morphization into\n        // this function, and share the rest in _render.\n        self._render(Value::from_serializable(&ctx)).map(|x| x.0)\n    }", "test": "fn test_auto_escaping() {\n    let mut env = Environment::new();\n    env.add_template(\"index.html\", \"{{ var }}\").unwrap();\n    #[cfg(feature = \"json\")]\n    {\n        env.add_template(\"index.js\", \"{{ var }}\").unwrap();\n    }\n    env.add_template(\"index.txt\", \"{{ var }}\").unwrap();\n\n    // html\n    let tmpl = env.get_template(\"index.html\").unwrap();\n    let rv = tmpl.render(context!(var => \"<script>\")).unwrap();\n    insta::assert_snapshot!(rv, @\"&lt;script&gt;\");\n\n    // JSON\n    #[cfg(feature = \"json\")]\n    {\n        use minijinja::value::Value;\n        let tmpl = env.get_template(\"index.js\").unwrap();\n        let rv = tmpl.render(context!(var => \"foo\\\"bar'baz\")).unwrap();\n        insta::assert_snapshot!(rv, @r###\"\"foo\\\"bar'baz\"\"###);\n        let rv = tmpl\n            .render(context!(var => [Value::from(true), Value::from(\"<foo>\"), Value::from(())]))\n            .unwrap();\n        insta::assert_snapshot!(rv, @r###\"[true,\"<foo>\",null]\"###);\n    }\n\n    // Text\n    let tmpl = env.get_template(\"index.txt\").unwrap();\n    let rv = tmpl.render(context!(var => \"foo\\\"bar'baz\")).unwrap();\n    insta::assert_snapshot!(rv, @r###\"foo\"bar'baz\"###);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_kill.rs::test_kill_with_signal_prefixed_name_old_form", "code": "fn wait_for_signal(&mut self) -> Option<i32> {\n        let sig = self.child.wait().expect(\"cannot wait on target\").signal();\n        self.killed = true;\n        sig\n    }", "test": "fn test_kill_with_signal_prefixed_name_old_form() {\n    let mut target = Target::new();\n    new_ucmd!()\n        .arg(\"-SIGKILL\")\n        .arg(format!(\"{}\", target.pid()))\n        .succeeds();\n    assert_eq!(target.wait_for_signal(), Some(libc::SIGKILL));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_head.rs::test_bad_utf8", "code": "pub fn stdout_is_bytes<T: AsRef<[u8]>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout, msg.as_ref(),\n            \"stdout as bytes wasn't equal to expected bytes. Result as strings:\\nstdout  ='{:?}'\\nexpected='{:?}'\",\n            std::str::from_utf8(&self.stdout),\n            std::str::from_utf8(msg.as_ref()),\n        );\n        self\n    }", "test": "fn test_bad_utf8() {\n    let bytes: &[u8] = b\"\\xfc\\x80\\x80\\x80\\x80\\xaf\";\n    new_ucmd!()\n        .args(&[\"-c\", \"6\"])\n        .pipe_in(bytes)\n        .succeeds()\n        .stdout_is_bytes(bytes);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_rmdir.rs::test_rmdir_remove_symlink_file", "code": "pub fn stderr_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stderr_str(), msg.as_ref());\n        self\n    }", "test": "fn test_rmdir_remove_symlink_file() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    at.touch(\"file\");\n    at.symlink_file(\"file\", \"fl\");\n\n    ucmd.arg(\"fl/\").fails().stderr_is(format!(\n        \"rmdir: failed to remove 'fl/': {NOT_A_DIRECTORY}\\n\"\n    ));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_timeout.rs::test_zero_timeout", "code": "pub fn no_stdout(&self) -> &Self {\n        assert!(\n            self.stdout.is_empty(),\n            \"Expected stdout to be empty, but it's:\\n{}\",\n            self.stdout_str()\n        );\n        self\n    }", "test": "fn test_zero_timeout() {\n    new_ucmd!()\n        .args(&[\"-v\", \"0\", \"sleep\", \".1\"])\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n    new_ucmd!()\n        .args(&[\"-v\", \"0\", \"-s0\", \"-k0\", \"sleep\", \".1\"])\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_tty.rs::test_close_stdin_silent_long", "code": "pub fn wait(self) -> io::Result<CmdResult> {\n        let (bin_path, util_name, tmpd) = (\n            self.bin_path.clone(),\n            self.util_name.clone(),\n            self.tmpd.clone(),\n        );\n\n        #[allow(deprecated)]\n        let output = self.wait_with_output()?;\n\n        Ok(CmdResult {\n            bin_path,\n            util_name,\n            tmpd,\n            exit_status: Some(output.status),\n            stdout: output.stdout,\n            stderr: output.stderr,\n        })\n    }", "test": "fn test_close_stdin_silent_long() {\n    let mut child = new_ucmd!().arg(\"--silent\").run_no_wait();\n    child.close_stdin();\n    child.wait().unwrap().code_is(1).no_stdout();\n}"}
{"test_id": "image-rs-jpeg-decoder/image-rs-jpeg-decoder-cacc433/tests/rayon-2.rs::decoding_in_global_pool", "code": "pub fn decode(&mut self) -> Result<Vec<u8>> {\n        WorkerScope::with(|worker| self.decode_internal(false, worker))\n    }", "test": "fn decoding_in_global_pool() {\n    let path = Path::new(\"tests/reftest/images/progressive3.jpg\");\n\n    rayon::ThreadPoolBuilder::new()\n        .num_threads(2)\n        .build_global()\n        .unwrap();\n\n    let _: Vec<_> = (0..1024)\n        .map(|_| {\n            let path = path.clone();\n            std::thread::spawn(move || {\n                let mut decoder = Decoder::new(File::open(&path).unwrap());\n                let _ = decoder.decode().unwrap();\n            });\n        }).collect();\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_status_command.rs::test_sync_latency_inspect", "code": "pub fn recv_timeout<S, I>(s: &mut S, dur: std::time::Duration) -> Result<Option<I>, ()>\nwhere\n    S: Stream<Item = I> + Unpin,\n{\n    poll_timeout(&mut s.next(), dur)\n}", "test": "fn test_sync_latency_inspect() {\n    let mut cluster = new_node_cluster(0, 1);\n    cluster.cfg.raft_store.store_io_pool_size = 0;\n    cluster.run();\n    let router = cluster.sim.wl().get_router(1).unwrap();\n    let (tx, rx) = std::sync::mpsc::sync_channel(10);\n    let inspector = LatencyInspector::new(\n        1,\n        Box::new(move |_, duration| {\n            let dur = duration.sum();\n            tx.send(dur).unwrap();\n        }),\n    );\n    let msg = StoreMsg::LatencyInspect {\n        send_time: Instant::now(),\n        inspector,\n    };\n    router.send_control(msg).unwrap();\n    rx.recv_timeout(std::time::Duration::from_secs(2)).unwrap();\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/format.rs::no_supported_file_found", "code": "pub fn assert_cli_snapshot(payload: SnapshotPayload<'_>) {\n    let module_path = payload.module_path.to_owned();\n    let test_name = payload.test_name;\n    let cli_snapshot = CliSnapshot::from(payload);\n\n    let content = cli_snapshot.emit_content_snapshot();\n\n    let module_path = module_path.replace(\"::\", \"_\");\n    let snapshot_path = PathBuf::from(\"snapshots\").join(module_path);\n\n    insta::with_settings!({\n        prepend_module_to_snapshot => false,\n        snapshot_path => snapshot_path\n    }, {\n        insta::assert_snapshot!(test_name, content);\n\n    });\n}", "test": "fn no_supported_file_found() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"format\"), \".\"].as_slice()),\n    );\n\n    eprintln!(\"{:?}\", console.out_buffer);\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"no_supported_file_found\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/control_flow/mod.rs::finally", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn finally() {\n    run_test_actions([TestAction::assert_eq(\n        indoc! {r#\"\n            let a = 10;\n            try {\n                a = 20;\n            } finally {\n                a = 30;\n            }\n\n            a;\n        \"#},\n        30,\n    )]);\n}"}
{"test_id": "dtolnay-serde-yaml/dtolnay-serde-yaml-f8adb28/tests/test_serde.rs::test_i128_small", "code": "fn test_serde<T>(thing: &T, yaml: &str)\nwhere\n    T: serde::Serialize + serde::de::DeserializeOwned + PartialEq + Debug,\n{\n    let serialized = serde_yaml::to_string(&thing).unwrap();\n    assert_eq!(yaml, serialized);\n\n    let value = serde_yaml::to_value(thing).unwrap();\n    let serialized = serde_yaml::to_string(&value).unwrap();\n    assert_eq!(yaml, serialized);\n\n    let deserialized: T = serde_yaml::from_str(yaml).unwrap();\n    assert_eq!(*thing, deserialized);\n\n    let value: Value = serde_yaml::from_str(yaml).unwrap();\n    let deserialized = T::deserialize(&value).unwrap();\n    assert_eq!(*thing, deserialized);\n\n    let deserialized: T = serde_yaml::from_value(value).unwrap();\n    assert_eq!(*thing, deserialized);\n\n    serde_yaml::from_str::<serde::de::IgnoredAny>(yaml).unwrap();\n}", "test": "fn test_i128_small() {\n    let thing: i128 = -256;\n    let yaml = indoc! {\"\n        -256\n    \"};\n    test_serde(&thing, yaml);\n}"}
{"test_id": "quinn-rs-quinn/quinn-rs-quinn-83e4f46/quinn-proto/src/tests/mod.rs::instant_close_1", "code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn instant_close_1() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    info!(\"connecting\");\n    let client_ch = pair.begin_connect(client_config());\n    pair.client\n        .connections\n        .get_mut(&client_ch)\n        .unwrap()\n        .close(pair.time, VarInt(0), Bytes::new());\n    pair.drive();\n    let server_ch = pair.server.assert_accept();\n    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::ConnectionLost {\n            reason: ConnectionError::ConnectionClosed(ConnectionClose {\n                error_code: TransportErrorCode::APPLICATION_ERROR,\n                ..\n            }),\n        })\n    );\n}"}
{"test_id": "weggli-rs-weggli/weggli-rs-weggli-ad8d424/tests/query.rs::tertiary", "code": "fn parse_and_match(needle: &str, source: &str) -> usize {\n    parse_and_match_helper(needle, source, false).len()\n}", "test": "fn tertiary() {\n    let source = r#\"\n    void foo() {\n    int16_t next = (d->flags & flag)\n                       ? d->next\n                       : EndOfChain;\n    }\"#;\n\n    let needle = \"{\n       _ = _(_ ? d->next : _);\n    }\";\n\n    let matches = parse_and_match(needle, source);\n    assert_eq!(matches, 1);\n\n    let needle = \"{\n       $t _ = _ ? d->next : _;\n    }\";\n\n    let matches = parse_and_match(needle, source);\n    assert_eq!(matches, 1);\n}"}
{"test_id": "Lokathor-tinyvec/Lokathor-tinyvec-6e1bbaf/tests/arrayvec.rs::ArrayVec_swap_remove", "code": "pub fn swap_remove(&mut self, index: usize) -> A::Item {\n    assert!(\n      index < self.len(),\n      \"ArrayVec::swap_remove> index {} is out of bounds {}\",\n      index,\n      self.len\n    );\n    if index == self.len() - 1 {\n      self.pop().unwrap()\n    } else {\n      let i = self.pop().unwrap();\n      replace(&mut self[index], i)\n    }\n  }", "test": "fn ArrayVec_swap_remove() {\n  let mut av: ArrayVec<[i32; 10]> = Default::default();\n  av.push(1);\n  av.push(2);\n  av.push(3);\n  av.push(4);\n  assert_eq!(av.swap_remove(3), 4);\n  assert_eq!(&av[..], &[1, 2, 3][..]);\n  assert_eq!(av.swap_remove(0), 1);\n  assert_eq!(&av[..], &[3, 2][..]);\n  assert_eq!(av.swap_remove(0), 3);\n  assert_eq!(&av[..], &[2][..]);\n  assert_eq!(av.swap_remove(0), 2);\n  assert_eq!(&av[..], &[][..]);\n}"}
{"test_id": "hyperium-h2/hyperium-h2-da38b1c/tests/h2-tests/tests/trailers.rs::send_trailers_immediately", "code": "pub fn status(self, value: StatusCode) -> Self {\n        let (id, mut pseudo, fields) = self.into_parts();\n\n        pseudo.set_status(value);\n\n        Mock(frame::Headers::new(id, pseudo, fields))\n    }", "test": "async fn send_trailers_immediately() {\n    h2_support::trace_init!();\n\n    let mock = mock_io::Builder::new()\n        .handshake()\n        // Write GET /\n        .write(&[\n            0, 0, 0x10, 1, 4, 0, 0, 0, 1, 0x82, 0x87, 0x41, 0x8B, 0x9D, 0x29, 0xAC, 0x4B, 0x8F,\n            0xA8, 0xE9, 0x19, 0x97, 0x21, 0xE9, 0x84, 0, 0, 0x0A, 1, 5, 0, 0, 0, 1, 0x40, 0x83,\n            0xF6, 0x7A, 0x66, 0x84, 0x9C, 0xB4, 0x50, 0x7F,\n        ])\n        .write(frames::SETTINGS_ACK)\n        // Read response\n        .read(&[\n            0, 0, 1, 1, 4, 0, 0, 0, 1, 0x88, 0, 0, 0x0B, 0, 1, 0, 0, 0, 1, 0x68, 0x65, 0x6C, 0x6C,\n            0x6F, 0x20, 0x77, 0x6F, 0x72, 0x6C, 0x64,\n        ])\n        .build();\n\n    let (mut client, mut h2) = client::handshake(mock).await.unwrap();\n\n    // Send the request\n    let request = Request::builder()\n        .uri(\"https://http2.akamai.com/\")\n        .body(())\n        .unwrap();\n\n    tracing::info!(\"sending request\");\n    let (response, mut stream) = client.send_request(request, false).unwrap();\n\n    let mut trailers = HeaderMap::new();\n    trailers.insert(\"zomg\", \"hello\".parse().unwrap());\n\n    stream.send_trailers(trailers).unwrap();\n\n    let response = h2.run(response).await.unwrap();\n    assert_eq!(response.status(), StatusCode::OK);\n\n    let (_, mut body) = response.into_parts();\n\n    // There is a data chunk\n    let _ = h2.run(body.next()).await.unwrap().unwrap();\n\n    let chunk = h2.run(body.next()).await;\n    assert!(chunk.is_none());\n\n    let trailers = h2.run(poll_fn(|cx| body.poll_trailers(cx))).await.unwrap();\n    assert!(trailers.is_none());\n\n    h2.await.unwrap();\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/component_model/resources.rs::host_borrow_as_resource_any", "code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn host_borrow_as_resource_any() -> Result<()> {\n    let engine = super::engine();\n    let c = Component::new(\n        &engine,\n        r#\"\n            (component\n                (import \"t\" (type $t (sub resource)))\n                (import \"f\" (func $f (param \"f\" (borrow $t))))\n\n                (core func $f (canon lower (func $f)))\n\n                (core module $m\n                    (import \"\" \"f\" (func $f (param i32)))\n                    (func (export \"f2\") (param i32)\n                        (call $f (local.get 0))\n                    )\n                )\n                (core instance $i (instantiate $m\n                    (with \"\" (instance\n                        (export \"f\" (func $f))\n                    ))\n                ))\n\n                (func (export \"f2\") (param \"x\" (borrow $t))\n                    (canon lift (core func $i \"f2\")))\n            )\n        \"#,\n    )?;\n\n    struct MyType;\n\n    let mut store = Store::new(&engine, ());\n\n    // First test the above component where the host properly drops the argument\n    {\n        let mut linker = Linker::new(&engine);\n        linker.root().resource::<MyType>(\"t\", |_, _| Ok(()))?;\n        linker\n            .root()\n            .func_wrap(\"f\", |mut cx, (r,): (ResourceAny,)| {\n                r.resource_drop(&mut cx)?;\n                Ok(())\n            })?;\n        let i = linker.instantiate(&mut store, &c)?;\n\n        let f = i.get_typed_func::<(&Resource<MyType>,), ()>(&mut store, \"f2\")?;\n\n        let resource = Resource::new_own(100);\n        f.call(&mut store, (&resource,))?;\n    }\n\n    // Then also test the case where the host forgets a drop\n    {\n        let mut linker = Linker::new(&engine);\n        linker.root().resource::<MyType>(\"t\", |_, _| Ok(()))?;\n        linker.root().func_wrap(\"f\", |_cx, (_r,): (ResourceAny,)| {\n            // ... no drop here\n            Ok(())\n        })?;\n        let i = linker.instantiate(&mut store, &c)?;\n\n        let f = i.get_typed_func::<(&Resource<MyType>,), ()>(&mut store, \"f2\")?;\n\n        let resource = Resource::new_own(100);\n        let err = f.call(&mut store, (&resource,)).unwrap_err();\n        assert!(\n            format!(\"{err:?}\").contains(\"borrow handles still remain at the end of the call\"),\n            \"bad error: {err:?}\"\n        );\n    }\n    Ok(())\n}"}
{"test_id": "Keats-tera/Keats-tera-1f95878/src/parser/tests/errors.rs::invalid_filter_section_missing_name", "code": "fn assert_err_msg(input: &str, needles: &[&str]) {\n    let res = parse(input);\n    assert!(res.is_err());\n    let err = res.unwrap_err();\n    let err_msg = err.to_string();\n    println!(\"{}\", err_msg);\n    println!(\"Looking for:\");\n    for needle in needles {\n        println!(\"{}\", needle);\n        assert!(err_msg.contains(needle));\n    }\n}", "test": "fn invalid_filter_section_missing_name() {\n    assert_err_msg(\n        r#\"{% filter %}sd{% endfilter %}\"#,\n        &[\"1:11\", \"expected an identifier (must start with a-z)\"],\n    );\n}"}
{"test_id": "astral-sh-ruff/astral-sh-ruff-1a6898a/crates/ruff_cache/tests/cache_key.rs::enum_named_fields_variant", "code": "fn finish(&self) -> u64 {\n        self.inner.finish()\n    }", "test": "fn enum_named_fields_variant() {\n    let mut key = CacheKeyHasher::new();\n\n    let variant = Enum::NamedFields {\n        a: \"Hello\".to_string(),\n        b: \"World\".to_string(),\n    };\n    variant.cache_key(&mut key);\n\n    let mut hash = CacheKeyHasher::new();\n    variant.hash(&mut hash);\n\n    assert_eq!(hash.finish(), key.finish());\n}"}
{"test_id": "rust-bitcoin-rust-bitcoin/rust-bitcoin-rust-bitcoin-5ee33ea/bitcoin/tests/serde.rs::serde_regression_child_number", "code": "pub fn serialize(&self) -> Vec<u8> {\n        let mut buf: Vec<u8> = Vec::new();\n\n        //  <magic>\n        buf.extend_from_slice(b\"psbt\");\n\n        buf.push(0xff_u8);\n\n        buf.extend(self.serialize_map());\n\n        for i in &self.inputs {\n            buf.extend(i.serialize_map());\n        }\n\n        for i in &self.outputs {\n            buf.extend(i.serialize_map());\n        }\n\n        buf\n    }", "test": "fn serde_regression_child_number() {\n    let num = ChildNumber::Normal { index: 0xDEADBEEF };\n    let got = serialize(&num).unwrap();\n    let want = include_bytes!(\"data/serde/child_number_bincode\") as &[_];\n    assert_eq!(got, want)\n}"}
{"test_id": "weggli-rs-weggli/weggli-rs-weggli-ad8d424/tests/query.rs::negative_if", "code": "fn parse_and_match_cpp(needle: &str, source: &str) -> usize {\n    parse_and_match_helper(needle, source, true).len()\n}", "test": "fn negative_if() {\n    let source = r#\"\n    void f() {\n        if (size > 1) return;\n        memcpy(&value,buffer,size);\n        size = 1;\n    }\n    \"#;\n\n    let needle = \"_ $func(){if ($size > 1 ) return;\n        memcpy(_,_, $size);\n        $size = 1;}\";\n    let matches = parse_and_match_cpp(needle, source);\n    assert_eq!(matches, 1);\n\n    let needle = \"_ $func(){NOT: if ($size > 1 ) return;\n        memcpy(_,_, $size);\n        $size = 1;}\";\n    let matches = parse_and_match_cpp(needle, source);\n    assert_eq!(matches, 0);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_prevote.rs::test_prevote_partition_leader_in_majority_detect_in_majority", "code": "fn test_prevote<T: Simulator>(\n    cluster: &mut Cluster<T>,\n    failure_type: FailureType<'_>,\n    leader_after_failure_id: impl Into<Option<u64>>,\n    detect_during_failure: impl Into<Option<(u64, bool)>>,\n    detect_during_recovery: impl Into<Option<(u64, bool)>>,\n) {\n    cluster.cfg.raft_store.prevote = true;\n    // Disable this feature because the test could run slow, in which case peers\n    // shouldn't hibernate, otherwise it's possible to detect no vote messages.\n    cluster.cfg.raft_store.hibernate_regions = false;\n    // To stable the test, we use a large election timeout to make\n    // leader's readiness get handle within an election timeout\n    configure_for_lease_read(&mut cluster.cfg, Some(20), Some(10));\n\n    let leader_id = 1;\n    let detect_during_failure = detect_during_failure.into();\n    let detect_during_recovery = detect_during_recovery.into();\n\n    // We must start the cluster before adding send filters, otherwise it panics.\n    cluster.run();\n\n    cluster.must_transfer_leader(1, new_peer(leader_id, 1));\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    // Determine how to fail.\n    let rx = if let Some((id, _)) = detect_during_failure {\n        let rx = attach_prevote_notifiers(cluster, id);\n        debug!(\"Attached failure prevote notifier.\");\n        Some(rx)\n    } else {\n        None\n    };\n\n    match failure_type {\n        FailureType::Partition(majority, minority) => {\n            cluster.partition(majority.to_vec(), minority.to_vec());\n        }\n        FailureType::Reboot(peers) => {\n            peers.iter().for_each(|&peer| cluster.stop_node(peer));\n        }\n    };\n\n    if let (Some(rx), Some((_, should_detect))) = (rx, detect_during_failure) {\n        // Once we see a response on the wire we know a prevote round is happening.\n        let received = rx.recv_timeout(Duration::from_secs(5));\n        debug!(\"Done with failure prevote notifier, got {:?}\", received);\n        assert_eq!(\n            received.is_ok(),\n            should_detect,\n            \"Sends a PreVote or PreVoteResponse during failure.\",\n        );\n    }\n\n    // Let the cluster recover.\n    match failure_type {\n        FailureType::Partition(..) => {\n            cluster.clear_send_filters();\n        }\n        FailureType::Reboot(peers) => {\n            cluster.clear_send_filters();\n            peers.iter().for_each(|&peer| {\n                cluster.run_node(peer).unwrap();\n            });\n        }\n    };\n\n    // Prepare to listen.\n    let rx = if let Some((id, _)) = detect_during_recovery {\n        let rx = attach_prevote_notifiers(cluster, id);\n        debug!(\"Attached recovery prevote notifier.\");\n        Some(rx)\n    } else {\n        None\n    };\n\n    if let Some(leader_id) = leader_after_failure_id.into() {\n        cluster.must_transfer_leader(1, new_peer(leader_id, 1));\n    };\n\n    // Once we see a response on the wire we know a prevote round is happening.\n    if let (Some(rx), Some((_, should_detect))) = (rx, detect_during_failure) {\n        let received = rx.recv_timeout(Duration::from_secs(5));\n        debug!(\"Done with recovery prevote notifier, got {:?}\", received);\n\n        assert_eq!(\n            received.is_ok(),\n            should_detect,\n            \"Sends a PreVote or PreVoteResponse during recovery.\",\n        );\n    };\n\n    cluster.must_put(b\"k3\", b\"v3\");\n    assert_eq!(cluster.must_get(b\"k1\"), Some(b\"v1\".to_vec()));\n}", "test": "fn test_prevote_partition_leader_in_majority_detect_in_majority() {\n    let mut cluster = new_node_cluster(0, 5);\n    // Since the leader is in the majority and not rebooted, it sees no prevote.\n    test_prevote(\n        &mut cluster,\n        FailureType::Partition(&[1, 2, 3], &[4, 5]),\n        None,\n        (1, false),\n        (1, false),\n    );\n}"}
{"test_id": "astral-sh-ruff/astral-sh-ruff-1a6898a/crates/ruff_python_ast/tests/visitor.rs::class_type_parameters", "code": "fn trace_visitation(source: &str) -> String {\n    let tokens = lex(source, Mode::Module);\n    let parsed = parse_tokens(tokens, source, Mode::Module, \"test.py\").unwrap();\n\n    let mut visitor = RecordVisitor::default();\n    walk_module(&mut visitor, &parsed);\n\n    visitor.output\n}", "test": "fn class_type_parameters() {\n    let source = r#\"class X[T: str, U, *Ts, **P]: ...\"#;\n\n    let trace = trace_visitation(source);\n\n    assert_snapshot!(trace);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_replica_stale_read.rs::test_new_leader_init_resolver", "code": "pub fn has_data_is_not_ready(&self) -> bool {\n        self.data_is_not_ready.is_some()\n    }", "test": "fn test_new_leader_init_resolver() {\n    let (mut cluster, pd_client, mut peer_client1) = prepare_for_stale_read(new_peer(1, 1));\n    let mut peer_client2 = PeerClient::new(&cluster, 1, new_peer(2, 2));\n    peer_client1.ctx.set_stale_read(true);\n    peer_client2.ctx.set_stale_read(true);\n\n    // Write `(key1, value1)`\n    let commit_ts1 = peer_client1.must_kv_write(\n        &pd_client,\n        vec![new_mutation(Op::Put, &b\"key1\"[..], &b\"value1\"[..])],\n        b\"key1\".to_vec(),\n    );\n\n    // There are no lock in the region, the `safe_ts` should keep updating by the\n    // new leader, so we can read `key1` with the newest ts\n    cluster.must_transfer_leader(1, new_peer(2, 2));\n    peer_client1.must_kv_read_equal(b\"key1\".to_vec(), b\"value1\".to_vec(), get_tso(&pd_client));\n\n    // Prewrite on `key2` but not commit yet\n    peer_client2.must_kv_prewrite(\n        vec![new_mutation(Op::Put, &b\"key2\"[..], &b\"value1\"[..])],\n        b\"key2\".to_vec(),\n        get_tso(&pd_client),\n    );\n\n    // There are locks in the region, the `safe_ts` can't be updated, so we can't\n    // read `key1` with the newest ts\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    let resp = peer_client2.kv_read(b\"key1\".to_vec(), get_tso(&pd_client));\n    assert!(resp.get_region_error().has_data_is_not_ready());\n    // But we can read `key1` with `commit_ts1`\n    peer_client2.must_kv_read_equal(b\"key1\".to_vec(), b\"value1\".to_vec(), commit_ts1);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_replica_stale_read.rs::test_update_apply_index_before_sync_read_state", "code": "fn to_vec(&self) -> Vec<Option<Bytes>> {\n        let mut x = Vec::with_capacity(self.len());\n        for i in 0..self.len() {\n            x.push(self.get(i).map(|x| x.to_owned()));\n        }\n        x\n    }", "test": "fn test_update_apply_index_before_sync_read_state() {\n    let (mut cluster, pd_client, mut leader_client) = prepare_for_stale_read(new_peer(1, 1));\n    let mut follower_client2 = PeerClient::new(&cluster, 1, new_peer(2, 2));\n    follower_client2.ctx.set_stale_read(true);\n    leader_client.ctx.set_stale_read(true);\n\n    // Stop node 3 to ensure data must replicated to follower 2 before write return\n    cluster.stop_node(3);\n\n    // Stop sync `(apply_index, safe_ts)` item to the replica\n    let before_sync_replica_read_state = \"before_sync_replica_read_state\";\n    fail::cfg(before_sync_replica_read_state, \"return()\").unwrap();\n\n    // Write `(key1, value1)`\n    let commit_ts1 = leader_client.must_kv_write(\n        &pd_client,\n        vec![new_mutation(Op::Put, &b\"key1\"[..], &b\"value1\"[..])],\n        b\"key1\".to_vec(),\n    );\n    // Leave a lock on `key2` so the item's `safe_ts` won't be updated\n    leader_client.must_kv_prewrite(\n        vec![new_mutation(Op::Put, &b\"key2\"[..], &b\"value2\"[..])],\n        b\"key2\".to_vec(),\n        get_tso(&pd_client),\n    );\n    leader_client.must_kv_read_equal(b\"key1\".to_vec(), b\"value1\".to_vec(), commit_ts1);\n\n    cluster.run_node(3).unwrap();\n    // Stop replicate data to follower 2\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(1, 2)\n            .direction(Direction::Recv)\n            .msg_type(MessageType::MsgAppend),\n    ));\n\n    // Write `(key3, value3)` to update the leader `apply_index`\n    leader_client.must_kv_write(\n        &pd_client,\n        vec![new_mutation(Op::Put, &b\"key3\"[..], &b\"value3\"[..])],\n        b\"key3\".to_vec(),\n    );\n\n    // Sync `(apply_index, safe_ts)` item to the replica\n    fail::remove(before_sync_replica_read_state);\n    follower_client2.must_kv_read_equal(b\"key1\".to_vec(), b\"value1\".to_vec(), commit_ts1);\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-parse-float/tests/lemire_tests.rs::compute_error_scaled32_test", "code": "fn compute_error_scaled32(q: i64, w: u64, lz: i32) -> (i32, u64) {\n    let fp = lemire::compute_error_scaled::<f32>(q, w, lz);\n    (fp.exp, fp.mant)\n}", "test": "fn compute_error_scaled32_test() {\n    // These are the same examples above, just using pre-computed scaled values.\n\n    // These test near-halfway cases for single-precision floats.\n    assert_eq!(\n        compute_error_scaled32(0, 4611686018427387904, 39),\n        (111 + INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error_scaled32(0, 4611686293305294848, 39),\n        (111 + INVALID_FP, 9223372586610589696)\n    );\n    assert_eq!(\n        compute_error_scaled32(0, 4611686568183201792, 39),\n        (111 + INVALID_FP, 9223373136366403584)\n    );\n    assert_eq!(\n        compute_error_scaled32(0, 4611686843061108736, 39),\n        (111 + INVALID_FP, 9223373686122217472)\n    );\n    assert_eq!(\n        compute_error_scaled32(0, 4611687117939015680, 39),\n        (111 + INVALID_FP, 9223374235878031360)\n    );\n\n    assert_eq!(\n        compute_error_scaled32(-10, 9223372036854775808, 6),\n        (111 + INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error_scaled32(-10, 9223372586610589696, 6),\n        (111 + INVALID_FP, 9223372586610589696)\n    );\n    assert_eq!(\n        compute_error_scaled32(-10, 9223373136366403584, 6),\n        (111 + INVALID_FP, 9223373136366403584)\n    );\n    assert_eq!(\n        compute_error_scaled32(-10, 9223373686122217472, 6),\n        (111 + INVALID_FP, 9223373686122217472)\n    );\n    assert_eq!(\n        compute_error_scaled32(-10, 9223374235878031360, 6),\n        (111 + INVALID_FP, 9223374235878031360)\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cksum.rs::test_folder", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_folder() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let folder_name = \"a_folder\";\n    at.mkdir(folder_name);\n\n    ucmd.arg(folder_name)\n        .succeeds()\n        .stdout_only(format!(\"4294967295 0 {folder_name}\\n\"));\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-parse-float/tests/options_tests.rs::invalid_decimal_point_test", "code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn invalid_decimal_point_test() {\n    let mut builder = OptionsBuilder::default();\n    builder = builder.decimal_point(b'\\x00');\n    assert!(!builder.is_valid());\n    builder = builder.decimal_point(b'\\x7f');\n    assert!(!builder.is_valid());\n    assert!(builder.build().is_err());\n    builder = builder.decimal_point(b',');\n    assert!(builder.is_valid());\n    assert!(builder.build().is_ok());\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/control_flow/loops.rs::try_break_labels", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn try_break_labels() {\n    let scenario = r#\"\n        {\n            var str = '';\n\n            outer: {\n                foo: {\n                    bar: {\n                        while (true) {\n                            try {\n                                try {\n                                    break;\n                                } catch(f) {\n                                } finally {\n                                    str = \"fin\";\n                                    break foo;\n                                    str += \"This won't execute\";\n                                }\n                            } finally {\n                                str = str + \"ally!\"\n                                break bar;\n                            }\n                        }\n                        str += \" oh no\";\n                    }\n                    str += \" :)\";\n                }\n            }\n            str\n        }\n    \"#;\n\n    run_test_actions([TestAction::assert_eq(scenario, \"finally! :)\")]);\n}"}
{"test_id": "raphlinus-pulldown-cmark/raphlinus-pulldown-cmark-3da63d5/tests/suite/footnotes.rs::footnotes_test_1", "code": "pub fn test_markdown_html(input: &str, output: &str, smart_punct: bool) {\n    let mut s = String::new();\n\n    let mut opts = Options::empty();\n    opts.insert(Options::ENABLE_TABLES);\n    opts.insert(Options::ENABLE_FOOTNOTES);\n    opts.insert(Options::ENABLE_STRIKETHROUGH);\n    opts.insert(Options::ENABLE_TASKLISTS);\n    if smart_punct {\n        opts.insert(Options::ENABLE_SMART_PUNCTUATION);\n    }\n    opts.insert(Options::ENABLE_HEADING_ATTRIBUTES);\n\n    let p = Parser::new_ext(input, opts);\n    pulldown_cmark::html::push_html(&mut s, p);\n\n    assert_eq!(normalize_html(output), normalize_html(&s));\n}", "test": "fn footnotes_test_1() {\n    let original = r##\"Lorem ipsum.[^a]\n\n[^a]: Cool.\n\"##;\n    let expected = r##\"<p>Lorem ipsum.<sup class=\"footnote-reference\"><a href=\"#a\">1</a></sup></p>\n<div class=\"footnote-definition\" id=\"a\"><sup class=\"footnote-definition-label\">1</sup>\n<p>Cool.</p>\n</div>\n\"##;\n\n    test_markdown_html(original, expected, false);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_split.rs::test_invalid_suffix_length", "code": "pub fn no_stdout(&self) -> &Self {\n        assert!(\n            self.stdout.is_empty(),\n            \"Expected stdout to be empty, but it's:\\n{}\",\n            self.stdout_str()\n        );\n        self\n    }", "test": "fn test_invalid_suffix_length() {\n    new_ucmd!()\n        .args(&[\"-a\", \"xyz\"])\n        .fails()\n        .no_stdout()\n        .stderr_contains(\"invalid suffix length: 'xyz'\");\n}"}
{"test_id": "serde-rs-json/serde-rs-json-66f862f/tests/test.rs::test_write_enum", "code": "pub fn to_string<T>(value: &T) -> Result<String>\nwhere\n    T: ?Sized + Serialize,\n{\n    let vec = tri!(to_vec(value));\n    let string = unsafe {\n        // We do not emit invalid UTF-8.\n        String::from_utf8_unchecked(vec)\n    };\n    Ok(string)\n}", "test": "fn test_write_enum() {\n    test_encode_ok(&[\n        (Animal::Dog, \"\\\"Dog\\\"\"),\n        (\n            Animal::Frog(\"Henry\".to_string(), vec![]),\n            \"{\\\"Frog\\\":[\\\"Henry\\\",[]]}\",\n        ),\n        (\n            Animal::Frog(\"Henry\".to_string(), vec![349]),\n            \"{\\\"Frog\\\":[\\\"Henry\\\",[349]]}\",\n        ),\n        (\n            Animal::Frog(\"Henry\".to_string(), vec![349, 102]),\n            \"{\\\"Frog\\\":[\\\"Henry\\\",[349,102]]}\",\n        ),\n        (\n            Animal::Cat {\n                age: 5,\n                name: \"Kate\".to_string(),\n            },\n            \"{\\\"Cat\\\":{\\\"age\\\":5,\\\"name\\\":\\\"Kate\\\"}}\",\n        ),\n        (\n            Animal::AntHive(vec![\"Bob\".to_string(), \"Stuart\".to_string()]),\n            \"{\\\"AntHive\\\":[\\\"Bob\\\",\\\"Stuart\\\"]}\",\n        ),\n    ]);\n\n    test_pretty_encode_ok(&[\n        (Animal::Dog, \"\\\"Dog\\\"\"),\n        (\n            Animal::Frog(\"Henry\".to_string(), vec![]),\n            pretty_str!({\n                \"Frog\": [\n                    \"Henry\",\n                    []\n                ]\n            }),\n        ),\n        (\n            Animal::Frog(\"Henry\".to_string(), vec![349]),\n            pretty_str!({\n                \"Frog\": [\n                    \"Henry\",\n                    [\n                        349\n                    ]\n                ]\n            }),\n        ),\n        (\n            Animal::Frog(\"Henry\".to_string(), vec![349, 102]),\n            pretty_str!({\n                \"Frog\": [\n                    \"Henry\",\n                    [\n                      349,\n                      102\n                    ]\n                ]\n            }),\n        ),\n    ]);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/engine_traits_tests/src/iterator.rs::seek_key_miss_snapshot", "code": "fn iterator(&self, cf: &str) -> Result<Self::Iterator> {\n        self.iterator_opt(cf, IterOptions::default())\n    }", "test": "fn seek_key_miss_snapshot() {\n    let db = default_engine();\n    seek_key_miss(&db.engine, |e| e.snapshot().iterator(CF_DEFAULT).unwrap());\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/crates/server/tests/config_tests.rs::test_parse_toml", "code": "pub fn get_listen_port(&self) -> u16 {\n        self.listen_port.unwrap_or(DEFAULT_PORT)\n    }", "test": "fn test_parse_toml() {\n    let config = Config::from_toml(\"listen_port = 2053\").unwrap();\n    assert_eq!(config.get_listen_port(), 2053);\n\n    let config = Config::from_toml(\"listen_addrs_ipv4 = [\\\"0.0.0.0\\\"]\").unwrap();\n    assert_eq!(\n        config.get_listen_addrs_ipv4(),\n        Ok(vec![Ipv4Addr::new(0, 0, 0, 0)])\n    );\n\n    let config = Config::from_toml(\"listen_addrs_ipv4 = [\\\"0.0.0.0\\\", \\\"127.0.0.1\\\"]\").unwrap();\n    assert_eq!(\n        config.get_listen_addrs_ipv4(),\n        Ok(vec![Ipv4Addr::new(0, 0, 0, 0), Ipv4Addr::new(127, 0, 0, 1)])\n    );\n\n    let config = Config::from_toml(\"listen_addrs_ipv6 = [\\\"::0\\\"]\").unwrap();\n    assert_eq!(\n        config.get_listen_addrs_ipv6(),\n        Ok(vec![Ipv6Addr::new(0, 0, 0, 0, 0, 0, 0, 0)])\n    );\n\n    let config = Config::from_toml(\"listen_addrs_ipv6 = [\\\"::0\\\", \\\"::1\\\"]\").unwrap();\n    assert_eq!(\n        config.get_listen_addrs_ipv6(),\n        Ok(vec![\n            Ipv6Addr::new(0, 0, 0, 0, 0, 0, 0, 0),\n            Ipv6Addr::new(0, 0, 0, 0, 0, 0, 0, 1),\n        ])\n    );\n\n    let config = Config::from_toml(\"tcp_request_timeout = 25\").unwrap();\n    assert_eq!(config.get_tcp_request_timeout(), Duration::from_secs(25));\n\n    let config = Config::from_toml(\"log_level = \\\"Debug\\\"\").unwrap();\n    assert_eq!(config.get_log_level(), tracing::Level::DEBUG);\n\n    let config = Config::from_toml(\"directory = \\\"/dev/null\\\"\").unwrap();\n    assert_eq!(config.get_directory(), Path::new(\"/dev/null\"));\n}"}
{"test_id": "ron-rs-ron/ron-rs-ron-eafa2b6/tests/min_max.rs::test_i128_max", "code": "pub fn to_string<T>(&self, value: &T) -> Result<String>\n    where\n        T: ?Sized + ser::Serialize,\n    {\n        let mut output = Vec::new();\n        let mut s = Serializer::with_options(&mut output, None, self.clone())?;\n        value.serialize(&mut s)?;\n        Ok(String::from_utf8(output).expect(\"Ron should be utf-8\"))\n    }", "test": "fn test_i128_max() {\n    assert_eq!(\n        std::i128::MAX,\n        from_str(&to_string(&std::i128::MAX).unwrap()).unwrap()\n    );\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_multi.rs::test_multi_server_base", "code": "fn test_multi_base<T: Simulator>(cluster: &mut Cluster<T>) {\n    cluster.run();\n\n    test_multi_base_after_bootstrap(cluster);\n}", "test": "fn test_multi_server_base() {\n    let count = 5;\n    let mut cluster = new_server_cluster(0, count);\n    test_multi_base(&mut cluster)\n}"}
{"test_id": "wasmerio-wasmer/wasmerio-wasmer-7cb550d/tests/integration/cli/tests/msrv.rs::docker_file_is_up_to_date", "code": "fn ensure_file_contents(path: impl AsRef<Path>, contents: impl AsRef<str>) {\n    let path = path.as_ref();\n    let contents = contents.as_ref();\n\n    if let Ok(old_contents) = std::fs::read_to_string(path) {\n        if contents == old_contents {\n            // File is already up to date\n            return;\n        }\n    }\n\n    let display_path = path.strip_prefix(project_root()).unwrap_or(path);\n\n    eprintln!(\"{} was not up-to-date, updating...\", display_path.display());\n\n    if std::env::var(\"CI\").is_ok() {\n        eprintln!(\"Note: run `cargo test` locally and commit the updated files\");\n    }\n\n    if let Some(parent) = path.parent() {\n        let _ = std::fs::create_dir_all(parent);\n    }\n    std::fs::write(&path, contents).unwrap();\n    panic!(\n        \"\\\"{}\\\" was not up to date and has been updated. Please commit the changes and re-run the tests.\",\n        path.strip_prefix(project_root()).unwrap_or(path).display()\n    );\n}", "test": "fn docker_file_is_up_to_date() {\n    let pattern = Regex::new(r\"1\\.\\d\\d\").unwrap();\n    let dockerfile = project_root()\n        .join(\".github\")\n        .join(\"cross-linux-riscv64\")\n        .join(\"Dockerfile\");\n\n    let contents = std::fs::read_to_string(&dockerfile).unwrap();\n    let expected = pattern.replace_all(&contents, MSRV.as_str());\n\n    ensure_file_contents(dockerfile, expected);\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/name_server_pool_tests.rs::test_tcp_fallback_only_on_truncated", "code": "pub fn kind(&self) -> &ErrorKind {\n        &self.kind\n    }", "test": "fn test_tcp_fallback_only_on_truncated() {\n    // Lookup to UDP should fail with an error, and the resolver should not then try the query over\n    // TCP, because the default behavior is only to retry if the response was truncated.\n\n    let query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n\n    let mut udp_message = message(query.clone(), vec![], vec![], vec![]);\n    udp_message.set_response_code(ResponseCode::ServFail);\n    let tcp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 2));\n    let tcp_message = message(query.clone(), vec![tcp_record], vec![], vec![]);\n\n    let udp_nameserver = mock_nameserver(\n        vec![ResolveError::from_response(\n            DnsResponse::from_message(udp_message).unwrap(),\n            false,\n        )],\n        Default::default(),\n    );\n    let tcp_nameserver = mock_nameserver(\n        vec![Ok(DnsResponse::from_message(tcp_message).unwrap())],\n        Default::default(),\n    );\n\n    let pool = mock_nameserver_pool(\n        vec![udp_nameserver],\n        vec![tcp_nameserver],\n        None,\n        Default::default(),\n    );\n\n    let request = message(query, vec![], vec![], vec![]);\n    let future = pool.send(request).first_answer();\n    let error = block_on(future).expect_err(\"lookup request should fail with SERVFAIL\");\n    match error.kind() {\n        ResolveErrorKind::NoRecordsFound { response_code, .. }\n            if *response_code == ResponseCode::ServFail => {}\n        kind => panic!(\n            \"got unexpected kind of resolve error; expected `NoRecordsFound` error with SERVFAIL,\n            got {:#?}\",\n            kind,\n        ),\n    }\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-write-float/tests/algorithm_tests.rs::floor_log10_pow2_test", "code": "fn dragonbox_log10_2(q: i32) -> i32 {\n    let c = floor_shift(0, 0x4d104d427de7fbcc, 22);\n    let s = floor_shift(0, 0, 22);\n    (q * c - s) >> 22\n}", "test": "fn floor_log10_pow2_test() {\n    for q in -1700i32..=1700 {\n        let actual = algorithm::floor_log10_pow2(q);\n        let expected = dragonbox_log10_2(q);\n        assert_eq!(actual, expected);\n    }\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_storage.rs::test_pipelined_pessimistic_lock", "code": "pub fn delete_pessimistic_lock<E: Engine, L: LockManager, F: KvFormat>(\n        storage: &Storage<E, L, F>,\n        key: Key,\n        start_ts: u64,\n        for_update_ts: u64,\n    ) {\n        let (tx, rx) = channel();\n        storage\n            .sched_txn_command(\n                commands::PessimisticRollback::new(\n                    vec![key],\n                    start_ts.into(),\n                    for_update_ts.into(),\n                    Context::default(),\n                ),\n                expect_ok_callback(tx, 0),\n            )\n            .unwrap();\n        rx.recv().unwrap();\n    }", "test": "fn test_pipelined_pessimistic_lock() {\n    let rockskv_async_write_fp = \"rockskv_async_write\";\n    let rockskv_write_modifies_fp = \"rockskv_write_modifies\";\n    let scheduler_async_write_finish_fp = \"scheduler_async_write_finish\";\n    let before_pipelined_write_finish_fp = \"before_pipelined_write_finish\";\n\n    {\n        let storage = TestStorageBuilderApiV1::new(MockLockManager::new())\n            .pipelined_pessimistic_lock(false)\n            .build()\n            .unwrap();\n        let (tx, rx) = channel();\n        // If storage fails to write the lock to engine, client should\n        // receive the error when pipelined locking is disabled.\n        fail::cfg(rockskv_write_modifies_fp, \"return()\").unwrap();\n        storage\n            .sched_txn_command(\n                new_acquire_pessimistic_lock_command(\n                    vec![(Key::from_raw(b\"key\"), false)],\n                    10,\n                    10,\n                    true,\n                    false,\n                ),\n                Box::new(move |res| {\n                    res.unwrap_err();\n                    tx.send(()).unwrap();\n                }),\n            )\n            .unwrap();\n        rx.recv().unwrap();\n        fail::remove(rockskv_write_modifies_fp);\n    }\n\n    let storage = TestStorageBuilderApiV1::new(MockLockManager::new())\n        .pipelined_pessimistic_lock(true)\n        .build()\n        .unwrap();\n\n    let (tx, rx) = channel();\n    let (key, val) = (Key::from_raw(b\"key\"), b\"val\".to_vec());\n\n    // Even if storage fails to write the lock to engine, client should\n    // receive the successful response.\n    fail::cfg(rockskv_write_modifies_fp, \"return()\").unwrap();\n    fail::cfg(scheduler_async_write_finish_fp, \"pause\").unwrap();\n    storage\n        .sched_txn_command(\n            new_acquire_pessimistic_lock_command(vec![(key.clone(), false)], 10, 10, true, false),\n            expect_pessimistic_lock_res_callback(\n                tx.clone(),\n                PessimisticLockResults(vec![PessimisticLockKeyResult::Value(None)]),\n            ),\n        )\n        .unwrap();\n    rx.recv().unwrap();\n    fail::remove(rockskv_write_modifies_fp);\n    fail::remove(scheduler_async_write_finish_fp);\n    storage\n        .sched_txn_command(\n            commands::PrewritePessimistic::new(\n                vec![(\n                    Mutation::make_put(key.clone(), val.clone()),\n                    DoPessimisticCheck,\n                )],\n                key.to_raw().unwrap(),\n                10.into(),\n                3000,\n                10.into(),\n                1,\n                11.into(),\n                TimeStamp::default(),\n                None,\n                false,\n                AssertionLevel::Off,\n                vec![],\n                Context::default(),\n            ),\n            expect_ok_callback(tx.clone(), 0),\n        )\n        .unwrap();\n    rx.recv().unwrap();\n    storage\n        .sched_txn_command(\n            commands::Commit::new(vec![key.clone()], 10.into(), 20.into(), Context::default()),\n            expect_ok_callback(tx.clone(), 0),\n        )\n        .unwrap();\n    rx.recv().unwrap();\n\n    // Should report failure if storage fails to schedule write request to engine.\n    fail::cfg(rockskv_async_write_fp, \"return()\").unwrap();\n    storage\n        .sched_txn_command(\n            new_acquire_pessimistic_lock_command(vec![(key.clone(), false)], 30, 30, true, false),\n            expect_fail_callback(tx.clone(), 0, |_| ()),\n        )\n        .unwrap();\n    rx.recv().unwrap();\n    fail::remove(rockskv_async_write_fp);\n\n    // Shouldn't release latches until async write finished.\n    fail::cfg(scheduler_async_write_finish_fp, \"pause\").unwrap();\n    for blocked in &[false, true] {\n        storage\n            .sched_txn_command(\n                new_acquire_pessimistic_lock_command(\n                    vec![(key.clone(), false)],\n                    40,\n                    40,\n                    true,\n                    false,\n                ),\n                expect_pessimistic_lock_res_callback(\n                    tx.clone(),\n                    PessimisticLockResults(vec![PessimisticLockKeyResult::Value(Some(\n                        val.clone(),\n                    ))]),\n                ),\n            )\n            .unwrap();\n\n        if !*blocked {\n            rx.recv().unwrap();\n        } else {\n            // Blocked by latches.\n            rx.recv_timeout(Duration::from_millis(500)).unwrap_err();\n        }\n    }\n    fail::remove(scheduler_async_write_finish_fp);\n    rx.recv().unwrap();\n    delete_pessimistic_lock(&storage, key.clone(), 40, 40);\n\n    // Pipelined write is finished before async write.\n    fail::cfg(scheduler_async_write_finish_fp, \"pause\").unwrap();\n    storage\n        .sched_txn_command(\n            new_acquire_pessimistic_lock_command(vec![(key.clone(), false)], 50, 50, true, false),\n            expect_pessimistic_lock_res_callback(\n                tx.clone(),\n                PessimisticLockResults(vec![PessimisticLockKeyResult::Value(Some(val.clone()))]),\n            ),\n        )\n        .unwrap();\n    rx.recv().unwrap();\n    fail::remove(scheduler_async_write_finish_fp);\n    delete_pessimistic_lock(&storage, key.clone(), 50, 50);\n\n    // The proposed callback, which is responsible for returning response, is not\n    // guaranteed to be invoked. In this case it should still be continued\n    // properly.\n    fail::cfg(before_pipelined_write_finish_fp, \"return()\").unwrap();\n    storage\n        .sched_txn_command(\n            new_acquire_pessimistic_lock_command(\n                vec![(key.clone(), false), (Key::from_raw(b\"nonexist\"), false)],\n                60,\n                60,\n                true,\n                false,\n            ),\n            expect_pessimistic_lock_res_callback(\n                tx,\n                PessimisticLockResults(vec![\n                    PessimisticLockKeyResult::Value(Some(val)),\n                    PessimisticLockKeyResult::Value(None),\n                ]),\n            ),\n        )\n        .unwrap();\n    rx.recv_timeout(Duration::from_secs(5)).unwrap();\n    fail::remove(before_pipelined_write_finish_fp);\n    delete_pessimistic_lock(&storage, key, 60, 60);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_tr.rs::test_invalid_arg", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_invalid_arg() {\n    new_ucmd!().arg(\"--definitely-invalid\").fails().code_is(1);\n}"}
{"test_id": "hyperium-h2/hyperium-h2-da38b1c/tests/h2-tests/tests/server.rs::extended_connect_protocol_disabled_by_default", "code": "pub fn is_extended_connect_protocol_enabled(&self) -> Option<bool> {\n        self.enable_connect_protocol.map(|val| val != 0)\n    }", "test": "async fn extended_connect_protocol_disabled_by_default() {\n    h2_support::trace_init!();\n\n    let (io, mut client) = mock::new();\n\n    let client = async move {\n        let settings = client.assert_server_handshake().await;\n\n        assert_eq!(settings.is_extended_connect_protocol_enabled(), None);\n\n        client\n            .send_frame(\n                frames::headers(1)\n                    .request(\"CONNECT\", \"http://bread/baguette\")\n                    .protocol(\"the-bread-protocol\"),\n            )\n            .await;\n\n        client.recv_frame(frames::reset(1).protocol_error()).await;\n    };\n\n    let srv = async move {\n        let mut srv = server::handshake(io).await.expect(\"handshake\");\n\n        poll_fn(move |cx| srv.poll_closed(cx))\n            .await\n            .expect(\"server\");\n    };\n\n    join(client, srv).await;\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/name_server_pool_tests.rs::test_datagram_stream_upgrade_on_truncation_despite_udp", "code": "pub fn answers(answers: LookupRecords, additionals: Option<LookupRecords>) -> Self {\n        Self::Records {\n            answers,\n            additionals,\n        }\n    }", "test": "fn test_datagram_stream_upgrade_on_truncation_despite_udp() {\n    // Lookup to UDP should return a truncated message, then we expect lookup on TCP.\n    // This should occur even though `try_tcp_on_error` is set to false.\n\n    let query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n\n    let udp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 1));\n    let tcp_record1 = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 2));\n    let tcp_record2 = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 3));\n\n    let mut udp_message = message(query.clone(), vec![udp_record], vec![], vec![]);\n    udp_message.set_truncated(true);\n\n    let tcp_message = message(\n        query.clone(),\n        vec![tcp_record1.clone(), tcp_record2.clone()],\n        vec![],\n        vec![],\n    );\n\n    let udp_nameserver = mock_nameserver(\n        vec![Ok(DnsResponse::from_message(udp_message).unwrap())],\n        Default::default(),\n    );\n    let tcp_nameserver = mock_nameserver(\n        vec![Ok(DnsResponse::from_message(tcp_message).unwrap())],\n        Default::default(),\n    );\n\n    let pool = mock_nameserver_pool(\n        vec![udp_nameserver],\n        vec![tcp_nameserver],\n        None,\n        Default::default(),\n    );\n\n    // lookup on UDP succeeds, any other would fail\n    let request = message(query, vec![], vec![], vec![]);\n    let future = pool.send(request).first_answer();\n\n    let response = block_on(future).unwrap();\n    assert_eq!(response.answers(), &[tcp_record1, tcp_record2]);\n}"}
{"test_id": "paritytech-wasmi/paritytech-wasmi-d66f271/crates/wasmi/tests/e2e/v1/resumable_call.rs::resumable_call_smoldot_tail_02", "code": "pub fn resume<T>(\n        self,\n        mut ctx: impl AsContextMut<UserState = T>,\n        inputs: &[Value],\n        outputs: &mut [Value],\n    ) -> Result<ResumableCall, Error> {\n        self.engine\n            .resolve_func_type(self.host_func().ty_dedup(ctx.as_context()), |func_type| {\n                func_type.match_results(inputs, true)\n            })?;\n        self.engine\n            .resolve_func_type(self.func.ty_dedup(ctx.as_context()), |func_type| {\n                func_type.match_results(outputs, false)?;\n                func_type.prepare_outputs(outputs);\n                <Result<(), Error>>::Ok(()) // TODO: why do we need types here?\n            })?;\n        self.engine\n            .clone()\n            .resume_func(ctx.as_context_mut(), self, inputs, outputs)\n            .map_err(Into::into)\n            .map(ResumableCall::new)\n    }", "test": "fn resumable_call_smoldot_tail_02() {\n    let (mut store, wasm_fn) = resumable_call_smoldot_common(\n        r#\"\n        (module\n            (import \"env\" \"host_fn\" (func $host (result i32)))\n            (func $wasm (result i32)\n                (return_call $host)\n            )\n            (func (export \"test\") (result i32)\n                (call $wasm)\n            )\n        )\n        \"#,\n    );\n    let invocation = wasm_fn.call_resumable(&mut store, ()).unwrap_resumable();\n    match invocation.resume(&mut store, &[Value::I32(42)]).unwrap() {\n        TypedResumableCall::Finished(result) => assert_eq!(result, 42),\n        TypedResumableCall::Resumable(_) => panic!(\"expected TypeResumableCall::Finished\"),\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_seq.rs::test_neg_infinity", "code": "pub fn run(&mut self) -> CmdResult {\n        self.run_no_wait().wait().unwrap()\n    }", "test": "fn test_neg_infinity() {\n    run(&[\"--\", \"-infinity\", \"0\"], b\"-inf\\n-inf\\n-inf\\n\");\n}"}
{"test_id": "mitsuhiko-minijinja/mitsuhiko-minijinja-5f2c1e8/minijinja/tests/test_environment.rs::test_clone", "code": "pub fn get_template(&self, name: &str) -> Result<Template<'_, '_>, Error> {\n        let compiled = ok!(self.templates.get(name));\n        Ok(Template::new(\n            self,\n            CompiledTemplateRef::Borrowed(compiled),\n            self.initial_auto_escape(name),\n        ))\n    }", "test": "fn test_clone() {\n    let mut env = Environment::new();\n    env.add_template(\"test\", \"a\").unwrap();\n    let mut env2 = env.clone();\n    assert_eq!(env2.get_template(\"test\").unwrap().render(()).unwrap(), \"a\");\n    env2.add_template(\"test\", \"b\").unwrap();\n    assert_eq!(env2.get_template(\"test\").unwrap().render(()).unwrap(), \"b\");\n    assert_eq!(env.get_template(\"test\").unwrap().render(()).unwrap(), \"a\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_replication_mode.rs::test_switching_replication_mode_hibernate", "code": "fn region_replication_status<T>(\n        &mut self,\n        ctx: &PollContext<EK, ER, T>,\n    ) -> Option<RegionReplicationStatus> {\n        if self.replication_mode_version == 0 {\n            return None;\n        }\n        let mut status = RegionReplicationStatus {\n            state_id: self.replication_mode_version,\n            ..Default::default()\n        };\n        let state = if !self.replication_sync {\n            if self.dr_auto_sync_state != DrAutoSyncState::Async {\n                // use raft_log_gc_threshold, it's indicate the log is almost synced.\n                let res = self.check_group_commit_consistent(ctx.cfg.raft_log_gc_threshold);\n                if Some(true) != res {\n                    let mut buffer: SmallVec<[(u64, u64, u64); 5]> = SmallVec::new();\n                    if self.get_store().applied_term() >= self.term() {\n                        let progress = self.raft_group.raft.prs();\n                        for (id, p) in progress.iter() {\n                            if !progress.conf().voters().contains(*id) {\n                                continue;\n                            }\n                            buffer.push((*id, p.commit_group_id, p.matched));\n                        }\n                    };\n                    info!(\n                        \"still not reach integrity over label\";\n                        \"status\" => ?res,\n                        \"region_id\" => self.region_id,\n                        \"peer_id\" => self.peer.id,\n                        \"progress\" => ?buffer,\n                        \"dr_auto_sync_state\" => ?self.dr_auto_sync_state,\n                    );\n                } else {\n                    // Once the DR replicas catch up the log during the `SyncRecover` phase, we\n                    // should enable group commit to promise `IntegrityOverLabel`. then safe\n                    // to switch to the `Sync` phase.\n                    if self.dr_auto_sync_state == DrAutoSyncState::SyncRecover {\n                        self.switch_group_commit(true, &ctx.global_replication_state)\n                    }\n                    self.replication_sync = true;\n                }\n                match res {\n                    Some(true) => RegionReplicationState::IntegrityOverLabel,\n                    Some(false) => RegionReplicationState::SimpleMajority,\n                    None => RegionReplicationState::Unknown,\n                }\n            } else {\n                RegionReplicationState::SimpleMajority\n            }\n        } else {\n            RegionReplicationState::IntegrityOverLabel\n        };\n        status.set_state(state);\n        Some(status)\n    }", "test": "fn test_switching_replication_mode_hibernate() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.max_leader_missing_duration = ReadableDuration::hours(1);\n    cluster.cfg.raft_store.peer_stale_state_check_interval = ReadableDuration::minutes(30);\n    cluster.cfg.raft_store.abnormal_leader_missing_duration = ReadableDuration::hours(1);\n    let pd_client = cluster.pd_client.clone();\n    pd_client.disable_default_operator();\n    pd_client.configure_dr_auto_sync(\"zone\");\n    cluster.cfg.raft_store.pd_store_heartbeat_tick_interval = ReadableDuration::millis(50);\n    cluster.cfg.raft_store.raft_log_gc_threshold = 20;\n    cluster.add_label(1, \"zone\", \"ES\");\n    cluster.add_label(2, \"zone\", \"ES\");\n    cluster.add_label(3, \"zone\", \"WS\");\n    let r = cluster.run_conf_change();\n    cluster.must_put(b\"k1\", b\"v0\");\n\n    pd_client.must_add_peer(r, new_peer(2, 2));\n    pd_client.must_add_peer(r, new_learner_peer(3, 3));\n    let state = pd_client.region_replication_status(r);\n    assert_eq!(state.state_id, 1);\n    assert_eq!(state.state, RegionReplicationState::SimpleMajority);\n\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v0\");\n    // Wait for append response after applying snapshot.\n    thread::sleep(Duration::from_millis(50));\n    cluster.add_send_filter(IsolationFilterFactory::new(3));\n    pd_client.must_add_peer(r, new_peer(3, 3));\n    // Wait for leader become hibernated.\n    thread::sleep(\n        cluster.cfg.raft_store.raft_base_tick_interval.0\n            * 2\n            * (cluster.cfg.raft_store.raft_election_timeout_ticks as u32),\n    );\n    cluster.clear_send_filters();\n    // Wait for region heartbeat.\n    thread::sleep(Duration::from_millis(100));\n    let state = cluster.pd_client.region_replication_status(r);\n    assert_eq!(state.state_id, 1);\n    assert_eq!(state.state, RegionReplicationState::IntegrityOverLabel);\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/migrate.rs::missing_configuration_file", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn missing_configuration_file() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"migrate\")].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"missing_configuration_file\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_bigquery.rs::parse_cast_string_to_bytes_format", "code": "pub fn verified_only_select(&self, query: &str) -> Select {\n        match *self.verified_query(query).body {\n            SetExpr::Select(s) => *s,\n            _ => panic!(\"Expected SetExpr::Select\"),\n        }\n    }", "test": "fn parse_cast_string_to_bytes_format() {\n    let sql = r\"SELECT CAST('Hello' AS BYTES FORMAT 'ASCII') AS string_to_bytes\";\n    bigquery_and_generic().verified_only_select(sql);\n}"}
{"test_id": "web-infra-dev-oxc/oxc-project-oxc-884a819/crates/oxc_minifier/tests/oxc/precedence.rs::bitwise_xor", "code": "fn test(args: &[&str]) -> LintResult {\n        let mut new_args = vec![\"--quiet\"];\n        new_args.extend(args);\n        let options = lint_command().run_inner(new_args.as_slice()).unwrap().lint_options;\n        let CliRunResult::LintResult(lint_result) = LintRunner::new(options).run() else {\n            unreachable!()\n        };\n        lint_result\n    }", "test": "fn bitwise_xor() {\n    test(\"a ^ b ^ c\", \"a^b^c;\");\n    test(\"(a ^ b) ^ c\", \"a^b^c;\");\n    test(\"a ^ (b ^ c)\", \"a^b^c;\");\n    test(\"a | b & c\", \"a|b&c;\");\n    test(\"a | (b & c)\", \"a|b&c;\");\n    test(\"a | (b || c)\", \"a|(b||c);\");\n    test(\"a | b || c\", \"a|b||c;\");\n    test(\"(a, b) ^ (c, d)\", \"(a,b)^(c,d);\");\n    test(\"(a | b) ^ (c | d)\", \"(a|b)^(c|d);\");\n    test(\"a, b ^ c, d\", \"a,b^c,d;\");\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/client_future_tests.rs::test_delete_by_rdata_multi", "code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "fn test_delete_by_rdata_multi() {\n    let io_loop = Runtime::new().unwrap();\n    let ((mut client, bg), origin) = io_loop.block_on(create_sig0_ready_client());\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    // append a record\n    let mut rrset = RecordSet::with_ttl(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n\n    let record1 = rrset\n        .new_record(&RData::A(A::new(100, 10, 100, 10)))\n        .clone();\n    let record2 = rrset\n        .new_record(&RData::A(A::new(100, 10, 100, 11)))\n        .clone();\n    let record3 = rrset\n        .new_record(&RData::A(A::new(100, 10, 100, 12)))\n        .clone();\n    let record4 = rrset\n        .new_record(&RData::A(A::new(100, 10, 100, 13)))\n        .clone();\n    let rrset = rrset;\n\n    // first check the must_exist option\n    let result = io_loop\n        .block_on(client.delete_by_rdata(rrset.clone(), origin.clone()))\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // next create to a non-existent RRset\n    let result = io_loop\n        .block_on(client.create(rrset, origin.clone()))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // append a record\n    let mut rrset = RecordSet::with_ttl(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n\n    let record1 = rrset.new_record(record1.data().unwrap()).clone();\n    let record3 = rrset.new_record(record3.data().unwrap()).clone();\n    let rrset = rrset;\n\n    let result = io_loop\n        .block_on(client.append(rrset.clone(), origin.clone(), true))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // verify record contents\n    let result = io_loop\n        .block_on(client.delete_by_rdata(rrset, origin))\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let result = io_loop\n        .block_on(client.query(\n            record1.name().clone(),\n            record1.dns_class(),\n            record1.record_type(),\n        ))\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.answers().len(), 2);\n    assert!(!result.answers().iter().any(|rr| *rr == record1));\n    assert!(result.answers().iter().any(|rr| *rr == record2));\n    assert!(!result.answers().iter().any(|rr| *rr == record3));\n    assert!(result.answers().iter().any(|rr| *rr == record4));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_split.rs::test_split_both_lines_and_obs_lines_standalone", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_split_both_lines_and_obs_lines_standalone() {\n    // This test will ensure that:\n    // if both lines option '-l' or '--lines' (with value) and obsolete lines option '-100' are used - it fails\n    // if standalone lines option is used incorrectly and treated as a hyphen prefixed value of other option - it fails\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    at.touch(\"file\");\n\n    scene\n        .ucmd()\n        .args(&[\"-l\", \"2\", \"-2\", \"file\"])\n        .fails()\n        .code_is(1)\n        .stderr_contains(\"split: cannot split in more than one way\\n\");\n    scene\n        .ucmd()\n        .args(&[\"--lines\", \"2\", \"-2\", \"file\"])\n        .fails()\n        .code_is(1)\n        .stderr_contains(\"split: cannot split in more than one way\\n\");\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-parse-float/tests/slow_tests.rs::b_test", "code": "pub fn b<F: RawFloat>(float: F) -> ExtendedFloat80 {\n    ExtendedFloat80 {\n        mant: float.mantissa().as_u64(),\n        exp: float.exponent(),\n    }\n}", "test": "fn b_test() {\n    assert_eq!(b(1e-45_f32), (1, -149));\n    assert_eq!(b(5e-324_f64), (1, -1074));\n    assert_eq!(b(1e-323_f64), (2, -1074));\n    assert_eq!(b(2e-323_f64), (4, -1074));\n    assert_eq!(b(3e-323_f64), (6, -1074));\n    assert_eq!(b(4e-323_f64), (8, -1074));\n    assert_eq!(b(5e-323_f64), (10, -1074));\n    assert_eq!(b(6e-323_f64), (12, -1074));\n    assert_eq!(b(7e-323_f64), (14, -1074));\n    assert_eq!(b(8e-323_f64), (16, -1074));\n    assert_eq!(b(9e-323_f64), (18, -1074));\n    assert_eq!(b(1_f32), (8388608, -23));\n    assert_eq!(b(1_f64), (4503599627370496, -52));\n    assert_eq!(b(1e38_f32), (9860761, 103));\n    assert_eq!(b(1e308_f64), (5010420900022432, 971));\n}"}
{"test_id": "rust-bakery-nom/rust-bakery-nom-869f897/tests/css.rs::parse_color", "code": "fn hex_color(input: &str) -> IResult<&str, Color> {\n  let (input, _) = tag(\"#\")(input)?;\n  let (input, (red, green, blue)) = tuple((hex_primary, hex_primary, hex_primary))(input)?;\n\n  Ok((input, Color { red, green, blue }))\n}", "test": "fn parse_color() {\n  assert_eq!(\n    hex_color(\"#2F14DF\"),\n    Ok((\n      \"\",\n      Color {\n        red: 47,\n        green: 20,\n        blue: 223,\n      }\n    ))\n  );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_install.rs::test_install_dir_dot", "code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_dir_dot() {\n    // To match tests/install/d-slashdot.sh\n    let scene = TestScenario::new(util_name!());\n\n    scene.ucmd().arg(\"-d\").arg(\"dir1/.\").succeeds();\n    scene.ucmd().arg(\"-d\").arg(\"dir2/..\").succeeds();\n    // Tests that we don't have dir3/. in the output\n    // but only 'dir3'\n    scene\n        .ucmd()\n        .arg(\"-d\")\n        .arg(\"dir3/.\")\n        .arg(\"-v\")\n        .succeeds()\n        .stdout_contains(\"creating directory 'dir3'\");\n    scene\n        .ucmd()\n        .arg(\"-d\")\n        .arg(\"dir4/./cal\")\n        .arg(\"-v\")\n        .succeeds()\n        .stdout_contains(\"creating directory 'dir4/./cal'\");\n    scene\n        .ucmd()\n        .arg(\"-d\")\n        .arg(\"dir5/./cali/.\")\n        .arg(\"-v\")\n        .succeeds()\n        .stdout_contains(\"creating directory 'dir5/cali'\");\n\n    let at = &scene.fixtures;\n\n    assert!(at.dir_exists(\"dir1\"));\n    assert!(at.dir_exists(\"dir2\"));\n    assert!(at.dir_exists(\"dir3\"));\n    assert!(at.dir_exists(\"dir4/cal\"));\n    assert!(at.dir_exists(\"dir5/cali\"));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_timeout.rs::test_invalid_multi_byte_characters", "code": "pub fn usage_error<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.stderr_only(format!(\n            \"{0}: {2}\\nTry '{1} {0} --help' for more information.\\n\",\n            self.util_name.as_ref().unwrap(), // This shouldn't be called using a normal command\n            self.bin_path.display(),\n            msg.as_ref()\n        ))\n    }", "test": "fn test_invalid_multi_byte_characters() {\n    new_ucmd!()\n        .args(&[\"10\u20ac\", \"sleep\", \"0\"])\n        .fails()\n        .usage_error(\"invalid time interval '10\u20ac'\");\n}\n\n//"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_common.rs::parse_simple_math_expr_minus", "code": "pub fn verified_only_select(&self, query: &str) -> Select {\n        match *self.verified_query(query).body {\n            SetExpr::Select(s) => *s,\n            _ => panic!(\"Expected SetExpr::Select\"),\n        }\n    }", "test": "fn parse_simple_math_expr_minus() {\n    let sql = \"SELECT a - b, 2 - a, 2.5 - a, a_f - b_f, 2 - a_f, 2.5 - a_f FROM c\";\n    verified_only_select(sql);\n}"}
{"test_id": "tokio-rs-prost/tokio-rs-prost-0c89fa6/tests/src/deprecated_field.rs::test_warns_when_using_fields_with_deprecated_field", "code": "fn drop(&mut self) {\n                    self.0.clear();\n                }", "test": "fn test_warns_when_using_fields_with_deprecated_field() {\n    #[allow(deprecated)]\n    let message = deprecated_field::Test {\n        not_outdated: \".ogg\".to_string(),\n        outdated: \".wav\".to_string(),\n    };\n    // This test relies on the `#[allow(deprecated)]` attribute to ignore the warning that should\n    // be raised by the compiler.\n    // This test has a shortcoming since it doesn't explicitly check for the presence of the\n    // `deprecated` attribute since it doesn't exist at runtime. If complied without the `allow`\n    // attribute the following warning would be raised:\n    //\n    //    warning: use of deprecated item 'deprecated_field::deprecated_field::Test::outdated'\n    //      --> tests/src/deprecated_field.rs:11:9\n    //       |\n    //    11 |         outdated: \".wav\".to_string(),\n    //       |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    //       |\n    //       = note: `#[warn(deprecated)]` on by default\n    drop(message);\n}"}
{"test_id": "ordinals-ord/ordinals-ord-8090538/tests/wallet/send.rs::inscriptions_cannot_be_sent_by_satpoint", "code": "pub(crate) fn run_and_extract_stdout(self) -> String {\n    self.run().1\n  }", "test": "fn inscriptions_cannot_be_sent_by_satpoint() {\n  let rpc_server = test_bitcoincore_rpc::spawn();\n  create_wallet(&rpc_server);\n\n  let (_, reveal) = inscribe(&rpc_server);\n\n  rpc_server.mine_blocks(1);\n\n  CommandBuilder::new(format!(\n    \"wallet send --fee-rate 1 bc1qw508d6qejxtdg4y5r3zarvary0c5xw7kv8f3t4 {reveal}:0:0\"\n  ))\n  .rpc_server(&rpc_server)\n  .expected_stderr(\"error: inscriptions must be sent by inscription ID\\n\")\n  .expected_exit_code(1)\n  .run_and_extract_stdout();\n}"}
{"test_id": "raphlinus-pulldown-cmark/raphlinus-pulldown-cmark-3da63d5/tests/suite/footnotes.rs::footnotes_test_7", "code": "pub fn test_markdown_html(input: &str, output: &str, smart_punct: bool) {\n    let mut s = String::new();\n\n    let mut opts = Options::empty();\n    opts.insert(Options::ENABLE_TABLES);\n    opts.insert(Options::ENABLE_FOOTNOTES);\n    opts.insert(Options::ENABLE_STRIKETHROUGH);\n    opts.insert(Options::ENABLE_TASKLISTS);\n    if smart_punct {\n        opts.insert(Options::ENABLE_SMART_PUNCTUATION);\n    }\n    opts.insert(Options::ENABLE_HEADING_ATTRIBUTES);\n\n    let p = Parser::new_ext(input, opts);\n    pulldown_cmark::html::push_html(&mut s, p);\n\n    assert_eq!(normalize_html(output), normalize_html(&s));\n}", "test": "fn footnotes_test_7() {\n    let original = r##\"Nested footnotes are considered poor style. [^a] [^xkcd]\n\n[^a]: This does not mean that footnotes cannot reference each other. [^b]\n\n[^b]: This means that a footnote definition cannot be directly inside another footnote definition.\n> This means that a footnote cannot be directly inside another footnote's body. [^e]\n>\n> [^e]: They can, however, be inside anything else.\n\n[^xkcd]: [The other kind of nested footnote is, however, considered poor style.](https://xkcd.com/1208/)\n\"##;\n    let expected = r##\"<p>Nested footnotes are considered poor style. <sup class=\"footnote-reference\"><a href=\"#a\">1</a></sup> <sup class=\"footnote-reference\"><a href=\"#xkcd\">2</a></sup></p>\n<div class=\"footnote-definition\" id=\"a\"><sup class=\"footnote-definition-label\">1</sup>\n<p>This does not mean that footnotes cannot reference each other. <sup class=\"footnote-reference\"><a href=\"#b\">3</a></sup></p>\n</div>\n<div class=\"footnote-definition\" id=\"b\"><sup class=\"footnote-definition-label\">3</sup>\n<p>This means that a footnote definition cannot be directly inside another footnote definition.</p>\n<blockquote>\n<p>This means that a footnote cannot be directly inside another footnote's body. <sup class=\"footnote-reference\"><a href=\"#e\">4</a></sup></p>\n<div class=\"footnote-definition\" id=\"e\"><sup class=\"footnote-definition-label\">4</sup>\n<p>They can, however, be inside anything else.</p>\n</div>\n</blockquote>\n</div>\n<div class=\"footnote-definition\" id=\"xkcd\"><sup class=\"footnote-definition-label\">2</sup>\n<p><a href=\"https://xkcd.com/1208/\">The other kind of nested footnote is, however, considered poor style.</a></p>\n</div>\n\"##;\n\n    test_markdown_html(original, expected, false);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_du.rs::test_du_exclude", "code": "pub fn stdout_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stdout_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stdout_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_du_exclude() {\n    let ts = TestScenario::new(util_name!());\n    let at = &ts.fixtures;\n\n    at.symlink_dir(SUB_DEEPER_DIR, SUB_DIR_LINKS_DEEPER_SYM_DIR);\n    at.mkdir_all(SUB_DIR_LINKS);\n\n    ts.ucmd()\n        .arg(\"--exclude=subdir\")\n        .arg(SUB_DEEPER_DIR)\n        .succeeds()\n        .stdout_contains(\"subdir/deeper/deeper_dir\");\n    ts.ucmd()\n        .arg(\"--exclude=subdir\")\n        .arg(\"subdir\")\n        .succeeds()\n        .stdout_is(\"\");\n    ts.ucmd()\n        .arg(\"--exclude=subdir\")\n        .arg(\"--verbose\")\n        .arg(\"subdir\")\n        .succeeds()\n        .stdout_contains(\"'subdir' ignored\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_prevote.rs::test_node_create_peer_from_pre_vote", "code": "fn test_create_peer_from_pre_vote<T: Simulator>(cluster: &mut Cluster<T>) {\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    let r1 = cluster.run_conf_change();\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    let rx = attach_prevote_notifiers(cluster, 1);\n    cluster.add_send_filter(IsolationFilterFactory::new(2));\n    pd_client.must_add_peer(r1, new_peer(2, 2));\n\n    if rx.recv_timeout(Duration::from_secs(3)).is_err() {\n        panic!(\"peer 1 should send pre vote\");\n    }\n\n    // The peer 2 should be created.\n    cluster.clear_send_filters();\n    must_get_equal(&cluster.get_engine(2), b\"k1\", b\"v1\");\n}", "test": "fn test_node_create_peer_from_pre_vote() {\n    let mut cluster = new_node_cluster(0, 2);\n    cluster.cfg.raft_store.prevote = true;\n    test_create_peer_from_pre_vote(&mut cluster);\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-util/tests/bf16_tests.rs::as_f32_test", "code": "pub fn as_f32(self) -> f32 {\n        // This is super easy, since we have the same exponent bits:\n        // just need to shift left 16.\n        f32::from_bits((self.bits as u32) << 16)\n    }", "test": "fn as_f32_test() {\n    assert_eq!(bf16::from_bits(1).as_f32(), 9.18355e-41f32);\n    assert_eq!(bf16::ZERO.as_f32(), 0.0f32);\n    assert_eq!(bf16::ZERO.to_bits(), 0);\n    assert_eq!(bf16::ONE.as_f32(), 1.0f32);\n    assert_eq!(bf16::ONE.to_bits(), (127 << 7));\n    assert_eq!(bf16::TWO.as_f32(), 2.0f32);\n    assert_eq!(bf16::TWO.to_bits(), (128 << 7));\n    assert_eq!(bf16::from_bits(126 << 7).as_f32(), 0.5f32);\n    assert!(bf16::NAN.as_f32().is_nan());\n    assert!(bf16::INFINITY.as_f32().is_inf());\n    assert!(bf16::NEG_INFINITY.as_f32().is_inf());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_ln.rs::test_relative_requires_symbolic", "code": "pub fn fails(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.failure();\n        cmd_result\n    }", "test": "fn test_relative_requires_symbolic() {\n    new_ucmd!().args(&[\"-r\", \"foo\", \"bar\"]).fails();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_realpath.rs::test_realpath_physical_mode", "code": "pub fn stdout_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stdout_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stdout_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_realpath_physical_mode() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    at.mkdir(\"dir1\");\n    at.mkdir_all(\"dir2/bar\");\n    at.symlink_dir(\"dir2/bar\", \"dir1/foo\");\n\n    scene\n        .ucmd()\n        .arg(\"dir1/foo/..\")\n        .succeeds()\n        .stdout_contains(\"dir2\\n\");\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/fallback.rs::doesnt_work_with_justfile", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn doesnt_work_with_justfile() {\n  Test::new()\n    .tree(tree! {\n      bar: {\n        justfile: \"\n          baz:\n            echo subdir\n        \"\n      }\n    })\n    .justfile(\n      \"\n      foo:\n        echo root\n    \",\n    )\n    .args([\"--justfile\", \"justfile\", \"foo\"])\n    .current_dir(\"bar\")\n    .status(EXIT_FAILURE)\n    .stderr(\"error: Justfile does not contain recipe `foo`.\\n\")\n    .run();\n}"}
{"test_id": "gfx-rs-naga/gfx-rs-naga-92e41b4/tests/spirv-capabilities.rs::sampler1d", "code": "fn require(capabilities: &[Ca], source: &str) {\n    require_and_forbid(capabilities, &[], source);\n}", "test": "fn sampler1d() {\n    require(\n        &[Ca::Sampled1D],\n        r#\"\n        @group(0) @binding(0)\n        var image_1d: texture_1d<f32>;\n    \"#,\n    );\n}"}
{"test_id": "ron-rs-ron/ron-rs-ron-eafa2b6/tests/123_enum_representation.rs::test_adjacently_a_de", "code": "fn test_de<T>(s: &str, expected: T)\nwhere\n    T: for<'a> Deserialize<'a> + Debug + PartialEq,\n{\n    let actual: Result<T, _> = from_str(s);\n    assert_eq!(actual, Ok(expected));\n}", "test": "fn test_adjacently_a_de() {\n    let s = \"(type:VariantA,content:(foo:1,bar:2,different:Foo))\";\n    let e = EnumStructAdjacently::VariantA {\n        foo: 1,\n        bar: 2,\n        different: Inner::Foo,\n    };\n    test_de(s, e);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_df.rs::test_default_block_size", "code": "fn next(&mut self) -> Option<Self::Item> {\n        match self.matcher.next_match(&self.haystack[self.position..]) {\n            Some((first, last)) => {\n                let result = (first + self.position, last + self.position);\n                self.position += last;\n                Some(result)\n            }\n            None => None,\n        }\n    }", "test": "fn test_default_block_size() {\n    let output = new_ucmd!()\n        .arg(\"--output=size\")\n        .succeeds()\n        .stdout_move_str();\n    let header = output.lines().next().unwrap().trim().to_string();\n\n    assert_eq!(header, \"1K-blocks\");\n\n    let output = new_ucmd!()\n        .arg(\"--output=size\")\n        .env(\"POSIXLY_CORRECT\", \"1\")\n        .succeeds()\n        .stdout_move_str();\n    let header = output.lines().next().unwrap().trim().to_string();\n\n    assert_eq!(header, \"512B-blocks\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_arg_backup_with_other_args", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_arg_backup_with_other_args() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .arg(\"-vbL\")\n        .succeeds();\n\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), \"Hello, World!\\n\");\n    assert_eq!(\n        at.read(&format!(\"{TEST_HOW_ARE_YOU_SOURCE}~\")),\n        \"How are you?\\n\"\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_install.rs::test_install_target_new_file", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_target_new_file() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"file\";\n    let dir = \"target_dir\";\n\n    at.touch(file);\n    at.mkdir(dir);\n    ucmd.arg(file)\n        .arg(format!(\"{dir}/{file}\"))\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n    assert!(at.file_exists(format!(\"{dir}/{file}\")));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_expand.rs::test_tabs_with_invalid_chars", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_tabs_with_invalid_chars() {\n    new_ucmd!()\n        .arg(\"--tabs=x\")\n        .fails()\n        .stderr_contains(\"tab size contains invalid character(s): 'x'\");\n    new_ucmd!()\n        .arg(\"--tabs=1x2\")\n        .fails()\n        .stderr_contains(\"tab size contains invalid character(s): 'x2'\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/storage/test_raft_storage.rs::test_auto_gc", "code": "pub fn recv_timeout<S, I>(s: &mut S, dur: std::time::Duration) -> Result<Option<I>, ()>\nwhere\n    S: Stream<Item = I> + Unpin,\n{\n    poll_timeout(&mut s.next(), dur)\n}", "test": "fn test_auto_gc() {\n    let count = 3;\n    let (mut cluster, first_leader_storage, ctx) =\n        new_raft_storage_with_store_count::<ApiV1>(count, \"\");\n    let pd_client = Arc::clone(&cluster.pd_client);\n\n    // Used to wait for all storage's GC to finish\n    let (finish_signal_tx, finish_signal_rx) = channel();\n\n    // Create storage object for each store in the cluster\n    let mut storages: HashMap<_, _> = cluster\n        .sim\n        .rl()\n        .storages\n        .iter()\n        .map(|(id, engine)| {\n            let mut config = GcConfig::default();\n            // Do not skip GC\n            config.ratio_threshold = 0.9;\n            let storage = SyncTestStorageBuilderApiV1::from_engine(engine.clone())\n                .gc_config(config)\n                .build(*id)\n                .unwrap();\n\n            (*id, storage)\n        })\n        .collect();\n\n    let mut region_info_accessors = cluster.sim.rl().region_info_accessors.clone();\n\n    for (id, storage) in &mut storages {\n        let tx = finish_signal_tx.clone();\n\n        let mut cfg = AutoGcConfig::new_test_cfg(\n            Arc::clone(&pd_client),\n            region_info_accessors.remove(id).unwrap(),\n            *id,\n        );\n        cfg.post_a_round_of_gc = Some(Box::new(move || tx.send(()).unwrap()));\n\n        storage.start_auto_gc(cfg);\n    }\n\n    assert_eq!(storages.len(), count);\n\n    // test_data will be wrote with ts < 50\n    let test_data: Vec<_> = [\n        (b\"k1\", b\"v1\"),\n        (b\"k2\", b\"v2\"),\n        (b\"k3\", b\"v3\"),\n        (b\"k4\", b\"v4\"),\n        (b\"k5\", b\"v5\"),\n        (b\"k6\", b\"v6\"),\n        (b\"k7\", b\"v7\"),\n        (b\"k8\", b\"v8\"),\n        (b\"k9\", b\"v9\"),\n    ]\n    .iter()\n    .map(|(k, v)| (k.to_vec(), v.to_vec()))\n    .collect();\n\n    let test_data2: Vec<_> = test_data\n        .iter()\n        .map(|(k, v)| {\n            let mut v = v.to_vec();\n            v.push(b'1');\n            (k.to_vec(), v)\n        })\n        .collect();\n\n    let test_data3: Vec<_> = test_data\n        .iter()\n        .map(|(k, v)| {\n            let mut v = v.to_vec();\n            v.push(b'2');\n            (k.to_vec(), v)\n        })\n        .collect();\n\n    write_test_data(&first_leader_storage, &ctx, &test_data, 10);\n    write_test_data(&first_leader_storage, &ctx, &test_data2, 100);\n    write_test_data(&first_leader_storage, &ctx, &test_data3, 200);\n\n    let split_keys: &[&[u8]] = &[b\"k2\", b\"k4\", b\"k6\", b\"k8\"];\n\n    for k in split_keys {\n        let region = cluster.get_region(k);\n        cluster.must_split(&region, k);\n    }\n\n    check_data(&mut cluster, &storages, &test_data, 50, true);\n    check_data(&mut cluster, &storages, &test_data2, 150, true);\n    check_data(&mut cluster, &storages, &test_data3, 250, true);\n\n    pd_client.set_gc_safe_point(150);\n\n    for _ in 0..count {\n        finish_signal_rx.recv().unwrap();\n    }\n\n    check_data(&mut cluster, &storages, &test_data, 50, false);\n    check_data(&mut cluster, &storages, &test_data2, 150, true);\n    check_data(&mut cluster, &storages, &test_data3, 250, true);\n\n    // No more signals.\n    finish_signal_rx\n        .recv_timeout(Duration::from_millis(300))\n        .unwrap_err();\n}"}
{"test_id": "hyperium-h2/hyperium-h2-da38b1c/tests/h2-tests/tests/server.rs::push_request", "code": "fn method(s: &str) -> Header<Option<HeaderName>> {\n        Header::Method(Method::from_bytes(s.as_bytes()).unwrap())\n    }", "test": "async fn push_request() {\n    h2_support::trace_init!();\n    let (io, mut client) = mock::new();\n\n    let client = async move {\n        client\n            .assert_server_handshake_with_settings(frames::settings().max_concurrent_streams(100))\n            .await;\n        client\n            .send_frame(\n                frames::headers(1)\n                    .request(\"GET\", \"https://example.com/\")\n                    .eos(),\n            )\n            .await;\n        client\n            .recv_frame(\n                frames::push_promise(1, 2).request(\"GET\", \"https://http2.akamai.com/style.css\"),\n            )\n            .await;\n        client\n            .recv_frame(frames::headers(2).response(200).eos())\n            .await;\n        client\n            .recv_frame(\n                frames::push_promise(1, 4).request(\"GET\", \"https://http2.akamai.com/style2.css\"),\n            )\n            .await;\n        client\n            .recv_frame(frames::headers(4).response(200).eos())\n            .await;\n        client\n            .recv_frame(frames::headers(1).response(200).eos())\n            .await;\n    };\n\n    let srv = async move {\n        let mut srv = server::handshake(io).await.expect(\"handshake\");\n        let (req, mut stream) = srv.next().await.unwrap().unwrap();\n\n        assert_eq!(req.method(), &http::Method::GET);\n\n        // Promise stream 2\n        let mut pushed_s2 = {\n            let req = http::Request::builder()\n                .method(\"GET\")\n                .uri(\"https://http2.akamai.com/style.css\")\n                .body(())\n                .unwrap();\n            stream.push_request(req).unwrap()\n        };\n\n        // Promise stream 4 and push response headers\n        {\n            let req = http::Request::builder()\n                .method(\"GET\")\n                .uri(\"https://http2.akamai.com/style2.css\")\n                .body(())\n                .unwrap();\n            let rsp = http::Response::builder().status(200).body(()).unwrap();\n            stream\n                .push_request(req)\n                .unwrap()\n                .send_response(rsp, true)\n                .unwrap();\n        }\n\n        // Push response to stream 2\n        {\n            let rsp = http::Response::builder().status(200).body(()).unwrap();\n            pushed_s2.send_response(rsp, true).unwrap();\n        }\n\n        // Send response for stream 1\n        let rsp = http::Response::builder().status(200).body(()).unwrap();\n        stream.send_response(rsp, true).unwrap();\n\n        assert!(srv.next().await.is_none());\n    };\n\n    join(client, srv).await;\n}"}
{"test_id": "mitsuhiko-minijinja/mitsuhiko-minijinja-5f2c1e8/minijinja/tests/test_value.rs::test_rest_args", "code": "pub fn apply_filter(&self, filter: &str, args: &[Value]) -> Result<Value, Error> {\n        match self.env.get_filter(filter) {\n            Some(filter) => filter.apply_to(self, args),\n            None => Err(Error::from(ErrorKind::UnknownFilter)),\n        }\n    }", "test": "fn test_rest_args() {\n    fn sum(val: u32, rest: Rest<u32>) -> u32 {\n        rest.iter().fold(val, |a, b| a + b)\n    }\n\n    let mut env = Environment::new();\n    env.add_filter(\"sum\", sum);\n    assert_eq!(\n        env.empty_state()\n            .apply_filter(\"sum\", args!(1, 2, 3, 4))\n            .unwrap(),\n        Value::from(1 + 2 + 3 + 4)\n    );\n}"}
{"test_id": "cberner-redb/cberner-redb-267b473/tests/basic_tests.rs::drain", "code": "fn abort() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(STR_TABLE).unwrap();\n        table.insert(\"hello\", \"aborted\").unwrap();\n        assert_eq!(\"aborted\", table.get(\"hello\").unwrap().unwrap().value());\n    }\n    write_txn.abort().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(STR_TABLE);\n    assert!(table.is_err());\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(STR_TABLE).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(STR_TABLE).unwrap();\n    assert_eq!(\"world\", table.get(\"hello\").unwrap().unwrap().value());\n    assert_eq!(table.len().unwrap(), 1);\n}", "test": "fn drain() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(U64_TABLE).unwrap();\n        for i in 0..10 {\n            table.insert(&i, &i).unwrap();\n        }\n        // Test draining uncommitted data\n        drop(table.drain(0..10).unwrap());\n        for i in 0..10 {\n            table.insert(&i, &i).unwrap();\n        }\n    }\n    write_txn.commit().unwrap();\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(U64_TABLE).unwrap();\n        assert_eq!(table.len().unwrap(), 10);\n        for (i, item) in table.drain(0..5).unwrap().enumerate() {\n            let (k, v) = item.unwrap();\n            assert_eq!(i as u64, k.value());\n            assert_eq!(i as u64, v.value());\n        }\n        assert_eq!(table.len().unwrap(), 5);\n        let mut i = 5u64;\n        for item in table.range(0..10).unwrap() {\n            let (k, v) = item.unwrap();\n            assert_eq!(i, k.value());\n            assert_eq!(i, v.value());\n            i += 1;\n        }\n    }\n    write_txn.abort().unwrap();\n\n    // Check that dropping the iter early works too\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(U64_TABLE).unwrap();\n        assert_eq!(table.len().unwrap(), 10);\n        drop(table.drain(0..5).unwrap());\n        assert_eq!(table.len().unwrap(), 5);\n    }\n    write_txn.abort().unwrap();\n}"}
{"test_id": "astral-sh-ruff/astral-sh-ruff-1a6898a/crates/ruff_cache/tests/cache_key.rs::struct_ignored_fields", "code": "fn finish(&self) -> u64 {\n        self.inner.finish()\n    }", "test": "fn struct_ignored_fields() {\n    #[derive(CacheKey)]\n    struct NamedFieldsStruct {\n        a: String,\n        #[cache_key(ignore)]\n        #[allow(unused)]\n        b: String,\n    }\n\n    impl Hash for NamedFieldsStruct {\n        fn hash<H: Hasher>(&self, state: &mut H) {\n            self.a.hash(state);\n        }\n    }\n\n    let mut key = CacheKeyHasher::new();\n\n    let named_fields = NamedFieldsStruct {\n        a: \"Hello\".into(),\n        b: \"World\".into(),\n    };\n\n    named_fields.cache_key(&mut key);\n\n    let mut hash = CacheKeyHasher::new();\n    named_fields.hash(&mut hash);\n\n    assert_eq!(hash.finish(), key.finish());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_csplit.rs::test_up_to_match_negative_offset_repeat_twice", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_up_to_match_negative_offset_repeat_twice() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"/9$/-3\", \"{2}\"])\n        .succeeds()\n        .stdout_only(\"10\\n26\\n30\\n75\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"there should be splits created\")\n        .count();\n    assert_eq!(count, 4);\n    assert_eq!(at.read(\"xx00\"), generate(1, 6));\n    assert_eq!(at.read(\"xx01\"), generate(6, 16));\n    assert_eq!(at.read(\"xx02\"), generate(16, 26));\n    assert_eq!(at.read(\"xx03\"), generate(26, 51));\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/cli_tests.rs::table_growth_failure", "code": "fn success() -> Self {\n        Self::Success\n    }", "test": "fn table_growth_failure() -> Result<()> {\n    let output = get_wasmtime_command()?\n        .args(&[\n            \"run\",\n            \"-Wtrap-on-grow-failure\",\n            \"tests/all/cli_tests/table-grow-failure.wat\",\n        ])\n        .output()?;\n    assert!(!output.status.success());\n    let stderr = String::from_utf8_lossy(&output.stderr);\n    assert!(\n        stderr.contains(\"forcing trap when growing table\"),\n        \"bad stderr: {stderr}\"\n    );\n    Ok(())\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_rm.rs::test_rm_empty_directory", "code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_empty_directory() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_rm_empty_directory\";\n\n    at.mkdir(dir);\n\n    ucmd.arg(\"-d\").arg(dir).succeeds().no_stderr();\n\n    assert!(!at.dir_exists(dir));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_kill.rs::test_kill_with_signal_prefixed_name_new_form", "code": "fn wait_for_signal(&mut self) -> Option<i32> {\n        let sig = self.child.wait().expect(\"cannot wait on target\").signal();\n        self.killed = true;\n        sig\n    }", "test": "fn test_kill_with_signal_prefixed_name_new_form() {\n    let mut target = Target::new();\n    new_ucmd!()\n        .arg(\"-s\")\n        .arg(\"SIGKILL\")\n        .arg(format!(\"{}\", target.pid()))\n        .succeeds();\n    assert_eq!(target.wait_for_signal(), Some(libc::SIGKILL));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_split.rs::test_line_bytes", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_line_bytes() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-C\", \"8\", \"letters.txt\"]).succeeds();\n    assert_eq!(at.read(\"xaa\"), \"aaaaaaaa\");\n    assert_eq!(at.read(\"xab\"), \"a\\nbbbb\\n\");\n    assert_eq!(at.read(\"xac\"), \"cccc\\ndd\\n\");\n    assert_eq!(at.read(\"xad\"), \"ee\\n\");\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/cli_tests.rs::name_same_as_builtin_command", "code": "fn success() -> Self {\n        Self::Success\n    }", "test": "fn name_same_as_builtin_command() -> Result<()> {\n    // a bare subcommand shouldn't run successfully\n    let output = get_wasmtime_command()?\n        .current_dir(\"tests/all/cli_tests\")\n        .arg(\"run\")\n        .output()?;\n    assert!(!output.status.success());\n\n    // a `--` prefix should let everything else get interpreted as a wasm\n    // module and arguments, even if the module has a name like `run`\n    let output = get_wasmtime_command()?\n        .current_dir(\"tests/all/cli_tests\")\n        .arg(\"--\")\n        .arg(\"run\")\n        .output()?;\n    assert!(output.status.success(), \"expected success got {output:#?}\");\n\n    // Passing options before the subcommand should work and doesn't require\n    // `--` to disambiguate\n    let output = get_wasmtime_command()?\n        .current_dir(\"tests/all/cli_tests\")\n        .arg(\"-Ccache=n\")\n        .arg(\"run\")\n        .output()?;\n    assert!(output.status.success(), \"expected success got {output:#?}\");\n    Ok(())\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_test.rs::test_solo_empty_parenthetical_is_error", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_solo_empty_parenthetical_is_error() {\n    new_ucmd!().args(&[\"(\", \")\"]).run().code_is(2);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_chmod.rs::test_permission_denied", "code": "pub fn stderr_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stderr_str(), msg.as_ref());\n        self\n    }", "test": "fn test_permission_denied() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    at.mkdir(\"d/\");\n    at.mkdir(\"d/no-x\");\n    at.mkdir(\"d/no-x/y\");\n\n    scene.ucmd().arg(\"u=rw\").arg(\"d/no-x\").succeeds();\n\n    scene\n        .ucmd()\n        .arg(\"-R\")\n        .arg(\"o=r\")\n        .arg(\"d\")\n        .fails()\n        .stderr_is(\"chmod: 'd/no-x/y': Permission denied\\n\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_joint_consensus.rs::test_invalid_confchange_request", "code": "pub fn get_id(&self) -> DownstreamId {\n        self.id\n    }", "test": "fn test_invalid_confchange_request() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.cfg.raft_store.allow_remove_leader = false;\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n    let region_id = cluster.run_conf_change();\n    let region = cluster.get_region(b\"\");\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    pd_client.must_add_peer(region_id, new_peer(2, 2));\n    pd_client.must_add_peer(region_id, new_learner_peer(3, 3));\n    must_get_equal(&cluster.get_engine(2), b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n\n    // Can not remove voter directly in joint confchange request\n    let resp = call_conf_change_v2(\n        &mut cluster,\n        region_id,\n        vec![\n            change_peer(ConfChangeType::RemoveNode, new_peer(2, 2)),\n            change_peer(ConfChangeType::AddLearnerNode, new_learner_peer(4, 4)),\n        ],\n    )\n    .unwrap();\n    must_contains_error(&resp, \"can not remove voter\");\n\n    // Can not have multiple commands for the same peer\n    let resp = call_conf_change_v2(\n        &mut cluster,\n        region_id,\n        vec![\n            change_peer(ConfChangeType::AddLearnerNode, new_learner_peer(2, 2)),\n            change_peer(ConfChangeType::RemoveNode, new_learner_peer(2, 2)),\n        ],\n    )\n    .unwrap();\n    must_contains_error(&resp, \"multiple commands for the same peer\");\n\n    // Can not have multiple changes that only effect learner\n    let resp = call_conf_change_v2(\n        &mut cluster,\n        region_id,\n        vec![\n            change_peer(ConfChangeType::RemoveNode, new_learner_peer(3, 3)),\n            change_peer(ConfChangeType::AddLearnerNode, new_learner_peer(4, 4)),\n        ],\n    )\n    .unwrap();\n    must_contains_error(&resp, \"multiple changes that only effect learner\");\n\n    // Can not demote leader with simple confchange\n    let resp = call_conf_change_v2(\n        &mut cluster,\n        region_id,\n        vec![change_peer(\n            ConfChangeType::AddLearnerNode,\n            new_learner_peer(1, 1),\n        )],\n    )\n    .unwrap();\n    must_contains_error(&resp, \"ignore remove leader or demote leader\");\n\n    let resp = call_conf_change(\n        &mut cluster,\n        region_id,\n        ConfChangeType::AddLearnerNode,\n        new_learner_peer(1, 1),\n    )\n    .unwrap();\n    must_contains_error(&resp, \"ignore remove leader or demote leader\");\n\n    // Can not leave a non-joint config\n    let resp = leave_joint(&mut cluster, region_id).unwrap();\n    must_contains_error(&resp, \"leave a non-joint config\");\n\n    // Split region\n    cluster.must_split(&region, b\"k3\");\n    let left = pd_client.get_region(b\"k1\").unwrap();\n    let right = pd_client.get_region(b\"k5\").unwrap();\n    assert_eq!(region_id, right.get_id());\n    // Enter joint\n    pd_client.must_joint_confchange(\n        region_id,\n        vec![\n            (ConfChangeType::AddLearnerNode, new_learner_peer(2, 2)),\n            (ConfChangeType::AddNode, new_peer(3, 3)),\n        ],\n    );\n    assert!(pd_client.is_in_joint(region_id));\n\n    // Can not merge region while in jonit state\n    let resp = cluster.try_merge(right.get_id(), left.get_id());\n    must_contains_error(&resp, \"in joint state, can not propose merge command\");\n\n    // Can not leave joint if which will demote leader\n    cluster.must_transfer_leader(region_id, new_peer(2, 2));\n    let resp = leave_joint(&mut cluster, region_id).unwrap();\n    must_contains_error(&resp, \"ignore leave joint command that demoting leader\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_ln.rs::test_symlink_verbose", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_symlink_verbose() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let file_a = \"test_symlink_verbose_file_a\";\n    let file_b = \"test_symlink_verbose_file_b\";\n\n    at.touch(file_a);\n\n    scene\n        .ucmd()\n        .args(&[\"-s\", \"-v\", file_a, file_b])\n        .succeeds()\n        .stdout_only(format!(\"'{file_b}' -> '{file_a}'\\n\"));\n\n    at.touch(file_b);\n\n    scene\n        .ucmd()\n        .args(&[\"-s\", \"-v\", \"-b\", file_a, file_b])\n        .succeeds()\n        .stdout_only(format!(\"'{file_b}' -> '{file_a}' (backup: '{file_b}~')\\n\"));\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/pooling_allocator.rs::multi_memory_with_imported_memories", "code": "pub fn data(&self) -> &[u8] {\n        // N.B.: we emit every section into the .text section as far as\n        // the `CodeSink` is concerned; we do not bother to segregate\n        // the contents into the actual program text, the jumptable and the\n        // rodata (constant pool). This allows us to generate code assuming\n        // that these will not be relocated relative to each other, and avoids\n        // having to designate each section as belonging in one of the three\n        // fixed categories defined by `CodeSink`. If this becomes a problem\n        // later (e.g. because of memory permissions or similar), we can\n        // add this designation and segregate the output; take care, however,\n        // to add the appropriate relocations in this case.\n\n        &self.data[..]\n    }", "test": "fn multi_memory_with_imported_memories() -> Result<()> {\n    // This test checks that the base address for the defined memory is correct for the instance\n    // despite the presence of an imported memory.\n\n    let mut pool = crate::small_pool_config();\n    pool.total_memories(2).max_memories_per_module(2);\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling(pool));\n    config.wasm_multi_memory(true);\n\n    let engine = Engine::new(&config)?;\n    let module = Module::new(\n        &engine,\n        r#\"(module (import \"\" \"m1\" (memory 0)) (memory (export \"m2\") 1))\"#,\n    )?;\n\n    let mut store = Store::new(&engine, ());\n\n    let m1 = Memory::new(&mut store, MemoryType::new(0, None))?;\n    let instance = Instance::new(&mut store, &module, &[m1.into()])?;\n\n    let m2 = instance.get_memory(&mut store, \"m2\").unwrap();\n\n    m2.data_mut(&mut store)[0] = 0x42;\n    assert_eq!(m2.data(&store)[0], 0x42);\n\n    Ok(())\n}"}
{"test_id": "quinn-rs-quinn/quinn-rs-quinn-83e4f46/quinn-proto/src/tests/mod.rs::server_alpn_unset", "code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn server_alpn_unset() {\n    let _guard = subscribe();\n    let mut pair = Pair::new(Arc::new(EndpointConfig::default()), server_config());\n\n    let mut client_crypto = client_crypto();\n    client_crypto.alpn_protocols = vec![\"foo\".into()];\n    let client_config = ClientConfig::new(Arc::new(client_crypto));\n\n    let client_ch = pair.begin_connect(client_config);\n    pair.drive();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::ConnectionLost { reason: ConnectionError::ConnectionClosed(err) }) if err.error_code == TransportErrorCode::crypto(0x78)\n    );\n}"}
{"test_id": "dtolnay-syn/dtolnay-syn-b1a038c/tests/test_attribute.rs::test_meta_item_list_lit", "code": "fn test(input: &str) -> Meta {\n    let attrs = Attribute::parse_outer.parse_str(input).unwrap();\n\n    assert_eq!(attrs.len(), 1);\n    let attr = attrs.into_iter().next().unwrap();\n\n    attr.meta\n}", "test": "fn test_meta_item_list_lit() {\n    let meta = test(\"#[foo(5)]\");\n\n    snapshot!(meta, @r###\"\n    Meta::List {\n        path: Path {\n            segments: [\n                PathSegment {\n                    ident: \"foo\",\n                },\n            ],\n        },\n        delimiter: MacroDelimiter::Paren,\n        tokens: TokenStream(`5`),\n    }\n    \"###);\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/control_flow/mod.rs::test_invalid_break", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn test_invalid_break() {\n    run_test_actions([TestAction::assert_native_error(\n        \"break;\",\n        JsNativeErrorKind::Syntax,\n        \"illegal break statement at line 1, col 1\",\n    )]);\n}"}
{"test_id": "raphlinus-pulldown-cmark/raphlinus-pulldown-cmark-3da63d5/tests/suite/table.rs::table_test_1", "code": "pub fn test_markdown_html(input: &str, output: &str, smart_punct: bool) {\n    let mut s = String::new();\n\n    let mut opts = Options::empty();\n    opts.insert(Options::ENABLE_TABLES);\n    opts.insert(Options::ENABLE_FOOTNOTES);\n    opts.insert(Options::ENABLE_STRIKETHROUGH);\n    opts.insert(Options::ENABLE_TASKLISTS);\n    if smart_punct {\n        opts.insert(Options::ENABLE_SMART_PUNCTUATION);\n    }\n    opts.insert(Options::ENABLE_HEADING_ATTRIBUTES);\n\n    let p = Parser::new_ext(input, opts);\n    pulldown_cmark::html::push_html(&mut s, p);\n\n    assert_eq!(normalize_html(output), normalize_html(&s));\n}", "test": "fn table_test_1() {\n    let original = r##\"Test header\n-----------\n\"##;\n    let expected = r##\"<h2>Test header</h2>\n\"##;\n\n    test_markdown_html(original, expected, false);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_chmod.rs::test_gnu_special_options", "code": "pub fn fails(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.failure();\n        cmd_result\n    }", "test": "fn test_gnu_special_options() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    at.touch(\"file\");\n    scene.ucmd().arg(\"--\").arg(\"--\").arg(\"file\").succeeds();\n    scene.ucmd().arg(\"--\").arg(\"--\").fails();\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/relocs.rs::mixed", "code": "fn test_many_call_module(mut store: Store<()>) -> Result<()> {\n    const N: i32 = 200;\n\n    let mut wat = String::new();\n    wat.push_str(\"(module\\n\");\n    wat.push_str(\"(func $first (result i32) (i32.const 1))\\n\");\n    for i in 0..N {\n        wat.push_str(&format!(\"(func (export \\\"{}\\\") (result i32 i32)\\n\", i));\n        wat.push_str(\"call $first\\n\");\n        wat.push_str(&format!(\"i32.const {}\\n\", i));\n        wat.push_str(\"i32.add\\n\");\n        wat.push_str(\"call $last\\n\");\n        wat.push_str(&format!(\"i32.const {}\\n\", i));\n        wat.push_str(\"i32.add)\\n\");\n    }\n    wat.push_str(\"(func $last (result i32) (i32.const 2))\\n\");\n    wat.push_str(\")\\n\");\n\n    let module = Module::new(store.engine(), &wat)?;\n\n    let instance = Instance::new(&mut store, &module, &[])?;\n\n    for i in 0..N {\n        let name = i.to_string();\n        let func = instance.get_typed_func::<(), (i32, i32)>(&mut store, &name)?;\n        let (a, b) = func.call(&mut store, ())?;\n        assert_eq!(a, i + 1);\n        assert_eq!(b, i + 2);\n    }\n    Ok(())\n}", "test": "fn mixed() -> Result<()> {\n    test_many_call_module(store_with_padding(MB)?)\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/externals.rs::get_set_funcref_globals_via_api", "code": "pub fn get(&self, mut store: impl AsContextMut) -> Val {\n        unsafe {\n            let store = store.as_context_mut();\n            let definition = &*store[self.0].definition;\n            match self.ty(&store).content() {\n                ValType::I32 => Val::from(*definition.as_i32()),\n                ValType::I64 => Val::from(*definition.as_i64()),\n                ValType::F32 => Val::F32(*definition.as_u32()),\n                ValType::F64 => Val::F64(*definition.as_u64()),\n                ValType::ExternRef => Val::ExternRef(\n                    definition\n                        .as_externref()\n                        .clone()\n                        .map(|inner| ExternRef { inner }),\n                ),\n                ValType::FuncRef => {\n                    Val::FuncRef(Func::from_raw(store, definition.as_func_ref().cast()))\n                }\n                ValType::V128 => Val::V128((*definition.as_u128()).into()),\n            }\n        }\n    }", "test": "fn get_set_funcref_globals_via_api() -> anyhow::Result<()> {\n    let mut cfg = Config::new();\n    cfg.wasm_reference_types(true);\n    let engine = Engine::new(&cfg)?;\n    let mut store = Store::new(&engine, ());\n\n    let f = Func::wrap(&mut store, || {});\n\n    // Initialize with a null funcref.\n\n    let global = Global::new(\n        &mut store,\n        GlobalType::new(ValType::FuncRef, Mutability::Var),\n        Val::FuncRef(None),\n    )?;\n    assert!(global.get(&mut store).unwrap_funcref().is_none());\n\n    global.set(&mut store, Val::FuncRef(Some(f.clone())))?;\n    let f2 = global.get(&mut store).unwrap_funcref().cloned().unwrap();\n    assert_eq!(f.ty(&store), f2.ty(&store));\n\n    // Initialize with a non-null funcref.\n\n    let global = Global::new(\n        &mut store,\n        GlobalType::new(ValType::FuncRef, Mutability::Var),\n        Val::FuncRef(Some(f.clone())),\n    )?;\n    let f2 = global.get(&mut store).unwrap_funcref().cloned().unwrap();\n    assert_eq!(f.ty(&store), f2.ty(&store));\n\n    Ok(())\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_seq.rs::test_width_negative_zero_decimal_notation", "code": "pub fn no_stderr(&self) -> &Self {\n        assert!(\n            self.stderr.is_empty(),\n            \"Expected stderr to be empty, but it's:\\n{}\",\n            self.stderr_str()\n        );\n        self\n    }", "test": "fn test_width_negative_zero_decimal_notation() {\n    new_ucmd!()\n        .args(&[\"-w\", \"-0.0\", \"1\"])\n        .succeeds()\n        .stdout_is(\"-0.0\\n01.0\\n\")\n        .no_stderr();\n    new_ucmd!()\n        .args(&[\"-w\", \"-0.0\", \"1.0\"])\n        .succeeds()\n        .stdout_is(\"-0.0\\n01.0\\n\")\n        .no_stderr();\n    new_ucmd!()\n        .args(&[\"-w\", \"-0.0\", \"1\", \"2\"])\n        .succeeds()\n        .stdout_is(\"-0.0\\n01.0\\n02.0\\n\")\n        .no_stderr();\n    new_ucmd!()\n        .args(&[\"-w\", \"-0.0\", \"1\", \"2.0\"])\n        .succeeds()\n        .stdout_is(\"-0.0\\n01.0\\n02.0\\n\")\n        .no_stderr();\n    new_ucmd!()\n        .args(&[\"-w\", \"-0.0\", \"1.0\", \"2\"])\n        .succeeds()\n        .stdout_is(\"-0.0\\n01.0\\n02.0\\n\")\n        .no_stderr();\n    new_ucmd!()\n        .args(&[\"-w\", \"-0.0\", \"1.0\", \"2.0\"])\n        .succeeds()\n        .stdout_is(\"-0.0\\n01.0\\n02.0\\n\")\n        .no_stderr();\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/component_model/resources.rs::drop_on_owned_resource", "code": "pub fn owned(&self) -> bool {\n        match self.state.load(Relaxed) {\n            BORROW => false,\n            _ => true,\n        }\n    }", "test": "fn drop_on_owned_resource() -> Result<()> {\n    let engine = super::engine();\n    let c = Component::new(\n        &engine,\n        r#\"\n            (component\n                (import \"t\" (type $t (sub resource)))\n                (import \"[constructor]t\" (func $ctor (result (own $t))))\n                (import \"[method]t.foo\" (func $foo (param \"self\" (borrow $t)) (result (list u8))))\n\n                (core func $ctor (canon lower (func $ctor)))\n                (core func $drop (canon resource.drop $t))\n\n                (core module $m1\n                    (import \"\" \"drop\" (func $drop (param i32)))\n                    (memory (export \"memory\") 1)\n                    (global $to-drop (export \"to-drop\") (mut i32) (i32.const 0))\n                    (func (export \"realloc\") (param i32 i32 i32 i32) (result i32)\n                        (call $drop (global.get $to-drop))\n                        unreachable)\n                )\n                (core instance $i1 (instantiate $m1\n                    (with \"\" (instance\n                        (export \"drop\" (func $drop))\n                    ))\n                ))\n\n                (core func $foo (canon lower (func $foo)\n                    (memory $i1 \"memory\")\n                    (realloc (func $i1 \"realloc\"))))\n\n                (core module $m2\n                    (import \"\" \"ctor\" (func $ctor (result i32)))\n                    (import \"\" \"foo\" (func $foo (param i32 i32)))\n                    (import \"i1\" \"to-drop\" (global $to-drop (mut i32)))\n\n                    (func (export \"f\")\n                        (local $r i32)\n                        (local.set $r (call $ctor))\n                        (global.set $to-drop (local.get $r))\n                        (call $foo\n                            (local.get $r)\n                            (i32.const 200))\n                    )\n                )\n                (core instance $i2 (instantiate $m2\n                    (with \"\" (instance\n                        (export \"ctor\" (func $ctor))\n                        (export \"foo\" (func $foo))\n                    ))\n                    (with \"i1\" (instance $i1))\n                ))\n                (func (export \"f\") (canon lift (core func $i2 \"f\")))\n            )\n        \"#,\n    )?;\n\n    struct MyType;\n\n    let mut store = Store::new(&engine, ());\n    let mut linker = Linker::new(&engine);\n    linker.root().resource::<MyType>(\"t\", |_, _| Ok(()))?;\n    linker.root().func_wrap(\"[constructor]t\", |_cx, ()| {\n        Ok((Resource::<MyType>::new_own(300),))\n    })?;\n    linker\n        .root()\n        .func_wrap(\"[method]t.foo\", |_cx, (r,): (Resource<MyType>,)| {\n            assert!(!r.owned());\n            Ok((vec![2u8],))\n        })?;\n    let i = linker.instantiate(&mut store, &c)?;\n    let f = i.get_typed_func::<(), ()>(&mut store, \"f\")?;\n\n    let err = f.call(&mut store, ()).unwrap_err();\n    assert!(\n        format!(\"{err:?}\").contains(\"cannot remove owned resource while borrowed\"),\n        \"bad error: {err:?}\"\n    );\n\n    Ok(())\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_wc.rs::test_utf8_line_length_chars_words", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_utf8_line_length_chars_words() {\n    new_ucmd!()\n        .arg(\"-Lmw\")\n        .pipe_in_fixture(\"UTF_8_weirdchars.txt\")\n        .run()\n        .stdout_is(\"     87     442      48\\n\");\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/client_future_tests.rs::test_timeout_query_nonet", "code": "fn test_timeout_query(mut client: AsyncClient, io_loop: Runtime) {\n    let name = Name::from_str(\"www.example.com\").unwrap();\n\n    let err = io_loop\n        .block_on(client.query(name.clone(), DNSClass::IN, RecordType::A))\n        .unwrap_err();\n\n    println!(\"got error: {err:?}\");\n    if let ClientErrorKind::Timeout = err.kind() {\n    } else {\n        panic!(\"expected timeout error\");\n    }\n\n    io_loop\n        .block_on(client.query(name, DNSClass::IN, RecordType::AAAA))\n        .unwrap_err();\n\n    // test that we don't have any thing funky with registering new timeouts, etc...\n    //   it would be cool if we could maintain a different error here, but shutdown is probably ok.\n    //\n    // match err.kind() {\n    //     &ClientErrorKind::Timeout => (),\n    //     e @ _ => assert!(false, format!(\"something else: {}\", e)),\n    // }\n}", "test": "fn test_timeout_query_nonet() {\n    //env_logger::try_init().ok();\n    let io_loop = Runtime::new().expect(\"failed to create Tokio Runtime\");\n    let (stream, sender) = NeverReturnsClientStream::new();\n    let client =\n        AsyncClient::with_timeout(stream, sender, std::time::Duration::from_millis(1), None);\n    let (client, bg) = io_loop.block_on(client).expect(\"client failed to connect\");\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    test_timeout_query(client, io_loop);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_yes.rs::test_simple", "code": "pub fn run(&mut self) -> CmdResult {\n        self.run_no_wait().wait().unwrap()\n    }", "test": "fn test_simple() {\n    run(NO_ARGS, b\"y\\ny\\ny\\ny\\n\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_ln.rs::test_symlink_relative_path", "code": "pub fn is_symlink(&self, path: &str) -> bool {\n        log_info(\"is_symlink\", self.plus_as_string(path));\n        match fs::symlink_metadata(self.plus(path)) {\n            Ok(m) => m.file_type().is_symlink(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_relative_path() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_symlink_existing_dir\";\n    let file_a = \"test_symlink_relative_a\";\n    let link = \"test_symlink_relative_link\";\n    let multi_dir =\n        \"test_symlink_existing_dir/../test_symlink_existing_dir/../test_symlink_existing_dir/../\";\n    let p = PathBuf::from(multi_dir).join(file_a);\n    at.mkdir(dir);\n\n    // relative symlink\n    // Thanks to -r, all the ../ should be resolved to a single file\n    ucmd.args(&[\"-r\", \"-s\", \"-v\", &p.to_string_lossy(), link])\n        .succeeds()\n        .stdout_only(format!(\"'{link}' -> '{file_a}'\\n\"));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file_a);\n\n    // Run the same command without -r to verify that we keep the full\n    // crazy path\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-s\", \"-v\", &p.to_string_lossy(), link])\n        .succeeds()\n        .stdout_only(format!(\"'{}' -> '{}'\\n\", link, &p.to_string_lossy()));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), p.to_string_lossy());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_install.rs::test_install_ancestors_directories", "code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_ancestors_directories() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let ancestor1 = \"ancestor1\";\n    let ancestor2 = \"ancestor1/ancestor2\";\n    let target_dir = \"ancestor1/ancestor2/target_dir\";\n    let directories_arg = \"-d\";\n\n    ucmd.args(&[directories_arg, target_dir])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.dir_exists(ancestor1));\n    assert!(at.dir_exists(ancestor2));\n    assert!(at.dir_exists(target_dir));\n}"}
{"test_id": "mitsuhiko-minijinja/mitsuhiko-minijinja-5f2c1e8/minijinja/tests/test_environment.rs::test_expression_lifetimes", "code": "pub fn eval<S: Serialize>(&self, ctx: S) -> Result<Value, Error> {\n        // reduce total amount of code faling under mono morphization into\n        // this function, and share the rest in _eval.\n        self._eval(Value::from_serializable(&ctx))\n    }", "test": "fn test_expression_lifetimes() {\n    let mut env = Environment::new();\n    let s = String::new();\n    env.add_template(\"test\", &s).unwrap();\n    {\n        let x = String::from(\"1 + 1\");\n        let expr = env.compile_expression(&x).unwrap();\n        assert_eq!(expr.eval(()).unwrap().to_string(), \"2\");\n    }\n}"}
{"test_id": "paritytech-wasmi/paritytech-wasmi-d66f271/crates/wasmi/tests/e2e/v1/func.rs::static_many_params_many_results_works", "code": "pub fn call(&self, mut ctx: impl AsContextMut, params: Params) -> Result<Results, Trap> {\n        // Note: Cloning an [`Engine`] is intentionally a cheap operation.\n        ctx.as_context().store.engine().clone().execute_func(\n            ctx.as_context_mut(),\n            &self.func,\n            params,\n            <CallResultsTuple<Results>>::default(),\n        )\n    }", "test": "fn static_many_params_many_results_works() {\n    let (mut store, func) = setup_many_params_many_results();\n    let typed_func = func.typed::<I32x16, I32x16>(&mut store).unwrap();\n    let inputs = ascending_tuple();\n    let result = typed_func.call(&mut store, inputs).unwrap();\n    assert_eq_tuple!(result, inputs; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_arg_interactive", "code": "pub fn stderr_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stderr_str(), msg.as_ref());\n        self\n    }", "test": "fn test_cp_arg_interactive() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    at.touch(\"a\");\n    at.touch(\"b\");\n    ucmd.args(&[\"-i\", \"a\", \"b\"])\n        .pipe_in(\"N\\n\")\n        .fails()\n        .no_stdout()\n        .stderr_is(\"cp: overwrite 'b'? \");\n}"}
{"test_id": "mitsuhiko-minijinja/mitsuhiko-minijinja-5f2c1e8/minijinja/tests/test_compiler.rs::test_if_branches", "code": "pub fn end_if(&mut self) {\n        self.end_condition(self.next_instruction());\n    }", "test": "fn test_if_branches() {\n    let mut c = CodeGenerator::new(\"<unknown>\", \"\");\n    c.add(Instruction::Lookup(\"false\"));\n    c.start_if();\n    c.add(Instruction::EmitRaw(\"nope1\"));\n    c.start_else();\n    c.add(Instruction::Lookup(\"nil\"));\n    c.start_if();\n    c.add(Instruction::EmitRaw(\"nope1\"));\n    c.start_else();\n    c.add(Instruction::EmitRaw(\"yes\"));\n    c.end_if();\n    c.end_if();\n\n    insta::assert_debug_snapshot!(&c.finish());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_chroot.rs::test_invalid_arg", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_invalid_arg() {\n    new_ucmd!().arg(\"--definitely-invalid\").fails().code_is(125);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cat.rs::test_stdin_nonprinting_and_endofline", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_stdin_nonprinting_and_endofline() {\n    new_ucmd!()\n        .args(&[\"-e\"])\n        .pipe_in(\"\\t\\0\\n\")\n        .succeeds()\n        .stdout_only(\"\\t^@$\\n\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_chcon.rs::reference_errors", "code": "pub fn fails(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.failure();\n        cmd_result\n    }", "test": "fn reference_errors() {\n    for args in [\n        &[\"--verbose\", \"--reference\"] as &[&str],\n        &[\"--verbose\", \"--reference=/dev/null\"],\n        &[\"--verbose\", \"--reference=/inexistent\", \"/dev/null\"],\n    ] {\n        new_ucmd!().args(args).fails();\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_fold.rs::test_fold_after_tab", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_fold_after_tab() {\n    new_ucmd!()\n        .arg(\"-w10\")\n        .pipe_in(\"a\\tbbb\\n\")\n        .succeeds()\n        .stdout_is(\"a\\tbb\\nb\\n\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_fold.rs::test_carriage_return_is_not_word_boundary", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_carriage_return_is_not_word_boundary() {\n    new_ucmd!()\n        .args(&[\"-w6\", \"-s\"])\n        .pipe_in(\"fizz\\rbuzz\\rfizzbuzz\") // spell-checker:disable-line\n        .succeeds()\n        .stdout_is(\"fizz\\rbuzz\\rfizzbu\\nzz\"); // spell-checker:disable-line\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_chgrp.rs::test_fail_silently", "code": "fn run(input_string: &[u8], output_string: &[u8]) {\n    println!(\"STDIN='{}'\", String::from_utf8_lossy(input_string));\n    println!(\n        \"STDOUT(expected)='{}'\",\n        String::from_utf8_lossy(output_string)\n    );\n    // now run factor\n    new_ucmd!()\n        .timeout(Duration::from_secs(240))\n        .pipe_in(input_string)\n        .run()\n        .stdout_is(String::from_utf8(output_string.to_owned()).unwrap());\n}", "test": "fn test_fail_silently() {\n    if getegid() != 0 {\n        for opt in [\"-f\", \"--silent\", \"--quiet\", \"--sil\", \"--qui\"] {\n            new_ucmd!()\n                .arg(opt)\n                .arg(\"bin\")\n                .arg(DIR)\n                .run()\n                .fails_silently();\n        }\n    }\n}"}
{"test_id": "ordinals-ord/ordinals-ord-8090538/tests/version.rs::version_flag_prints_version", "code": "pub(crate) fn run_and_extract_stdout(self) -> String {\n    self.run().1\n  }", "test": "fn version_flag_prints_version() {\n  CommandBuilder::new(\"--version\")\n    .stdout_regex(\"ord .*\\n\")\n    .run_and_extract_stdout();\n}"}
{"test_id": "weggli-rs-weggli/weggli-rs-weggli-ad8d424/tests/query.rs::all_subqueries_must_match", "code": "fn parse_and_match(needle: &str, source: &str) -> usize {\n    parse_and_match_helper(needle, source, false).len()\n}", "test": "fn all_subqueries_must_match() {\n    let source = r\"\n        static int ms_scsi_read(struct us_data *us, struct scsi_cmnd *srb)\n        {\n            u16 blen = ((cdb[7] << 8) & 0xff00) | ((cdb[8] << 0) & 0x00ff);\n            u32 blenByte = blen * 0x200;\n\n            if (bn > info->bl_num)\n                return USB_STOR_TRANSPORT_ERROR;\n\n            if (info->MS_Status.IsMSPro) {\n            } else {\n                void *buf;\n                int offset = 0;\n                u16 phyblk, logblk;\n                u8 PageNum;\n                u16 len;\n                u32 blkno;\n\n                buf = kmalloc(blenByte, GFP_KERNEL);\n            }\n            return result;  }\";\n\n    let needle = \"{u16 $size; $size=_+_; kmalloc($size);}\";\n\n    let matches = parse_and_match(needle, source);\n    assert_eq!(0, matches);\n}"}
{"test_id": "rust-lang-flate2-rs/rust-lang-flate2-rs-649aaae/tests/empty-read.rs::gzip_decoder_empty_read", "code": "fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        // If we don't have any buffered data and we're doing a massive read\n        // (larger than our internal buffer), bypass our internal buffer\n        // entirely.\n        if self.pos == self.cap && buf.len() >= self.buf.len() {\n            return self.inner.read(buf);\n        }\n        let nread = {\n            let mut rem = self.fill_buf()?;\n            rem.read(buf)?\n        };\n        self.consume(nread);\n        Ok(nread)\n    }", "test": "fn gzip_decoder_empty_read() {\n    let original: &[u8] = b\"Lorem ipsum dolor sit amet.\";\n    let mut encoder = flate2::write::GzEncoder::new(Vec::new(), flate2::Compression::default());\n    encoder.write_all(original).unwrap();\n    let encoded: Vec<u8> = encoder.finish().unwrap();\n    let mut decoder = flate2::read::GzDecoder::new(encoded.as_slice());\n    assert_eq!(decoder.read(&mut []).unwrap(), 0);\n    let mut decoded = Vec::new();\n    decoder.read_to_end(&mut decoded).unwrap();\n    assert_eq!(decoded.as_slice(), original);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/storage/test_raftkv.rs::test_invalid_read_index_when_no_leader", "code": "pub fn has_not_leader(&self) -> bool {\n        self.not_leader.is_some()\n    }", "test": "fn test_invalid_read_index_when_no_leader() {\n    // Initialize cluster\n    let mut cluster = new_node_cluster(0, 3);\n    configure_for_lease_read(&mut cluster.cfg, Some(10), Some(6));\n    cluster.cfg.raft_store.raft_heartbeat_ticks = 1;\n    cluster.cfg.raft_store.hibernate_regions = false;\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    // Set region and peers\n    cluster.run();\n    cluster.must_put(b\"k0\", b\"v0\");\n    // Transfer leader to p2\n    let region = cluster.get_region(b\"k0\");\n    let leader = cluster.leader_of_region(region.get_id()).unwrap();\n    let mut follower_peers = region.get_peers().to_vec();\n    follower_peers.retain(|p| p.get_id() != leader.get_id());\n    let follower = follower_peers.pop().unwrap();\n\n    // Delay all raft messages on follower.\n    cluster.sim.wl().add_recv_filter(\n        follower.get_store_id(),\n        Box::new(\n            RegionPacketFilter::new(region.get_id(), follower.get_store_id())\n                .direction(Direction::Recv)\n                .msg_type(MessageType::MsgHeartbeat)\n                .msg_type(MessageType::MsgAppend)\n                .msg_type(MessageType::MsgRequestVoteResponse)\n                .when(Arc::new(AtomicBool::new(true))),\n        ),\n    );\n\n    // wait for election timeout\n    thread::sleep(time::Duration::from_millis(300));\n    // send read index requests to follower\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_read_index_cmd()],\n        true,\n    );\n    request.mut_header().set_peer(follower.clone());\n    let (cb, mut rx) = make_cb(&request);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(follower.get_store_id(), request, cb)\n        .unwrap();\n\n    let resp = rx.recv_timeout(time::Duration::from_millis(500)).unwrap();\n    assert!(\n        resp.get_header().get_error().has_not_leader(),\n        \"{:?}\",\n        resp.get_header()\n    );\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/coprocessor/test_analyze.rs::test_analyze_sampling_reservoir", "code": "fn is_empty(&self) -> bool {\n        self.pending_writes.is_empty() && self.unpacked_size == 0\n    }", "test": "fn test_analyze_sampling_reservoir() {\n    let data = vec![\n        (1, Some(\"name:0\"), 2),\n        (2, Some(\"name:4\"), 3),\n        (4, Some(\"name:3\"), 1),\n        (5, None, 4),\n        (6, Some(\"name:1\"), 1),\n        (7, Some(\"name:1\"), 1),\n        (8, Some(\"name:1\"), 1),\n        (9, Some(\"name:2\"), 1),\n        (10, Some(\"name:2\"), 1),\n    ];\n\n    let product = ProductTable::new();\n    let (_, endpoint, _) = init_data_with_commit(&product, &data, true);\n\n    // Pass the 2nd column as a column group.\n    let req = new_analyze_sampling_req(&product, 1, 5, 0.0);\n    let resp = handle_request(&endpoint, req);\n    assert!(!resp.get_data().is_empty());\n    let mut analyze_resp = AnalyzeColumnsResp::default();\n    analyze_resp.merge_from_bytes(resp.get_data()).unwrap();\n    let collector = analyze_resp.get_row_collector();\n    assert_eq!(collector.get_samples().len(), 5);\n    // The column group is at 4th place and the data should be equal to the 2nd.\n    assert_eq!(collector.get_null_counts(), vec![0, 1, 0, 1]);\n    assert_eq!(collector.get_count(), 9);\n    assert_eq!(collector.get_fm_sketch().len(), 4);\n    assert_eq!(collector.get_total_size(), vec![72, 56, 9, 56]);\n}"}
{"test_id": "dtolnay-ryu/dtolnay-ryu-2fc2d1c/tests/s2d_test.rs::test_overflow", "code": "pub fn s2d(buffer: &[u8]) -> Result<f64, Error> {\n    let len = buffer.len();\n    if len == 0 {\n        return Err(Error::InputTooShort);\n    }\n\n    let mut m10digits = 0;\n    let mut e10digits = 0;\n    let mut dot_index = len;\n    let mut e_index = len;\n    let mut m10 = 0u64;\n    let mut e10 = 0i32;\n    let mut signed_m = false;\n    let mut signed_e = false;\n\n    let mut i = 0;\n    if unsafe { *buffer.get_unchecked(0) } == b'-' {\n        signed_m = true;\n        i += 1;\n    }\n\n    while let Some(c) = buffer.get(i).copied() {\n        if c == b'.' {\n            if dot_index != len {\n                return Err(Error::MalformedInput);\n            }\n            dot_index = i;\n            i += 1;\n            continue;\n        }\n        if c < b'0' || c > b'9' {\n            break;\n        }\n        if m10digits >= 17 {\n            return Err(Error::InputTooLong);\n        }\n        m10 = 10 * m10 + (c - b'0') as u64;\n        if m10 != 0 {\n            m10digits += 1;\n        }\n        i += 1;\n    }\n\n    if let Some(b'e') | Some(b'E') = buffer.get(i) {\n        e_index = i;\n        i += 1;\n        match buffer.get(i) {\n            Some(b'-') => {\n                signed_e = true;\n                i += 1;\n            }\n            Some(b'+') => i += 1,\n            _ => {}\n        }\n        while let Some(c) = buffer.get(i).copied() {\n            if c < b'0' || c > b'9' {\n                return Err(Error::MalformedInput);\n            }\n            if e10digits > 3 {\n                // TODO: Be more lenient. Return +/-Infinity or +/-0 instead.\n                return Err(Error::InputTooLong);\n            }\n            e10 = 10 * e10 + (c - b'0') as i32;\n            if e10 != 0 {\n                e10digits += 1;\n            }\n            i += 1;\n        }\n    }\n\n    if i < len {\n        return Err(Error::MalformedInput);\n    }\n    if signed_e {\n        e10 = -e10;\n    }\n    e10 -= if dot_index < e_index {\n        (e_index - dot_index - 1) as i32\n    } else {\n        0\n    };\n    if m10 == 0 {\n        return Ok(if signed_m { -0.0 } else { 0.0 });\n    }\n\n    if m10digits + e10 <= -324 || m10 == 0 {\n        // Number is less than 1e-324, which should be rounded down to 0; return\n        // +/-0.0.\n        let ieee = (signed_m as u64) << (d2s::DOUBLE_EXPONENT_BITS + d2s::DOUBLE_MANTISSA_BITS);\n        return Ok(f64::from_bits(ieee));\n    }\n    if m10digits + e10 >= 310 {\n        // Number is larger than 1e+309, which should be rounded to +/-Infinity.\n        let ieee = ((signed_m as u64) << (d2s::DOUBLE_EXPONENT_BITS + d2s::DOUBLE_MANTISSA_BITS))\n            | (0x7ff_u64 << d2s::DOUBLE_MANTISSA_BITS);\n        return Ok(f64::from_bits(ieee));\n    }\n\n    // Convert to binary float m2 * 2^e2, while retaining information about\n    // whether the conversion was exact (trailing_zeros).\n    let e2: i32;\n    let m2: u64;\n    let mut trailing_zeros: bool;\n    if e10 >= 0 {\n        // The length of m * 10^e in bits is:\n        //   log2(m10 * 10^e10) = log2(m10) + e10 log2(10) = log2(m10) + e10 + e10 * log2(5)\n        //\n        // We want to compute the DOUBLE_MANTISSA_BITS + 1 top-most bits (+1 for\n        // the implicit leading one in IEEE format). We therefore choose a\n        // binary output exponent of\n        //   log2(m10 * 10^e10) - (DOUBLE_MANTISSA_BITS + 1).\n        //\n        // We use floor(log2(5^e10)) so that we get at least this many bits;\n        // better to have an additional bit than to not have enough bits.\n        e2 = floor_log2(m10)\n            .wrapping_add(e10 as u32)\n            .wrapping_add(log2_pow5(e10) as u32)\n            .wrapping_sub(d2s::DOUBLE_MANTISSA_BITS + 1) as i32;\n\n        // We now compute [m10 * 10^e10 / 2^e2] = [m10 * 5^e10 / 2^(e2-e10)].\n        // To that end, we use the DOUBLE_POW5_SPLIT table.\n        let j = e2\n            .wrapping_sub(e10)\n            .wrapping_sub(ceil_log2_pow5(e10))\n            .wrapping_add(d2s::DOUBLE_POW5_BITCOUNT);\n        debug_assert!(j >= 0);\n        debug_assert!(e10 < d2s::DOUBLE_POW5_SPLIT.len() as i32);\n        m2 = mul_shift_64(\n            m10,\n            unsafe { d2s::DOUBLE_POW5_SPLIT.get_unchecked(e10 as usize) },\n            j as u32,\n        );\n\n        // We also compute if the result is exact, i.e.,\n        //   [m10 * 10^e10 / 2^e2] == m10 * 10^e10 / 2^e2.\n        // This can only be the case if 2^e2 divides m10 * 10^e10, which in turn\n        // requires that the largest power of 2 that divides m10 + e10 is\n        // greater than e2. If e2 is less than e10, then the result must be\n        // exact. Otherwise we use the existing multiple_of_power_of_2 function.\n        trailing_zeros =\n            e2 < e10 || e2 - e10 < 64 && multiple_of_power_of_2(m10, (e2 - e10) as u32);\n    } else {\n        e2 = floor_log2(m10)\n            .wrapping_add(e10 as u32)\n            .wrapping_sub(ceil_log2_pow5(-e10) as u32)\n            .wrapping_sub(d2s::DOUBLE_MANTISSA_BITS + 1) as i32;\n        let j = e2\n            .wrapping_sub(e10)\n            .wrapping_add(ceil_log2_pow5(-e10))\n            .wrapping_sub(1)\n            .wrapping_add(d2s::DOUBLE_POW5_INV_BITCOUNT);\n        debug_assert!(-e10 < d2s::DOUBLE_POW5_INV_SPLIT.len() as i32);\n        m2 = mul_shift_64(\n            m10,\n            unsafe { d2s::DOUBLE_POW5_INV_SPLIT.get_unchecked(-e10 as usize) },\n            j as u32,\n        );\n        trailing_zeros = multiple_of_power_of_5(m10, -e10 as u32);\n    }\n\n    // Compute the final IEEE exponent.\n    let mut ieee_e2 = i32::max(0, e2 + DOUBLE_EXPONENT_BIAS as i32 + floor_log2(m2) as i32) as u32;\n\n    if ieee_e2 > 0x7fe {\n        // Final IEEE exponent is larger than the maximum representable; return +/-Infinity.\n        let ieee = ((signed_m as u64) << (d2s::DOUBLE_EXPONENT_BITS + d2s::DOUBLE_MANTISSA_BITS))\n            | (0x7ff_u64 << d2s::DOUBLE_MANTISSA_BITS);\n        return Ok(f64::from_bits(ieee));\n    }\n\n    // We need to figure out how much we need to shift m2. The tricky part is\n    // that we need to take the final IEEE exponent into account, so we need to\n    // reverse the bias and also special-case the value 0.\n    let shift = if ieee_e2 == 0 { 1 } else { ieee_e2 as i32 }\n        .wrapping_sub(e2)\n        .wrapping_sub(DOUBLE_EXPONENT_BIAS as i32)\n        .wrapping_sub(d2s::DOUBLE_MANTISSA_BITS as i32);\n    debug_assert!(shift >= 0);\n\n    // We need to round up if the exact value is more than 0.5 above the value\n    // we computed. That's equivalent to checking if the last removed bit was 1\n    // and either the value was not just trailing zeros or the result would\n    // otherwise be odd.\n    //\n    // We need to update trailing_zeros given that we have the exact output\n    // exponent ieee_e2 now.\n    trailing_zeros &= (m2 & ((1_u64 << (shift - 1)) - 1)) == 0;\n    let last_removed_bit = (m2 >> (shift - 1)) & 1;\n    let round_up = last_removed_bit != 0 && (!trailing_zeros || ((m2 >> shift) & 1) != 0);\n\n    let mut ieee_m2 = (m2 >> shift).wrapping_add(round_up as u64);\n    debug_assert!(ieee_m2 <= 1_u64 << (d2s::DOUBLE_MANTISSA_BITS + 1));\n    ieee_m2 &= (1_u64 << d2s::DOUBLE_MANTISSA_BITS) - 1;\n    if ieee_m2 == 0 && round_up {\n        // Due to how the IEEE represents +/-Infinity, we don't need to check\n        // for overflow here.\n        ieee_e2 += 1;\n    }\n    let ieee = ((((signed_m as u64) << d2s::DOUBLE_EXPONENT_BITS) | ieee_e2 as u64)\n        << d2s::DOUBLE_MANTISSA_BITS)\n        | ieee_m2;\n    Ok(f64::from_bits(ieee))\n}", "test": "fn test_overflow() {\n    assert_eq!(f64::INFINITY, s2d(b\"2e308\").unwrap());\n    assert_eq!(f64::INFINITY, s2d(b\"1e309\").unwrap());\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/engine_traits_tests/src/iterator.rs::iter_forward_engine", "code": "fn iterator(&self, cf: &str) -> Result<Self::Iterator> {\n        self.iterator_opt(cf, IterOptions::default())\n    }", "test": "fn iter_forward_engine() {\n    let db = default_engine();\n    iter_forward(&db.engine, |e| e.iterator(CF_DEFAULT).unwrap());\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/cli_tests.rs::table_growth_failure2", "code": "fn success() -> Self {\n        Self::Success\n    }", "test": "fn table_growth_failure2() -> Result<()> {\n    let output = get_wasmtime_command()?\n        .args(&[\n            \"run\",\n            \"-Wtrap-on-grow-failure\",\n            \"tests/all/cli_tests/table-grow-failure2.wat\",\n        ])\n        .output()?;\n    assert!(!output.status.success());\n    let stderr = String::from_utf8_lossy(&output.stderr);\n    assert!(\n        stderr.contains(\"forcing a table growth failure to be a trap\"),\n        \"bad stderr: {stderr}\"\n    );\n    Ok(())\n}"}
{"test_id": "raphlinus-pulldown-cmark/raphlinus-pulldown-cmark-3da63d5/tests/errors.rs::test_fuzzer_input_1", "code": "fn parse(md: &str) {\n    let parser = Parser::new(md);\n\n    for _ in parser {}\n}", "test": "fn test_fuzzer_input_1() {\n    parse(\">\\n >>><N\\n\");\n}"}
{"test_id": "ordinals-ord/ordinals-ord-8090538/tests/info.rs::json_without_satoshi_index", "code": "pub(crate) fn run_and_extract_stdout(self) -> String {\n    self.run().1\n  }", "test": "fn json_without_satoshi_index() {\n  let rpc_server = test_bitcoincore_rpc::spawn();\n  CommandBuilder::new(\"info\")\n    .rpc_server(&rpc_server)\n    .stdout_regex(\n      r#\"\\{\n  \"blocks_indexed\": 1,\n  \"branch_pages\": \\d+,\n  \"fragmented_bytes\": \\d+,\n  \"index_file_size\": \\d+,\n  \"index_path\": \".*\\.redb\",\n  \"leaf_pages\": \\d+,\n  \"metadata_bytes\": \\d+,\n  \"outputs_traversed\": 0,\n  \"page_size\": \\d+,\n  \"sat_ranges\": 0,\n  \"stored_bytes\": \\d+,\n  \"transactions\": \\[\n    \\{\n      \"starting_block_count\": 0,\n      \"starting_timestamp\": \\d+\n    \\}\n  \\],\n  \"tree_height\": \\d+,\n  \"utxos_indexed\": 0\n\\}\n\"#,\n    )\n    .run_and_extract_stdout();\n}"}
{"test_id": "gimli-rs-gimli/gimli-rs-gimli-3947879/tests/parse_self.rs::test_parse_self_debug_loc", "code": "pub fn encoding(&self) -> Encoding {\n        Encoding {\n            format: self.format,\n            version: u16::from(self.version),\n            address_size: self.address_size,\n        }\n    }", "test": "fn test_parse_self_debug_loc() {\n    let debug_info = read_section(\"debug_info\");\n    let debug_info = DebugInfo::new(&debug_info, LittleEndian);\n\n    let debug_abbrev = read_section(\"debug_abbrev\");\n    let debug_abbrev = DebugAbbrev::new(&debug_abbrev, LittleEndian);\n\n    let debug_addr = DebugAddr::from(EndianSlice::new(&[], LittleEndian));\n    let debug_addr_base = DebugAddrBase(0);\n\n    let debug_loc = read_section(\"debug_loc\");\n    let debug_loc = DebugLoc::new(&debug_loc, LittleEndian);\n    let debug_loclists = DebugLocLists::new(&[], LittleEndian);\n    let loclists = LocationLists::new(debug_loc, debug_loclists);\n\n    let mut iter = debug_info.units();\n    while let Some(unit) = iter.next().expect(\"Should parse compilation unit\") {\n        let abbrevs = unit\n            .abbreviations(&debug_abbrev)\n            .expect(\"Should parse abbreviations\");\n\n        let mut cursor = unit.entries(&abbrevs);\n        cursor.next_dfs().expect(\"Should parse next dfs\");\n\n        let mut low_pc = 0;\n\n        {\n            let unit_entry = cursor.current().expect(\"Should have a root entry\");\n            let low_pc_attr = unit_entry\n                .attr_value(gimli::DW_AT_low_pc)\n                .expect(\"Should parse low_pc\");\n            if let Some(gimli::AttributeValue::Addr(address)) = low_pc_attr {\n                low_pc = address;\n            }\n        }\n\n        while cursor.next_dfs().expect(\"Should parse next dfs\").is_some() {\n            let entry = cursor.current().expect(\"Should have a current entry\");\n            let mut attrs = entry.attrs();\n            while let Some(attr) = attrs.next().expect(\"Should parse entry's attribute\") {\n                if let AttributeValue::LocationListsRef(offset) = attr.value() {\n                    let mut locs = loclists\n                        .locations(\n                            offset,\n                            unit.encoding(),\n                            low_pc,\n                            &debug_addr,\n                            debug_addr_base,\n                        )\n                        .expect(\"Should parse locations OK\");\n                    while let Some(loc) = locs.next().expect(\"Should parse next location\") {\n                        assert!(loc.range.begin <= loc.range.end);\n                        parse_expression(loc.data, unit.encoding());\n                    }\n                }\n            }\n        }\n    }\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/pooling_allocator.rs::table_zeroed", "code": "pub fn size(&self) -> u32 {\n        match self {\n            Table::Static { size, .. } => *size,\n            Table::Dynamic { elements, .. } => elements.len().try_into().unwrap(),\n        }\n    }", "test": "fn table_zeroed() -> Result<()> {\n    if skip_pooling_allocator_tests() {\n        return Ok(());\n    }\n\n    let pool = crate::small_pool_config();\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling(pool));\n    config.dynamic_memory_guard_size(0);\n    config.static_memory_guard_size(0);\n    config.static_memory_maximum_size(65536);\n\n    let engine = Engine::new(&config)?;\n\n    let module = Module::new(&engine, r#\"(module (table (export \"t\") 10 funcref))\"#)?;\n\n    // Instantiate the module repeatedly after filling table elements\n    for _ in 0..10 {\n        let mut store = Store::new(&engine, ());\n        let instance = Instance::new(&mut store, &module, &[])?;\n        let table = instance.get_table(&mut store, \"t\").unwrap();\n        let f = Func::wrap(&mut store, || {});\n\n        assert_eq!(table.size(&store), 10);\n\n        for i in 0..10 {\n            match table.get(&mut store, i).unwrap() {\n                Val::FuncRef(r) => assert!(r.is_none()),\n                _ => panic!(\"expected a funcref\"),\n            }\n            table\n                .set(&mut store, i, Val::FuncRef(Some(f.clone())))\n                .unwrap();\n        }\n    }\n\n    Ok(())\n}"}
{"test_id": "Lokathor-tinyvec/Lokathor-tinyvec-6e1bbaf/tests/tinyvec.rs::TinyVec_move_to_heap_and_shrink", "code": "pub fn is_inline(&self) -> bool {\n    !self.is_heap()\n  }", "test": "fn TinyVec_move_to_heap_and_shrink() {\n  let mut tv: TinyVec<[i32; 4]> = Default::default();\n  assert!(tv.is_inline());\n  tv.move_to_the_heap();\n  assert!(tv.is_heap());\n  assert_eq!(tv.capacity(), 0);\n\n  tv.push(1);\n  tv.shrink_to_fit();\n  assert!(tv.is_inline());\n  assert_eq!(tv.capacity(), 4);\n\n  tv.move_to_the_heap_and_reserve(3);\n  assert!(tv.is_heap());\n  assert_eq!(tv.capacity(), 4);\n  tv.extend(2..=4);\n  assert_eq!(tv.capacity(), 4);\n  assert_eq!(tv.as_slice(), [1, 2, 3, 4]);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_transaction.rs::test_exceed_max_commit_ts_in_the_middle_of_prewrite", "code": "pub fn is_zero(&self) -> bool {\n        let len = word_cnt!(self.int_cnt) + word_cnt!(self.frac_cnt);\n        self.word_buf[0..len as usize].iter().all(|&x| x == 0)\n    }", "test": "fn test_exceed_max_commit_ts_in_the_middle_of_prewrite() {\n    let engine = TestEngineBuilder::new().build().unwrap();\n    let storage = TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine, MockLockManager::new())\n        .build()\n        .unwrap();\n    let cm = storage.get_concurrency_manager();\n\n    let (prewrite_tx, prewrite_rx) = channel();\n    // Pause between getting max ts and store the lock in memory\n    fail::cfg(\"before-set-lock-in-memory\", \"pause\").unwrap();\n\n    cm.update_max_ts(40.into());\n    let mutations = vec![\n        Mutation::make_put(Key::from_raw(b\"k1\"), b\"v\".to_vec()),\n        Mutation::make_put(Key::from_raw(b\"k2\"), b\"v\".to_vec()),\n    ];\n    storage\n        .sched_txn_command(\n            commands::Prewrite::new(\n                mutations.clone(),\n                b\"k1\".to_vec(),\n                10.into(),\n                20000,\n                false,\n                2,\n                11.into(),\n                50.into(),\n                Some(vec![]),\n                false,\n                AssertionLevel::Off,\n                Context::default(),\n            ),\n            Box::new(move |res| {\n                prewrite_tx.send(res).unwrap();\n            }),\n        )\n        .unwrap();\n    // sleep a while so the first key gets max ts.\n    thread::sleep(Duration::from_millis(200));\n\n    cm.update_max_ts(51.into());\n    fail::remove(\"before-set-lock-in-memory\");\n    let res = prewrite_rx.recv().unwrap().unwrap();\n    assert!(res.min_commit_ts.is_zero());\n    assert!(res.one_pc_commit_ts.is_zero());\n\n    let locks = block_on(storage.scan_lock(\n        Context::default(),\n        20.into(),\n        Some(Key::from_raw(b\"k1\")),\n        None,\n        2,\n    ))\n    .unwrap();\n    assert_eq!(locks.len(), 2);\n    assert_eq!(locks[0].get_key(), b\"k1\");\n    assert!(locks[0].get_use_async_commit());\n    assert_eq!(locks[0].get_min_commit_ts(), 41);\n    assert_eq!(locks[1].get_key(), b\"k2\");\n    assert!(!locks[1].get_use_async_commit());\n\n    // Send a duplicated request to test the idempotency of prewrite when falling\n    // back to 2PC.\n    let (prewrite_tx, prewrite_rx) = channel();\n    storage\n        .sched_txn_command(\n            commands::Prewrite::new(\n                mutations,\n                b\"k1\".to_vec(),\n                10.into(),\n                20000,\n                false,\n                2,\n                11.into(),\n                50.into(),\n                Some(vec![]),\n                false,\n                AssertionLevel::Off,\n                Context::default(),\n            ),\n            Box::new(move |res| {\n                prewrite_tx.send(res).unwrap();\n            }),\n        )\n        .unwrap();\n    let res = prewrite_rx.recv().unwrap().unwrap();\n    assert!(res.min_commit_ts.is_zero());\n    assert!(res.one_pc_commit_ts.is_zero());\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_common.rs::parse_interval_and_or_xor", "code": "pub fn verified_stmt(&self, sql: &str) -> Statement {\n        self.one_statement_parses_to(sql, sql)\n    }", "test": "fn parse_interval_and_or_xor() {\n    let sql = \"SELECT col FROM test \\\n        WHERE d3_date > d1_date + INTERVAL '5 days' \\\n        AND d2_date > d1_date + INTERVAL '3 days'\";\n\n    let actual_ast = Parser::parse_sql(&GenericDialect {}, sql).unwrap();\n\n    let expected_ast = vec![Statement::Query(Box::new(Query {\n        with: None,\n        body: Box::new(SetExpr::Select(Box::new(Select {\n            distinct: None,\n            top: None,\n            projection: vec![UnnamedExpr(Expr::Identifier(Ident {\n                value: \"col\".to_string(),\n                quote_style: None,\n            }))],\n            into: None,\n            from: vec![TableWithJoins {\n                relation: TableFactor::Table {\n                    name: ObjectName(vec![Ident {\n                        value: \"test\".to_string(),\n                        quote_style: None,\n                    }]),\n                    alias: None,\n                    args: None,\n                    with_hints: vec![],\n                    version: None,\n                    partitions: vec![],\n                },\n                joins: vec![],\n            }],\n            lateral_views: vec![],\n            selection: Some(Expr::BinaryOp {\n                left: Box::new(Expr::BinaryOp {\n                    left: Box::new(Expr::Identifier(Ident {\n                        value: \"d3_date\".to_string(),\n                        quote_style: None,\n                    })),\n                    op: BinaryOperator::Gt,\n                    right: Box::new(Expr::BinaryOp {\n                        left: Box::new(Expr::Identifier(Ident {\n                            value: \"d1_date\".to_string(),\n                            quote_style: None,\n                        })),\n                        op: BinaryOperator::Plus,\n                        right: Box::new(Expr::Interval(Interval {\n                            value: Box::new(Expr::Value(Value::SingleQuotedString(\n                                \"5 days\".to_string(),\n                            ))),\n                            leading_field: None,\n                            leading_precision: None,\n                            last_field: None,\n                            fractional_seconds_precision: None,\n                        })),\n                    }),\n                }),\n                op: BinaryOperator::And,\n                right: Box::new(Expr::BinaryOp {\n                    left: Box::new(Expr::Identifier(Ident {\n                        value: \"d2_date\".to_string(),\n                        quote_style: None,\n                    })),\n                    op: BinaryOperator::Gt,\n                    right: Box::new(Expr::BinaryOp {\n                        left: Box::new(Expr::Identifier(Ident {\n                            value: \"d1_date\".to_string(),\n                            quote_style: None,\n                        })),\n                        op: BinaryOperator::Plus,\n                        right: Box::new(Expr::Interval(Interval {\n                            value: Box::new(Expr::Value(Value::SingleQuotedString(\n                                \"3 days\".to_string(),\n                            ))),\n                            leading_field: None,\n                            leading_precision: None,\n                            last_field: None,\n                            fractional_seconds_precision: None,\n                        })),\n                    }),\n                }),\n            }),\n            group_by: GroupByExpr::Expressions(vec![]),\n            cluster_by: vec![],\n            distribute_by: vec![],\n            sort_by: vec![],\n            having: None,\n            named_window: vec![],\n            qualify: None,\n        }))),\n        order_by: vec![],\n        limit: None,\n        limit_by: vec![],\n        offset: None,\n        fetch: None,\n        locks: vec![],\n    }))];\n\n    assert_eq!(actual_ast, expected_ast);\n\n    verified_stmt(\n        \"SELECT col FROM test \\\n        WHERE d3_date > d1_date + INTERVAL '5 days' \\\n        AND d2_date > d1_date + INTERVAL '3 days'\",\n    );\n\n    verified_stmt(\n        \"SELECT col FROM test \\\n        WHERE d3_date > d1_date + INTERVAL '5 days' \\\n        OR d2_date > d1_date + INTERVAL '3 days'\",\n    );\n\n    verified_stmt(\n        \"SELECT col FROM test \\\n        WHERE d3_date > d1_date + INTERVAL '5 days' \\\n        XOR d2_date > d1_date + INTERVAL '3 days'\",\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_unexpand.rs::unexpand_init_0", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn unexpand_init_0() {\n    new_ucmd!()\n        .args(&[\"-t4\"])\n        .pipe_in(\" 1\\n  2\\n   3\\n    4\\n\")\n        .run()\n        .stdout_is(\" 1\\n  2\\n   3\\n\\t4\\n\");\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/mod.rs::undefined_constant", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn undefined_constant() {\n    run_test_actions([TestAction::assert_eq(\"undefined\", JsValue::undefined())]);\n}"}
{"test_id": "web-infra-dev-oxc/oxc-project-oxc-884a819/crates/oxc_minifier/tests/oxc/code_removal.rs::undefined_assignment", "code": "fn test(args: &[&str]) -> LintResult {\n        let mut new_args = vec![\"--quiet\"];\n        new_args.extend(args);\n        let options = lint_command().run_inner(new_args.as_slice()).unwrap().lint_options;\n        let CliRunResult::LintResult(lint_result) = LintRunner::new(options).run() else {\n            unreachable!()\n        };\n        lint_result\n    }", "test": "fn undefined_assignment() {\n    test(\"let x = undefined\", \"let x;\");\n    test(\"var x = undefined\", \"var x;\");\n    test(\"const x = undefined\", \"const x=void 0;\");\n    test(\"let x; x = undefined\", \"let x;x=void 0;\");\n    test(\"function foo(a = undefined) {}\", \"function foo(a=void 0){}\");\n    test(\"let a = undefined; let b = 5; let c = undefined;\", \"let a,b=5,c;\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_du.rs::test_du_apparent_size", "code": "pub fn stdout_contains_line<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stdout_str().lines().any(|line| line == cmp.as_ref()),\n            \"'{}' does not contain line '{}'\",\n            self.stdout_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_du_apparent_size() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    at.mkdir_all(\"a/b\");\n\n    at.write(\"a/b/file1\", \"foo\");\n    at.write(\"a/b/file2\", \"foobar\");\n\n    let result = ucmd.args(&[\"--apparent-size\", \"--all\", \"a\"]).succeeds();\n\n    #[cfg(not(target_os = \"windows\"))]\n    {\n        result.stdout_contains_line(\"1\\ta/b/file2\");\n        result.stdout_contains_line(\"1\\ta/b/file1\");\n        result.stdout_contains_line(\"1\\ta/b\");\n        result.stdout_contains_line(\"1\\ta\");\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        result.stdout_contains_line(\"1\\ta\\\\b\\\\file2\");\n        result.stdout_contains_line(\"1\\ta\\\\b\\\\file1\");\n        result.stdout_contains_line(\"1\\ta\\\\b\");\n        result.stdout_contains_line(\"1\\ta\");\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cat.rs::test_non_blank_overrides_number", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_non_blank_overrides_number() {\n    // spell-checker:disable-next-line\n    for same_param in [\"-b\", \"--number-nonblank\"] {\n        new_ucmd!()\n            .args(&[same_param, \"-\"])\n            .pipe_in(\"\\na\\nb\\n\\n\\nc\")\n            .succeeds()\n            .stdout_only(\"\\n     1\\ta\\n     2\\tb\\n\\n\\n     3\\tc\");\n    }\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_transport.rs::test_secure_connect", "code": "pub fn get_engine(&self, node_id: u64) -> WrapFactory<EK> {\n        WrapFactory::new(\n            self.pd_client.clone(),\n            self.raft_engines[&node_id].clone(),\n            self.tablet_registries[&node_id].clone(),\n        )\n    }", "test": "fn test_secure_connect() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.security = test_util::new_security_cfg(None);\n    cluster.pd_client.disable_default_operator();\n    cluster.run();\n\n    let (key, value) = (b\"k1\", b\"v1\");\n    cluster.must_put(key, value);\n\n    for id in 1..4 {\n        must_get_equal(&cluster.get_engine(id), key, value);\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_nproc.rs::test_nproc_omp_limit", "code": "fn parse(s: &str) -> Result<usize, &'static str> {\n            match s.parse::<usize>() {\n                Ok(0) => Err(\"fields and positions are numbered from 1\"),\n                // GNU fails when we are at the limit. Match their behavior\n                Ok(n) if n == usize::MAX => Err(\"byte/character offset is too large\"),\n                Ok(n) => Ok(n),\n                Err(_) => Err(\"failed to parse range\"),\n            }\n        }", "test": "fn test_nproc_omp_limit() {\n    let result = TestScenario::new(util_name!())\n        .ucmd()\n        .env(\"OMP_NUM_THREADS\", \"42\")\n        .env(\"OMP_THREAD_LIMIT\", \"0\")\n        .succeeds();\n    let nproc: u8 = result.stdout_str().trim().parse().unwrap();\n    assert_eq!(nproc, 42);\n\n    let result = TestScenario::new(util_name!())\n        .ucmd()\n        .env(\"OMP_NUM_THREADS\", \"42\")\n        .env(\"OMP_THREAD_LIMIT\", \"2\")\n        .succeeds();\n    let nproc: u8 = result.stdout_str().trim().parse().unwrap();\n    assert_eq!(nproc, 2);\n\n    let result = TestScenario::new(util_name!())\n        .ucmd()\n        .env(\"OMP_NUM_THREADS\", \"42\")\n        .env(\"OMP_THREAD_LIMIT\", \"2bad\")\n        .succeeds();\n    let nproc: u8 = result.stdout_str().trim().parse().unwrap();\n    assert_eq!(nproc, 42);\n\n    let result = new_ucmd!().arg(\"--all\").succeeds();\n    let nproc_system: u8 = result.stdout_str().trim().parse().unwrap();\n    assert!(nproc_system > 0);\n\n    let result = TestScenario::new(util_name!())\n        .ucmd()\n        .env(\"OMP_THREAD_LIMIT\", \"1\")\n        .succeeds();\n    let nproc: u8 = result.stdout_str().trim().parse().unwrap();\n    assert_eq!(nproc, 1);\n\n    let result = TestScenario::new(util_name!())\n        .ucmd()\n        .env(\"OMP_NUM_THREADS\", \"0\")\n        .env(\"OMP_THREAD_LIMIT\", \"\")\n        .succeeds();\n    let nproc: u8 = result.stdout_str().trim().parse().unwrap();\n    assert_eq!(nproc, nproc_system);\n\n    let result = TestScenario::new(util_name!())\n        .ucmd()\n        .env(\"OMP_NUM_THREADS\", \"\")\n        .env(\"OMP_THREAD_LIMIT\", \"\")\n        .succeeds();\n    let nproc: u8 = result.stdout_str().trim().parse().unwrap();\n    assert_eq!(nproc, nproc_system);\n\n    let result = TestScenario::new(util_name!())\n        .ucmd()\n        .env(\"OMP_NUM_THREADS\", \"2,2,1\")\n        .env(\"OMP_THREAD_LIMIT\", \"\")\n        .succeeds();\n    let nproc: u8 = result.stdout_str().trim().parse().unwrap();\n    assert_eq!(2, nproc);\n\n    let result = TestScenario::new(util_name!())\n        .ucmd()\n        .env(\"OMP_NUM_THREADS\", \"2,ignored\")\n        .env(\"OMP_THREAD_LIMIT\", \"\")\n        .succeeds();\n    let nproc: u8 = result.stdout_str().trim().parse().unwrap();\n    assert_eq!(2, nproc);\n\n    let result = TestScenario::new(util_name!())\n        .ucmd()\n        .env(\"OMP_NUM_THREADS\", \"2,2,1\")\n        .env(\"OMP_THREAD_LIMIT\", \"0\")\n        .succeeds();\n    let nproc: u8 = result.stdout_str().trim().parse().unwrap();\n    assert_eq!(2, nproc);\n\n    let result = TestScenario::new(util_name!())\n        .ucmd()\n        .env(\"OMP_NUM_THREADS\", \"2,2,1\")\n        .env(\"OMP_THREAD_LIMIT\", \"1bad\")\n        .succeeds();\n    let nproc: u8 = result.stdout_str().trim().parse().unwrap();\n    assert_eq!(2, nproc);\n\n    let result = TestScenario::new(util_name!())\n        .ucmd()\n        .env(\"OMP_NUM_THREADS\", \"29,2,1\")\n        .env(\"OMP_THREAD_LIMIT\", \"1bad\")\n        .succeeds();\n    let nproc: u8 = result.stdout_str().trim().parse().unwrap();\n    assert_eq!(29, nproc);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_split.rs::test_guard_input", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_guard_input() {\n    let ts = TestScenario::new(util_name!());\n    let at = &ts.fixtures;\n\n    ts.ucmd()\n        .args(&[\"-C\", \"6\"])\n        .pipe_in(\"1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n\")\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"xaa\"), \"1\\n2\\n3\\n\");\n\n    ts.ucmd()\n        .args(&[\"-C\", \"6\"])\n        .pipe_in(\"1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n\")\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"xaa\"), \"1\\n2\\n3\\n\");\n\n    ts.ucmd()\n        .args(&[\"-C\", \"6\", \"xaa\"])\n        .fails()\n        .stderr_only(\"split: 'xaa' would overwrite input; aborting\\n\");\n    assert_eq!(at.read(\"xaa\"), \"1\\n2\\n3\\n\");\n}"}
{"test_id": "hyperium-http/hyperium-http-818269d/tests/header_map.rs::remove_multiple_b", "code": "pub fn remove<K2: PartialEq<K> + ?Sized>(&mut self, key: &K2) -> Option<V> {\n        self.find(key)\n            .map(|pos| self.vec.remove(pos))\n            .map(|(_, v)| v)\n    }", "test": "fn remove_multiple_b() {\n    let mut headers = HeaderMap::new();\n    headers.insert(VIA, \"1.1 example.com\".parse().unwrap());\n    headers.insert(SET_COOKIE, \"cookie_1=value 1\".parse().unwrap());\n    headers.append(SET_COOKIE, \"cookie_2=value 2\".parse().unwrap());\n    headers.append(VIA, \"1.1 other.com\".parse().unwrap());\n    headers.append(SET_COOKIE, \"cookie_3=value 3\".parse().unwrap());\n    headers.insert(VARY, \"*\".parse().unwrap());\n\n    assert_eq!(headers.len(), 6);\n\n    let vary = headers.remove(VARY);\n    assert_eq!(vary, Some(\"*\".parse().unwrap()));\n    assert_eq!(headers.len(), 5);\n\n    let via = headers.remove(VIA);\n    assert_eq!(via, Some(\"1.1 example.com\".parse().unwrap()));\n    assert_eq!(headers.len(), 3);\n\n    let cookie = headers.remove(SET_COOKIE);\n    assert_eq!(cookie, Some(\"cookie_1=value 1\".parse().unwrap()));\n    assert_eq!(headers.len(), 0);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_dd.rs::test_stdin_stdout_count", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_stdin_stdout_count() {\n    let input = build_ascii_block(521);\n    let mut output = String::from_utf8(input.clone()).unwrap();\n    output.truncate(256);\n    new_ucmd!()\n        .args(&[\"status=none\", \"count=2\", \"ibs=128\"])\n        .pipe_in(input)\n        .run()\n        .no_stderr()\n        .stdout_only(output);\n}"}
{"test_id": "ordinals-ord/ordinals-ord-8090538/tests/parse.rs::unrecognized_object", "code": "pub(crate) fn run_and_extract_stdout(self) -> String {\n    self.run().1\n  }", "test": "fn unrecognized_object() {\n  CommandBuilder::new(\"parse A\")\n    .stderr_regex(r\"error: .*: unrecognized object\\n.*\")\n    .expected_exit_code(2)\n    .run_and_extract_stdout();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_seq.rs::test_seq_wrong_arg_floats", "code": "pub fn fails(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.failure();\n        cmd_result\n    }", "test": "fn test_seq_wrong_arg_floats() {\n    new_ucmd!().args(&[\"-w\", \"5\", \"10.0\", \"33\", \"32\"]).fails();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_numbered_if_existing_backup_nil", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_cp_numbered_if_existing_backup_nil() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let existing_backup = &format!(\"{TEST_HOW_ARE_YOU_SOURCE}.~1~\");\n\n    at.touch(existing_backup);\n    ucmd.arg(\"--backup=nil\")\n        .arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(TEST_HOW_ARE_YOU_SOURCE));\n    assert!(at.file_exists(existing_backup));\n    assert_eq!(\n        at.read(&format!(\"{TEST_HOW_ARE_YOU_SOURCE}.~2~\")),\n        \"How are you?\\n\"\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_mv.rs::test_mv_arg_update_all_then_none", "code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_mv_arg_update_all_then_none() {\n    // take last if multiple update args are supplied,\n    // update=none wins in this case\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let old = \"test_mv_arg_update_all_then_none_file1\";\n    let new = \"test_mv_arg_update_all_then_none_file2\";\n    let old_content = \"old content\\n\";\n    let new_content = \"new content\\n\";\n\n    at.write(old, old_content);\n\n    sleep(Duration::from_secs(1));\n\n    at.write(new, new_content);\n\n    ucmd.arg(old)\n        .arg(new)\n        .arg(\"--update=all\")\n        .arg(\"--update=none\")\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    assert_eq!(at.read(new), \"new content\\n\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_chmod.rs::test_chmod_file_after_non_existing_file", "code": "pub fn mode(&self) -> u32 {\n        match self.specified_mode {\n            Some(x) => x,\n            None => DEFAULT_MODE,\n        }\n    }", "test": "fn test_chmod_file_after_non_existing_file() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    at.touch(TEST_FILE);\n    at.touch(\"file2\");\n    set_permissions(at.plus(TEST_FILE), Permissions::from_mode(0o664)).unwrap();\n    set_permissions(at.plus(\"file2\"), Permissions::from_mode(0o664)).unwrap();\n    scene\n        .ucmd()\n        .arg(\"u+x\")\n        .arg(\"does-not-exist\")\n        .arg(TEST_FILE)\n        .fails()\n        .stderr_contains(\"chmod: cannot access 'does-not-exist': No such file or directory\")\n        .code_is(1);\n\n    assert_eq!(at.metadata(TEST_FILE).permissions().mode(), 0o100_764);\n\n    scene\n        .ucmd()\n        .arg(\"u+x\")\n        .arg(\"--q\")\n        .arg(\"does-not-exist\")\n        .arg(\"file2\")\n        .fails()\n        .no_stderr()\n        .code_is(1);\n    assert_eq!(at.metadata(\"file2\").permissions().mode(), 0o100_764);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_who.rs::test_too_many_args", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_too_many_args() {\n    const EXPECTED: &str =\n        \"error: unexpected value 'u' for '[FILE]...' found; no more were expected\";\n\n    let args = [\"am\", \"i\", \"u\"];\n    new_ucmd!().args(&args).fails().stderr_contains(EXPECTED);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_csplit.rs::test_too_small_line_num", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_too_small_line_num() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"/20/\", \"10\", \"/40/\"])\n        .succeeds()\n        .stdout_only(\"48\\n0\\n60\\n33\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"there should be splits created\")\n        .count();\n    assert_eq!(count, 4);\n    assert_eq!(at.read(\"xx00\"), generate(1, 20));\n    assert_eq!(at.read(\"xx01\"), \"\");\n    assert_eq!(at.read(\"xx02\"), generate(20, 40));\n    assert_eq!(at.read(\"xx03\"), generate(40, 51));\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_postgres.rs::parse_create_sequence", "code": "pub fn one_statement_parses_to(&self, sql: &str, canonical: &str) -> Statement {\n        let mut statements = self.parse_sql_statements(sql).expect(sql);\n        assert_eq!(statements.len(), 1);\n\n        if !canonical.is_empty() && sql != canonical {\n            assert_eq!(self.parse_sql_statements(canonical).unwrap(), statements);\n        }\n\n        let only_statement = statements.pop().unwrap();\n        if !canonical.is_empty() {\n            assert_eq!(canonical, only_statement.to_string())\n        }\n        only_statement\n    }", "test": "fn parse_create_sequence() {\n    // SimpleLogger::new().init().unwrap();\n\n    let sql1 = \"CREATE SEQUENCE  name0\";\n    pg().one_statement_parses_to(sql1, \"CREATE SEQUENCE name0\");\n\n    let sql2 = \"CREATE SEQUENCE  IF NOT EXISTS  name0\";\n    pg().one_statement_parses_to(sql2, \"CREATE SEQUENCE IF NOT EXISTS name0\");\n\n    let sql3 = \"CREATE TEMPORARY SEQUENCE  IF NOT EXISTS  name0\";\n    pg().one_statement_parses_to(sql3, \"CREATE TEMPORARY SEQUENCE IF NOT EXISTS name0\");\n\n    let sql4 = \"CREATE TEMPORARY SEQUENCE  name0\";\n    pg().one_statement_parses_to(sql4, \"CREATE TEMPORARY SEQUENCE name0\");\n\n    let sql2 = \"CREATE TEMPORARY SEQUENCE IF NOT EXISTS  name1\n      AS BIGINT\n     INCREMENT BY  1\n     MINVALUE 1  MAXVALUE 20\n     START WITH 10\";\n    pg().one_statement_parses_to(\n        sql2,\n        \"CREATE TEMPORARY SEQUENCE IF NOT EXISTS name1 AS BIGINT INCREMENT BY 1 MINVALUE 1 MAXVALUE 20 START WITH 10\", );\n\n    let sql3 = \"CREATE SEQUENCE IF NOT EXISTS  name2\n     AS BIGINT\n     INCREMENT  1\n     MINVALUE 1  MAXVALUE 20\n     START WITH 10 CACHE 2 NO CYCLE\";\n    pg().one_statement_parses_to(\n        sql3,\n        \"CREATE SEQUENCE IF NOT EXISTS name2 AS BIGINT INCREMENT 1 MINVALUE 1 MAXVALUE 20 START WITH 10 CACHE 2 NO CYCLE\",\n    );\n\n    let sql4 = \"CREATE TEMPORARY SEQUENCE  IF NOT EXISTS  name3\n         INCREMENT  1\n     NO MINVALUE  MAXVALUE 20 CACHE 2 CYCLE\";\n    pg().one_statement_parses_to(\n        sql4,\n        \"CREATE TEMPORARY SEQUENCE IF NOT EXISTS name3 INCREMENT 1 NO MINVALUE MAXVALUE 20 CACHE 2 CYCLE\",\n    );\n\n    let sql5 = \"CREATE TEMPORARY SEQUENCE  IF NOT EXISTS  name3\n         INCREMENT  1\n     NO MINVALUE  MAXVALUE 20 OWNED BY public.table01\";\n    pg().one_statement_parses_to(\n        sql5,\n        \"CREATE TEMPORARY SEQUENCE IF NOT EXISTS name3 INCREMENT 1 NO MINVALUE MAXVALUE 20 OWNED BY public.table01\",\n    );\n\n    let sql6 = \"CREATE TEMPORARY SEQUENCE  IF NOT EXISTS  name3\n         INCREMENT  1\n     NO MINVALUE  MAXVALUE 20 OWNED BY NONE\";\n    pg().one_statement_parses_to(\n        sql6,\n        \"CREATE TEMPORARY SEQUENCE IF NOT EXISTS name3 INCREMENT 1 NO MINVALUE MAXVALUE 20 OWNED BY NONE\",\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_readlink.rs::test_long_redirection_to_current_dir", "code": "pub fn root_dir_resolved(&self) -> String {\n        log_info(\"current_directory_resolved\", \"\");\n        let s = self\n            .subdir\n            .canonicalize()\n            .unwrap()\n            .to_str()\n            .unwrap()\n            .to_owned();\n\n        // Due to canonicalize()'s use of GetFinalPathNameByHandleW() on Windows, the resolved path\n        // starts with '\\\\?\\' to extend the limit of a given path to 32,767 wide characters.\n        //\n        // To address this issue, we remove this prepended string if available.\n        //\n        // Source:\n        // http://stackoverflow.com/questions/31439011/getfinalpathnamebyhandle-without-prepended\n        let prefix = \"\\\\\\\\?\\\\\";\n\n        if let Some(stripped) = s.strip_prefix(prefix) {\n            String::from(stripped)\n        } else {\n            s\n        }\n    }", "test": "fn test_long_redirection_to_current_dir() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    // Create a 256-character path to current directory\n    let dir = path_concat!(\".\", ..128);\n    let actual = ucmd.arg(\"-n\").arg(\"-m\").arg(dir).run().stdout_move_str();\n    let expect = at.root_dir_resolved();\n    println!(\"actual: {actual:?}\");\n    println!(\"expect: {expect:?}\");\n    assert_eq!(actual, expect);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_ls.rs::test_ls_columns", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_ls_columns() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    at.touch(at.plus_as_string(\"test-columns-1\"));\n    at.touch(at.plus_as_string(\"test-columns-2\"));\n    at.touch(at.plus_as_string(\"test-columns-3\"));\n    at.touch(at.plus_as_string(\"test-columns-4\"));\n\n    // Columns is the default\n    let result = scene.ucmd().succeeds();\n\n    result.stdout_only(\"test-columns-1\\ntest-columns-2\\ntest-columns-3\\ntest-columns-4\\n\");\n\n    for option in COLUMN_ARGS {\n        let result = scene.ucmd().arg(option).succeeds();\n        result.stdout_only(\"test-columns-1  test-columns-2  test-columns-3  test-columns-4\\n\");\n    }\n\n    for option in COLUMN_ARGS {\n        scene\n            .ucmd()\n            .arg(\"-w=40\")\n            .arg(option)\n            .succeeds()\n            .stdout_only(\"test-columns-1  test-columns-3\\ntest-columns-2  test-columns-4\\n\");\n    }\n\n    // On windows we are always able to get the terminal size, so we can't simulate falling back to the\n    // environment variable.\n    #[cfg(not(windows))]\n    {\n        for option in COLUMN_ARGS {\n            scene\n                .ucmd()\n                .env(\"COLUMNS\", \"40\")\n                .arg(option)\n                .succeeds()\n                .stdout_only(\"test-columns-1  test-columns-3\\ntest-columns-2  test-columns-4\\n\");\n        }\n\n        scene\n            .ucmd()\n            .env(\"COLUMNS\", \"garbage\")\n            .arg(\"-C\")\n            .succeeds()\n            .stdout_is(\"test-columns-1  test-columns-2  test-columns-3  test-columns-4\\n\")\n            .stderr_is(\"ls: ignoring invalid width in environment variable COLUMNS: 'garbage'\\n\");\n    }\n    scene\n        .ucmd()\n        .arg(\"-Cw0\")\n        .succeeds()\n        .stdout_only(\"test-columns-1  test-columns-2  test-columns-3  test-columns-4\\n\");\n    scene\n        .ucmd()\n        .arg(\"-mw0\")\n        .succeeds()\n        .stdout_only(\"test-columns-1, test-columns-2, test-columns-3, test-columns-4\\n\");\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/externals.rs::grow_funcref_tables_via_api", "code": "pub fn size(&self) -> u32 {\n        match self {\n            Table::Static { size, .. } => *size,\n            Table::Dynamic { elements, .. } => elements.len().try_into().unwrap(),\n        }\n    }", "test": "fn grow_funcref_tables_via_api() -> anyhow::Result<()> {\n    let mut cfg = Config::new();\n    cfg.wasm_reference_types(true);\n    let engine = Engine::new(&cfg)?;\n    let mut store = Store::new(&engine, ());\n\n    let table_ty = TableType::new(ValType::FuncRef, 10, None);\n    let table = Table::new(&mut store, table_ty, Val::FuncRef(None))?;\n\n    assert_eq!(table.size(&store), 10);\n    table.grow(&mut store, 3, Val::FuncRef(None))?;\n    assert_eq!(table.size(&store), 13);\n\n    Ok(())\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_install.rs::test_install_backup_none", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_backup_none() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"test_install_backup_numbering_file_a\";\n    let file_b = \"test_install_backup_numbering_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    scene\n        .ucmd()\n        .arg(\"--backup=none\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(!at.file_exists(format!(\"{file_b}~\")));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_shuf.rs::test_repeat", "code": "pub(crate) fn parse(self, operands: &[&str]) -> Result<Settings, ParseError> {\n        self.read(operands)?.validate()\n    }", "test": "fn test_repeat() {\n    let repeat_limit = 15000;\n    let input_seq = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n    let input = input_seq\n        .iter()\n        .map(ToString::to_string)\n        .collect::<Vec<String>>()\n        .join(\"\\n\");\n\n    let result = new_ucmd!()\n        .arg(\"-r\")\n        .args(&[\"-n\", &repeat_limit.to_string()])\n        .pipe_in(input.as_bytes())\n        .succeeds();\n    result.no_stderr();\n\n    let result_seq: Vec<i32> = result\n        .stdout_str()\n        .split('\\n')\n        .filter(|x| !x.is_empty())\n        .map(|x| x.parse().unwrap())\n        .collect();\n    assert_eq!(\n        result_seq.len(),\n        repeat_limit,\n        \"Output is not repeating forever\"\n    );\n    assert!(\n        result_seq.iter().all(|x| input_seq.contains(x)),\n        \"Output includes element not from input: {:?}\",\n        result_seq\n            .iter()\n            .filter(|x| !input_seq.contains(x))\n            .collect::<Vec<&i32>>()\n    );\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/format.rs::format_is_disabled", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn format_is_disabled() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n    let file_path = Path::new(\"biome.json\");\n    fs.insert(file_path.into(), CONFIG_DISABLED_FORMATTER.as_bytes());\n\n    let file_path = Path::new(\"file.js\");\n    fs.insert(file_path.into(), CUSTOM_FORMAT_BEFORE.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"format\"), (\"file.js\"), (\"--write\")].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut file = fs\n        .open(file_path)\n        .expect(\"formatting target file was removed by the CLI\");\n\n    let mut content = String::new();\n    file.read_to_string(&mut content)\n        .expect(\"failed to read file from memory FS\");\n\n    assert_eq!(content, CUSTOM_FORMAT_BEFORE);\n\n    drop(file);\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"format_is_disabled\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_mv.rs::test_mv_target_dir_single_source", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_target_dir_single_source() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_mv_target_dir_single_source_dir\";\n    let file = \"test_mv_target_dir_single_source_file\";\n\n    at.touch(file);\n    at.mkdir(dir);\n    ucmd.arg(\"-t\").arg(dir).arg(file).succeeds().no_stderr();\n\n    assert!(!at.file_exists(file));\n    assert!(at.file_exists(format!(\"{dir}/{file}\")));\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_replication_mode.rs::test_dr_auto_sync", "code": "pub fn get_id(&self) -> ConnId {\n        self.id\n    }", "test": "fn test_dr_auto_sync() {\n    let mut cluster = prepare_cluster();\n    run_cluster(&mut cluster);\n    cluster.add_send_filter(IsolationFilterFactory::new(2));\n    let region = cluster.get_region(b\"k1\");\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_put_cf_cmd(\"default\", b\"k1\", b\"v1\")],\n        false,\n    );\n    request.mut_header().set_peer(new_peer(1, 1));\n    let (cb, mut rx) = make_cb(&request);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(1, request, cb)\n        .unwrap();\n    rx.recv_timeout(Duration::from_millis(100)).unwrap();\n    must_get_equal(&cluster.get_engine(1), b\"k1\", b\"v1\");\n    thread::sleep(Duration::from_millis(100));\n    let state = cluster.pd_client.region_replication_status(region.get_id());\n    assert_eq!(state.state_id, 1);\n    assert_eq!(state.state, RegionReplicationState::IntegrityOverLabel);\n\n    cluster.clear_send_filters();\n    cluster.add_send_filter(IsolationFilterFactory::new(3));\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_put_cf_cmd(\"default\", b\"k2\", b\"v2\")],\n        false,\n    );\n    request.mut_header().set_peer(new_peer(1, 1));\n    let (cb, mut rx) = make_cb(&request);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(1, request, cb)\n        .unwrap();\n    assert_eq!(\n        rx.recv_timeout(Duration::from_millis(100)),\n        Err(future::RecvTimeoutError::Timeout)\n    );\n    must_get_none(&cluster.get_engine(1), b\"k2\");\n    let state = cluster.pd_client.region_replication_status(region.get_id());\n    assert_eq!(state.state_id, 1);\n    assert_eq!(state.state, RegionReplicationState::IntegrityOverLabel);\n}"}
{"test_id": "web-infra-dev-oxc/oxc-project-oxc-884a819/crates/oxc_minifier/tests/closure/fold_constants.rs::test_string_string_comparison", "code": "pub(crate) fn test_same(source_text: &str) {\n    test(source_text, source_text);\n}", "test": "fn test_string_string_comparison() {\n    test(\"'a' < 'b'\", \"!0;\");\n    test(\"'a' <= 'b'\", \"!0;\");\n    test(\"'a' > 'b'\", \"!1;\");\n    test(\"'a' >= 'b'\", \"!1;\");\n    test(\"+'a' < +'b'\", \"!1;\");\n    test_same(\"typeof a<'a';\");\n    test_same(\"'a'>=typeof a;\");\n    test(\"typeof a < typeof a\", \"!1;\");\n    test(\"typeof a >= typeof a\", \"!0;\");\n    test(\"typeof 3 > typeof 4\", \"!1;\");\n    test(\"typeof function() {} < typeof function() {}\", \"!1;\");\n    test(\"'a' == 'a'\", \"!0;\");\n    test(\"'b' != 'a'\", \"!0;\");\n    test_same(\"'undefined'==typeof a;\");\n    test_same(\"typeof a!='number';\");\n    test_same(\"'undefined'==typeof a;\");\n    test_same(\"'undefined'==typeof a;\");\n    test(\"typeof a == typeof a\", \"!0;\");\n    test(\"'a' === 'a'\", \"!0;\");\n    test(\"'b' !== 'a'\", \"!0;\");\n    test(\"typeof a === typeof a\", \"!0;\");\n    test(\"typeof a !== typeof a\", \"!1;\");\n    test_same(\"''+x<=''+y;\");\n    test_same(\"''+x!=''+y;\");\n    test_same(\"''+x===''+y;\");\n\n    test_same(\"''+x<=''+x;\"); // potentially foldable\n    test_same(\"''+x!=''+x;\"); // potentially foldable\n    test_same(\"''+x===''+x;\"); // potentially foldable\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/import/test_sst_service.rs::test_ingest_sst_region_not_found", "code": "pub fn has_region_not_found(&self) -> bool {\n        self.region_not_found.is_some()\n    }", "test": "fn test_ingest_sst_region_not_found() {\n    let (_cluster, mut ctx_not_found, _, import) = new_cluster_and_tikv_import_client();\n\n    let temp_dir = Builder::new()\n        .prefix(\"test_ingest_sst_errors\")\n        .tempdir()\n        .unwrap();\n\n    ctx_not_found.set_region_id(1 << 31); // A large region id that must no exists.\n    let sst_path = temp_dir.path().join(\"test_split.sst\");\n    let sst_range = (0, 100);\n    let (mut meta, _data) = gen_sst_file(sst_path, sst_range);\n    meta.set_region_id(ctx_not_found.get_region_id());\n    meta.set_region_epoch(ctx_not_found.get_region_epoch().clone());\n\n    let mut ingest = IngestRequest::default();\n    ingest.set_context(ctx_not_found);\n    ingest.set_sst(meta);\n    let resp = import.ingest(&ingest).unwrap();\n    assert!(resp.get_error().has_region_not_found());\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_parser/src/parser/tests/format/expression.rs::call", "code": "fn test_formatting(source: &'static str) {\n    // Remove preceding newline.\n\n    use crate::{Parser, Source};\n    use boa_interner::{Interner, ToInternedString};\n    let source = &source[1..];\n\n    // Find out how much the code is indented\n    let first_line = &source[..source.find('\\n').unwrap()];\n    let trimmed_first_line = first_line.trim();\n    let characters_to_remove = first_line.len() - trimmed_first_line.len();\n\n    let scenario = source\n        .lines()\n        .map(|l| &l[characters_to_remove..]) // Remove preceding whitespace from each line\n        .collect::<Vec<&'static str>>()\n        .join(\"\\n\");\n    let source = Source::from_bytes(source);\n    let interner = &mut Interner::default();\n    let result = Parser::new(source)\n        .parse_script(interner)\n        .expect(\"parsing failed\")\n        .to_interned_string(interner);\n    if scenario != result {\n        eprint!(\"========= Expected:\\n{scenario}\");\n        eprint!(\"========= Got:\\n{result}\");\n        // Might be helpful to find differing whitespace\n        eprintln!(\"========= Expected: {scenario:?}\");\n        eprintln!(\"========= Got:      {result:?}\");\n        panic!(\"parsing test did not give the correct result (see above)\");\n    }\n}", "test": "fn call() {\n    test_formatting(\n        r#\"\n        call_1(1, 2, 3);\n        call_2(\"argument here\");\n        call_3();\n        \"#,\n    );\n}"}
{"test_id": "tokio-rs-prost/tokio-rs-prost-0c89fa6/tests/src/message_encoding.rs::check_scalar_types", "code": "pub fn check_message<M>(msg: &M)\nwhere\n    M: Message + Default + PartialEq,\n{\n    let expected_len = msg.encoded_len();\n\n    let mut buf = Vec::with_capacity(18);\n    msg.encode(&mut buf).unwrap();\n    assert_eq!(expected_len, buf.len());\n\n    let mut buf = &*buf;\n    let roundtrip = M::decode(&mut buf).unwrap();\n\n    assert!(\n        !buf.has_remaining(),\n        \"expected buffer to be empty: {}\",\n        buf.remaining()\n    );\n    assert_eq!(msg, &roundtrip);\n}", "test": "fn check_scalar_types() {\n    check_message(&ScalarTypes::default());\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_multi.rs::test_node_catch_up_logs", "code": "pub fn get_engine(&self, node_id: u64) -> WrapFactory<EK> {\n        WrapFactory::new(\n            self.pd_client.clone(),\n            self.raft_engines[&node_id].clone(),\n            self.tablet_registries[&node_id].clone(),\n        )\n    }", "test": "fn test_node_catch_up_logs() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.cfg.raft_store.raft_base_tick_interval = ReadableDuration::millis(500);\n    cluster.cfg.raft_store.raft_max_size_per_msg = ReadableSize(5);\n    cluster.cfg.raft_store.raft_election_timeout_ticks = 50;\n    cluster.cfg.raft_store.max_leader_missing_duration = ReadableDuration::hours(1);\n    cluster.cfg.raft_store.peer_stale_state_check_interval = ReadableDuration::minutes(30);\n    cluster.cfg.raft_store.abnormal_leader_missing_duration = ReadableDuration::hours(1);\n    // disable compact log to make test more stable.\n    cluster.cfg.raft_store.raft_log_gc_threshold = 3000;\n    cluster.pd_client.disable_default_operator();\n    // We use three peers([1, 2, 3]) for this test.\n    let r1 = cluster.run_conf_change();\n    cluster.pd_client.must_add_peer(r1, new_peer(2, 2));\n    cluster.pd_client.must_add_peer(r1, new_peer(3, 3));\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n    cluster.stop_node(3);\n    for i in 0..10 {\n        let v = format!(\"{:04}\", i);\n        cluster.async_put(v.as_bytes(), v.as_bytes()).unwrap();\n    }\n    must_get_equal(&cluster.get_engine(1), b\"0009\", b\"0009\");\n    cluster.run_node(3).unwrap();\n    must_get_equal(&cluster.get_engine(3), b\"0009\", b\"0009\");\n}"}
{"test_id": "rust-bitcoin-rust-bitcoin/rust-bitcoin-rust-bitcoin-5ee33ea/bitcoin/tests/serde.rs::serde_regression_relative_lock_time_time", "code": "pub fn serialize(&self) -> Vec<u8> {\n        let mut buf: Vec<u8> = Vec::new();\n\n        //  <magic>\n        buf.extend_from_slice(b\"psbt\");\n\n        buf.push(0xff_u8);\n\n        buf.extend(self.serialize_map());\n\n        for i in &self.inputs {\n            buf.extend(i.serialize_map());\n        }\n\n        for i in &self.outputs {\n            buf.extend(i.serialize_map());\n        }\n\n        buf\n    }", "test": "fn serde_regression_relative_lock_time_time() {\n    let t = relative::LockTime::from(relative::Time::from_512_second_intervals(0xFACE_u16));\n    let got = serialize(&t).unwrap();\n\n    let want = include_bytes!(\"data/serde/relative_lock_time_seconds_bincode\") as &[_];\n    assert_eq!(got, want);\n}"}
{"test_id": "dtolnay-semver/dtolnay-semver-750f0ac/tests/test_version.rs::test_parse", "code": "pub(super) fn prerelease(text: &str) -> Prerelease {\n    Prerelease::new(text).unwrap()\n}", "test": "fn test_parse() {\n    let err = version_err(\"\");\n    assert_to_string(err, \"empty string, expected a semver version\");\n\n    let err = version_err(\"  \");\n    assert_to_string(\n        err,\n        \"unexpected character ' ' while parsing major version number\",\n    );\n\n    let err = version_err(\"1\");\n    assert_to_string(\n        err,\n        \"unexpected end of input while parsing major version number\",\n    );\n\n    let err = version_err(\"1.2\");\n    assert_to_string(\n        err,\n        \"unexpected end of input while parsing minor version number\",\n    );\n\n    let err = version_err(\"1.2.3-\");\n    assert_to_string(err, \"empty identifier segment in pre-release identifier\");\n\n    let err = version_err(\"a.b.c\");\n    assert_to_string(\n        err,\n        \"unexpected character 'a' while parsing major version number\",\n    );\n\n    let err = version_err(\"1.2.3 abc\");\n    assert_to_string(err, \"unexpected character ' ' after patch version number\");\n\n    let err = version_err(\"1.2.3-01\");\n    assert_to_string(err, \"invalid leading zero in pre-release identifier\");\n\n    let err = version_err(\"1.2.3++\");\n    assert_to_string(err, \"empty identifier segment in build metadata\");\n\n    let err = version_err(\"07\");\n    assert_to_string(err, \"invalid leading zero in major version number\");\n\n    let err = version_err(\"111111111111111111111.0.0\");\n    assert_to_string(err, \"value of major version number exceeds u64::MAX\");\n\n    let err = version_err(\"8\\0\");\n    assert_to_string(err, \"unexpected character '\\\\0' after major version number\");\n\n    let parsed = version(\"1.2.3\");\n    let expected = Version::new(1, 2, 3);\n    assert_eq!(parsed, expected);\n    let expected = Version {\n        major: 1,\n        minor: 2,\n        patch: 3,\n        pre: Prerelease::EMPTY,\n        build: BuildMetadata::EMPTY,\n    };\n    assert_eq!(parsed, expected);\n\n    let parsed = version(\"1.2.3-alpha1\");\n    let expected = Version {\n        major: 1,\n        minor: 2,\n        patch: 3,\n        pre: prerelease(\"alpha1\"),\n        build: BuildMetadata::EMPTY,\n    };\n    assert_eq!(parsed, expected);\n\n    let parsed = version(\"1.2.3+build5\");\n    let expected = Version {\n        major: 1,\n        minor: 2,\n        patch: 3,\n        pre: Prerelease::EMPTY,\n        build: build_metadata(\"build5\"),\n    };\n    assert_eq!(parsed, expected);\n\n    let parsed = version(\"1.2.3+5build\");\n    let expected = Version {\n        major: 1,\n        minor: 2,\n        patch: 3,\n        pre: Prerelease::EMPTY,\n        build: build_metadata(\"5build\"),\n    };\n    assert_eq!(parsed, expected);\n\n    let parsed = version(\"1.2.3-alpha1+build5\");\n    let expected = Version {\n        major: 1,\n        minor: 2,\n        patch: 3,\n        pre: prerelease(\"alpha1\"),\n        build: build_metadata(\"build5\"),\n    };\n    assert_eq!(parsed, expected);\n\n    let parsed = version(\"1.2.3-1.alpha1.9+build5.7.3aedf\");\n    let expected = Version {\n        major: 1,\n        minor: 2,\n        patch: 3,\n        pre: prerelease(\"1.alpha1.9\"),\n        build: build_metadata(\"build5.7.3aedf\"),\n    };\n    assert_eq!(parsed, expected);\n\n    let parsed = version(\"1.2.3-0a.alpha1.9+05build.7.3aedf\");\n    let expected = Version {\n        major: 1,\n        minor: 2,\n        patch: 3,\n        pre: prerelease(\"0a.alpha1.9\"),\n        build: build_metadata(\"05build.7.3aedf\"),\n    };\n    assert_eq!(parsed, expected);\n\n    let parsed = version(\"0.4.0-beta.1+0851523\");\n    let expected = Version {\n        major: 0,\n        minor: 4,\n        patch: 0,\n        pre: prerelease(\"beta.1\"),\n        build: build_metadata(\"0851523\"),\n    };\n    assert_eq!(parsed, expected);\n\n    // for https://nodejs.org/dist/index.json, where some older npm versions are \"1.1.0-beta-10\"\n    let parsed = version(\"1.1.0-beta-10\");\n    let expected = Version {\n        major: 1,\n        minor: 1,\n        patch: 0,\n        pre: prerelease(\"beta-10\"),\n        build: BuildMetadata::EMPTY,\n    };\n    assert_eq!(parsed, expected);\n}"}
{"test_id": "hyperium-http/hyperium-http-818269d/tests/header_map.rs::remove_entry_multi_0", "code": "fn remove_all_values<K>(headers: &mut HeaderMap, key: K) -> Vec<HeaderValue>\n    where K: IntoHeaderName\n{\n    match headers.entry(key) {\n        Entry::Occupied(e) => e.remove_entry_mult().1.collect(),\n        Entry::Vacant(_) => vec![],\n    }\n}", "test": "fn remove_entry_multi_0() {\n    let mut headers = HeaderMap::new();\n    let cookies = remove_all_values(&mut headers, SET_COOKIE);\n    assert_eq!(cookies.len(), 0);\n    assert_eq!(headers.len(), 0);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_storage.rs::test_async_apply_prewrite_fallback", "code": "pub fn recv_timeout<S, I>(s: &mut S, dur: std::time::Duration) -> Result<Option<I>, ()>\nwhere\n    S: Stream<Item = I> + Unpin,\n{\n    poll_timeout(&mut s.next(), dur)\n}", "test": "fn test_async_apply_prewrite_fallback() {\n    let mut cluster = new_server_cluster(0, 1);\n    cluster.run();\n\n    let engine = cluster\n        .sim\n        .read()\n        .unwrap()\n        .storages\n        .get(&1)\n        .unwrap()\n        .clone();\n    let storage = TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine, MockLockManager::new())\n        .async_apply_prewrite(true)\n        .build()\n        .unwrap();\n\n    let mut ctx = Context::default();\n    ctx.set_region_id(1);\n    ctx.set_region_epoch(cluster.get_region_epoch(1));\n    ctx.set_peer(cluster.leader_of_region(1).unwrap());\n\n    let before_async_apply_prewrite_finish = \"before_async_apply_prewrite_finish\";\n    let on_handle_apply = \"on_handle_apply\";\n\n    fail::cfg(before_async_apply_prewrite_finish, \"return()\").unwrap();\n    fail::cfg(on_handle_apply, \"pause\").unwrap();\n\n    let (key, value) = (b\"k1\", b\"v1\");\n    let (tx, rx) = channel();\n    storage\n        .sched_txn_command(\n            commands::Prewrite::new(\n                vec![Mutation::make_put(Key::from_raw(key), value.to_vec())],\n                key.to_vec(),\n                10.into(),\n                0,\n                false,\n                1,\n                0.into(),\n                0.into(),\n                Some(vec![]),\n                false,\n                AssertionLevel::Off,\n                ctx.clone(),\n            ),\n            Box::new(move |r| tx.send(r).unwrap()),\n        )\n        .unwrap();\n\n    assert_eq!(\n        rx.recv_timeout(Duration::from_millis(200)).unwrap_err(),\n        RecvTimeoutError::Timeout\n    );\n\n    fail::remove(on_handle_apply);\n\n    let res = rx.recv().unwrap().unwrap();\n    assert!(res.min_commit_ts > 10.into());\n\n    fail::remove(before_async_apply_prewrite_finish);\n\n    let (tx, rx) = channel();\n    storage\n        .sched_txn_command(\n            commands::Commit::new(vec![Key::from_raw(key)], 10.into(), res.min_commit_ts, ctx),\n            Box::new(move |r| tx.send(r).unwrap()),\n        )\n        .unwrap();\n\n    rx.recv_timeout(Duration::from_secs(5)).unwrap().unwrap();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_tail.rs::test_single_big_args", "code": "pub fn run(&mut self) -> CmdResult {\n        self.run_no_wait().wait().unwrap()\n    }", "test": "fn test_single_big_args() {\n    const FILE: &str = \"single_big_args.txt\";\n    const EXPECTED_FILE: &str = \"single_big_args_expected.txt\";\n    const LINES: usize = 1_000_000;\n    const N_ARG: usize = 100_000;\n\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let mut big_input = at.make_file(FILE);\n    for i in 0..LINES {\n        writeln!(big_input, \"Line {i}\").expect(\"Could not write to FILE\");\n    }\n    big_input.flush().expect(\"Could not flush FILE\");\n\n    let mut big_expected = at.make_file(EXPECTED_FILE);\n    for i in (LINES - N_ARG)..LINES {\n        writeln!(big_expected, \"Line {i}\").expect(\"Could not write to EXPECTED_FILE\");\n    }\n    big_expected.flush().expect(\"Could not flush EXPECTED_FILE\");\n\n    ucmd.arg(FILE).arg(\"-n\").arg(format!(\"{N_ARG}\")).run();\n    // .stdout_is(at.read(EXPECTED_FILE));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_echo.rs::test_escape_one_slash", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_escape_one_slash() {\n    new_ucmd!()\n        .args(&[\"-e\", \"foo\\\\ bar\"])\n        .succeeds()\n        .stdout_only(\"foo\\\\ bar\\n\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_chown.rs::test_chown_only_group_id_nonexistent_group", "code": "pub fn no_stderr(&self) -> &Self {\n        assert!(\n            self.stderr.is_empty(),\n            \"Expected stderr to be empty, but it's:\\n{}\",\n            self.stderr_str()\n        );\n        self\n    }", "test": "fn test_chown_only_group_id_nonexistent_group() {\n    let ts = TestScenario::new(util_name!());\n    let at = ts.fixtures.clone();\n    at.touch(\"f\");\n    if let Ok(result) = run_ucmd_as_root(&ts, &[\":12345\", \"f\"]) {\n        result.success().no_stdout().no_stderr();\n    } else {\n        print!(\"Test skipped; requires root user\");\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_touch.rs::test_touch_set_both_date_and_reference", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_both_date_and_reference() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let ref_file = \"test_touch_reference\";\n    let file = \"test_touch_set_both_date_and_reference\";\n\n    let start_of_year = str_to_filetime(\"%Y%m%d%H%M\", \"201501011234\");\n\n    at.touch(ref_file);\n    set_file_times(&at, ref_file, start_of_year, start_of_year);\n    assert!(at.file_exists(ref_file));\n\n    ucmd.args(&[\"-d\", \"Thu Jan 01 12:34:00 2015\", \"-r\", ref_file, file])\n        .succeeds()\n        .no_stderr();\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, start_of_year);\n    assert_eq!(mtime, start_of_year);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_printenv.rs::test_get_all", "code": "pub fn stdout_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stdout_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stdout_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_get_all() {\n    TestScenario::new(util_name!())\n        .ucmd()\n        .env(\"HOME\", \"FOO\")\n        .env(\"KEY\", \"VALUE\")\n        .succeeds()\n        .stdout_contains(\"HOME=FOO\")\n        .stdout_contains(\"KEY=VALUE\");\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/ci.rs::file_too_large_config_limit", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn file_too_large_config_limit() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    fs.insert(PathBuf::from(\"biome.json\"), CONFIG_FILE_SIZE_LIMIT);\n\n    let file_path = Path::new(\"ci.js\");\n    fs.insert(file_path.into(), \"statement1();\\nstatement2();\");\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"ci\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"file_too_large_config_limit\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/allow_duplicate_recipes.rs::allow_duplicate_recipes", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn allow_duplicate_recipes() {\n  Test::new()\n    .justfile(\n      \"\n      b:\n        echo foo\n      b:\n        echo bar\n\n      set allow-duplicate-recipes\n    \",\n    )\n    .stdout(\"bar\\n\")\n    .stderr(\"echo bar\\n\")\n    .run();\n}"}
{"test_id": "rustls-rustls/rustls-rustls-ae583bd/rustls/tests/api.rs::client_stream_read", "code": "fn test_client_stream_read(stream_kind: StreamKind, read_kind: ReadKind) {\n    for kt in ALL_KEY_TYPES.iter() {\n        let (mut client, mut server) = make_pair(*kt);\n        let data = b\"world\";\n        server.writer().write_all(data).unwrap();\n\n        {\n            let mut pipe = OtherSession::new(&mut server);\n            transfer_eof(&mut client);\n\n            let stream: Box<dyn Read> = match stream_kind {\n                StreamKind::Ref => Box::new(Stream::new(&mut client, &mut pipe)),\n                StreamKind::Owned => Box::new(StreamOwned::new(client, pipe)),\n            };\n\n            test_stream_read(read_kind, stream, data)\n        }\n    }\n}", "test": "fn client_stream_read() {\n    test_client_stream_read(StreamKind::Ref, ReadKind::Buf);\n    test_client_stream_read(StreamKind::Owned, ReadKind::Buf);\n    #[cfg(read_buf)]\n    {\n        test_client_stream_read(StreamKind::Ref, ReadKind::BorrowedBuf);\n        test_client_stream_read(StreamKind::Owned, ReadKind::BorrowedBuf);\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_rm.rs::test_rm_silently_accepts_presume_input_tty2", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_silently_accepts_presume_input_tty2() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_2 = \"test_rm_silently_accepts_presume_input_tty2\";\n\n    at.touch(file_2);\n\n    ucmd.arg(\"---presume-input-tty\").arg(file_2).succeeds();\n\n    assert!(!at.file_exists(file_2));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_ln.rs::test_symlink_interactive", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_interactive() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let file = \"test_symlink_interactive_file\";\n    let link = \"test_symlink_interactive_file_link\";\n\n    at.touch(file);\n    at.touch(link);\n\n    scene\n        .ucmd()\n        .args(&[\"-i\", \"-s\", file, link])\n        .pipe_in(\"n\")\n        .fails()\n        .no_stdout();\n\n    assert!(at.file_exists(file));\n    assert!(!at.is_symlink(link));\n\n    scene\n        .ucmd()\n        .args(&[\"-i\", \"-s\", file, link])\n        .pipe_in(\"Yesh\") // spell-checker:disable-line\n        .succeeds()\n        .no_stdout();\n\n    assert!(at.file_exists(file));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_date.rs::test_date_rfc_8601_second", "code": "pub fn stdout_matches(&self, regex: &regex::Regex) -> &Self {\n        assert!(\n            regex.is_match(self.stdout_str()),\n            \"Stdout does not match regex:\\n{}\",\n            self.stdout_str()\n        );\n        self\n    }", "test": "fn test_date_rfc_8601_second() {\n    let re = Regex::new(r\"^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}[+-]\\d{2}:\\d{2}\\n$\").unwrap();\n    for param in [\"--iso-8601\", \"--i\"] {\n        new_ucmd!()\n            .arg(format!(\"{param}=second\"))\n            .succeeds()\n            .stdout_matches(&re);\n        new_ucmd!()\n            .arg(format!(\"{param}=seconds\"))\n            .succeeds()\n            .stdout_matches(&re);\n    }\n}"}
{"test_id": "marshallpierce-rust-base64/marshallpierce-rust-base64-4ef33cc/tests/encode.rs::encode_all_bytes", "code": "fn compare_encode(expected: &str, target: &[u8]) {\n    assert_eq!(expected, STANDARD.encode(target));\n}", "test": "fn encode_all_bytes() {\n    let bytes: Vec<u8> = (0..=255).collect();\n\n    compare_encode(\n        \"AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7P\\\n         D0+P0BBQkNERUZHSElKS0xNTk9QUVJTVFVWV1hZWltcXV5fYGFiY2RlZmdoaWprbG1ub3BxcnN0dXZ3eHl6e3x9fn\\\n         +AgYKDhIWGh4iJiouMjY6PkJGSk5SVlpeYmZqbnJ2en6ChoqOkpaanqKmqq6ytrq+wsbKztLW2t7i5uru8vb6\\\n         /wMHCw8TFxsfIycrLzM3Oz9DR0tPU1dbX2Nna29zd3t/g4eLj5OXm5+jp6uvs7e7v8PHy8/T19vf4+fr7/P3+/w==\",\n        &bytes,\n    );\n}"}
{"test_id": "rust-bitcoin-rust-bitcoin/rust-bitcoin-rust-bitcoin-5ee33ea/bitcoin/tests/serde.rs::serde_regression_script", "code": "pub fn serialize(&self) -> Vec<u8> {\n        let mut buf: Vec<u8> = Vec::new();\n\n        //  <magic>\n        buf.extend_from_slice(b\"psbt\");\n\n        buf.push(0xff_u8);\n\n        buf.extend(self.serialize_map());\n\n        for i in &self.inputs {\n            buf.extend(i.serialize_map());\n        }\n\n        for i in &self.outputs {\n            buf.extend(i.serialize_map());\n        }\n\n        buf\n    }", "test": "fn serde_regression_script() {\n    let script = ScriptBuf::from(vec![0u8, 1u8, 2u8]);\n    let got = serialize(&script).unwrap();\n    let want = include_bytes!(\"data/serde/script_bincode\") as &[_];\n    assert_eq!(got, want)\n}"}
{"test_id": "rust-lang-regex/rust-lang-regex-cf1a26a/tests/crazy.rs::dfa_handles_pathological_case", "code": "pub fn is_match(&self, text: &[u8]) -> bool {\n        self.is_match_at(text, 0)\n    }", "test": "fn dfa_handles_pathological_case() {\n    fn ones_and_zeroes(count: usize) -> String {\n        use rand::{Rng, thread_rng};\n\n        let mut rng = thread_rng();\n        let mut s = String::new();\n        for _ in 0..count {\n            if rng.gen() {\n                s.push('1');\n            } else {\n                s.push('0');\n            }\n        }\n        s\n    }\n\n    let re = regex!(r\"[01]*1[01]{20}$\");\n    let text = {\n        let mut pieces = ones_and_zeroes(100_000);\n        pieces.push('1');\n        pieces.push_str(&ones_and_zeroes(20));\n        pieces\n    };\n    assert!(re.is_match(text!(&*text)));\n}"}
{"test_id": "web-infra-dev-oxc/oxc-project-oxc-884a819/crates/oxc_minifier/tests/oxc/precedence.rs::logical_or", "code": "fn test(args: &[&str]) -> LintResult {\n        let mut new_args = vec![\"--quiet\"];\n        new_args.extend(args);\n        let options = lint_command().run_inner(new_args.as_slice()).unwrap().lint_options;\n        let CliRunResult::LintResult(lint_result) = LintRunner::new(options).run() else {\n            unreachable!()\n        };\n        lint_result\n    }", "test": "fn logical_or() {\n    test(\"a || b || c\", \"a||b||c;\");\n    test(\"(a || (b || c)) || d\", \"a||b||c||d;\");\n    test(\"a || (b || (c || d))\", \"a||b||c||d;\");\n    test(\"a || b && c\", \"a||b&&c;\");\n    test(\"(a || b) && c\", \"(a||b)&&c;\");\n    test(\"a, b || c, d\", \"a,b||c,d;\");\n    test(\"(a, b) || (c, d)\", \"(a,b)||(c,d);\");\n    test(\"(a && b) || (c && d)\", \"a&&b||c&&d;\");\n    test(\"a && b || c && d\", \"a&&b||c&&d;\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/storage/test_storage.rs::test_txn_store_batch_get", "code": "pub fn batch_get_ok(&self, keys: &[&[u8]], ts: impl Into<TimeStamp>, expect: Vec<&[u8]>) {\n        let keys: Vec<Key> = keys.iter().map(|x| Key::from_raw(x)).collect();\n        let result: Vec<Vec<u8>> = self\n            .store\n            .batch_get(self.ctx.clone(), &keys, ts.into())\n            .unwrap()\n            .0\n            .into_iter()\n            .map(|x| x.unwrap().1)\n            .collect();\n        let expect: Vec<Vec<u8>> = expect.into_iter().map(|x| x.to_vec()).collect();\n        assert_eq!(result, expect);\n    }", "test": "fn test_txn_store_batch_get() {\n    let store = AssertionStorage::default();\n    store.put_ok(b\"x\", b\"x1\", 5, 10);\n    store.put_ok(b\"y\", b\"y1\", 15, 20);\n    store.put_ok(b\"z\", b\"z1\", 25, 30);\n    store.batch_get_ok(&[b\"x\", b\"y\", b\"z\", b\"w\"], 15, vec![b\"x1\"]);\n    store.batch_get_ok(&[b\"x\", b\"y\", b\"z\", b\"w\"], 16, vec![b\"x1\"]);\n    store.batch_get_ok(&[b\"x\", b\"y\", b\"z\", b\"w\"], 19, vec![b\"x1\"]);\n    store.batch_get_ok(&[b\"x\", b\"y\", b\"z\", b\"w\"], 20, vec![b\"x1\", b\"y1\"]);\n    store.batch_get_ok(&[b\"x\", b\"y\", b\"z\", b\"w\"], 21, vec![b\"x1\", b\"y1\"]);\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/client_future_tests.rs::test_query_udp_ipv4", "code": "fn block_on<F: Future>(&mut self, future: F) -> F::Output {\n        async_std::task::block_on(future)\n    }", "test": "fn test_query_udp_ipv4() {\n    let io_loop = Runtime::new().unwrap();\n    let addr: SocketAddr = (\"8.8.8.8\", 53).to_socket_addrs().unwrap().next().unwrap();\n    let stream = UdpClientStream::<TokioUdpSocket>::new(addr);\n    let client = AsyncClient::connect(stream);\n    let (mut client, bg) = io_loop.block_on(client).expect(\"client failed to connect\");\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    // TODO: timeouts on these requests so that the test doesn't hang\n    io_loop.block_on(test_query(&mut client));\n    io_loop.block_on(test_query(&mut client));\n    io_loop.block_on(test_query_edns(&mut client));\n}"}
{"test_id": "gfx-rs-naga/gfx-rs-naga-92e41b4/tests/snapshots.rs::convert_wgsl", "code": "fn check_targets(\n    input: &Input,\n    module: &mut naga::Module,\n    targets: Targets,\n    source_code: Option<&str>,\n) {\n    let params = input.read_parameters();\n    let name = &input.file_name;\n\n    let capabilities = if params.god_mode {\n        naga::valid::Capabilities::all()\n    } else {\n        naga::valid::Capabilities::default()\n    };\n\n    #[cfg(feature = \"serialize\")]\n    {\n        if targets.contains(Targets::IR) {\n            let config = ron::ser::PrettyConfig::default().new_line(\"\\n\".to_string());\n            let string = ron::ser::to_string_pretty(module, config).unwrap();\n            input.write_output_file(\"ir\", \"ron\", string);\n        }\n    }\n\n    let info = naga::valid::Validator::new(naga::valid::ValidationFlags::all(), capabilities)\n        .validate(module)\n        .expect(&format!(\n            \"Naga module validation failed on test '{}'\",\n            name.display()\n        ));\n\n    #[cfg(feature = \"compact\")]\n    let info = {\n        naga::compact::compact(module);\n\n        #[cfg(feature = \"serialize\")]\n        {\n            if targets.contains(Targets::IR) {\n                let config = ron::ser::PrettyConfig::default().new_line(\"\\n\".to_string());\n                let string = ron::ser::to_string_pretty(module, config).unwrap();\n                input.write_output_file(\"ir\", \"compact.ron\", string);\n            }\n        }\n\n        naga::valid::Validator::new(naga::valid::ValidationFlags::all(), capabilities)\n            .validate(module)\n            .expect(&format!(\n                \"Post-compaction module validation failed on test '{}'\",\n                name.display()\n            ))\n    };\n\n    #[cfg(feature = \"serialize\")]\n    {\n        if targets.contains(Targets::ANALYSIS) {\n            let config = ron::ser::PrettyConfig::default().new_line(\"\\n\".to_string());\n            let string = ron::ser::to_string_pretty(&info, config).unwrap();\n            input.write_output_file(\"analysis\", \"info.ron\", string);\n        }\n    }\n\n    #[cfg(all(feature = \"deserialize\", feature = \"spv-out\"))]\n    {\n        let debug_info = if cfg!(feature = \"span\") {\n            source_code.map(|code| naga::back::spv::DebugInfo {\n                source_code: code,\n                file_name: name.as_ref(),\n            })\n        } else {\n            None\n        };\n\n        if targets.contains(Targets::SPIRV) {\n            write_output_spv(\n                input,\n                module,\n                &info,\n                debug_info,\n                &params.spv,\n                params.bounds_check_policies,\n            );\n        }\n    }\n    #[cfg(all(feature = \"deserialize\", feature = \"msl-out\"))]\n    {\n        if targets.contains(Targets::METAL) {\n            write_output_msl(\n                input,\n                module,\n                &info,\n                &params.msl,\n                &params.msl_pipeline,\n                params.bounds_check_policies,\n            );\n        }\n    }\n    #[cfg(all(feature = \"deserialize\", feature = \"glsl-out\"))]\n    {\n        if targets.contains(Targets::GLSL) {\n            for ep in module.entry_points.iter() {\n                if params.glsl_exclude_list.contains(&ep.name) {\n                    continue;\n                }\n                write_output_glsl(\n                    input,\n                    module,\n                    &info,\n                    ep.stage,\n                    &ep.name,\n                    &params.glsl,\n                    params.bounds_check_policies,\n                    params.glsl_multiview,\n                );\n            }\n        }\n    }\n    #[cfg(feature = \"dot-out\")]\n    {\n        if targets.contains(Targets::DOT) {\n            let string = naga::back::dot::write(module, Some(&info), Default::default()).unwrap();\n            input.write_output_file(\"dot\", \"dot\", string);\n        }\n    }\n    #[cfg(all(feature = \"deserialize\", feature = \"hlsl-out\"))]\n    {\n        if targets.contains(Targets::HLSL) {\n            write_output_hlsl(input, module, &info, &params.hlsl);\n        }\n    }\n    #[cfg(all(feature = \"deserialize\", feature = \"wgsl-out\"))]\n    {\n        if targets.contains(Targets::WGSL) {\n            write_output_wgsl(input, module, &info, &params.wgsl);\n        }\n    }\n}", "test": "fn convert_wgsl() {\n    let _ = env_logger::try_init();\n\n    let inputs = [\n        // TODO: merge array-in-ctor and array-in-function-return-type tests after fix HLSL issue https://github.com/gfx-rs/naga/issues/1930\n        (\n            \"array-in-ctor\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\n            \"array-in-function-return-type\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::WGSL,\n        ),\n        (\n            \"empty\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\n            \"quad\",\n            Targets::SPIRV\n                | Targets::METAL\n                | Targets::GLSL\n                | Targets::DOT\n                | Targets::HLSL\n                | Targets::WGSL,\n        ),\n        (\n            \"bits\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\n            \"bitcast\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\n            \"boids\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\n            \"skybox\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\n            \"collatz\",\n            Targets::SPIRV\n                | Targets::METAL\n                | Targets::IR\n                | Targets::ANALYSIS\n                | Targets::HLSL\n                | Targets::WGSL,\n        ),\n        (\n            \"shadow\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\n            \"image\",\n            Targets::SPIRV | Targets::METAL | Targets::HLSL | Targets::WGSL | Targets::GLSL,\n        ),\n        (\"extra\", Targets::SPIRV | Targets::METAL | Targets::WGSL),\n        (\"push-constants\", Targets::GLSL | Targets::HLSL),\n        (\n            \"operators\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\n            \"functions\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\n            \"fragment-output\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\n            \"dualsource\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\"functions-webgl\", Targets::GLSL),\n        (\n            \"interpolate\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\n            \"access\",\n            Targets::SPIRV\n                | Targets::METAL\n                | Targets::GLSL\n                | Targets::HLSL\n                | Targets::WGSL\n                | Targets::IR\n                | Targets::ANALYSIS,\n        ),\n        (\n            \"atomicOps\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\"atomicCompareExchange\", Targets::SPIRV | Targets::WGSL),\n        (\n            \"padding\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\"pointers\", Targets::SPIRV | Targets::WGSL),\n        (\n            \"control-flow\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\n            \"standard\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        //TODO: GLSL https://github.com/gfx-rs/naga/issues/874\n        (\n            \"interface\",\n            Targets::SPIRV | Targets::METAL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\n            \"globals\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\"bounds-check-zero\", Targets::SPIRV | Targets::METAL),\n        (\"bounds-check-zero-atomic\", Targets::METAL),\n        (\"bounds-check-restrict\", Targets::SPIRV | Targets::METAL),\n        (\n            \"bounds-check-image-restrict\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL,\n        ),\n        (\n            \"bounds-check-image-rzsw\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL,\n        ),\n        (\"policy-mix\", Targets::SPIRV | Targets::METAL),\n        (\n            \"texture-arg\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\"cubeArrayShadow\", Targets::GLSL),\n        (\n            \"math-functions\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\n            \"binding-arrays\",\n            Targets::WGSL | Targets::HLSL | Targets::METAL | Targets::SPIRV,\n        ),\n        (\n            \"binding-buffer-arrays\",\n            Targets::WGSL | Targets::SPIRV, //TODO: more backends, eventually merge into \"binding-arrays\"\n        ),\n        (\"resource-binding-map\", Targets::METAL),\n        (\"multiview\", Targets::SPIRV | Targets::GLSL | Targets::WGSL),\n        (\"multiview_webgl\", Targets::GLSL),\n        (\n            \"break-if\",\n            Targets::WGSL | Targets::GLSL | Targets::SPIRV | Targets::HLSL | Targets::METAL,\n        ),\n        (\"lexical-scopes\", Targets::WGSL),\n        (\"type-alias\", Targets::WGSL),\n        (\"module-scope\", Targets::WGSL),\n        (\n            \"workgroup-var-init\",\n            Targets::WGSL | Targets::GLSL | Targets::SPIRV | Targets::HLSL | Targets::METAL,\n        ),\n        (\n            \"workgroup-uniform-load\",\n            Targets::WGSL | Targets::GLSL | Targets::SPIRV | Targets::HLSL | Targets::METAL,\n        ),\n        (\"runtime-array-in-unused-struct\", Targets::SPIRV),\n        (\"sprite\", Targets::SPIRV),\n        (\"force_point_size_vertex_shader_webgl\", Targets::GLSL),\n        (\"invariant\", Targets::GLSL),\n        (\"ray-query\", Targets::SPIRV | Targets::METAL),\n        (\"hlsl-keyword\", Targets::HLSL),\n        (\n            \"constructors\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\"msl-varyings\", Targets::METAL),\n        (\n            \"const-exprs\",\n            Targets::SPIRV | Targets::METAL | Targets::GLSL | Targets::HLSL | Targets::WGSL,\n        ),\n        (\"separate-entry-points\", Targets::SPIRV | Targets::GLSL),\n    ];\n\n    for &(name, targets) in inputs.iter() {\n        // WGSL shaders lives in root dir as a privileged.\n        let input = Input::new(None, name, \"wgsl\");\n        let source = input.read_source();\n        match naga::front::wgsl::parse_str(&source) {\n            Ok(mut module) => check_targets(&input, &mut module, targets, None),\n            Err(e) => panic!(\"{}\", e.emit_to_string(&source)),\n        }\n    }\n\n    #[cfg(feature = \"span\")]\n    {\n        let inputs = [\n            (\"debug-symbol-simple\", Targets::SPIRV),\n            (\"debug-symbol-terrain\", Targets::SPIRV),\n        ];\n        for &(name, targets) in inputs.iter() {\n            // WGSL shaders lives in root dir as a privileged.\n            let input = Input::new(None, name, \"wgsl\");\n            let source = input.read_source();\n            match naga::front::wgsl::parse_str(&source) {\n                Ok(mut module) => check_targets(&input, &mut module, targets, Some(&source)),\n                Err(e) => panic!(\"{}\", e.emit_to_string(&source)),\n            }\n        }\n    }\n}"}
{"test_id": "mitsuhiko-minijinja/mitsuhiko-minijinja-5f2c1e8/minijinja-contrib/tests/datetime.rs::test_dateformat_chrono_rs", "code": "pub fn eval<S: Serialize>(&self, ctx: S) -> Result<Value, Error> {\n        // reduce total amount of code faling under mono morphization into\n        // this function, and share the rest in _eval.\n        self._eval(Value::from_serializable(&ctx))\n    }", "test": "fn test_dateformat_chrono_rs() {\n    let mut env = minijinja::Environment::new();\n    env.add_global(\"TIMEZONE\", \"Europe/Vienna\");\n    env.add_global(\"DATE_FORMAT\", \"[year]-[month]\");\n    minijinja_contrib::add_to_environment(&mut env);\n\n    let expr = env\n        .compile_expression(\"d|dateformat(format=format)\")\n        .unwrap();\n\n    let d = chrono::NaiveDate::from_num_days_from_ce_opt(739073);\n    assert_eq!(\n        expr.eval(context!(d, format => \"short\"))\n            .unwrap()\n            .to_string(),\n        \"2024-07-06\"\n    );\n\n    assert_eq!(\n        expr.eval(context!(d => \"2024-07-06\", format => \"short\"))\n            .unwrap()\n            .to_string(),\n        \"2024-07-06\"\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_seq.rs::test_width_scientific_notation", "code": "pub fn no_stderr(&self) -> &Self {\n        assert!(\n            self.stderr.is_empty(),\n            \"Expected stderr to be empty, but it's:\\n{}\",\n            self.stderr_str()\n        );\n        self\n    }", "test": "fn test_width_scientific_notation() {\n    new_ucmd!()\n        .args(&[\"-w\", \"999\", \"1e3\"])\n        .succeeds()\n        .stdout_is(\"0999\\n1000\\n\")\n        .no_stderr();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_fold.rs::test_bytewise_word_boundary_split_should_preserve_empty_lines", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_bytewise_word_boundary_split_should_preserve_empty_lines() {\n    new_ucmd!()\n        .args(&[\"-s\", \"-b\"])\n        .pipe_in(\"\\n\")\n        .succeeds()\n        .stdout_is(\"\\n\");\n\n    new_ucmd!()\n        .args(&[\"-w1\", \"-s\", \"-b\"])\n        .pipe_in(\"0\\n1\\n\\n2\\n\\n\\n\")\n        .succeeds()\n        .stdout_is(\"0\\n1\\n\\n2\\n\\n\\n\");\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/bin/tests/named_tests.rs::test_ipv4_and_ipv6_toml_startup", "code": "pub fn query_a<C: ClientHandle>(io_loop: &mut Runtime, client: &mut C) {\n    let name = Name::from_str(\"www.example.com\").unwrap();\n    let response = query_message(io_loop, client, name, RecordType::A);\n    let record = &response.answers()[0];\n\n    if let Some(RData::A(ref address)) = record.data() {\n        assert_eq!(address, &A::new(127, 0, 0, 1))\n    } else {\n        panic!(\"wrong RDATA\")\n    }\n}", "test": "fn test_ipv4_and_ipv6_toml_startup() {\n    named_test_harness(\"ipv4_and_ipv6.toml\", |_, tcp_port, _, _, _| {\n        let mut io_loop = Runtime::new().unwrap();\n        let addr: SocketAddr = SocketAddr::new(\n            Ipv4Addr::new(127, 0, 0, 1).into(),\n            tcp_port.expect(\"no tcp_port\"),\n        );\n        let (stream, sender) = TcpClientStream::<AsyncIoTokioAsStd<TokioTcpStream>>::new(addr);\n        let client = AsyncClient::new(Box::new(stream), sender, None);\n\n        let (mut client, bg) = io_loop.block_on(client).expect(\"client failed to connect\");\n        hickory_proto::spawn_bg(&io_loop, bg);\n        // ipv4 should succeed\n        query_a(&mut io_loop, &mut client);\n\n        let addr: SocketAddr = SocketAddr::new(\n            Ipv6Addr::new(0, 0, 0, 0, 0, 0, 0, 1).into(),\n            tcp_port.expect(\"no tcp_port\"),\n        );\n        let (stream, sender) = TcpClientStream::<AsyncIoTokioAsStd<TokioTcpStream>>::new(addr);\n        let client = AsyncClient::new(Box::new(stream), sender, None);\n        let (mut client, bg) = io_loop.block_on(client).expect(\"client failed to connect\");\n        hickory_proto::spawn_bg(&io_loop, bg);\n\n        // ipv6 should succeed\n        query_a(&mut io_loop, &mut client);\n    })\n}"}
{"test_id": "hyperium-h2/hyperium-h2-da38b1c/tests/h2-tests/tests/hammer.rs::hammer_client_concurrency", "code": "pub(crate) fn load(head: Head, mut payload: Bytes) -> Result<Self, Error> {\n        let flags = DataFlags::load(head.flag());\n\n        // The stream identifier must not be zero\n        if head.stream_id().is_zero() {\n            return Err(Error::InvalidStreamId);\n        }\n\n        let pad_len = if flags.is_padded() {\n            let len = util::strip_padding(&mut payload)?;\n            Some(len)\n        } else {\n            None\n        };\n\n        Ok(Data {\n            stream_id: head.stream_id(),\n            data: payload,\n            flags,\n            pad_len,\n        })\n    }", "test": "fn hammer_client_concurrency() {\n    // This reproduces issue #326.\n    const N: usize = 5000;\n\n    let server = Server::serve(|| Bytes::from_static(b\"hello world!\"));\n\n    let addr = server.addr();\n    let rsps = Arc::new(AtomicUsize::new(0));\n\n    for i in 0..N {\n        print!(\"sending {}\", i);\n        let rsps = rsps.clone();\n        let tcp = TcpStream::connect(&addr);\n        let tcp = tcp\n            .then(|res| {\n                let tcp = res.unwrap();\n                client::handshake(tcp)\n            })\n            .then(move |res| {\n                let rsps = rsps;\n                let (mut client, h2) = res.unwrap();\n                let request = Request::builder()\n                    .uri(\"https://http2.akamai.com/\")\n                    .body(())\n                    .unwrap();\n\n                let (response, mut stream) = client.send_request(request, false).unwrap();\n                stream.send_trailers(HeaderMap::new()).unwrap();\n\n                tokio::spawn(async move {\n                    h2.await.unwrap();\n                });\n\n                response\n                    .and_then(|response| {\n                        let mut body = response.into_body();\n\n                        async move {\n                            while let Some(res) = body.data().await {\n                                res?;\n                            }\n                            body.trailers().await?;\n                            Ok(())\n                        }\n                    })\n                    .map_err(|e| {\n                        panic!(\"client error: {:?}\", e);\n                    })\n                    .map(move |_| {\n                        rsps.fetch_add(1, Ordering::Release);\n                    })\n            });\n\n        let rt = tokio::runtime::Runtime::new().unwrap();\n        rt.block_on(tcp);\n        println!(\"...done\");\n    }\n\n    println!(\"all done\");\n\n    assert_eq!(N, rsps.load(Ordering::Acquire));\n    assert_eq!(N, server.request_count());\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/name_server_pool_tests.rs::test_concurrent_requests_1_conn", "code": "pub fn answers(answers: LookupRecords, additionals: Option<LookupRecords>) -> Self {\n        Self::Records {\n            answers,\n            additionals,\n        }\n    }", "test": "fn test_concurrent_requests_1_conn() {\n    let mut options = ResolverOpts::default();\n\n    // there are two connections, but no concurrency requested\n    options.num_concurrent_reqs = 1;\n\n    // we want to make sure that both udp connections are called\n    //   this will count down to 0 only if both are called.\n    let on_send = OnSendBarrier::new(1);\n\n    let query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n\n    let udp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 1));\n\n    let udp_message = message(query.clone(), vec![udp_record.clone()], vec![], vec![]);\n\n    let udp1_nameserver = mock_nameserver_on_send(\n        vec![Ok(DnsResponse::from_message(udp_message).unwrap())],\n        options.clone(),\n        on_send,\n    );\n    let udp2_nameserver = udp1_nameserver.clone();\n\n    let pool = mock_nameserver_pool_on_send(\n        vec![udp2_nameserver, udp1_nameserver],\n        vec![],\n        None,\n        options,\n    );\n\n    // lookup on UDP succeeds, any other would fail\n    let request = message(query, vec![], vec![], vec![]);\n    let future = pool.send(request).first_answer();\n\n    // there's no actual network traffic happening, 1 sec should be plenty\n    //   TODO: for some reason this timeout doesn't work, not clear why...\n    // let future = Timeout::new(future, Duration::from_secs(1));\n\n    let response = block_on(future).unwrap();\n    assert_eq!(response.answers()[0], udp_record);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_rm.rs::test_invalid_arg", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_invalid_arg() {\n    new_ucmd!().arg(\"--definitely-invalid\").fails().code_is(1);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_true.rs::test_version", "code": "pub fn stdout_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stdout_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stdout_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_version() {\n    new_ucmd!()\n        .args(&[\"--version\"])\n        .succeeds()\n        .stdout_contains(\"true\");\n}"}
{"test_id": "ordinals-ord/ordinals-ord-8090538/tests/wallet/inscribe.rs::inscribe_with_parent_inscription_and_fee_rate", "code": "pub fn descriptors(&self) -> Vec<String> {\n    self.state().descriptors.clone()\n  }", "test": "fn inscribe_with_parent_inscription_and_fee_rate() {\n  let rpc_server = test_bitcoincore_rpc::spawn();\n  create_wallet(&rpc_server);\n  rpc_server.mine_blocks(1);\n\n  let parent_output = CommandBuilder::new(\"wallet inscribe --fee-rate 5.0 --file parent.png\")\n    .write(\"parent.png\", [1; 520])\n    .rpc_server(&rpc_server)\n    .run_and_deserialize_output::<Inscribe>();\n\n  assert_eq!(rpc_server.descriptors().len(), 3);\n  let parent_id = parent_output.inscriptions[0].id;\n\n  let commit_tx = &rpc_server.mempool()[0];\n  let reveal_tx = &rpc_server.mempool()[1];\n\n  assert_eq!(\n    ord::FeeRate::try_from(5.0)\n      .unwrap()\n      .fee(commit_tx.vsize() + reveal_tx.vsize())\n      .to_sat(),\n    parent_output.total_fees\n  );\n\n  rpc_server.mine_blocks(1);\n\n  let child_output = CommandBuilder::new(format!(\n    \"wallet inscribe --fee-rate 7.3 --parent {parent_id} --file child.png\"\n  ))\n  .write(\"child.png\", [1; 520])\n  .rpc_server(&rpc_server)\n  .run_and_deserialize_output::<Inscribe>();\n\n  assert_eq!(rpc_server.descriptors().len(), 4);\n  assert_eq!(parent_id, child_output.parent.unwrap());\n\n  let commit_tx = &rpc_server.mempool()[0];\n  let reveal_tx = &rpc_server.mempool()[1];\n\n  assert_eq!(\n    ord::FeeRate::try_from(7.3)\n      .unwrap()\n      .fee(commit_tx.vsize() + reveal_tx.vsize())\n      .to_sat(),\n    child_output.total_fees\n  );\n\n  rpc_server.mine_blocks(1);\n\n  let ord_server = TestServer::spawn_with_args(&rpc_server, &[]);\n\n  ord_server.assert_response_regex(\n    format!(\"/inscription/{}\", child_output.parent.unwrap()),\n    format!(\n      \".*<dt>children</dt>.*<a href=/inscription/{}>.*\",\n      child_output.inscriptions[0].id\n    ),\n  );\n\n  ord_server.assert_response_regex(\n    format!(\"/inscription/{}\", child_output.inscriptions[0].id),\n    format!(\n      \".*<dt>parent</dt>.*<a class=monospace href=/inscription/{}>.*\",\n      child_output.parent.unwrap()\n    ),\n  );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_fmt.rs::test_fmt_goal", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_fmt_goal() {\n    for param in [\"-g\", \"--goal\"] {\n        new_ucmd!()\n            .args(&[\"one-word-per-line.txt\", param, \"7\"])\n            .succeeds()\n            .stdout_is(\"this is a\\nfile with one\\nword per line\\n\");\n    }\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_unsafe_recovery.rs::test_unsafe_recovery_early_return_after_exit_joint_state", "code": "pub fn sleep_ms(ms: u64) {\n    std::thread::sleep(Duration::from_millis(ms));\n}", "test": "fn test_unsafe_recovery_early_return_after_exit_joint_state() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    // Disable default max peer number check.\n    pd_client.disable_default_operator();\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n    // Changes the group config to\n    let peer_on_store0 = find_peer(&region, nodes[0]).unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[1]).unwrap();\n    let peer_on_store2 = find_peer(&region, nodes[2]).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store2.clone());\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), peer_on_store0.clone());\n    cluster.pd_client.must_add_peer(\n        region.get_id(),\n        new_learner_peer(nodes[0], peer_on_store0.get_id()),\n    );\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), peer_on_store2.clone());\n    cluster.pd_client.must_add_peer(\n        region.get_id(),\n        new_learner_peer(nodes[2], peer_on_store2.get_id()),\n    );\n    // Wait the new learner to be initialized.\n    sleep_ms(100);\n    pd_client.must_joint_confchange(\n        region.get_id(),\n        vec![\n            (\n                ConfChangeType::AddNode,\n                new_peer(nodes[0], peer_on_store0.get_id()),\n            ),\n            (\n                ConfChangeType::AddLearnerNode,\n                new_learner_peer(nodes[1], peer_on_store1.get_id()),\n            ),\n        ],\n    );\n    cluster.stop_node(nodes[1]);\n    cluster.stop_node(nodes[2]);\n    cluster.must_wait_for_leader_expire(nodes[0], region.get_id());\n\n    confirm_quorum_is_lost(&mut cluster, &region);\n    cluster.must_enter_force_leader(region.get_id(), nodes[0], vec![nodes[1], nodes[2]]);\n\n    let to_be_removed: Vec<metapb::Peer> = region\n        .get_peers()\n        .iter()\n        .filter(|&peer| peer.get_store_id() != nodes[0])\n        .cloned()\n        .collect();\n    let mut plan = pdpb::RecoveryPlan::default();\n    let mut demote = pdpb::DemoteFailedVoters::default();\n    demote.set_region_id(region.get_id());\n    demote.set_failed_voters(to_be_removed.into());\n    plan.mut_demotes().push(demote);\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);\n    cluster.must_send_store_heartbeat(nodes[0]);\n\n    let mut demoted = true;\n    for _ in 0..10 {\n        let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n        demoted = region\n            .get_peers()\n            .iter()\n            .filter(|peer| peer.get_store_id() != nodes[0])\n            .all(|peer| peer.get_role() == metapb::PeerRole::Learner);\n        if demoted {\n            break;\n        }\n        sleep_ms(100);\n    }\n    assert_eq!(demoted, true);\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/functions.rs::sha256_file", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn sha256_file() {\n  Test::new()\n    .justfile(\"x := sha256_file('sub/shafile')\")\n    .tree(tree! {\n      sub: {\n        shafile: \"just is great\\n\",\n      }\n    })\n    .current_dir(\"sub\")\n    .args([\"--evaluate\", \"x\"])\n    .stdout(\"177b3d79aaafb53a7a4d7aaba99a82f27c73370e8cb0295571aade1e4fea1cd2\")\n    .run();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_seq.rs::test_zero_step_floats", "code": "pub fn fails(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.failure();\n        cmd_result\n    }", "test": "fn test_zero_step_floats() {\n    new_ucmd!().args(&[\"10.0\", \"0\", \"32\"]).fails();\n}"}
{"test_id": "paritytech-wasmi/paritytech-wasmi-d66f271/crates/wasmi/tests/e2e/v1/func.rs::static_add2_works", "code": "pub fn call(\n        &self,\n        mut ctx: impl AsContextMut<UserState = T>,\n        instance: Option<&Instance>,\n        params: FuncParams,\n    ) -> Result<FuncFinished, Trap> {\n        let caller = <Caller<T>>::new(&mut ctx, instance);\n        (self.closure)(caller, params)\n    }", "test": "fn static_add2_works() {\n    let (mut store, add2, add2_dyn) = setup_add2();\n    let add2 = add2.typed::<(i32, i32), i32>(&mut store).unwrap();\n    let add2_dyn = add2_dyn.typed::<(i32, i32), i32>(&mut store).unwrap();\n    for a in 0..10 {\n        for b in 0..10 {\n            let expected = a + b;\n            assert_eq!(add2.call(&mut store, (a, b)).unwrap(), expected);\n            assert_eq!(add2_dyn.call(&mut store, (a, b)).unwrap(), expected);\n        }\n    }\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_common.rs::parse_offset", "code": "pub fn verified_query(&self, sql: &str) -> Query {\n        match self.verified_stmt(sql) {\n            Statement::Query(query) => *query,\n            _ => panic!(\"Expected Query\"),\n        }\n    }", "test": "fn parse_offset() {\n    let expect = Some(Offset {\n        value: Expr::Value(number(\"2\")),\n        rows: OffsetRows::Rows,\n    });\n    let ast = verified_query(\"SELECT foo FROM bar OFFSET 2 ROWS\");\n    assert_eq!(ast.offset, expect);\n    let ast = verified_query(\"SELECT foo FROM bar WHERE foo = 4 OFFSET 2 ROWS\");\n    assert_eq!(ast.offset, expect);\n    let ast = verified_query(\"SELECT foo FROM bar ORDER BY baz OFFSET 2 ROWS\");\n    assert_eq!(ast.offset, expect);\n    let ast = verified_query(\"SELECT foo FROM bar WHERE foo = 4 ORDER BY baz OFFSET 2 ROWS\");\n    assert_eq!(ast.offset, expect);\n    let ast = verified_query(\"SELECT foo FROM (SELECT * FROM bar OFFSET 2 ROWS) OFFSET 2 ROWS\");\n    assert_eq!(ast.offset, expect);\n    match *ast.body {\n        SetExpr::Select(s) => match only(s.from).relation {\n            TableFactor::Derived { subquery, .. } => {\n                assert_eq!(subquery.offset, expect);\n            }\n            _ => panic!(\"Test broke\"),\n        },\n        _ => panic!(\"Test broke\"),\n    }\n    let ast = verified_query(\"SELECT 'foo' OFFSET 0 ROWS\");\n    assert_eq!(\n        ast.offset,\n        Some(Offset {\n            value: Expr::Value(number(\"0\")),\n            rows: OffsetRows::Rows,\n        })\n    );\n    let ast = verified_query(\"SELECT 'foo' OFFSET 1 ROW\");\n    assert_eq!(\n        ast.offset,\n        Some(Offset {\n            value: Expr::Value(number(\"1\")),\n            rows: OffsetRows::Row,\n        })\n    );\n    let ast = verified_query(\"SELECT 'foo' OFFSET 1\");\n    assert_eq!(\n        ast.offset,\n        Some(Offset {\n            value: Expr::Value(number(\"1\")),\n            rows: OffsetRows::None,\n        })\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_mv.rs::test_mv_rename_dir", "code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_rename_dir() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir1 = \"test_mv_rename_dir\";\n    let dir2 = \"test_mv_rename_dir2\";\n\n    at.mkdir(dir1);\n\n    ucmd.arg(dir1).arg(dir2).succeeds().no_stderr();\n\n    assert!(at.dir_exists(dir2));\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/dotenv.rs::path_flag_overwrites_no_load", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn path_flag_overwrites_no_load() {\n  Test::new()\n    .justfile(\n      \"\n      set dotenv-load := false\n\n      foo:\n        @echo $NAME\n    \",\n    )\n    .tree(tree! {\n      subdir: {\n        \".env\": \"NAME=bar\"\n      }\n    })\n    .args([\"--dotenv-path\", \"subdir/.env\"])\n    .stdout(\"bar\\n\")\n    .status(EXIT_SUCCESS)\n    .run();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_join.rs::new_line_separated", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn new_line_separated() {\n    new_ucmd!()\n        .arg(\"-\")\n        .arg(\"fields_2.txt\")\n        .arg(\"-t\")\n        .arg(\"\")\n        .pipe_in(\"1 a\\n1 b\\n8 h\\n\")\n        .succeeds()\n        .stdout_only(\"1 a\\n8 h\\n\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_expand.rs::test_comma_with_plus_3", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_comma_with_plus_3() {\n    new_ucmd!()\n        .args(&[\"--tabs=2,+5\"])\n        .pipe_in(\"a\\tb\\tc\")\n        .succeeds()\n        //          01234567890\n        .stdout_is(\"a b    c\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_transfer_leader.rs::test_transfer_leader_msg_index", "code": "pub fn recv_timeout<S, I>(s: &mut S, dur: std::time::Duration) -> Result<Option<I>, ()>\nwhere\n    S: Stream<Item = I> + Unpin,\n{\n    poll_timeout(&mut s.next(), dur)\n}", "test": "fn test_transfer_leader_msg_index() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.cfg.raft_store.raft_entry_cache_life_time = ReadableDuration::secs(1000);\n    prevent_from_gc_raft_log(&mut cluster);\n    run_cluster_for_test_warmup_entry_cache(&mut cluster);\n\n    let (sx, rx) = channel::unbounded();\n    let recv_filter = Box::new(\n        RegionPacketFilter::new(1, 2)\n            .direction(Direction::Recv)\n            .msg_type(MessageType::MsgTransferLeader)\n            .set_msg_callback(Arc::new(move |m| {\n                sx.send(m.get_message().get_index()).unwrap();\n            })),\n    );\n    cluster.sim.wl().add_recv_filter(2, recv_filter);\n\n    // TransferLeaderMsg.index should be equal to the store3's replicated_index.\n    cluster.transfer_leader(1, new_peer(2, 2));\n    let replicated_index = cluster.raft_local_state(1, 3).last_index;\n    assert_eq!(\n        rx.recv_timeout(Duration::from_secs(2)).unwrap(),\n        replicated_index,\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_mkdir.rs::test_mkdir_dup_dir", "code": "pub fn fails(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.failure();\n        cmd_result\n    }", "test": "fn test_mkdir_dup_dir() {\n    let _guard = TEST_MUTEX.lock();\n\n    let scene = TestScenario::new(util_name!());\n    let test_dir = \"test_dir\";\n\n    scene.ucmd().arg(test_dir).succeeds();\n    scene.ucmd().arg(test_dir).fails();\n}"}
{"test_id": "rust-bitcoin-rust-bitcoin/rust-bitcoin-rust-bitcoin-5ee33ea/bitcoin/tests/serde.rs::serde_regression_private_key", "code": "pub fn serialize(&self) -> Vec<u8> {\n        let mut buf: Vec<u8> = Vec::new();\n\n        //  <magic>\n        buf.extend_from_slice(b\"psbt\");\n\n        buf.push(0xff_u8);\n\n        buf.extend(self.serialize_map());\n\n        for i in &self.inputs {\n            buf.extend(i.serialize_map());\n        }\n\n        for i in &self.outputs {\n            buf.extend(i.serialize_map());\n        }\n\n        buf\n    }", "test": "fn serde_regression_private_key() {\n    let sk = PrivateKey::from_wif(\"cVt4o7BGAig1UXywgGSmARhxMdzP5qvQsxKkSsc1XEkw3tDTQFpy\").unwrap();\n    let got = serialize(&sk).unwrap();\n    let want = include_bytes!(\"data/serde/private_key_bincode\") as &[_];\n    assert_eq!(got, want)\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_cmd_epoch_checker.rs::test_propose_before_transfer_leader", "code": "pub fn get_engine(&self, node_id: u64) -> WrapFactory<EK> {\n        WrapFactory::new(\n            self.pd_client.clone(),\n            self.raft_engines[&node_id].clone(),\n            self.tablet_registries[&node_id].clone(),\n        )\n    }", "test": "fn test_propose_before_transfer_leader() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.pd_client.disable_default_operator();\n    cluster.run();\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    cluster.must_put(b\"k\", b\"v\");\n\n    let force_delay_propose_batch_raft_command_fp = \"force_delay_propose_batch_raft_command\";\n    fail::cfg(force_delay_propose_batch_raft_command_fp, \"return\").unwrap();\n\n    let write_req = make_write_req(&mut cluster, b\"k1\");\n    let (cb, mut cb_receivers) = make_cb(&write_req);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(1, write_req, cb)\n        .unwrap();\n    // Proposed cb is called.\n    cb_receivers.assert_proposed_ok();\n\n    cluster.must_transfer_leader(1, new_peer(2, 2));\n\n    // Write request should succeed.\n    cb_receivers.assert_applied_ok();\n    must_get_equal(&cluster.get_engine(2), b\"k1\", b\"v\");\n}"}
{"test_id": "serde-rs-json/serde-rs-json-66f862f/tests/test.rs::test_parse_trailing_whitespace", "code": "fn test_parse_ok<T>(tests: Vec<(&str, T)>)\nwhere\n    T: Clone + Debug + PartialEq + ser::Serialize + de::DeserializeOwned,\n{\n    for (s, value) in tests {\n        let v: T = from_str(s).unwrap();\n        assert_eq!(v, value.clone());\n\n        let v: T = from_slice(s.as_bytes()).unwrap();\n        assert_eq!(v, value.clone());\n\n        // Make sure we can deserialize into a `Value`.\n        let json_value: Value = from_str(s).unwrap();\n        assert_eq!(json_value, to_value(&value).unwrap());\n\n        // Make sure we can deserialize from a `&Value`.\n        let v = T::deserialize(&json_value).unwrap();\n        assert_eq!(v, value);\n\n        // Make sure we can deserialize from a `Value`.\n        let v: T = from_value(json_value.clone()).unwrap();\n        assert_eq!(v, value);\n\n        // Make sure we can round trip back to `Value`.\n        let json_value2: Value = from_value(json_value.clone()).unwrap();\n        assert_eq!(json_value2, json_value);\n\n        // Make sure we can fully ignore.\n        let twoline = s.to_owned() + \"\\n3735928559\";\n        let mut de = Deserializer::from_str(&twoline);\n        IgnoredAny::deserialize(&mut de).unwrap();\n        assert_eq!(0xDEAD_BEEF, u64::deserialize(&mut de).unwrap());\n\n        // Make sure every prefix is an EOF error, except that a prefix of a\n        // number may be a valid number.\n        if !json_value.is_number() {\n            for (i, _) in s.trim_end().char_indices() {\n                assert!(from_str::<Value>(&s[..i]).unwrap_err().is_eof());\n                assert!(from_str::<IgnoredAny>(&s[..i]).unwrap_err().is_eof());\n            }\n        }\n    }\n}", "test": "fn test_parse_trailing_whitespace() {\n    test_parse_ok(vec![\n        (\"[1, 2] \", vec![1u64, 2]),\n        (\"[1, 2]\\n\", vec![1, 2]),\n        (\"[1, 2]\\t\", vec![1, 2]),\n        (\"[1, 2]\\t \\n\", vec![1, 2]),\n    ]);\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/attributes.rs::multiple_attributes_one_line", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn multiple_attributes_one_line() {\n  Test::new()\n    .justfile(\n      \"\n      [macos, windows,linux]\n      [no-exit-message]\n      foo:\n        exit 1\n    \",\n    )\n    .stderr(\"exit 1\\n\")\n    .status(1)\n    .run();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cp.rs::test_cp_sparse_always_non_empty", "code": "pub fn read_bytes(&self, name: &str) -> Vec<u8> {\n        let mut f = self.open(name);\n        let mut contents = Vec::new();\n        f.read_to_end(&mut contents)\n            .unwrap_or_else(|e| panic!(\"Couldn't read {name}: {e}\"));\n        contents\n    }", "test": "fn test_cp_sparse_always_non_empty() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    const BUFFER_SIZE: usize = 4096 * 16 + 3;\n    let mut buf: [u8; BUFFER_SIZE] = [0; BUFFER_SIZE];\n    let blocks_to_touch = [buf.len() / 3, 2 * (buf.len() / 3)];\n\n    for i in blocks_to_touch {\n        buf[i] = b'x';\n    }\n\n    at.make_file(\"src_file1\");\n    at.write_bytes(\"src_file1\", &buf);\n\n    ucmd.args(&[\"--sparse=always\", \"src_file1\", \"dst_file_sparse\"])\n        .succeeds();\n\n    let touched_block_count =\n        blocks_to_touch.len() as u64 * at.metadata(\"dst_file_sparse\").blksize() / 512;\n\n    assert_eq!(at.read_bytes(\"dst_file_sparse\"), buf);\n    assert_eq!(at.metadata(\"dst_file_sparse\").blocks(), touched_block_count);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_install.rs::test_install_backup_long_no_args_file_to_dir", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_backup_long_no_args_file_to_dir() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file = \"test_install_simple_backup_file_a\";\n    let dest_dir = \"test_install_dest/\";\n    let expect = format!(\"{dest_dir}{file}\");\n\n    at.touch(file);\n    at.mkdir(dest_dir);\n    at.touch(&expect);\n    scene\n        .ucmd()\n        .arg(\"--backup\")\n        .arg(file)\n        .arg(dest_dir)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n    assert!(at.file_exists(&expect));\n    assert!(at.file_exists(format!(\"{expect}~\")));\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_pd_client_legacy.rs::test_slow_periodical_update", "code": "pub fn join(&self, meta: &SstMeta) -> Result<ImportPath> {\n        let file_name = sst_meta_to_path(meta)?;\n        self.get_import_path(file_name.to_str().unwrap())\n    }", "test": "fn test_slow_periodical_update() {\n    let pd_client_reconnect_fp = \"pd_client_reconnect\";\n    let server = MockServer::new(1);\n    let eps = server.bind_addrs();\n\n    let mut cfg = new_config(eps);\n    let env = Arc::new(EnvBuilder::new().cq_count(1).build());\n    let mgr = Arc::new(SecurityManager::new(&SecurityConfig::default()).unwrap());\n\n    // client1 updates leader frequently (100ms).\n    cfg.update_interval = ReadableDuration(Duration::from_millis(100));\n    let _client1 = RpcClient::new(&cfg, Some(env.clone()), mgr.clone()).unwrap();\n\n    // client2 never updates leader in the test.\n    cfg.update_interval = ReadableDuration(Duration::from_secs(100));\n    let client2 = RpcClient::new(&cfg, Some(env), mgr).unwrap();\n\n    fail::cfg(pd_client_reconnect_fp, \"pause\").unwrap();\n    // Wait for the PD client thread blocking on the fail point.\n    // The GLOBAL_RECONNECT_INTERVAL is 0.1s so sleeps 0.2s here.\n    thread::sleep(Duration::from_millis(200));\n\n    let (tx, rx) = mpsc::channel();\n    let handle = thread::spawn(move || {\n        client2.alloc_id().unwrap();\n        tx.send(()).unwrap();\n    });\n\n    let timeout = Duration::from_millis(500);\n    if rx.recv_timeout(timeout).is_err() {\n        panic!(\"pd client2 is blocked\");\n    }\n\n    // Clean up the fail point.\n    fail::remove(pd_client_reconnect_fp);\n    handle.join().unwrap();\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/engine_traits_tests/src/iterator.rs::iter_reverse_engine", "code": "fn iterator(&self, cf: &str) -> Result<Self::Iterator> {\n        self.iterator_opt(cf, IterOptions::default())\n    }", "test": "fn iter_reverse_engine() {\n    let db = default_engine();\n    iter_reverse(&db.engine, |e| e.iterator(CF_DEFAULT).unwrap());\n}"}
{"test_id": "Keats-tera/Keats-tera-1f95878/src/parser/tests/whitespace.rs::handle_ws_both_sides_for_forloop_tag_and_remove_empty_node", "code": "pub fn remove_whitespace(nodes: Vec<Node>, body_ws: Option<WS>) -> Vec<Node> {\n    let mut res = Vec::with_capacity(nodes.len());\n\n    // Whether the node we just added to res is a Text node\n    let mut previous_was_text = false;\n    // Whether the previous block ended wth `-%}` and we need to trim left the next text node\n    let mut trim_left_next = body_ws.map_or(false, |ws| ws.left);\n\n    for n in nodes {\n        match n {\n            Node::Text(s) => {\n                previous_was_text = true;\n\n                if !trim_left_next {\n                    res.push(Node::Text(s));\n                    continue;\n                }\n                trim_left_next = false;\n\n                let new_val = s.trim_start();\n                if !new_val.is_empty() {\n                    res.push(Node::Text(new_val.to_string()));\n                }\n                // empty text nodes will be skipped\n                continue;\n            }\n            Node::VariableBlock(ws, _)\n            | Node::ImportMacro(ws, _, _)\n            | Node::Extends(ws, _)\n            | Node::Include(ws, _, _)\n            | Node::Set(ws, _)\n            | Node::Break(ws)\n            | Node::Comment(ws, _)\n            | Node::Continue(ws) => {\n                trim_right_previous!(previous_was_text && ws.left, res);\n                trim_left_next = ws.right;\n            }\n            Node::Raw(start_ws, ref s, end_ws) => {\n                trim_right_previous!(previous_was_text && start_ws.left, res);\n                previous_was_text = false;\n                trim_left_next = end_ws.right;\n\n                if start_ws.right || end_ws.left {\n                    let val = if start_ws.right && end_ws.left {\n                        s.trim()\n                    } else if start_ws.right {\n                        s.trim_start()\n                    } else {\n                        s.trim_end()\n                    };\n\n                    res.push(Node::Raw(start_ws, val.to_string(), end_ws));\n                    continue;\n                }\n            }\n            // Those nodes have a body surrounded by 2 tags\n            Node::Forloop(start_ws, _, end_ws)\n            | Node::MacroDefinition(start_ws, _, end_ws)\n            | Node::FilterSection(start_ws, _, end_ws)\n            | Node::Block(start_ws, _, end_ws) => {\n                trim_right_previous!(previous_was_text && start_ws.left, res);\n                previous_was_text = false;\n                trim_left_next = end_ws.right;\n\n                // let's remove ws from the bodies now and append the cleaned up node\n                let body_ws = WS { left: start_ws.right, right: end_ws.left };\n                match n {\n                    Node::Forloop(_, mut forloop, _) => {\n                        forloop.body = remove_whitespace(forloop.body, Some(body_ws));\n                        res.push(Node::Forloop(start_ws, forloop, end_ws));\n                    }\n                    Node::MacroDefinition(_, mut macro_def, _) => {\n                        macro_def.body = remove_whitespace(macro_def.body, Some(body_ws));\n                        res.push(Node::MacroDefinition(start_ws, macro_def, end_ws));\n                    }\n                    Node::FilterSection(_, mut filter_section, _) => {\n                        filter_section.body = remove_whitespace(filter_section.body, Some(body_ws));\n                        res.push(Node::FilterSection(start_ws, filter_section, end_ws));\n                    }\n                    Node::Block(_, mut block, _) => {\n                        block.body = remove_whitespace(block.body, Some(body_ws));\n                        res.push(Node::Block(start_ws, block, end_ws));\n                    }\n                    _ => unreachable!(),\n                };\n                continue;\n            }\n            // The ugly one\n            Node::If(If { conditions, otherwise }, end_ws) => {\n                trim_left_next = end_ws.right;\n                let mut new_conditions: Vec<(_, _, Vec<_>)> = Vec::with_capacity(conditions.len());\n\n                for mut condition in conditions {\n                    if condition.0.left {\n                        // We need to trim the text node before the if tag\n                        if new_conditions.is_empty() && previous_was_text {\n                            trim_right_previous!(res);\n                        } else if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                            trim_right_previous!(body);\n                        }\n                    }\n\n                    // we can't peek at the next one to know whether we need to trim right since\n                    // are consuming conditions. We'll find out at the next iteration.\n                    condition.2 = remove_whitespace(\n                        condition.2,\n                        Some(WS { left: condition.0.right, right: false }),\n                    );\n                    new_conditions.push(condition);\n                }\n\n                previous_was_text = false;\n\n                // We now need to look for the last potential `{%-` bit for if/elif\n\n                // That can be a `{%- else`\n                if let Some((else_ws, body)) = otherwise {\n                    if else_ws.left {\n                        if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                            trim_right_previous!(body);\n                        }\n                    }\n                    let mut else_body =\n                        remove_whitespace(body, Some(WS { left: else_ws.right, right: false }));\n                    // if we have an `else`, the `endif` will affect the else node so we need to check\n                    if end_ws.left {\n                        trim_right_previous!(else_body);\n                    }\n                    res.push(Node::If(\n                        If { conditions: new_conditions, otherwise: Some((else_ws, else_body)) },\n                        end_ws,\n                    ));\n                    continue;\n                }\n\n                // Or `{%- endif`\n                if end_ws.left {\n                    if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                        trim_right_previous!(true, body);\n                    }\n                }\n\n                res.push(Node::If(If { conditions: new_conditions, otherwise }, end_ws));\n                continue;\n            }\n            Node::Super => (),\n        };\n\n        // If we are there, that means it's not a text node and we didn't have to modify the node\n        previous_was_text = false;\n        res.push(n);\n    }\n\n    if let Some(whitespace) = body_ws {\n        trim_right_previous!(whitespace.right, res);\n    }\n\n    res\n}", "test": "fn handle_ws_both_sides_for_forloop_tag_and_remove_empty_node() {\n    let start_ws = WS { left: true, right: true };\n    let end_ws = WS { left: true, right: true };\n    let ast = vec![\n        Node::Forloop(\n            start_ws,\n            Forloop {\n                key: None,\n                value: \"item\".to_string(),\n                container: Expr::new(ExprVal::Int(1)),\n                // not valid but we don't care about it here\n                body: vec![Node::Text(\"   \".to_string()), Node::Text(\"hey   \".to_string())],\n                empty_body: None,\n            },\n            end_ws,\n        ),\n        Node::Text(\"  hey\".to_string()),\n    ];\n\n    assert_eq!(\n        remove_whitespace(ast, None),\n        vec![\n            Node::Forloop(\n                start_ws,\n                Forloop {\n                    key: None,\n                    value: \"item\".to_string(),\n                    container: Expr::new(ExprVal::Int(1)),\n                    // not valid but we don't care about it here\n                    body: vec![Node::Text(\"hey\".to_string())],\n                    empty_body: None,\n                },\n                end_ws,\n            ),\n            Node::Text(\"hey\".to_string()),\n        ]\n    );\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_hive.rs::lateral_view", "code": "pub fn verified_stmt(&self, sql: &str) -> Statement {\n        self.one_statement_parses_to(sql, sql)\n    }", "test": "fn lateral_view() {\n    let view = \"SELECT a FROM db.table LATERAL VIEW explode(a) t AS j, P LATERAL VIEW OUTER explode(a) t AS a, b WHERE a = 1\";\n    hive().verified_stmt(view);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_chgrp.rs::test_1", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_1() {\n    if getegid() != 0 {\n        new_ucmd!().arg(\"bin\").arg(DIR).fails().stderr_contains(\n            // linux fails with \"Operation not permitted (os error 1)\"\n            // because of insufficient permissions,\n            // android fails with \"Permission denied (os error 13)\"\n            // because it can't resolve /proc (even though it can resolve /proc/self/)\n            \"chgrp: changing group of '/dev': \",\n        );\n    }\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-parse-float/tests/stackvec_tests.rs::very_large_mul_test", "code": "pub fn vec_from_u32<const SIZE: usize>(x: &[u32]) -> StackVec<SIZE> {\n    let mut vec = StackVec::<SIZE>::new();\n    #[cfg(not(all(target_pointer_width = \"64\", not(target_arch = \"sparc\"))))]\n    {\n        for &xi in x {\n            vec.try_push(xi as Limb).unwrap();\n        }\n    }\n\n    #[cfg(all(target_pointer_width = \"64\", not(target_arch = \"sparc\")))]\n    {\n        for xi in x.chunks(2) {\n            match xi.len() {\n                1 => vec.try_push(xi[0] as Limb).unwrap(),\n                2 => {\n                    let xi0 = xi[0] as Limb;\n                    let xi1 = xi[1] as Limb;\n                    vec.try_push((xi1 << 32) | xi0).unwrap()\n                },\n                _ => unreachable!(),\n            }\n        }\n    }\n\n    vec\n}", "test": "fn very_large_mul_test() {\n    // Test cases triggered to that would normally use `karatsuba_mul`.\n    // Karatsuba multiplication was ripped out, however, these are useful\n    // test cases.\n    let mut x: VecType = vec_from_u32(&[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]);\n    let y: VecType = vec_from_u32(&[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]);\n    bigint::large_mul(&mut x, &y);\n    let expected: VecType = vec_from_u32(&[\n        4, 13, 28, 50, 80, 119, 168, 228, 300, 385, 484, 598, 728, 875, 1040, 1224, 1340, 1435,\n        1508, 1558, 1584, 1585, 1560, 1508, 1428, 1319, 1180, 1010, 808, 573, 304,\n    ]);\n    assert_eq!(&*x, &*expected);\n\n    // Test cases triggered to that would normally use `karatsuba_uneven_mul`.\n    let mut x: VecType = vec_from_u32(&[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]);\n    let y: VecType = vec_from_u32(&[\n        4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n        28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n    ]);\n    bigint::large_mul(&mut x, &y);\n    let expected: VecType = vec_from_u32(&[\n        4, 13, 28, 50, 80, 119, 168, 228, 300, 385, 484, 598, 728, 875, 1040, 1224, 1360, 1496,\n        1632, 1768, 1904, 2040, 2176, 2312, 2448, 2584, 2720, 2856, 2992, 3128, 3264, 3400, 3536,\n        3672, 3770, 3829, 3848, 3826, 3762, 3655, 3504, 3308, 3066, 2777, 2440, 2054, 1618, 1131,\n        592,\n    ]);\n    assert_eq!(&*x, &*expected);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_csplit.rs::test_up_to_no_match4", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_up_to_no_match4() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"/nope/\", \"/4/\"])\n        .fails()\n        .stdout_is(\"141\\n\")\n        .stderr_is(\"csplit: '/nope/': match not found\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"counting splits\")\n        .count();\n    assert_eq!(count, 0);\n\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"/nope/\", \"/4/\", \"-k\"])\n        .fails()\n        .stdout_is(\"141\\n\")\n        .stderr_is(\"csplit: '/nope/': match not found\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"counting splits\")\n        .count();\n    assert_eq!(count, 1);\n    assert_eq!(at.read(\"xx00\"), generate(1, 51));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_pathchk.rs::test_args_parsing", "code": "pub fn no_stdout(&self) -> &Self {\n        assert!(\n            self.stdout.is_empty(),\n            \"Expected stdout to be empty, but it's:\\n{}\",\n            self.stdout_str()\n        );\n        self\n    }", "test": "fn test_args_parsing() {\n    // fail on no args\n    let empty_args: [String; 0] = [];\n    new_ucmd!().args(&empty_args).fails().no_stdout();\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/client_tests.rs::test_timeout_query_udp", "code": "fn test_timeout_query(mut client: AsyncClient, io_loop: Runtime) {\n    let name = Name::from_str(\"www.example.com\").unwrap();\n\n    let err = io_loop\n        .block_on(client.query(name.clone(), DNSClass::IN, RecordType::A))\n        .unwrap_err();\n\n    println!(\"got error: {err:?}\");\n    if let ClientErrorKind::Timeout = err.kind() {\n    } else {\n        panic!(\"expected timeout error\");\n    }\n\n    io_loop\n        .block_on(client.query(name, DNSClass::IN, RecordType::AAAA))\n        .unwrap_err();\n\n    // test that we don't have any thing funky with registering new timeouts, etc...\n    //   it would be cool if we could maintain a different error here, but shutdown is probably ok.\n    //\n    // match err.kind() {\n    //     &ClientErrorKind::Timeout => (),\n    //     e @ _ => assert!(false, format!(\"something else: {}\", e)),\n    // }\n}", "test": "fn test_timeout_query_udp() {\n    let addr: SocketAddr = (\"203.0.113.0\", 53)\n        .to_socket_addrs()\n        .unwrap()\n        .next()\n        .unwrap();\n\n    // TODO: need to add timeout length to SyncClient\n    let client = SyncClient::new(UdpClientConnection::new(addr).unwrap());\n    test_timeout_query(client);\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/control_flow/loops.rs::do_while_post_inc", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn do_while_post_inc() {\n    run_test_actions([TestAction::assert_eq(\n        indoc! {r#\"\n            var i = 0;\n            do {} while(i++ < 10) i;\n        \"#},\n        11,\n    )]);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_mkdir.rs::test_mkdir_dup_file", "code": "pub fn fails(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.failure();\n        cmd_result\n    }", "test": "fn test_mkdir_dup_file() {\n    let _guard = TEST_MUTEX.lock();\n\n    let scene = TestScenario::new(util_name!());\n    let test_file = \"test_file.txt\";\n\n    scene.fixtures.touch(test_file);\n\n    scene.ucmd().arg(test_file).fails();\n\n    // mkdir should fail for a file even if -p is specified.\n    scene.ucmd().arg(\"-p\").arg(test_file).fails();\n}"}
{"test_id": "cberner-redb/cberner-redb-267b473/tests/multimap_tests.rs::iter", "code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn iter() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_multimap_table(U64_TABLE).unwrap();\n        for i in 0..10 {\n            for j in 0..10 {\n                table.insert(&i, &j).unwrap();\n            }\n        }\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_multimap_table(U64_TABLE).unwrap();\n    let mut iter = table.iter().unwrap();\n    for i in 0..10 {\n        let (k, mut values) = iter.next().unwrap().unwrap();\n        assert_eq!(k.value(), i);\n        for j in 0..10 {\n            assert_eq!(values.next().unwrap().unwrap().value(), j);\n        }\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_nl.rs::test_invalid_number_format", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_invalid_number_format() {\n    for arg in [\"-ninvalid\", \"--number-format=invalid\"] {\n        new_ucmd!()\n            .arg(arg)\n            .fails()\n            .stderr_contains(\"invalid value 'invalid'\");\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_shuf.rs::test_shuf_invalid_input_range_three", "code": "pub fn stderr_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stderr_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stderr_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_shuf_invalid_input_range_three() {\n    new_ucmd!()\n        .args(&[\"-i\", \"0-b\"])\n        .fails()\n        .stderr_contains(\"invalid input range: 'b'\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_realpath.rs::test_realpath_trailing_slash", "code": "pub fn stdout_contains<T: AsRef<str>>(&self, cmp: T) -> &Self {\n        assert!(\n            self.stdout_str().contains(cmp.as_ref()),\n            \"'{}' does not contain '{}'\",\n            self.stdout_str(),\n            cmp.as_ref()\n        );\n        self\n    }", "test": "fn test_realpath_trailing_slash() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    at.touch(\"file\");\n    at.mkdir(\"dir\");\n    at.relative_symlink_file(\"file\", \"link_file\");\n    at.relative_symlink_dir(\"dir\", \"link_dir\");\n    at.relative_symlink_dir(\"no_dir\", \"link_no_dir\");\n    scene\n        .ucmd()\n        .arg(\"link_file\")\n        .succeeds()\n        .stdout_contains(format!(\"{}file\\n\", std::path::MAIN_SEPARATOR));\n    scene.ucmd().arg(\"link_file/\").fails().code_is(1);\n    scene\n        .ucmd()\n        .arg(\"link_dir\")\n        .succeeds()\n        .stdout_contains(format!(\"{}dir\\n\", std::path::MAIN_SEPARATOR));\n    scene\n        .ucmd()\n        .arg(\"link_dir/\")\n        .succeeds()\n        .stdout_contains(format!(\"{}dir\\n\", std::path::MAIN_SEPARATOR));\n    scene\n        .ucmd()\n        .arg(\"link_no_dir\")\n        .succeeds()\n        .stdout_contains(format!(\"{}no_dir\\n\", std::path::MAIN_SEPARATOR));\n    scene\n        .ucmd()\n        .arg(\"link_no_dir/\")\n        .succeeds()\n        .stdout_contains(format!(\"{}no_dir\\n\", std::path::MAIN_SEPARATOR));\n    scene\n        .ucmd()\n        .args(&[\"-e\", \"link_file\"])\n        .succeeds()\n        .stdout_contains(format!(\"{}file\\n\", std::path::MAIN_SEPARATOR));\n    scene.ucmd().args(&[\"-e\", \"link_file/\"]).fails().code_is(1);\n    scene\n        .ucmd()\n        .args(&[\"-e\", \"link_dir\"])\n        .succeeds()\n        .stdout_contains(format!(\"{}dir\\n\", std::path::MAIN_SEPARATOR));\n    scene\n        .ucmd()\n        .args(&[\"-e\", \"link_dir/\"])\n        .succeeds()\n        .stdout_contains(format!(\"{}dir\\n\", std::path::MAIN_SEPARATOR));\n    scene.ucmd().args(&[\"-e\", \"link_no_dir\"]).fails().code_is(1);\n    scene\n        .ucmd()\n        .args(&[\"-e\", \"link_no_dir/\"])\n        .fails()\n        .code_is(1);\n    scene\n        .ucmd()\n        .args(&[\"-m\", \"link_file\"])\n        .succeeds()\n        .stdout_contains(format!(\"{}file\\n\", std::path::MAIN_SEPARATOR));\n    scene\n        .ucmd()\n        .args(&[\"-m\", \"link_file/\"])\n        .succeeds()\n        .stdout_contains(format!(\"{}file\\n\", std::path::MAIN_SEPARATOR));\n    scene\n        .ucmd()\n        .args(&[\"-m\", \"link_dir\"])\n        .succeeds()\n        .stdout_contains(format!(\"{}dir\\n\", std::path::MAIN_SEPARATOR));\n    scene\n        .ucmd()\n        .args(&[\"-m\", \"link_dir/\"])\n        .succeeds()\n        .stdout_contains(format!(\"{}dir\\n\", std::path::MAIN_SEPARATOR));\n    scene\n        .ucmd()\n        .args(&[\"-m\", \"link_no_dir\"])\n        .succeeds()\n        .stdout_contains(format!(\"{}no_dir\\n\", std::path::MAIN_SEPARATOR));\n    scene\n        .ucmd()\n        .args(&[\"-m\", \"link_no_dir/\"])\n        .succeeds()\n        .stdout_contains(format!(\"{}no_dir\\n\", std::path::MAIN_SEPARATOR));\n}"}
{"test_id": "casey-just/casey-just-af55be3/tests/slash_operator.rs::default_parenthesized", "code": "pub(crate) fn run(self) -> Output {\n    if let Some(justfile) = &self.justfile {\n      let justfile = unindent(justfile);\n      fs::write(self.justfile_path(), justfile).unwrap();\n    }\n\n    let stdout = if self.unindent_stdout {\n      unindent(&self.stdout)\n    } else {\n      self.stdout\n    };\n    let stderr = unindent(&self.stderr);\n\n    let mut dotenv_path = self.tempdir.path().to_path_buf();\n    dotenv_path.push(\".env\");\n    fs::write(dotenv_path, \"DOTENV_KEY=dotenv-value\").unwrap();\n\n    let mut command = Command::new(executable_path(\"just\"));\n\n    if self.shell {\n      command.args([\"--shell\", \"bash\"]);\n    }\n\n    let mut child = command\n      .args(self.args)\n      .envs(&self.env)\n      .current_dir(self.tempdir.path().join(self.current_dir))\n      .stdin(Stdio::piped())\n      .stdout(Stdio::piped())\n      .stderr(Stdio::piped())\n      .spawn()\n      .expect(\"just invocation failed\");\n\n    {\n      let mut stdin_handle = child.stdin.take().expect(\"failed to unwrap stdin handle\");\n\n      stdin_handle\n        .write_all(self.stdin.as_bytes())\n        .expect(\"failed to write stdin to just process\");\n    }\n\n    let output = child\n      .wait_with_output()\n      .expect(\"failed to wait for just process\");\n\n    fn compare<T: PartialEq + Debug>(name: &str, have: T, want: T) -> bool {\n      let equal = have == want;\n      if !equal {\n        eprintln!(\"Bad {name}: {}\", Comparison::new(&have, &want));\n      }\n      equal\n    }\n\n    let output_stdout = str::from_utf8(&output.stdout).unwrap();\n    let output_stderr = str::from_utf8(&output.stderr).unwrap();\n\n    if let Some(ref stdout_regex) = self.stdout_regex {\n      if !stdout_regex.is_match(output_stdout) {\n        panic!(\"Stdout regex mismatch:\\n{output_stdout:?}\\n!~=\\n/{stdout_regex:?}/\");\n      }\n    }\n\n    if let Some(ref stderr_regex) = self.stderr_regex {\n      if !stderr_regex.is_match(output_stderr) {\n        panic!(\"Stderr regex mismatch:\\n{output_stderr:?}\\n!~=\\n/{stderr_regex:?}/\");\n      }\n    }\n\n    if !compare(\"status\", output.status.code().unwrap(), self.status)\n      | (self.stdout_regex.is_none() && !compare(\"stdout\", output_stdout, &stdout))\n      | (self.stderr_regex.is_none() && !compare(\"stderr\", output_stderr, &stderr))\n    {\n      panic!(\"Output mismatch.\");\n    }\n\n    if self.test_round_trip && self.status == EXIT_SUCCESS {\n      test_round_trip(self.tempdir.path());\n    }\n\n    Output {\n      tempdir: self.tempdir,\n      stdout: output_stdout.into(),\n    }\n  }", "test": "fn default_parenthesized() {\n  Test::new()\n    .justfile(\n      \"\n      foo x=('a' / 'b'):\n        echo {{x}}\n    \",\n    )\n    .stderr(\"echo a/b\\n\")\n    .stdout(\"a/b\\n\")\n    .run();\n}"}
{"test_id": "ron-rs-ron/ron-rs-ron-eafa2b6/tests/123_enum_representation.rs::test_untagged_b_roundtrip", "code": "fn test_roundtrip<T>(value: T)\nwhere\n    T: Serialize + for<'a> Deserialize<'a> + Debug + PartialEq,\n{\n    let s = to_string(&value).expect(\"Failed to serialize\");\n    let actual: Result<T, _> = from_str(&s);\n    assert_eq!(actual, Ok(value));\n}", "test": "fn test_untagged_b_roundtrip() {\n    let v = EnumStructUntagged::VariantB { foo: 1, bar: 2 };\n    test_roundtrip(v);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_logname.rs::test_normal", "code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_normal() {\n    let result = new_ucmd!().run();\n    println!(\"env::var(CI).is_ok() = {}\", env::var(\"CI\").is_ok());\n\n    for (key, value) in env::vars() {\n        println!(\"{key}: {value}\");\n    }\n    if (is_ci() || uucore::os::is_wsl_1()) && result.stderr_str().contains(\"no login name\") {\n        // ToDO: investigate WSL failure\n        // In the CI, some server are failing to return logname.\n        // As seems to be a configuration issue, ignoring it\n        return;\n    }\n\n    result.success();\n    assert!(!result.stdout_str().trim().is_empty());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_wc.rs::test_stdin_line_len_regression", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_stdin_line_len_regression() {\n    new_ucmd!()\n        .args(&[\"-L\"])\n        .pipe_in(\"\\n123456\")\n        .run()\n        .stdout_is(\"6\\n\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/pd/test_rpc_client_legacy.rs::test_retry_sync", "code": "fn test_retry<F: Fn(&RpcClient)>(func: F) {\n    let eps_count = 1;\n    // Retry mocker returns `Err(_)` for most request, here two thirds are `Err(_)`.\n    let retry = Arc::new(Retry::new(3));\n    let server = MockServer::with_case(eps_count, retry);\n    let eps = server.bind_addrs();\n\n    let client = new_client(eps, None);\n\n    for _ in 0..3 {\n        func(&client);\n    }\n}", "test": "fn test_retry_sync() {\n    let sync = |client: &RpcClient| {\n        client.get_store(1).unwrap();\n    };\n    test_retry(sync)\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_nl.rs::test_number_width", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_number_width() {\n    for width in 1..10 {\n        for arg in [format!(\"-w{width}\"), format!(\"--number-width={width}\")] {\n            let spaces = \" \".repeat(width - 1);\n            new_ucmd!()\n                .arg(arg)\n                .pipe_in(\"test\")\n                .succeeds()\n                .stdout_is(format!(\"{spaces}1\\ttest\\n\"));\n        }\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_dd.rs::test_stdin_stdout_skip", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_stdin_stdout_skip() {\n    let input = build_ascii_block(521);\n    let mut output = String::from_utf8(input.clone()).unwrap();\n    let _ = output.drain(..256);\n    new_ucmd!()\n        .args(&[\"status=none\", \"skip=2\", \"ibs=128\"])\n        .pipe_in(input)\n        .run()\n        .no_stderr()\n        .stdout_only(output);\n}"}
{"test_id": "bytecodealliance-wasmtime/bytecodealliance-wasmtime-5fc1252/tests/all/cli_tests.rs::memory_growth_failure", "code": "fn success() -> Self {\n        Self::Success\n    }", "test": "fn memory_growth_failure() -> Result<()> {\n    let output = get_wasmtime_command()?\n        .args(&[\n            \"run\",\n            \"-Wmemory64\",\n            \"-Wtrap-on-grow-failure\",\n            \"tests/all/cli_tests/memory-grow-failure.wat\",\n        ])\n        .output()?;\n    assert!(!output.status.success());\n    let stderr = String::from_utf8_lossy(&output.stderr);\n    assert!(\n        stderr.contains(\"forcing a memory growth failure to be a trap\"),\n        \"bad stderr: {stderr}\"\n    );\n    Ok(())\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_csplit.rs::test_option_elide_empty_file1", "code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_option_elide_empty_file1() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"numbers50.txt\", \"--suppress-matched\", \"-z\", \"/0$/\", \"{*}\"])\n        .succeeds()\n        .stdout_only(\"18\\n27\\n27\\n27\\n27\\n\");\n\n    let count = glob(&at.plus_as_string(\"xx*\"))\n        .expect(\"there should be splits created\")\n        .count();\n    assert_eq!(count, 5);\n    assert_eq!(at.read(\"xx00\"), generate(1, 10));\n    assert_eq!(at.read(\"xx01\"), generate(11, 20));\n    assert_eq!(at.read(\"xx02\"), generate(21, 30));\n    assert_eq!(at.read(\"xx03\"), generate(31, 40));\n    assert_eq!(at.read(\"xx04\"), generate(41, 50));\n}"}
{"test_id": "Keats-tera/Keats-tera-1f95878/src/renderer/tests/errors.rs::error_unknown_index_variable", "code": "pub fn render(&self, template_name: &str, context: &Context) -> Result<String> {\n        let template = self.get_template(template_name)?;\n        let renderer = Renderer::new(template, self, context);\n        renderer.render()\n    }", "test": "fn error_unknown_index_variable() {\n    let mut tera = Tera::default();\n    tera.add_raw_templates(vec![(\"tpl\", \"{{ arr[a] }}\")]).unwrap();\n    let mut context = Context::new();\n    context.insert(\"arr\", &[1, 2, 3]);\n\n    let result = tera.render(\"tpl\", &context);\n\n    assert_eq!(\n        result.unwrap_err().source().unwrap().to_string(),\n        \"Variable arr[a] can not be evaluated because: Variable `a` not found in context while rendering \\'tpl\\'\"\n    );\n}"}
{"test_id": "dtolnay-syn/dtolnay-syn-b1a038c/tests/test_attribute.rs::test_meta_item_name_value", "code": "fn test(input: &str) -> Meta {\n    let attrs = Attribute::parse_outer.parse_str(input).unwrap();\n\n    assert_eq!(attrs.len(), 1);\n    let attr = attrs.into_iter().next().unwrap();\n\n    attr.meta\n}", "test": "fn test_meta_item_name_value() {\n    let meta = test(\"#[foo = 5]\");\n\n    snapshot!(meta, @r###\"\n    Meta::NameValue {\n        path: Path {\n            segments: [\n                PathSegment {\n                    ident: \"foo\",\n                },\n            ],\n        },\n        value: Expr::Lit {\n            lit: 5,\n        },\n    }\n    \"###);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/raftstore/test_witness.rs::test_witness_raftlog_gc_lagged_follower", "code": "pub fn get_raft_msg_or_default<M: protobuf::Message + Default>(\n    engines: &Engines<RocksEngine, RaftTestEngine>,\n    key: &[u8],\n) -> M {\n    engines\n        .kv\n        .get_msg_cf(CF_RAFT, key)\n        .unwrap()\n        .unwrap_or_default()\n}", "test": "fn test_witness_raftlog_gc_lagged_follower() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(100);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.must_put(b\"k0\", b\"v0\");\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1);\n    // nonwitness -> witness\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![true],\n    );\n\n    // make sure raft log gc is triggered\n    std::thread::sleep(Duration::from_millis(200));\n    let mut before_states = HashMap::default();\n    for (&id, engines) in &cluster.engines {\n        let mut state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        before_states.insert(id, state.take_truncated_state());\n    }\n\n    // one follower is down\n    cluster.stop_node(nodes[1]);\n\n    // write some data to make log gap exceeds the gc limit\n    for i in 1..1000 {\n        let (k, v) = (format!(\"k{}\", i), format!(\"v{}\", i));\n        let key = k.as_bytes();\n        let value = v.as_bytes();\n        cluster.must_put(key, value);\n    }\n\n    // the witness truncated index is not advanced\n    for (&id, engines) in &cluster.engines {\n        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        if id == 2 {\n            assert_eq!(\n                state.get_truncated_state().get_index() - before_states[&id].get_index(),\n                0\n            );\n        } else {\n            assert_ne!(\n                900,\n                state.get_truncated_state().get_index() - before_states[&id].get_index()\n            );\n        }\n    }\n\n    // the follower is back online\n    cluster.run_node(nodes[1]).unwrap();\n    cluster.must_put(b\"k00\", b\"v00\");\n    must_get_equal(&cluster.get_engine(nodes[1]), b\"k00\", b\"v00\");\n    // make sure raft log gc is triggered\n    std::thread::sleep(Duration::from_millis(300));\n\n    // the truncated index is advanced now, as all the peers has replicated\n    for (&id, engines) in &cluster.engines {\n        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        assert_ne!(\n            900,\n            state.get_truncated_state().get_index() - before_states[&id].get_index()\n        );\n    }\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/cases/config_extends.rs::extends_should_raise_an_error_for_unresolved_configuration_and_show_verbose", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn extends_should_raise_an_error_for_unresolved_configuration_and_show_verbose() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let rome_json = Path::new(\"biome.json\");\n    fs.insert(\n        rome_json.into(),\n        r#\"{ \"extends\": [\"formatTYPO.json\", \"linter.json\"] }\"#,\n    );\n    let format = Path::new(\"format.json\");\n    fs.insert(\n        format.into(),\n        r#\"{ \"javascript\": { \"formatter\": { \"quoteStyle\": \"single\" } } }\"#,\n    );\n    let lint = Path::new(\"linter.json\");\n    fs.insert(lint.into(), r#\"{ \"linter\": { \"enabled\": false } }\"#);\n\n    let test_file = Path::new(\"test.js\");\n    fs.insert(test_file.into(), r#\"debugger; console.log(\"string\"); \"#);\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"check\"),\n                \"--verbose\",\n                test_file.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"extends_should_raise_an_error_for_unresolved_configuration_and_show_verbose\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/storage/test_storage.rs::test_txn_store_delete", "code": "pub fn get_none(&self, key: &[u8], ts: impl Into<TimeStamp>) {\n        let key = Key::from_raw(key);\n        assert_eq!(\n            self.store.get(self.ctx.clone(), &key, ts.into()).unwrap().0,\n            None\n        );\n    }", "test": "fn test_txn_store_delete() {\n    let store = AssertionStorage::default();\n    store.put_ok(b\"x\", b\"x5-10\", 5, 10);\n    store.delete_ok(b\"x\", 15, 20);\n    store.get_none(b\"x\", 5);\n    store.get_none(b\"x\", 9);\n    store.get_ok(b\"x\", 10, b\"x5-10\");\n    store.get_ok(b\"x\", 19, b\"x5-10\");\n    store.get_none(b\"x\", 20);\n    store.get_none(b\"x\", 21);\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/control_flow/mod.rs::no_cases_switch", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn no_cases_switch() {\n    run_test_actions([TestAction::assert_eq(\n        indoc! {r#\"\n            let a = 10;\n            switch (a) {\n            }\n\n            a;\n        \"#},\n        10,\n    )]);\n}"}
{"test_id": "ron-rs-ron/ron-rs-ron-eafa2b6/tests/123_enum_representation.rs::test_externally_b_roundtrip", "code": "fn test_roundtrip<T>(value: T)\nwhere\n    T: Serialize + for<'a> Deserialize<'a> + Debug + PartialEq,\n{\n    let s = to_string(&value).expect(\"Failed to serialize\");\n    let actual: Result<T, _> = from_str(&s);\n    assert_eq!(actual, Ok(value));\n}", "test": "fn test_externally_b_roundtrip() {\n    let v = EnumStructExternally::VariantB { foo: 1, bar: 2 };\n    test_roundtrip(v);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/coprocessor/test_analyze.rs::test_analyze_index_with_lock", "code": "fn is_empty(&self) -> bool {\n        self.pending_writes.is_empty() && self.unpacked_size == 0\n    }", "test": "fn test_analyze_index_with_lock() {\n    let data = vec![\n        (1, Some(\"name:0\"), 2),\n        (2, Some(\"name:4\"), 3),\n        (4, Some(\"name:3\"), 1),\n        (5, Some(\"name:1\"), 4),\n    ];\n\n    let product = ProductTable::new();\n    for &iso_level in &[IsolationLevel::Si, IsolationLevel::Rc] {\n        let (_, endpoint, _) = init_data_with_commit(&product, &data, false);\n\n        let mut req = new_analyze_index_req(&product, 3, product[\"name\"].index, 4, 32, 0, 1);\n        let mut ctx = Context::default();\n        ctx.set_isolation_level(iso_level);\n        req.set_context(ctx);\n\n        let resp = handle_request(&endpoint, req);\n        match iso_level {\n            IsolationLevel::Si => {\n                assert!(resp.get_data().is_empty(), \"{:?}\", resp);\n                assert!(resp.has_locked(), \"{:?}\", resp);\n            }\n            IsolationLevel::Rc => {\n                let mut analyze_resp = AnalyzeIndexResp::default();\n                analyze_resp.merge_from_bytes(resp.get_data()).unwrap();\n                let hist = analyze_resp.get_hist();\n                assert!(hist.get_buckets().is_empty());\n                assert_eq!(hist.get_ndv(), 0);\n            }\n            IsolationLevel::RcCheckTs => unimplemented!(),\n        }\n    }\n}"}
{"test_id": "wasmerio-wasmer/wasmerio-wasmer-7cb550d/tests/integration/cli/tests/msrv.rs::rust_toolchain_file_is_up_to_date", "code": "fn ensure_file_contents(path: impl AsRef<Path>, contents: impl AsRef<str>) {\n    let path = path.as_ref();\n    let contents = contents.as_ref();\n\n    if let Ok(old_contents) = std::fs::read_to_string(path) {\n        if contents == old_contents {\n            // File is already up to date\n            return;\n        }\n    }\n\n    let display_path = path.strip_prefix(project_root()).unwrap_or(path);\n\n    eprintln!(\"{} was not up-to-date, updating...\", display_path.display());\n\n    if std::env::var(\"CI\").is_ok() {\n        eprintln!(\"Note: run `cargo test` locally and commit the updated files\");\n    }\n\n    if let Some(parent) = path.parent() {\n        let _ = std::fs::create_dir_all(parent);\n    }\n    std::fs::write(&path, contents).unwrap();\n    panic!(\n        \"\\\"{}\\\" was not up to date and has been updated. Please commit the changes and re-run the tests.\",\n        path.strip_prefix(project_root()).unwrap_or(path).display()\n    );\n}", "test": "fn rust_toolchain_file_is_up_to_date() {\n    let pattern = Regex::new(r\"1\\.\\d\\d\").unwrap();\n    let rust_toolchain = project_root().join(\"rust-toolchain\");\n\n    let contents = std::fs::read_to_string(&rust_toolchain).unwrap();\n    let expected = pattern.replace_all(&contents, MSRV.as_str());\n\n    ensure_file_contents(rust_toolchain, expected);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_truncate.rs::test_truncate_bytes_size", "code": "pub fn stderr_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stdout().stderr_is(msg)\n    }", "test": "fn test_truncate_bytes_size() {\n    // TODO: this should succeed without error, uncomment when '--no-create' is fixed\n    // new_ucmd!()\n    //     .args(&[\"--no-create\", \"--size\", \"K\", \"file\"])\n    //     .succeeds();\n    new_ucmd!()\n        .args(&[\"--size\", \"1024R\", \"file\"])\n        .fails()\n        .code_is(1)\n        .stderr_only(\"truncate: Invalid number: '1024R'\\n\");\n    #[cfg(not(target_pointer_width = \"128\"))]\n    new_ucmd!()\n        .args(&[\"--size\", \"1Y\", \"file\"])\n        .fails()\n        .code_is(1)\n        .stderr_only(\"truncate: Invalid number: '1Y': Value too large for defined data type\\n\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_split.rs::test_hex_dynamic_suffix_length", "code": "pub fn succeeds(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.success();\n        cmd_result\n    }", "test": "fn test_hex_dynamic_suffix_length() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    // Split into chunks of one byte each, use hexadecimal digits\n    // instead of letters as file suffixes.\n    //\n    // The input file has (16^2) - 16 + 1 = 241 bytes. This is just\n    // enough to force `split` to dynamically increase the length of\n    // the filename for the very last chunk.\n    //\n    //     x00, x01, x02, ..., xed, xee, xef, xf000\n    //\n    ucmd.args(&[\"-x\", \"-b\", \"1\", \"twohundredfortyonebytes.txt\"])\n        .succeeds();\n    for i in 0..240 {\n        let filename = format!(\"x{i:02x}\");\n        let contents = file_read(&at, &filename);\n        assert_eq!(contents, \"a\");\n    }\n    assert_eq!(file_read(&at, \"xf000\"), \"a\");\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/components/engine_traits_tests/src/write_batch.rs::write_batch_write_twice_1", "code": "fn get_value(&self, key: &[u8]) -> Result<Option<Self::DbVector>> {\n        self.get_value_opt(&ReadOptions::default(), key)\n    }", "test": "fn write_batch_write_twice_1() {\n    let db = default_engine();\n\n    let mut wb = db.engine.write_batch();\n\n    wb.put(b\"a\", b\"aa\").unwrap();\n\n    wb.write().unwrap();\n    wb.write().unwrap();\n\n    assert_eq!(db.engine.get_value(b\"a\").unwrap().unwrap(), b\"aa\");\n\n    let db = multi_batch_write_engine();\n\n    let mut wb = db.engine.write_batch_with_cap(1024);\n\n    for i in 0..123_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"a\", b\"aa\").unwrap();\n\n    wb.write().unwrap();\n    wb.write().unwrap();\n\n    assert_eq!(db.engine.get_value(b\"a\").unwrap().unwrap(), b\"aa\");\n    for i in 0..123_usize {\n        let x = i.to_be_bytes();\n        assert_eq!(db.engine.get_value(&x).unwrap().unwrap(), &x);\n    }\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-util/tests/skip_tests.rs::test_skip_iter_l", "code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn test_skip_iter_l() {\n    // Test iterators that skip single, leading-only digit separators.\n    pub const FORMAT: u128 = NumberFormatBuilder::new()\n        .digit_separator(num::NonZeroU8::new(b'_'))\n        .integer_leading_digit_separator(true)\n        .build();\n    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());\n\n    skip_iter_eq::<{ FORMAT }>(b\"123.45\", b\"123.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e45\", b\"1e45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e\", b\"1e\");\n    skip_iter_eq::<{ FORMAT }>(b\"1\", b\"1\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45\", b\"_45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45\", b\"_.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5\", b\"4_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5\", b\"4__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_\", b\"4_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__\", b\"4__\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_.\", b\"4_.\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__.\", b\"4__.\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_5\", b\"45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__5\", b\"_45__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45_5\", b\".45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45__5\", b\"_.45__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_\", b\"4_5_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__\", b\"4__5__\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_.5\", b\"4_5_.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__.5\", b\"4__5__.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_\", b\"45_\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__\", b\"_45__\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_.56\", b\"45_.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__.56\", b\"_45__.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_\", b\"4_5_\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__\", b\"_4__5__\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_.56\", b\"4_5_.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__.56\", b\"_4__5__.56\");\n}"}
{"test_id": "biomejs-biome/biomejs-biome-af24597/crates/biome_cli/tests/commands/check.rs::upgrade_severity", "code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn upgrade_severity() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n    let file_path = Path::new(\"biome.json\");\n    fs.insert(\n        file_path.into(),\n        CONFIG_LINTER_UPGRADE_DIAGNOSTIC.as_bytes(),\n    );\n\n    let file_path = Path::new(\"file.js\");\n    fs.insert(file_path.into(), UPGRADE_SEVERITY_CODE.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"check\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let messages = &console.out_buffer;\n\n    let error_count = messages\n        .iter()\n        .filter(|m| m.level == LogLevel::Error)\n        .filter(|m| {\n            let content = format!(\"{:?}\", m.content);\n            content.contains(\"style/noNegationElse\")\n        })\n        .count();\n\n    assert_eq!(\n        error_count, 1,\n        \"expected 1 error-level message in console buffer, found {error_count:?}:\\n{:?}\",\n        console.out_buffer\n    );\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"upgrade_severity\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_async_fetch.rs::test_node_async_fetch_remove_peer", "code": "pub fn get_engine(&self, node_id: u64) -> WrapFactory<EK> {\n        WrapFactory::new(\n            self.pd_client.clone(),\n            self.raft_engines[&node_id].clone(),\n            self.tablet_registries[&node_id].clone(),\n        )\n    }", "test": "fn test_node_async_fetch_remove_peer() {\n    let count = 5;\n    let mut cluster = new_node_cluster(0, count);\n    cluster.pd_client.disable_default_operator();\n\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(100000);\n    cluster.cfg.raft_store.raft_log_gc_threshold = 50;\n    cluster.cfg.raft_store.raft_log_gc_size_limit = Some(ReadableSize::mb(20));\n    cluster.cfg.raft_store.raft_log_gc_tick_interval = ReadableDuration::millis(100);\n    cluster.cfg.raft_store.raft_log_reserve_max_ticks = 2;\n    cluster.cfg.raft_store.raft_entry_cache_life_time = ReadableDuration::millis(100);\n    cluster.run();\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n\n    // cause log lag and trigger async fetch\n    cluster.stop_node(5);\n    for i in 1..60 {\n        let k = i.to_string().into_bytes();\n        let v = k.clone();\n        cluster.must_put(&k, &v);\n    }\n    fail::cfg(\"worker_async_fetch_raft_log\", \"pause\").unwrap();\n    cluster.run_node(5).unwrap();\n\n    // make sure destroy_peer and on_entries_fetched are called in one batch.\n    cluster.must_transfer_leader(1, new_peer(2, 2));\n    fail::cfg(\"worker_gc_raft_log\", \"pause\").unwrap();\n    cluster.pd_client.must_remove_peer(1, new_peer(1, 1));\n    fail::cfg(\"pause_on_peer_collect_message\", \"pause\").unwrap();\n    fail::remove(\"worker_gc_raft_log\");\n    sleep_ms(10);\n    fail::remove(\"worker_async_fetch_raft_log\");\n    sleep_ms(10);\n    fail::remove(\"pause_on_peer_collect_message\");\n\n    cluster.pd_client.must_add_peer(1, new_peer(1, 1));\n\n    // logs should be replicated to node 1 successfully.\n    for i in 1..60 {\n        let k = i.to_string().into_bytes();\n        let v = k.clone();\n        must_get_equal(&cluster.get_engine(1), &k, &v);\n    }\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_common.rs::parse_grant", "code": "pub fn assert_eq_vec<T: ToString>(expected: &[&str], actual: &[T]) {\n    assert_eq!(\n        expected,\n        actual.iter().map(ToString::to_string).collect::<Vec<_>>()\n    );\n}", "test": "fn parse_grant() {\n    let sql = \"GRANT SELECT, INSERT, UPDATE (shape, size), USAGE, DELETE, TRUNCATE, REFERENCES, TRIGGER, CONNECT, CREATE, EXECUTE, TEMPORARY ON abc, def TO xyz, m WITH GRANT OPTION GRANTED BY jj\";\n    match verified_stmt(sql) {\n        Statement::Grant {\n            privileges,\n            objects,\n            grantees,\n            with_grant_option,\n            granted_by,\n            ..\n        } => match (privileges, objects) {\n            (Privileges::Actions(actions), GrantObjects::Tables(objects)) => {\n                assert_eq!(\n                    vec![\n                        Action::Select { columns: None },\n                        Action::Insert { columns: None },\n                        Action::Update {\n                            columns: Some(vec![\n                                Ident {\n                                    value: \"shape\".into(),\n                                    quote_style: None,\n                                },\n                                Ident {\n                                    value: \"size\".into(),\n                                    quote_style: None,\n                                },\n                            ])\n                        },\n                        Action::Usage,\n                        Action::Delete,\n                        Action::Truncate,\n                        Action::References { columns: None },\n                        Action::Trigger,\n                        Action::Connect,\n                        Action::Create,\n                        Action::Execute,\n                        Action::Temporary,\n                    ],\n                    actions\n                );\n                assert_eq_vec(&[\"abc\", \"def\"], &objects);\n                assert_eq_vec(&[\"xyz\", \"m\"], &grantees);\n                assert!(with_grant_option);\n                assert_eq!(\"jj\", granted_by.unwrap().to_string());\n            }\n            _ => unreachable!(),\n        },\n        _ => unreachable!(),\n    }\n\n    let sql2 = \"GRANT INSERT ON ALL TABLES IN SCHEMA public TO browser\";\n    match verified_stmt(sql2) {\n        Statement::Grant {\n            privileges,\n            objects,\n            grantees,\n            with_grant_option,\n            ..\n        } => match (privileges, objects) {\n            (Privileges::Actions(actions), GrantObjects::AllTablesInSchema { schemas }) => {\n                assert_eq!(vec![Action::Insert { columns: None }], actions);\n                assert_eq_vec(&[\"public\"], &schemas);\n                assert_eq_vec(&[\"browser\"], &grantees);\n                assert!(!with_grant_option);\n            }\n            _ => unreachable!(),\n        },\n        _ => unreachable!(),\n    }\n\n    let sql3 = \"GRANT USAGE, SELECT ON SEQUENCE p TO u\";\n    match verified_stmt(sql3) {\n        Statement::Grant {\n            privileges,\n            objects,\n            grantees,\n            granted_by,\n            ..\n        } => match (privileges, objects, granted_by) {\n            (Privileges::Actions(actions), GrantObjects::Sequences(objects), None) => {\n                assert_eq!(\n                    vec![Action::Usage, Action::Select { columns: None }],\n                    actions\n                );\n                assert_eq_vec(&[\"p\"], &objects);\n                assert_eq_vec(&[\"u\"], &grantees);\n            }\n            _ => unreachable!(),\n        },\n        _ => unreachable!(),\n    }\n\n    let sql4 = \"GRANT ALL PRIVILEGES ON aa, b TO z\";\n    match verified_stmt(sql4) {\n        Statement::Grant { privileges, .. } => {\n            assert_eq!(\n                Privileges::All {\n                    with_privileges_keyword: true\n                },\n                privileges\n            );\n        }\n        _ => unreachable!(),\n    }\n\n    let sql5 = \"GRANT ALL ON SCHEMA aa, b TO z\";\n    match verified_stmt(sql5) {\n        Statement::Grant {\n            privileges,\n            objects,\n            ..\n        } => match (privileges, objects) {\n            (\n                Privileges::All {\n                    with_privileges_keyword,\n                },\n                GrantObjects::Schemas(schemas),\n            ) => {\n                assert!(!with_privileges_keyword);\n                assert_eq_vec(&[\"aa\", \"b\"], &schemas);\n            }\n            _ => unreachable!(),\n        },\n        _ => unreachable!(),\n    }\n\n    let sql6 = \"GRANT USAGE ON ALL SEQUENCES IN SCHEMA bus TO a, beta WITH GRANT OPTION\";\n    match verified_stmt(sql6) {\n        Statement::Grant {\n            privileges,\n            objects,\n            ..\n        } => match (privileges, objects) {\n            (Privileges::Actions(actions), GrantObjects::AllSequencesInSchema { schemas }) => {\n                assert_eq!(vec![Action::Usage], actions);\n                assert_eq_vec(&[\"bus\"], &schemas);\n            }\n            _ => unreachable!(),\n        },\n        _ => unreachable!(),\n    }\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cat.rs::test_stdin_show_ends", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn test_stdin_show_ends() {\n    for same_param in [\"-E\", \"--show-ends\", \"--show-e\"] {\n        new_ucmd!()\n            .args(&[same_param, \"-\"])\n            .pipe_in(\"\\t\\0\\n\\t\")\n            .succeeds()\n            .stdout_only(\"\\t\\0$\\n\\t\");\n    }\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/control_flow/mod.rs::single_case_switch", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn single_case_switch() {\n    run_test_actions([TestAction::assert_eq(\n        indoc! {r#\"\n            let a = 10;\n            switch (a) {\n                case 10:\n                    a = 20;\n                    break;\n            }\n\n            a;\n        \"#},\n        20,\n    )]);\n}"}
{"test_id": "rustls-rustls/rustls-rustls-ae583bd/rustls/tests/api.rs::client_complete_io_for_handshake_eof", "code": "pub fn is_handshaking(&self) -> bool {\n        !(self.may_send_application_data && self.may_receive_application_data)\n    }", "test": "fn client_complete_io_for_handshake_eof() {\n    let (mut client, _) = make_pair(KeyType::Rsa);\n    let mut input = io::Cursor::new(Vec::new());\n\n    assert!(client.is_handshaking());\n    let err = client\n        .complete_io(&mut input)\n        .unwrap_err();\n    assert_eq!(io::ErrorKind::UnexpectedEof, err.kind());\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_test.rs::test_file_is_not_symlink", "code": "pub fn succeeds(&mut self) -> CmdResult {\n        let cmd_result = self.run();\n        cmd_result.success();\n        cmd_result\n    }", "test": "fn test_file_is_not_symlink() {\n    let scenario = TestScenario::new(util_name!());\n\n    scenario\n        .ucmd()\n        .args(&[\"!\", \"-h\", \"regular_file\"])\n        .succeeds();\n    scenario\n        .ucmd()\n        .args(&[\"!\", \"-L\", \"regular_file\"])\n        .succeeds();\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_postgres.rs::parse_create_table_with_inherit", "code": "pub fn verified_stmt(&self, sql: &str) -> Statement {\n        self.one_statement_parses_to(sql, sql)\n    }", "test": "fn parse_create_table_with_inherit() {\n    let sql = \"\\\n               CREATE TABLE bazaar.settings (\\\n               settings_id UUID PRIMARY KEY DEFAULT uuid_generate_v4() NOT NULL, \\\n               user_id UUID UNIQUE, \\\n               value TEXT[], \\\n               use_metric BOOLEAN DEFAULT true\\\n               )\";\n    pg().verified_stmt(sql);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_printf.rs::escaped_newline", "code": "pub fn stdout_only<T: AsRef<str>>(&self, msg: T) -> &Self {\n        self.no_stderr().stdout_is(msg)\n    }", "test": "fn escaped_newline() {\n    new_ucmd!()\n        .args(&[\"hello\\\\n world\"])\n        .succeeds()\n        .stdout_only(\"hello\\n world\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_sort.rs::test_human_numeric_whitespace", "code": "fn test_helper(file_name: &str, term: &str) {\n    new_ucmd!()\n        .env(\"TERM\", term)\n        .arg(\"-c\")\n        .arg(format!(\"{file_name}.txt\"))\n        .run()\n        .stdout_is_fixture(format!(\"{file_name}.csh.expected\"));\n\n    new_ucmd!()\n        .env(\"TERM\", term)\n        .arg(\"-b\")\n        .arg(format!(\"{file_name}.txt\"))\n        .run()\n        .stdout_is_fixture(format!(\"{file_name}.sh.expected\"));\n}", "test": "fn test_human_numeric_whitespace() {\n    test_helper(\n        \"human-numeric-whitespace\",\n        &[\"-h\", \"--human-numeric-sort\", \"--sort=human-numeric\"],\n    );\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_gc_metrics.rs::test_txn_create_compaction_filter", "code": "fn get(&self, _: &[u8]) -> Option<&[u8]> {\n        None\n    }", "test": "fn test_txn_create_compaction_filter() {\n    GC_COMPACTION_FILTER_PERFORM.reset();\n    GC_COMPACTION_FILTER_SKIP.reset();\n\n    let mut cfg = DbConfig::default();\n    cfg.writecf.disable_auto_compactions = true;\n    cfg.writecf.dynamic_level_bytes = false;\n    let dir = tempfile::TempDir::new().unwrap();\n    let builder = TestEngineBuilder::new().path(dir.path());\n    let mut engine = builder.build_with_cfg(&cfg).unwrap();\n    let raw_engine = engine.get_rocksdb();\n\n    let mut gc_runner = TestGcRunner::new(0);\n    let value = vec![b'v'; 512];\n\n    must_prewrite_put(&mut engine, b\"zkey\", &value, b\"zkey\", 100);\n    must_commit(&mut engine, b\"zkey\", 100, 110);\n\n    gc_runner\n        .safe_point(TimeStamp::new(1).into_inner())\n        .gc(&raw_engine);\n    assert_eq!(\n        GC_COMPACTION_FILTER_PERFORM\n            .with_label_values(&[STAT_TXN_KEYMODE])\n            .get(),\n        1\n    );\n    assert_eq!(\n        GC_COMPACTION_FILTER_SKIP\n            .with_label_values(&[STAT_TXN_KEYMODE])\n            .get(),\n        1\n    );\n\n    GC_COMPACTION_FILTER_PERFORM.reset();\n    GC_COMPACTION_FILTER_SKIP.reset();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_od.rs::test_multiple_formats", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_multiple_formats() {\n    let input = \"abcdefghijklmnopqrstuvwxyz\\n\"; // spell-checker:disable-line\n    new_ucmd!()\n        .arg(\"-c\")\n        .arg(\"-b\")\n        .run_piped_stdin(input.as_bytes())\n        .success()\n        .no_stderr()\n        .stdout_is(unindent(\n            \"\n            0000000   a   b   c   d   e   f   g   h   i   j   k   l   m   n   o   p\n                    141 142 143 144 145 146 147 150 151 152 153 154 155 156 157 160\n            0000020   q   r   s   t   u   v   w   x   y   z  \\\\n\n                    161 162 163 164 165 166 167 170 171 172 012\n            0000033\n            \",\n        ));\n}"}
{"test_id": "cberner-redb/cberner-redb-267b473/tests/integration_tests.rs::regression18", "code": "fn drop(&mut self) {\n            let data = mem::take(&mut self.data);\n            assert!(self\n                .buffer\n                .lock()\n                .unwrap()\n                .insert(self.page, Arc::new(data))\n                .is_none());\n        }", "test": "fn regression18() {\n    let tmpfile = create_tempfile();\n\n    let db = Database::builder().create(tmpfile.path()).unwrap();\n\n    let table_def: TableDefinition<u64, &[u8]> = TableDefinition::new(\"x\");\n\n    let tx = db.begin_write().unwrap();\n    let savepoint0 = tx.ephemeral_savepoint().unwrap();\n    {\n        let mut t = tx.open_table(table_def).unwrap();\n        let mut value = t.insert_reserve(&118749, 817).unwrap();\n        value.as_mut().fill(0xFF);\n    }\n    tx.commit().unwrap();\n\n    let tx = db.begin_write().unwrap();\n    let savepoint1 = tx.ephemeral_savepoint().unwrap();\n    {\n        let mut t = tx.open_table(table_def).unwrap();\n        let mut value = t.insert_reserve(&65373, 1807).unwrap();\n        value.as_mut().fill(0xFF);\n    }\n    tx.commit().unwrap();\n\n    let mut tx = db.begin_write().unwrap();\n    let savepoint2 = tx.ephemeral_savepoint().unwrap();\n\n    tx.restore_savepoint(&savepoint2).unwrap();\n    tx.commit().unwrap();\n\n    drop(savepoint0);\n\n    let tx = db.begin_write().unwrap();\n    {\n        let mut t = tx.open_table(table_def).unwrap();\n        let mut value = t.insert_reserve(&118749, 2494).unwrap();\n        value.as_mut().fill(0xFF);\n    }\n    tx.commit().unwrap();\n\n    let tx = db.begin_write().unwrap();\n    let savepoint4 = tx.ephemeral_savepoint().unwrap();\n    tx.abort().unwrap();\n    drop(savepoint1);\n\n    let tx = db.begin_write().unwrap();\n    {\n        let mut t = tx.open_table(table_def).unwrap();\n        let mut value = t.insert_reserve(&429469, 667).unwrap();\n        value.as_mut().fill(0xFF);\n        drop(value);\n        let mut value = t.insert_reserve(&266845, 1614).unwrap();\n        value.as_mut().fill(0xFF);\n    }\n    tx.commit().unwrap();\n\n    let mut tx = db.begin_write().unwrap();\n    tx.restore_savepoint(&savepoint4).unwrap();\n    tx.commit().unwrap();\n\n    drop(savepoint2);\n    drop(savepoint4);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/integrations/storage/test_storage.rs::test_txn_store_get_with_type_lock", "code": "pub fn get_ok(&self, key: &[u8], ts: impl Into<TimeStamp>, expect: &[u8]) {\n        let key = Key::from_raw(key);\n        assert_eq!(\n            self.store\n                .get(self.ctx.clone(), &key, ts.into())\n                .unwrap()\n                .0\n                .unwrap(),\n            expect\n        );\n    }", "test": "fn test_txn_store_get_with_type_lock() {\n    let store = AssertionStorage::default();\n    store.put_ok(b\"k1\", b\"v1\", 1, 2);\n    store.prewrite_ok(vec![Mutation::make_lock(Key::from_raw(b\"k1\"))], b\"k1\", 5);\n    store.get_ok(b\"k1\", 20, b\"v1\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_dircolors.rs::test_keywords", "code": "fn test_helper(file_name: &str, term: &str) {\n    new_ucmd!()\n        .env(\"TERM\", term)\n        .arg(\"-c\")\n        .arg(format!(\"{file_name}.txt\"))\n        .run()\n        .stdout_is_fixture(format!(\"{file_name}.csh.expected\"));\n\n    new_ucmd!()\n        .env(\"TERM\", term)\n        .arg(\"-b\")\n        .arg(format!(\"{file_name}.txt\"))\n        .run()\n        .stdout_is_fixture(format!(\"{file_name}.sh.expected\"));\n}", "test": "fn test_keywords() {\n    test_helper(\"keywords\", \"\");\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_unlink.rs::test_unlink_symlink", "code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_unlink_symlink() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    at.touch(\"foo\");\n    at.symlink_file(\"foo\", \"bar\");\n\n    ucmd.arg(\"bar\").succeeds().no_stderr();\n\n    assert!(at.file_exists(\"foo\"));\n    assert!(!at.file_exists(\"bar\"));\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_expand.rs::test_ignore_initial_pluses", "code": "pub fn stdout_is<T: AsRef<str>>(&self, msg: T) -> &Self {\n        assert_eq!(self.stdout_str(), String::from(msg.as_ref()));\n        self\n    }", "test": "fn test_ignore_initial_pluses() {\n    new_ucmd!()\n        .args(&[\"--tabs=++3\"])\n        .pipe_in(\"\\ta\\tb\\tc\")\n        .succeeds()\n        //          01234567890\n        .stdout_is(\"   a  b  c\");\n}"}
{"test_id": "astral-sh-ruff/astral-sh-ruff-1a6898a/crates/ruff_python_ast/tests/visitor.rs::list_comprehension", "code": "fn trace_visitation(source: &str) -> String {\n    let tokens = lex(source, Mode::Module);\n    let parsed = parse_tokens(tokens, source, Mode::Module, \"test.py\").unwrap();\n\n    let mut visitor = RecordVisitor::default();\n    walk_module(&mut visitor, &parsed);\n\n    visitor.output\n}", "test": "fn list_comprehension() {\n    let source = \"[x for x in numbers]\";\n\n    let trace = trace_visitation(source);\n\n    assert_snapshot!(trace);\n}"}
{"test_id": "tikv-tikv/tikv-tikv-8632b39/tests/failpoints/cases/test_hibernate.rs::test_break_leadership_on_restart", "code": "pub fn recv_timeout<S, I>(s: &mut S, dur: std::time::Duration) -> Result<Option<I>, ()>\nwhere\n    S: Stream<Item = I> + Unpin,\n{\n    poll_timeout(&mut s.next(), dur)\n}", "test": "fn test_break_leadership_on_restart() {\n    let mut cluster = new_node_cluster(0, 3);\n    let base_tick_ms = 50;\n    cluster.cfg.raft_store.raft_base_tick_interval = ReadableDuration::millis(base_tick_ms);\n    cluster.cfg.raft_store.raft_heartbeat_ticks = 2;\n    cluster.cfg.raft_store.raft_election_timeout_ticks = 10;\n    // So the random election timeout will always be 10, which makes the case more\n    // stable.\n    cluster.cfg.raft_store.raft_min_election_timeout_ticks = 10;\n    cluster.cfg.raft_store.raft_max_election_timeout_ticks = 11;\n    configure_for_hibernate(&mut cluster.cfg);\n    cluster.pd_client.disable_default_operator();\n    let r = cluster.run_conf_change();\n    cluster.pd_client.must_add_peer(r, new_peer(2, 2));\n    cluster.pd_client.must_add_peer(r, new_peer(3, 3));\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(2), b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n\n    // Wait until all peers of region 1 hibernate and then stop peer 2.\n    thread::sleep(Duration::from_millis(base_tick_ms * 30));\n    cluster.stop_node(2);\n\n    // Peer 3 will:\n    // 1. steps a heartbeat message from its leader and then ticks 1 time.\n    // 2. ticks a peer_stale_state_check, which will change state from Idle to\n    // PreChaos. 3. continues to tick until it hibernates totally.\n    let (tx, rx) = mpsc::sync_channel(128);\n    fail::cfg_callback(\"on_raft_base_tick_idle\", move || tx.send(0).unwrap()).unwrap();\n    let mut raft_msg = RaftMessage::default();\n    raft_msg.region_id = 1;\n    raft_msg.set_from_peer(new_peer(1, 1));\n    raft_msg.set_to_peer(new_peer(3, 3));\n    raft_msg.mut_region_epoch().version = 1;\n    raft_msg.mut_region_epoch().conf_ver = 3;\n    raft_msg.mut_message().msg_type = MessageType::MsgHeartbeat;\n    raft_msg.mut_message().from = 1;\n    raft_msg.mut_message().to = 3;\n    raft_msg.mut_message().term = 6;\n    let router = cluster.sim.rl().get_router(3).unwrap();\n    router.send_raft_message(raft_msg).unwrap();\n\n    rx.recv_timeout(Duration::from_millis(200)).unwrap();\n    fail::remove(\"on_raft_base_tick_idle\");\n    router\n        .send(1, PeerMsg::Tick(PeerTick::CheckPeerStaleState))\n        .unwrap();\n\n    // Wait until the peer 3 hibernates again.\n    // Until here, peer 3 will be like `election_elapsed=3 && missing_ticks=6`.\n    thread::sleep(Duration::from_millis(base_tick_ms * 10));\n\n    // Restart the peer 2 and it will broadcast `MsgRequestPreVote` later, which\n    // will wake up peer 1 and 3.\n    let (tx, rx) = mpsc::sync_channel(128);\n    let filter = RegionPacketFilter::new(1, 3)\n        .direction(Direction::Send)\n        .msg_type(MessageType::MsgRequestVote)\n        .when(Arc::new(AtomicBool::new(false)))\n        .set_msg_callback(Arc::new(move |m| drop(tx.send(m.clone()))));\n    cluster.add_send_filter(CloneFilterFactory(filter));\n    cluster.run_node(2).unwrap();\n\n    // Peer 3 shouldn't start a new election, otherwise the leader may step down\n    // incorrectly.\n    rx.recv_timeout(Duration::from_secs(2)).unwrap_err();\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_readlink.rs::test_invalid_arg", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_invalid_arg() {\n    new_ucmd!().arg(\"--definitely-invalid\").fails().code_is(1);\n}"}
{"test_id": "tafia-quick-xml/tafia-quick-xml-120e074/tests/issues.rs::issue115", "code": "fn into_owned(self) -> PayloadEvent<'static> {\n        match self {\n            PayloadEvent::Start(e) => PayloadEvent::Start(e.into_owned()),\n            PayloadEvent::End(e) => PayloadEvent::End(e.into_owned()),\n            PayloadEvent::Text(e) => PayloadEvent::Text(e.into_owned()),\n            PayloadEvent::CData(e) => PayloadEvent::CData(e.into_owned()),\n            PayloadEvent::DocType(e) => PayloadEvent::DocType(e.into_owned()),\n            PayloadEvent::Eof => PayloadEvent::Eof,\n        }\n    }", "test": "fn issue115() {\n    let mut r = Reader::from_str(\"<tag1 attr1='line 1\\nline 2'></tag1>\");\n    match r.read_event() {\n        Ok(Event::Start(e)) if e.name() == QName(b\"tag1\") => {\n            let v = e.attributes().map(|a| a.unwrap().value).collect::<Vec<_>>();\n            assert_eq!(v[0].clone().into_owned(), b\"line 1\\nline 2\");\n        }\n        _ => (),\n    }\n}"}
{"test_id": "image-rs-image/image-rs-image-e5580ec/tests/truncate_images.rs::truncate_tga", "code": "fn truncate_images(decoder: &str) {\n    process_images(IMAGE_DIR, Some(decoder), |path| {\n        println!(\"{:?}\", path);\n        let fin = fs::File::open(&path).unwrap();\n        let max_length = 1000;\n        let mut buf = Vec::with_capacity(max_length);\n        fin.take(max_length as u64).read_to_end(&mut buf).unwrap();\n        for i in 0..buf.len() {\n            image::load_from_memory(&buf[..i + 1]).ok();\n        }\n    })\n}", "test": "fn truncate_tga() {\n    truncate_images(\"tga\")\n}"}
{"test_id": "mitsuhiko-minijinja/mitsuhiko-minijinja-5f2c1e8/minijinja-contrib/tests/datetime.rs::test_datetimeformat_chrono", "code": "pub fn eval<S: Serialize>(&self, ctx: S) -> Result<Value, Error> {\n        // reduce total amount of code faling under mono morphization into\n        // this function, and share the rest in _eval.\n        self._eval(Value::from_serializable(&ctx))\n    }", "test": "fn test_datetimeformat_chrono() {\n    let mut env = minijinja::Environment::new();\n    env.add_global(\"TIMEZONE\", \"Europe/Vienna\");\n    env.add_global(\"DATETIME_FORMAT\", \"[hour]:[minute]\");\n    minijinja_contrib::add_to_environment(&mut env);\n\n    let expr = env\n        .compile_expression(\"d|datetimeformat(format=format)\")\n        .unwrap();\n\n    let d = chrono::DateTime::parse_from_rfc3339(\"2023-06-24T16:37:00Z\").unwrap();\n    assert_eq!(\n        expr.eval(context!(d, format => \"short\"))\n            .unwrap()\n            .to_string(),\n        \"2023-06-24 18:37\"\n    );\n}"}
{"test_id": "sqlparser-rs-sqlparser-rs/sqlparser-rs-sqlparser-rs-964aee1/tests/sqlparser_common.rs::parse_start_transaction", "code": "pub fn parse_sql_statements(&self, sql: &str) -> Result<Vec<Statement>, ParserError> {\n        self.one_of_identical_results(|dialect| {\n            let mut tokenizer = Tokenizer::new(dialect, sql);\n            if let Some(options) = &self.options {\n                tokenizer = tokenizer.with_unescape(options.unescape);\n            }\n            let tokens = tokenizer.tokenize()?;\n            self.new_parser(dialect)\n                .with_tokens(tokens)\n                .parse_statements()\n        })\n        // To fail the `ensure_multiple_dialects_are_tested` test:\n        // Parser::parse_sql(&**self.dialects.first().unwrap(), sql)\n    }", "test": "fn parse_start_transaction() {\n    match verified_stmt(\"START TRANSACTION READ ONLY, READ WRITE, ISOLATION LEVEL SERIALIZABLE\") {\n        Statement::StartTransaction { modes, .. } => assert_eq!(\n            modes,\n            vec![\n                TransactionMode::AccessMode(TransactionAccessMode::ReadOnly),\n                TransactionMode::AccessMode(TransactionAccessMode::ReadWrite),\n                TransactionMode::IsolationLevel(TransactionIsolationLevel::Serializable),\n            ]\n        ),\n        _ => unreachable!(),\n    }\n\n    // For historical reasons, PostgreSQL allows the commas between the modes to\n    // be omitted.\n    match one_statement_parses_to(\n        \"START TRANSACTION READ ONLY READ WRITE ISOLATION LEVEL SERIALIZABLE\",\n        \"START TRANSACTION READ ONLY, READ WRITE, ISOLATION LEVEL SERIALIZABLE\",\n    ) {\n        Statement::StartTransaction { modes, .. } => assert_eq!(\n            modes,\n            vec![\n                TransactionMode::AccessMode(TransactionAccessMode::ReadOnly),\n                TransactionMode::AccessMode(TransactionAccessMode::ReadWrite),\n                TransactionMode::IsolationLevel(TransactionIsolationLevel::Serializable),\n            ]\n        ),\n        _ => unreachable!(),\n    }\n\n    verified_stmt(\"START TRANSACTION\");\n    one_statement_parses_to(\"BEGIN\", \"BEGIN TRANSACTION\");\n    one_statement_parses_to(\"BEGIN WORK\", \"BEGIN TRANSACTION\");\n    one_statement_parses_to(\"BEGIN TRANSACTION\", \"BEGIN TRANSACTION\");\n\n    verified_stmt(\"START TRANSACTION ISOLATION LEVEL READ UNCOMMITTED\");\n    verified_stmt(\"START TRANSACTION ISOLATION LEVEL READ COMMITTED\");\n    verified_stmt(\"START TRANSACTION ISOLATION LEVEL REPEATABLE READ\");\n    verified_stmt(\"START TRANSACTION ISOLATION LEVEL SERIALIZABLE\");\n\n    // Regression test for https://github.com/sqlparser-rs/sqlparser-rs/pull/139,\n    // in which START TRANSACTION would fail to parse if followed by a statement\n    // terminator.\n    assert_eq!(\n        parse_sql_statements(\"START TRANSACTION; SELECT 1\"),\n        Ok(vec![\n            verified_stmt(\"START TRANSACTION\"),\n            verified_stmt(\"SELECT 1\"),\n        ])\n    );\n\n    let res = parse_sql_statements(\"START TRANSACTION ISOLATION LEVEL BAD\");\n    assert_eq!(\n        ParserError::ParserError(\"Expected isolation level, found: BAD\".to_string()),\n        res.unwrap_err()\n    );\n\n    let res = parse_sql_statements(\"START TRANSACTION BAD\");\n    assert_eq!(\n        ParserError::ParserError(\"Expected end of statement, found: BAD\".to_string()),\n        res.unwrap_err()\n    );\n\n    let res = parse_sql_statements(\"START TRANSACTION READ ONLY,\");\n    assert_eq!(\n        ParserError::ParserError(\"Expected transaction mode, found: EOF\".to_string()),\n        res.unwrap_err()\n    );\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_mv.rs::test_invalid_arg", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_invalid_arg() {\n    new_ucmd!().arg(\"--definitely-invalid\").fails().code_is(1);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_cat.rs::test_write_to_self", "code": "fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        match self {\n            #[cfg(not(unix))]\n            Self::Stdin(stdin) => stdin.read(buf),\n            Self::File(f) => f.read(buf),\n            #[cfg(unix)]\n            Self::StdinFile(f) => f.read(buf),\n            #[cfg(unix)]\n            Self::Fifo(f) => f.read(buf),\n        }\n    }", "test": "fn test_write_to_self() {\n    let s = TestScenario::new(util_name!());\n    let file_path = s.fixtures.plus(\"first_file\");\n    s.fixtures.write(\"second_file\", \"second_file_content.\");\n\n    let file = OpenOptions::new()\n        .create_new(true)\n        .write(true)\n        .append(true)\n        .open(file_path)\n        .unwrap();\n\n    s.fixtures.append(\"first_file\", \"first_file_content.\");\n\n    s.ucmd()\n        .set_stdout(file)\n        .arg(\"first_file\")\n        .arg(\"first_file\")\n        .arg(\"second_file\")\n        .fails()\n        .code_is(2)\n        .stderr_only(\"cat: first_file: input file is output file\\ncat: first_file: input file is output file\\n\");\n\n    assert_eq!(\n        s.fixtures.read(\"first_file\"),\n        \"first_file_content.second_file_content.\"\n    );\n}"}
{"test_id": "hickory-dns-hickory-dns/hickory-dns-hickory-dns-408d0ba/tests/integration-tests/tests/name_server_pool_tests.rs::test_noerror_doesnt_leak", "code": "fn block_on<F: Future>(&mut self, future: F) -> F::Output {\n        Self::block_on(self, future)\n    }", "test": "fn test_noerror_doesnt_leak() {\n    let query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n\n    let soa_record = soa_record(\n        query.name().clone(),\n        Name::from_str(\"example.com.\").unwrap(),\n    );\n    let udp_message = message(query.clone(), vec![], vec![soa_record], vec![]);\n\n    let incorrect_success_msg = message(\n        query.clone(),\n        vec![v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 2))],\n        vec![],\n        vec![],\n    );\n\n    let udp_nameserver = mock_nameserver_trust_nx(\n        vec![Ok(DnsResponse::from_message(udp_message).unwrap())],\n        Default::default(),\n        true,\n    );\n    // Provide a fake A record; if this nameserver is queried the test should fail.\n    let second_nameserver = mock_nameserver_trust_nx(\n        vec![Ok(DnsResponse::from_message(incorrect_success_msg).unwrap())],\n        Default::default(),\n        true,\n    );\n\n    let mut options = ResolverOpts::default();\n    options.num_concurrent_reqs = 1;\n    options.server_ordering_strategy = ServerOrderingStrategy::UserProvidedOrder;\n    let pool = mock_nameserver_pool(\n        vec![udp_nameserver, second_nameserver],\n        vec![],\n        None,\n        options,\n    );\n\n    // lookup should only hit the first server\n    let request = message(query, vec![], vec![], vec![]);\n    let future = pool.send(request).first_answer();\n\n    match block_on(future).unwrap_err().kind() {\n        ResolveErrorKind::NoRecordsFound {\n            soa,\n            response_code,\n            trusted,\n            ..\n        } => {\n            assert_eq!(response_code, &ResponseCode::NoError);\n            assert!(soa.is_some());\n            assert!(trusted);\n        }\n        x => panic!(\"Expected NoRecordsFound, got {:?}\", x),\n    }\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_engine/src/tests/mod.rs::array_creation_benchmark", "code": "pub(crate) fn run_test_actions(actions: impl IntoIterator<Item = TestAction>) {\n        let context = &mut Context::default();\n        run_test_actions_with(actions, context);\n    }", "test": "fn array_creation_benchmark() {\n    run_test_actions([\n        TestAction::run_harness(),\n        TestAction::assert(indoc! {r#\"\n                const finalArr = [ \"p0\", \"p1\", \"p2\", \"p3\", \"p4\", \"p5\", \"p6\", \"p7\", \"p8\", \"p9\", \"p10\",\n                \"p11\", \"p12\", \"p13\", \"p14\", \"p15\", \"p16\", \"p17\", \"p18\", \"p19\", \"p20\",\n                \"p21\", \"p22\", \"p23\", \"p24\", \"p25\", \"p26\", \"p27\", \"p28\", \"p29\", \"p30\",\n                \"p31\", \"p32\", \"p33\", \"p34\", \"p35\", \"p36\", \"p37\", \"p38\", \"p39\", \"p40\",\n                \"p41\", \"p42\", \"p43\", \"p44\", \"p45\", \"p46\", \"p47\", \"p48\", \"p49\", \"p50\",\n                \"p51\", \"p52\", \"p53\", \"p54\", \"p55\", \"p56\", \"p57\", \"p58\", \"p59\", \"p60\",\n                \"p61\", \"p62\", \"p63\", \"p64\", \"p65\", \"p66\", \"p67\", \"p68\", \"p69\", \"p70\",\n                \"p71\", \"p72\", \"p73\", \"p74\", \"p75\", \"p76\", \"p77\", \"p78\", \"p79\", \"p80\",\n                \"p81\", \"p82\", \"p83\", \"p84\", \"p85\", \"p86\", \"p87\", \"p88\", \"p89\", \"p90\",\n                \"p91\", \"p92\", \"p93\", \"p94\", \"p95\", \"p96\", \"p97\", \"p98\", \"p99\", \"p100\",\n                \"p101\", \"p102\", \"p103\", \"p104\", \"p105\", \"p106\", \"p107\", \"p108\", \"p109\", \"p110\",\n                \"p111\", \"p112\", \"p113\", \"p114\", \"p115\", \"p116\", \"p117\", \"p118\", \"p119\", \"p120\",\n                \"p121\", \"p122\", \"p123\", \"p124\", \"p125\", \"p126\", \"p127\", \"p128\", \"p129\", \"p130\",\n                \"p131\", \"p132\", \"p133\", \"p134\", \"p135\", \"p136\", \"p137\", \"p138\", \"p139\", \"p140\",\n                \"p141\", \"p142\", \"p143\", \"p144\", \"p145\", \"p146\", \"p147\", \"p148\", \"p149\", \"p150\",\n                \"p151\", \"p152\", \"p153\", \"p154\", \"p155\", \"p156\", \"p157\", \"p158\", \"p159\", \"p160\",\n                \"p161\", \"p162\", \"p163\", \"p164\", \"p165\", \"p166\", \"p167\", \"p168\", \"p169\", \"p170\",\n                \"p171\", \"p172\", \"p173\", \"p174\", \"p175\", \"p176\", \"p177\", \"p178\", \"p179\", \"p180\",\n                \"p181\", \"p182\", \"p183\", \"p184\", \"p185\", \"p186\", \"p187\", \"p188\", \"p189\", \"p190\",\n                \"p191\", \"p192\", \"p193\", \"p194\", \"p195\", \"p196\", \"p197\", \"p198\", \"p199\", \"p200\",\n                \"p201\", \"p202\", \"p203\", \"p204\", \"p205\", \"p206\", \"p207\", \"p208\", \"p209\", \"p210\",\n                \"p211\", \"p212\", \"p213\", \"p214\", \"p215\", \"p216\", \"p217\", \"p218\", \"p219\", \"p220\",\n                \"p221\", \"p222\", \"p223\", \"p224\", \"p225\", \"p226\", \"p227\", \"p228\", \"p229\", \"p230\",\n                \"p231\", \"p232\", \"p233\", \"p234\", \"p235\", \"p236\", \"p237\", \"p238\", \"p239\", \"p240\",\n                \"p241\", \"p242\", \"p243\", \"p244\", \"p245\", \"p246\", \"p247\", \"p248\", \"p249\", \"p250\",\n                \"p251\", \"p252\", \"p253\", \"p254\", \"p255\", \"p256\", \"p257\", \"p258\", \"p259\", \"p260\",\n                \"p261\", \"p262\", \"p263\", \"p264\", \"p265\", \"p266\", \"p267\", \"p268\", \"p269\", \"p270\",\n                \"p271\", \"p272\", \"p273\", \"p274\", \"p275\", \"p276\", \"p277\", \"p278\", \"p279\", \"p280\",\n                \"p281\", \"p282\", \"p283\", \"p284\", \"p285\", \"p286\", \"p287\", \"p288\", \"p289\", \"p290\",\n                \"p291\", \"p292\", \"p293\", \"p294\", \"p295\", \"p296\", \"p297\", \"p298\", \"p299\", \"p300\",\n                \"p301\", \"p302\", \"p303\", \"p304\", \"p305\", \"p306\", \"p307\", \"p308\", \"p309\", \"p310\",\n                \"p311\", \"p312\", \"p313\", \"p314\", \"p315\", \"p316\", \"p317\", \"p318\", \"p319\", \"p320\",\n                \"p321\", \"p322\", \"p323\", \"p324\", \"p325\", \"p326\", \"p327\", \"p328\", \"p329\", \"p330\",\n                \"p331\", \"p332\", \"p333\", \"p334\", \"p335\", \"p336\", \"p337\", \"p338\", \"p339\", \"p340\",\n                \"p341\", \"p342\", \"p343\", \"p344\", \"p345\", \"p346\", \"p347\", \"p348\", \"p349\", \"p350\",\n                \"p351\", \"p352\", \"p353\", \"p354\", \"p355\", \"p356\", \"p357\", \"p358\", \"p359\", \"p360\",\n                \"p361\", \"p362\", \"p363\", \"p364\", \"p365\", \"p366\", \"p367\", \"p368\", \"p369\", \"p370\",\n                \"p371\", \"p372\", \"p373\", \"p374\", \"p375\", \"p376\", \"p377\", \"p378\", \"p379\", \"p380\",\n                \"p381\", \"p382\", \"p383\", \"p384\", \"p385\", \"p386\", \"p387\", \"p388\", \"p389\", \"p390\",\n                \"p391\", \"p392\", \"p393\", \"p394\", \"p395\", \"p396\", \"p397\", \"p398\", \"p399\", \"p400\",\n                \"p401\", \"p402\", \"p403\", \"p404\", \"p405\", \"p406\", \"p407\", \"p408\", \"p409\", \"p410\",\n                \"p411\", \"p412\", \"p413\", \"p414\", \"p415\", \"p416\", \"p417\", \"p418\", \"p419\", \"p420\",\n                \"p421\", \"p422\", \"p423\", \"p424\", \"p425\", \"p426\", \"p427\", \"p428\", \"p429\", \"p430\",\n                \"p431\", \"p432\", \"p433\", \"p434\", \"p435\", \"p436\", \"p437\", \"p438\", \"p439\", \"p440\",\n                \"p441\", \"p442\", \"p443\", \"p444\", \"p445\", \"p446\", \"p447\", \"p448\", \"p449\", \"p450\",\n                \"p451\", \"p452\", \"p453\", \"p454\", \"p455\", \"p456\", \"p457\", \"p458\", \"p459\", \"p460\",\n                \"p461\", \"p462\", \"p463\", \"p464\", \"p465\", \"p466\", \"p467\", \"p468\", \"p469\", \"p470\",\n                \"p471\", \"p472\", \"p473\", \"p474\", \"p475\", \"p476\", \"p477\", \"p478\", \"p479\", \"p480\",\n                \"p481\", \"p482\", \"p483\", \"p484\", \"p485\", \"p486\", \"p487\", \"p488\", \"p489\", \"p490\",\n                \"p491\", \"p492\", \"p493\", \"p494\", \"p495\", \"p496\", \"p497\", \"p498\", \"p499\", \"p500\" ];\n\n                let testArr = [];\n                for (let a = 0; a <= 500; a++) {\n                    testArr[a] = ('p' + a);\n                }\n\n                arrayEquals(testArr, finalArr)\n            \"#}),\n    ]);\n}"}
{"test_id": "uutils-coreutils/uutils-coreutils-73b7c46/tests/by-util/test_fold.rs::test_invalid_arg", "code": "pub fn code_is(&self, expected_code: i32) -> &Self {\n        assert_eq!(self.code(), expected_code);\n        self\n    }", "test": "fn test_invalid_arg() {\n    new_ucmd!().arg(\"--definitely-invalid\").fails().code_is(1);\n}"}
{"test_id": "Alexhuszagh-rust-lexical/Alexhuszagh-rust-lexical-933e2cc/lexical-write-integer/tests/api_tests.rs::u8_pow2_test", "code": "pub fn roundtrip<F>(float: F, buffer: &mut [u8]) -> Result<(), String>\nwhere\n    F: RawFloat + ToLexical + std::str::FromStr + std::string::ToString,\n{\n    let bytes = float.to_lexical(buffer);\n    let string = unsafe { std::str::from_utf8_unchecked(bytes) };\n    let roundtrip = string.parse::<F>().map_err(|_| float.to_string())?;\n    let is_equal = if float.is_nan() {\n        roundtrip.is_nan()\n    } else {\n        float == roundtrip\n    };\n    if !is_equal {\n        return Err(float.to_string());\n    }\n    Ok(())\n}", "test": "fn u8_pow2_test() {\n    let values: &[u8] =\n        &[0, 1, 2, 3, 4, 5, 7, 8, 9, 15, 16, 17, 31, 32, 33, 63, 64, 65, 127, 128, 129, 255];\n    for &i in values.iter() {\n        assert_eq!(i, roundtrip(i));\n    }\n}"}
{"test_id": "boa-dev-boa/boa-dev-boa-6008683/boa_parser/src/parser/tests/format/statement.rs::r#if", "code": "fn test_formatting(source: &'static str) {\n    // Remove preceding newline.\n\n    use crate::{Parser, Source};\n    use boa_interner::{Interner, ToInternedString};\n    let source = &source[1..];\n\n    // Find out how much the code is indented\n    let first_line = &source[..source.find('\\n').unwrap()];\n    let trimmed_first_line = first_line.trim();\n    let characters_to_remove = first_line.len() - trimmed_first_line.len();\n\n    let scenario = source\n        .lines()\n        .map(|l| &l[characters_to_remove..]) // Remove preceding whitespace from each line\n        .collect::<Vec<&'static str>>()\n        .join(\"\\n\");\n    let source = Source::from_bytes(source);\n    let interner = &mut Interner::default();\n    let result = Parser::new(source)\n        .parse_script(interner)\n        .expect(\"parsing failed\")\n        .to_interned_string(interner);\n    if scenario != result {\n        eprint!(\"========= Expected:\\n{scenario}\");\n        eprint!(\"========= Got:\\n{result}\");\n        // Might be helpful to find differing whitespace\n        eprintln!(\"========= Expected: {scenario:?}\");\n        eprintln!(\"========= Got:      {result:?}\");\n        panic!(\"parsing test did not give the correct result (see above)\");\n    }\n}", "test": "fn r#if() {\n    test_formatting(\n        r#\"\n        let a = true ? 5 : 6;\n        if (false) {\n            a = 10;\n        } else {\n            a = 20;\n        }\n        \"#,\n    );\n}"}
